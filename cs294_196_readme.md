## Setup Gepa
Please check [README](./README.md)

## How to run evolution for caching

```bash
$ python src/gepa/adapters/caching_adapter/example.py
```
You can set the LLM model to use in `MODEL`, and the number of iterations in `MAX_ITERATIONS` in [example.py](src/gepa/adapters/caching_adapter/example.py).

## Results
Check [data/](./data/) for 3 runs with gemini-3-pro and gpt-5.