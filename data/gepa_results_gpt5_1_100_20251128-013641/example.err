2025-11-27 17:56:12,961 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
m_key_timestamp = dict()

def evict(cache_snapshot, obj):
    '''
    This function defines how the algorithm chooses the eviction victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The new object that needs to be inserted into the cache.
    - Return:
        - `candid_obj_key`: The key of the cached object that will be evicted to make room for `obj`.
    '''
    candid_obj_key = None
    min_ts = min(m_key_timestamp.values())
    candid_obj_keys = list(key for key in cache_snapshot.cache if m_key_timestamp[key] == min_ts)
    candid_obj_key = candid_obj_keys[0]
    return candid_obj_key

def update_after_hit(cache_snapshot, obj):
    '''
    This function defines how the algorithm update the metadata it maintains immediately after a cache hit.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object accessed during the cache hit.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key in m_key_timestamp
    m_key_timestamp[obj.key] = cache_snapshot.access_count

def update_after_insert(cache_snapshot, obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object that was just inserted into the cache.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key not in m_key_timestamp
    m_key_timestamp[obj.key] = cache_snapshot.access_count

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    This function defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
    - Args:
        - `cache_snapshot`: A snapshot of the current cache state.
        - `obj`: The object to be inserted into the cache.
        - `evicted_obj`: The object that was just evicted from the cache.
    - Return: `None`
    '''
    global m_key_timestamp
    assert obj.key not in m_key_timestamp
    assert evicted_obj.key in m_key_timestamp
    m_key_timestamp.pop(evicted_obj.key)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 43
- Hit Rate: 0.05

Example 2:
- Trace ID: 1
- Hit Rate: 0.418

Example 3:
- Trace ID: 28
- Hit Rate: 0.0201

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m17:56:12 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 17:56:12,972 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m17:57:08 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 17:57:08,923 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 17:57:08,928 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# GreedyDual-Size-Frequency (GDSF) with LRU tie-breaks
# - Size-aware: prefers keeping small or highly reused objects
# - Frequency-aware: repeated hits increase priority
# - Aging (L): prevents cache pollution by old high-priority items

# Metadata
m_key_priority = dict()      # key -> float priority H
m_key_freq = dict()          # key -> int resident frequency (hits while resident; includes first insertion as 1)
m_key_last_access = dict()   # key -> int access_count (for LRU tie-breaks)
m_age_L = 0.0                # global aging value (updated to priority of evicted item)


def _compute_priority(size, freq, age_L):
    # Priority H = L + freq/size
    # - size > 0 by problem statement
    return age_L + (float(freq) / float(size))


def evict(cache_snapshot, obj):
    '''
    Choose the eviction victim as the cached object with the smallest GDSF priority.
    On ties (same priority), evict the least recently used among them.
    '''
    # Defensive defaults in case metadata is missing (cold start or partial metadata)
    global m_key_priority, m_key_last_access, m_age_L

    candid_key = None
    min_prio = None
    lru_time_for_min = None

    for key, cached_obj in cache_snapshot.cache.items():
        prio = m_key_priority.get(key, m_age_L)  # unknown entries treated as lowest-aged
        last = m_key_last_access.get(key, -1)

        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < lru_time_for_min):
            min_prio = prio
            lru_time_for_min = last
            candid_key = key

    # Fallback safety: if for some reason nothing selected, fall back to arbitrary key
    if candid_key is None:
        candid_key = next(iter(cache_snapshot.cache))

    return candid_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit: increase resident frequency and recompute priority using current aging L.
    Also refresh last-access time for LRU tie-breaks.
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_age_L
    # Initialize missing metadata gracefully (robustness)
    if obj.key not in m_key_freq:
        m_key_freq[obj.key] = 1
    else:
        m_key_freq[obj.key] += 1

    m_key_last_access[obj.key] = cache_snapshot.access_count
    m_key_priority[obj.key] = _compute_priority(obj.size, m_key_freq[obj.key], m_age_L)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert: initialize resident frequency to 1 and set priority H = L + 1/size.
    Also record last-access time.
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_age_L
    m_key_freq[obj.key] = 1
    m_key_last_access[obj.key] = cache_snapshot.access_count
    m_key_priority[obj.key] = _compute_priority(obj.size, m_key_freq[obj.key], m_age_L)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
    - Age the system by setting L to the evicted object's priority (classic GreedyDual aging).
    - Remove all metadata for the evicted key.
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_age_L

    # Capture evicted priority before deleting (default to current L if missing)
    evicted_key = evicted_obj.key
    evicted_prio = m_key_priority.get(evicted_key, m_age_L)

    # Age update: raise L to the evicted item's priority
    m_age_L = evicted_prio

    # Cleanup metadata for evicted item
    m_key_priority.pop(evicted_key, None)
    m_key_freq.pop(evicted_key, None)
    m_key_last_access.pop(evicted_key, None)
```
2025-11-27 17:59:36,815 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# GreedyDual-Size-Frequency (GDSF) with LRU tie-breaks
# - Size-aware: prefers keeping small or highly reused objects
# - Frequency-aware: repeated hits increase priority
# - Aging (L): prevents cache pollution by old high-priority items

# Metadata
m_key_priority = dict()      # key -> float priority H
m_key_freq = dict()          # key -> int resident frequency (hits while resident; includes first insertion as 1)
m_key_last_access = dict()   # key -> int access_count (for LRU tie-breaks)
m_age_L = 0.0                # global aging value (updated to priority of evicted item)


def _compute_priority(size, freq, age_L):
    # Priority H = L + freq/size
    # - size > 0 by problem statement
    return age_L + (float(freq) / float(size))


def evict(cache_snapshot, obj):
    '''
    Choose the eviction victim as the cached object with the smallest GDSF priority.
    On ties (same priority), evict the least recently used among them.
    '''
    # Defensive defaults in case metadata is missing (cold start or partial metadata)
    global m_key_priority, m_key_last_access, m_age_L

    candid_key = None
    min_prio = None
    lru_time_for_min = None

    for key, cached_obj in cache_snapshot.cache.items():
        prio = m_key_priority.get(key, m_age_L)  # unknown entries treated as lowest-aged
        last = m_key_last_access.get(key, -1)

        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < lru_time_for_min):
            min_prio = prio
            lru_time_for_min = last
            candid_key = key

    # Fallback safety: if for some reason nothing selected, fall back to arbitrary key
    if candid_key is None:
        candid_key = next(iter(cache_snapshot.cache))

    return candid_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit: increase resident frequency and recompute priority using current aging L.
    Also refresh last-access time for LRU tie-breaks.
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_age_L
    # Initialize missing metadata gracefully (robustness)
    if obj.key not in m_key_freq:
        m_key_freq[obj.key] = 1
    else:
        m_key_freq[obj.key] += 1

    m_key_last_access[obj.key] = cache_snapshot.access_count
    m_key_priority[obj.key] = _compute_priority(obj.size, m_key_freq[obj.key], m_age_L)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert: initialize resident frequency to 1 and set priority H = L + 1/size.
    Also record last-access time.
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_age_L
    m_key_freq[obj.key] = 1
    m_key_last_access[obj.key] = cache_snapshot.access_count
    m_key_priority[obj.key] = _compute_priority(obj.size, m_key_freq[obj.key], m_age_L)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
    - Age the system by setting L to the evicted object's priority (classic GreedyDual aging).
    - Remove all metadata for the evicted key.
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_age_L

    # Capture evicted priority before deleting (default to current L if missing)
    evicted_key = evicted_obj.key
    evicted_prio = m_key_priority.get(evicted_key, m_age_L)

    # Age update: raise L to the evicted item's priority
    m_age_L = evicted_prio

    # Cleanup metadata for evicted item
    m_key_priority.pop(evicted_key, None)
    m_key_freq.pop(evicted_key, None)
    m_key_last_access.pop(evicted_key, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 14
- Hit Rate: 0.0197

Example 2:
- Trace ID: 36
- Hit Rate: 0.0092

Example 3:
- Trace ID: 12
- Hit Rate: 0.0239

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m17:59:36 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 17:59:36,816 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m18:02:22 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 18:02:22,794 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 18:02:22,796 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Segmented GreedyDual-Size-Frequency (SGDSF) with ARC-style adaptive split
# - Two resident segments by bytes:
#     P (probation): admits all new objects; mostly recency-driven
#     S (protected): holds objects that hit at least once; more frequency-driven
# - Within each segment, eviction is GreedyDual-Size-Frequency:
#     H = L_seg + freq/size, with L_seg aged to the evicted item's priority
# - Adaptive split between P and S using ARC-like ghost lists:
#     On insert of a key found in P-ghost (recency ghost) => increase probation share
#     On insert of a key found in S-ghost (frequency ghost) => increase protected share
# - LRU tie-breaks within the chosen segment
#
# This design protects repeatedly-used items (S) from one-hit-wonders (P),
# is size-aware, ages priorities to combat stale items, and adapts online
# between recency- and frequency-friendly behavior.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_priority = dict()      # key -> float priority H
m_key_freq = dict()          # key -> int (resident frequency, incremented on hits)
m_key_last_access = dict()   # key -> int access_count (for LRU tie-breaks)
m_key_segment = dict()       # key -> 'P' (probation) or 'S' (protected)

# Segment ages (for GreedyDual aging)
m_age_P = 0.0
m_age_S = 0.0

# Current resident bytes per segment
m_bytes_P = 0
m_bytes_S = 0

# Adaptive target for protected bytes (S); probation target = capacity - target_S
m_target_S_bytes = None

# Ghost lists (non-resident metadata) to adapt split; store key -> (size, last_time)
m_ghost_P = dict()
m_ghost_S = dict()
m_ghost_P_bytes = 0
m_ghost_S_bytes = 0

# Ghost size limit (in bytes) per list; lazily set to capacity
m_ghost_limit_bytes = None


# -----------------------------
# Helpers
# -----------------------------

def _compute_priority(size, freq, age_L):
    # Priority H = L + freq/size
    return age_L + (float(freq) / float(size))


def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_S_bytes, m_ghost_limit_bytes
    if m_target_S_bytes is None:
        # Start with 50% protected, 50% probation by bytes; will adapt online
        m_target_S_bytes = cache_snapshot.capacity * 0.5
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cache_snapshot.capacity


def _pick_min_in_segment(cache_snapshot, seg_tag):
    # Returns (key, prio, last_time) of the minimum-priority key in a segment
    global m_key_priority, m_key_last_access, m_key_segment, m_age_P, m_age_S

    min_key = None
    min_prio = None
    min_time = None

    # Default age if priority missing (rare): use segment age so missing ones compare fairly
    default_age = m_age_P if seg_tag == 'P' else m_age_S

    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        prio = m_key_priority.get(key, default_age)
        last = m_key_last_access.get(key, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_prio = prio
            min_time = last
            min_key = key

    return (min_key, min_prio, min_time)


def _ghost_add(ghost_dict, key, size, time_now, is_P):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_P_bytes, m_ghost_S_bytes, m_ghost_limit_bytes

    if is_P:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_P_bytes += size
        else:
            # refresh time; adjust bytes if size changed (unlikely)
            old_size, _ = prev
            m_ghost_P_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_P_bytes > (m_ghost_limit_bytes or 0):
            # evict oldest by time
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_P_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_S_bytes += size
        else:
            old_size, _ = prev
            m_ghost_S_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_S_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_S_bytes -= sz


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    global m_ghost_P, m_ghost_S, m_ghost_P_bytes, m_ghost_S_bytes, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step size proportional to object size (bounded), which is standard in size-aware ARC variants
    step = obj.size

    if obj.key in m_ghost_P:
        # Recent ghost hit: recency pressure -> increase probation share (decrease protected target)
        m_target_S_bytes = _clamp(m_target_S_bytes - step, 0, cap)
        # Remove from ghost_P to avoid repeated adjustments
        sz, _ = m_ghost_P.pop(obj.key)
        m_ghost_P_bytes -= sz
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: frequency pressure -> increase protected share
        m_target_S_bytes = _clamp(m_target_S_bytes + step, 0, cap)
        sz, _ = m_ghost_S.pop(obj.key)
        m_ghost_S_bytes -= sz


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using Segmented GDSF with adaptive split.
    Prefer evicting from the segment exceeding its byte target, else evict the global min H.
    LRU is used as a tie-breaker within each segment.
    '''
    global m_bytes_P, m_bytes_S, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    # Compute segment byte targets
    cap = cache_snapshot.capacity
    target_S = _clamp(m_target_S_bytes, 0, cap)
    target_P = cap - target_S

    # Find min in each segment
    p_key, p_prio, p_lru = _pick_min_in_segment(cache_snapshot, 'P')
    s_key, s_prio, s_lru = _pick_min_in_segment(cache_snapshot, 'S')

    # Decide which segment to evict from
    evict_from_P = False
    evict_from_S = False

    # If a segment is over its byte target, evict from it
    if m_bytes_P > target_P and p_key is not None:
        evict_from_P = True
    elif m_bytes_S > target_S and s_key is not None:
        evict_from_S = True
    else:
        # Neither segment over target; choose the global minimum priority among available candidates
        if p_key is not None and s_key is not None:
            if (p_prio < s_prio) or (p_prio == s_prio and p_lru < s_lru):
                evict_from_P = True
            else:
                evict_from_S = True
        elif p_key is not None:
            evict_from_P = True
        elif s_key is not None:
            evict_from_S = True

    candid_key = None
    if evict_from_P and p_key is not None:
        candid_key = p_key
    elif evict_from_S and s_key is not None:
        candid_key = s_key

    # Fallback: if no segment candidate found (should not happen), fall back to global min over all
    if candid_key is None:
        # Choose the least priority over both segments
        min_key, min_prio, min_time = None, None, None
        for key in cache_snapshot.cache.keys():
            prio = m_key_priority.get(key, 0.0)
            last = m_key_last_access.get(key, -1)
            if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
                min_key, min_prio, min_time = key, prio, last
        candid_key = min_key if min_key is not None else next(iter(cache_snapshot.cache))

    return candid_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment resident frequency
      - If in probation (P), promote to protected (S)
      - Recompute priority using the segment's current age L
      - Refresh last-access time
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_age_P, m_age_S, m_bytes_P, m_bytes_S

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size
    m_key_last_access[k] = cache_snapshot.access_count
    m_key_freq[k] = m_key_freq.get(k, 0) + 1

    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        # Promote on first re-reference to protected segment
        m_key_segment[k] = 'S'
        # Move bytes P -> S (guard against negatives)
        m_bytes_P = max(0, m_bytes_P - sz)
        m_bytes_S += sz
        # Recompute priority in S with S's age
        m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_S)
    else:
        # Already protected: reinforce priority with current S age
        m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_S)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S byte split using ARC-like ghosts
      - Add the new object to probation (P) with freq = 1, priority H = L_P + 1/size
      - Record last access
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_bytes_P

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists (ARC-like)
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    sz = obj.size

    # Initialize metadata (new admit to probation)
    m_key_freq[k] = 1
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_P)

    # Account bytes in probation
    m_bytes_P += sz


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Update the corresponding segment age L to the victim's priority (GreedyDual aging)
      - Remove resident metadata for that key
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_age_P, m_age_S, m_bytes_P, m_bytes_S
    global m_ghost_P, m_ghost_S

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown
    # Use the stored priority or the segment age as a fallback
    evicted_prio = m_key_priority.get(ek, m_age_P if seg == 'P' else m_age_S)

    # Age update for the evicting segment
    if seg == 'S':
        m_age_S = evicted_prio
    else:
        m_age_P = evicted_prio

    # Cleanup resident metadata
    m_key_priority.pop(ek, None)
    m_key_freq.pop(ek, None)
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes
    if seg == 'S':
        m_bytes_S = max(0, m_bytes_S - esz)
        # Add to S ghost
        _ghost_add(m_ghost_S, ek, esz, cache_snapshot.access_count, is_P=False)
    else:
        m_bytes_P = max(0, m_bytes_P - esz)
        # Add to P ghost
        _ghost_add(m_ghost_P, ek, esz, cache_snapshot.access_count, is_P=True)
```
2025-11-27 18:05:14,350 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented GreedyDual-Size-Frequency (SGDSF) with ARC-style adaptive split
# - Two resident segments by bytes:
#     P (probation): admits all new objects; mostly recency-driven
#     S (protected): holds objects that hit at least once; more frequency-driven
# - Within each segment, eviction is GreedyDual-Size-Frequency:
#     H = L_seg + freq/size, with L_seg aged to the evicted item's priority
# - Adaptive split between P and S using ARC-like ghost lists:
#     On insert of a key found in P-ghost (recency ghost) => increase probation share
#     On insert of a key found in S-ghost (frequency ghost) => increase protected share
# - LRU tie-breaks within the chosen segment
#
# This design protects repeatedly-used items (S) from one-hit-wonders (P),
# is size-aware, ages priorities to combat stale items, and adapts online
# between recency- and frequency-friendly behavior.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_priority = dict()      # key -> float priority H
m_key_freq = dict()          # key -> int (resident frequency, incremented on hits)
m_key_last_access = dict()   # key -> int access_count (for LRU tie-breaks)
m_key_segment = dict()       # key -> 'P' (probation) or 'S' (protected)

# Segment ages (for GreedyDual aging)
m_age_P = 0.0
m_age_S = 0.0

# Current resident bytes per segment
m_bytes_P = 0
m_bytes_S = 0

# Adaptive target for protected bytes (S); probation target = capacity - target_S
m_target_S_bytes = None

# Ghost lists (non-resident metadata) to adapt split; store key -> (size, last_time)
m_ghost_P = dict()
m_ghost_S = dict()
m_ghost_P_bytes = 0
m_ghost_S_bytes = 0

# Ghost size limit (in bytes) per list; lazily set to capacity
m_ghost_limit_bytes = None


# -----------------------------
# Helpers
# -----------------------------

def _compute_priority(size, freq, age_L):
    # Priority H = L + freq/size
    return age_L + (float(freq) / float(size))


def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_S_bytes, m_ghost_limit_bytes
    if m_target_S_bytes is None:
        # Start with 50% protected, 50% probation by bytes; will adapt online
        m_target_S_bytes = cache_snapshot.capacity * 0.5
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cache_snapshot.capacity


def _pick_min_in_segment(cache_snapshot, seg_tag):
    # Returns (key, prio, last_time) of the minimum-priority key in a segment
    global m_key_priority, m_key_last_access, m_key_segment, m_age_P, m_age_S

    min_key = None
    min_prio = None
    min_time = None

    # Default age if priority missing (rare): use segment age so missing ones compare fairly
    default_age = m_age_P if seg_tag == 'P' else m_age_S

    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        prio = m_key_priority.get(key, default_age)
        last = m_key_last_access.get(key, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_prio = prio
            min_time = last
            min_key = key

    return (min_key, min_prio, min_time)


def _ghost_add(ghost_dict, key, size, time_now, is_P):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_P_bytes, m_ghost_S_bytes, m_ghost_limit_bytes

    if is_P:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_P_bytes += size
        else:
            # refresh time; adjust bytes if size changed (unlikely)
            old_size, _ = prev
            m_ghost_P_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_P_bytes > (m_ghost_limit_bytes or 0):
            # evict oldest by time
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_P_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_S_bytes += size
        else:
            old_size, _ = prev
            m_ghost_S_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_S_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_S_bytes -= sz


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    global m_ghost_P, m_ghost_S, m_ghost_P_bytes, m_ghost_S_bytes, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step size proportional to object size (bounded), which is standard in size-aware ARC variants
    step = obj.size

    if obj.key in m_ghost_P:
        # Recent ghost hit: recency pressure -> increase probation share (decrease protected target)
        m_target_S_bytes = _clamp(m_target_S_bytes - step, 0, cap)
        # Remove from ghost_P to avoid repeated adjustments
        sz, _ = m_ghost_P.pop(obj.key)
        m_ghost_P_bytes -= sz
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: frequency pressure -> increase protected share
        m_target_S_bytes = _clamp(m_target_S_bytes + step, 0, cap)
        sz, _ = m_ghost_S.pop(obj.key)
        m_ghost_S_bytes -= sz


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using Segmented GDSF with adaptive split.
    Prefer evicting from the segment exceeding its byte target, else evict the global min H.
    LRU is used as a tie-breaker within each segment.
    '''
    global m_bytes_P, m_bytes_S, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    # Compute segment byte targets
    cap = cache_snapshot.capacity
    target_S = _clamp(m_target_S_bytes, 0, cap)
    target_P = cap - target_S

    # Find min in each segment
    p_key, p_prio, p_lru = _pick_min_in_segment(cache_snapshot, 'P')
    s_key, s_prio, s_lru = _pick_min_in_segment(cache_snapshot, 'S')

    # Decide which segment to evict from
    evict_from_P = False
    evict_from_S = False

    # If a segment is over its byte target, evict from it
    if m_bytes_P > target_P and p_key is not None:
        evict_from_P = True
    elif m_bytes_S > target_S and s_key is not None:
        evict_from_S = True
    else:
        # Neither segment over target; choose the global minimum priority among available candidates
        if p_key is not None and s_key is not None:
            if (p_prio < s_prio) or (p_prio == s_prio and p_lru < s_lru):
                evict_from_P = True
            else:
                evict_from_S = True
        elif p_key is not None:
            evict_from_P = True
        elif s_key is not None:
            evict_from_S = True

    candid_key = None
    if evict_from_P and p_key is not None:
        candid_key = p_key
    elif evict_from_S and s_key is not None:
        candid_key = s_key

    # Fallback: if no segment candidate found (should not happen), fall back to global min over all
    if candid_key is None:
        # Choose the least priority over both segments
        min_key, min_prio, min_time = None, None, None
        for key in cache_snapshot.cache.keys():
            prio = m_key_priority.get(key, 0.0)
            last = m_key_last_access.get(key, -1)
            if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
                min_key, min_prio, min_time = key, prio, last
        candid_key = min_key if min_key is not None else next(iter(cache_snapshot.cache))

    return candid_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment resident frequency
      - If in probation (P), promote to protected (S)
      - Recompute priority using the segment's current age L
      - Refresh last-access time
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_age_P, m_age_S, m_bytes_P, m_bytes_S

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size
    m_key_last_access[k] = cache_snapshot.access_count
    m_key_freq[k] = m_key_freq.get(k, 0) + 1

    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        # Promote on first re-reference to protected segment
        m_key_segment[k] = 'S'
        # Move bytes P -> S (guard against negatives)
        m_bytes_P = max(0, m_bytes_P - sz)
        m_bytes_S += sz
        # Recompute priority in S with S's age
        m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_S)
    else:
        # Already protected: reinforce priority with current S age
        m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_S)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S byte split using ARC-like ghosts
      - Add the new object to probation (P) with freq = 1, priority H = L_P + 1/size
      - Record last access
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_bytes_P

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists (ARC-like)
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    sz = obj.size

    # Initialize metadata (new admit to probation)
    m_key_freq[k] = 1
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_P)

    # Account bytes in probation
    m_bytes_P += sz


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Update the corresponding segment age L to the victim's priority (GreedyDual aging)
      - Remove resident metadata for that key
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_age_P, m_age_S, m_bytes_P, m_bytes_S
    global m_ghost_P, m_ghost_S

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown
    # Use the stored priority or the segment age as a fallback
    evicted_prio = m_key_priority.get(ek, m_age_P if seg == 'P' else m_age_S)

    # Age update for the evicting segment
    if seg == 'S':
        m_age_S = evicted_prio
    else:
        m_age_P = evicted_prio

    # Cleanup resident metadata
    m_key_priority.pop(ek, None)
    m_key_freq.pop(ek, None)
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes
    if seg == 'S':
        m_bytes_S = max(0, m_bytes_S - esz)
        # Add to S ghost
        _ghost_add(m_ghost_S, ek, esz, cache_snapshot.access_count, is_P=False)
    else:
        m_bytes_P = max(0, m_bytes_P - esz)
        # Add to P ghost
        _ghost_add(m_ghost_P, ek, esz, cache_snapshot.access_count, is_P=True)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 0
- Hit Rate: 0.4345

Example 2:
- Trace ID: 27
- Hit Rate: 0.8657

Example 3:
- Trace ID: 47
- Hit Rate: 0.0817

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m18:05:14 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 18:05:14,351 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m18:07:24 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 18:07:24,513 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 18:07:24,514 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Window-TinyLFU + GreedyDual-Size in Main (WTinyLFU-GDS)
# - Three components:
#   1) TinyLFU (Count-Min Sketch) for long-term frequency estimation (size-aware scoring)
#   2) Window segment W (recency-biased) that admits all new items (scan-resistant)
#   3) Main segment M (frequency- and size-aware) using GreedyDual-Size with TinyLFU scores
#
# Eviction:
#   - Prefer evicting from W if W exceeds its adaptive byte target.
#   - Otherwise compare the incoming object's score (est_freq/size) with M's weakest item score.
#     If the incoming object is weaker, evict from W to protect M; else evict from M.
#   - Within W: evict LRU. Within M: evict min H, where H = L_M + (est_freq/size). Ties use LRU.
#
# Updates:
#   - On every access (hit or miss), increment TinyLFU.
#   - On hit in W: promote to M and set its GDS priority using TinyLFU estimate.
#   - On hit in M: refresh its GDS priority.
#   - On insert: admit to W, adapt W/M split using ARC-like ghosts.
#   - On evict: age L_M to evicted H for M, update ghosts, and adjust bytes.
#
# Adaptation of W/M split:
#   - If a newly inserted key is found in W-ghost => increase window target (recency pressure).
#   - If found in M-ghost => decrease window target (frequency pressure).
#
# This design is scan-resistant (small W), size-aware (freq/size), adapts between recency and
# frequency, and ages stale priorities via GDS in the main segment.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_priority = dict()      # key -> float priority H (only meaningful for M)
m_key_last_access = dict()   # key -> int access_count (for LRU tie-breaks)
m_key_segment = dict()       # key -> 'W' (window) or 'M' (main)

# Main segment GreedyDual age
m_age_M = 0.0

# Current resident bytes per segment
m_bytes_W = 0
m_bytes_M = 0

# Adaptive target for window bytes (W); M target = capacity - target_W
m_target_W_bytes = None

# Ghost lists for ARC-like adaptation of W/M split; store key -> (size, last_time)
m_ghost_W = dict()
m_ghost_M = dict()
m_ghost_W_bytes = 0
m_ghost_M_bytes = 0
m_ghost_limit_bytes = None

# -----------------------------
# TinyLFU (Count-Min Sketch)
# -----------------------------
m_cm_depth = None
m_cm_width = None
m_cm_mask = None
m_cm = None                 # 2D list: depth x width
m_cm_seeds = None
m_cm_inserts = 0
m_cm_sample = None          # when total increments exceed this, perform aging (halve)

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)

def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_W_bytes, m_ghost_limit_bytes
    global m_cm_depth, m_cm_width, m_cm_mask, m_cm, m_cm_seeds, m_cm_sample

    cap = cache_snapshot.capacity
    if m_target_W_bytes is None:
        # Start with a small window (10% of capacity), typical for WTinyLFU
        m_target_W_bytes = cap * 0.10
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cap

    # Initialize TinyLFU CM sketch parameters once
    if m_cm is None:
        # Depth x Width (power-of-two width for fast masking)
        m_cm_depth = 4
        # Width tuned by capacity; keep reasonable memory footprint
        # Aim for a few thousand counters; use 4096 default, scaled a bit by cap
        base = 4096
        if cap > 0:
            # scale to ~1 counter per ~ (cap/64) bytes, clamped to [2048, 16384]
            scaled = 1
            try:
                scaled = int(1 << max(11, min(14, (cap.bit_length() - 6))))
            except Exception:
                scaled = base
            m_cm_width = _clamp(scaled, 2048, 16384)
        else:
            m_cm_width = base
        # round width to power of two
        pw = 1
        while pw < m_cm_width:
            pw <<= 1
        m_cm_width = pw
        m_cm_mask = m_cm_width - 1
        m_cm = [[0] * m_cm_width for _ in range(m_cm_depth)]
        # Fixed seeds for hash mixing
        m_cm_seeds = [0x27d4eb2d, 0x85ebca6b, 0xc2b2ae35, 0x165667b1]
        # Sampling window before aging; higher than width to reduce aging overhead
        m_cm_sample = m_cm_width * 20  # e.g., 4096*20 = 81,920 increments between halvings

def _hash_idx(seed, key_str):
    # Simple mixed hash -> index [0..width-1]
    h = hash(str(seed) + '|' + key_str)
    return h & m_cm_mask

def _cm_increment(key, delta=1):
    # Increment TinyLFU counters for key; perform periodic aging
    global m_cm_inserts
    if m_cm is None:
        return
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key)
        # Saturate at a large value to avoid overflow
        if m_cm[d][idx] < 0x7fffffff:
            m_cm[d][idx] += delta
    m_cm_inserts += delta
    if m_cm_inserts >= (m_cm_sample or 1):
        # Halve all counters (right shift by 1) to age history
        for d in range(m_cm_depth):
            row = m_cm[d]
            for i in range(m_cm_width):
                row[i] >>= 1
        m_cm_inserts >>= 1  # approximate total after halving

def _cm_estimate(key):
    if m_cm is None:
        return 0
    est = None
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key)
        val = m_cm[d][idx]
        est = val if est is None else (val if val < est else est)
    return est or 0

def _score_freq_size(key, size):
    # Size-aware frequency score: est_freq / size
    if size <= 0:
        return 0.0
    est = _cm_estimate(key)
    return float(est) / float(size)

def _pick_oldest_in_segment(cache_snapshot, seg_tag):
    # Returns (key, last_time) of the oldest (LRU) key in a segment
    oldest_key = None
    oldest_time = None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != seg_tag:
            continue
        last = m_key_last_access.get(key, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = key
    return (oldest_key, oldest_time)

def _pick_min_in_main(cache_snapshot):
    # Returns (key, prio, last_time) of the minimum-priority key in main (M)
    min_key = None
    min_prio = None
    min_time = None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != 'M':
            continue
        # Use stored H if present; otherwise compute on-the-fly using current TinyLFU score
        prio = m_key_priority.get(key)
        if prio is None:
            obj = cache_snapshot.cache.get(key)
            if obj is None:
                continue
            prio = m_age_M + _score_freq_size(key, obj.size)
            m_key_priority[key] = prio
        last = m_key_last_access.get(key, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_prio = prio
            min_time = last
            min_key = key
    return (min_key, min_prio, min_time)

def _ghost_add(ghost_dict, key, size, time_now, is_W):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_W_bytes, m_ghost_M_bytes, m_ghost_limit_bytes

    if is_W:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_W_bytes += size
        else:
            old_size, _ = prev
            m_ghost_W_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_W_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_W_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_M_bytes += size
        else:
            old_size, _ = prev
            m_ghost_M_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_M_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_M_bytes -= sz

def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation of window target based on which ghost contains the new key
    global m_ghost_W, m_ghost_M, m_ghost_W_bytes, m_ghost_M_bytes, m_target_W_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step sized by object size; clamp to [1%, 10%] of capacity to avoid huge jumps
    step = _clamp(obj.size, int(0.01 * cap), int(0.10 * cap))

    if obj.key in m_ghost_W:
        # Recency pressure ↑ => increase window size target
        m_target_W_bytes = _clamp(m_target_W_bytes + step, 0, cap)
        sz, _ = m_ghost_W.pop(obj.key)
        m_ghost_W_bytes -= sz
    elif obj.key in m_ghost_M:
        # Frequency pressure ↑ => decrease window, giving more to main
        m_target_W_bytes = _clamp(m_target_W_bytes - step, 0, cap)
        sz, _ = m_ghost_M.pop(obj.key)
        m_ghost_M_bytes -= sz

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using a WTinyLFU-inspired policy:
      - Evict from W if W exceeds its adaptive target (recency window).
      - Else compare incoming score vs weakest main (M) item:
          * If incoming score < weakest main score => evict from W (protect main)
          * Else evict from M
      - Within W: LRU. Within M: Segmented GreedyDual-Size with TinyLFU scores and aging.
    '''
    global m_bytes_W, m_bytes_M, m_target_W_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Clamp window target to [1% cap, 50% cap]
    min_w = int(max(1, cap * 0.01))
    max_w = int(cap * 0.50)
    target_W = int(_clamp(int(m_target_W_bytes), min_w, max_w))

    # Candidates
    w_key, w_lru = _pick_oldest_in_segment(cache_snapshot, 'W')
    m_key, m_prio, m_lru = _pick_min_in_main(cache_snapshot)

    # Prefer evicting from W when it exceeds target
    if m_bytes_W > target_W and w_key is not None:
        return w_key

    # If either segment has no candidates, evict from the other
    if w_key is None and m_key is None:
        # Fallback: global LRU
        min_key, min_time = None, None
        for key in cache_snapshot.cache.keys():
            t = m_key_last_access.get(key, -1)
            if min_time is None or t < min_time:
                min_key, min_time = key, t
        return min_key if min_key is not None else next(iter(cache_snapshot.cache))
    if w_key is None:
        return m_key
    if m_key is None:
        return w_key

    # Decide based on admission: compare incoming vs weakest M's score
    incoming_score = _score_freq_size(obj.key, obj.size)
    m_victim_obj = cache_snapshot.cache.get(m_key)
    m_victim_score = _score_freq_size(m_key, m_victim_obj.size) if m_victim_obj is not None else 0.0

    # If incoming is weaker than weakest main item, protect main by evicting from window
    if incoming_score < m_victim_score:
        return w_key
    else:
        return m_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU
      - If in window (W), promote to main (M)
      - In main (M), recompute priority H = L_M + est_freq/size
      - Refresh last-access time
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_age_M, m_bytes_W, m_bytes_M

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Record access in TinyLFU
    _cm_increment(k, 1)

    # Update last access time
    m_key_last_access[k] = cache_snapshot.access_count

    seg = m_key_segment.get(k)
    if seg == 'W':
        # Promote to main (M)
        m_key_segment[k] = 'M'
        # Adjust bytes
        m_bytes_W = max(0, m_bytes_W - sz)
        m_bytes_M += sz
        # Set main priority using current TinyLFU estimate and M's age
        m_key_priority[k] = m_age_M + _score_freq_size(k, sz)
    else:
        # Already in main: refresh priority with current TinyLFU estimate
        m_key_priority[k] = m_age_M + _score_freq_size(k, sz)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU (record this access)
      - Adapt the W/M byte split using ARC-like ghosts
      - Admit the new object into window (W)
      - Record last access
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_bytes_W

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Record this access in TinyLFU
    _cm_increment(k, 1)

    # Adapt window target based on ghosts
    _adapt_targets_on_insert(cache_snapshot, obj)

    # Initialize metadata in window
    m_key_segment[k] = 'W'
    m_key_last_access[k] = cache_snapshot.access_count
    # No priority needed in W; clear any stale
    m_key_priority.pop(k, None)

    # Account bytes in window
    m_bytes_W += sz


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - If victim was in main (M), set L_M to victim's priority (GreedyDual aging)
      - Remove resident metadata
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_age_M, m_bytes_W, m_bytes_M
    global m_ghost_W, m_ghost_M

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'W')  # default to window if unknown
    # Use stored priority for main; if missing, approximate using current age + TinyLFU score
    if seg == 'M':
        evicted_prio = m_key_priority.get(ek)
        if evicted_prio is None:
            evicted_prio = m_age_M + _score_freq_size(ek, esz)
        # Age update for main
        m_age_M = evicted_prio

    # Cleanup resident metadata
    m_key_priority.pop(ek, None)
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes and add to appropriate ghost
    if seg == 'M':
        m_bytes_M = max(0, m_bytes_M - esz)
        _ghost_add(m_ghost_M, ek, esz, cache_snapshot.access_count, is_W=False)
    else:
        m_bytes_W = max(0, m_bytes_W - esz)
        _ghost_add(m_ghost_W, ek, esz, cache_snapshot.access_count, is_W=True)
```
2025-11-27 18:10:08,884 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Window-TinyLFU + GreedyDual-Size in Main (WTinyLFU-GDS)
# - Three components:
#   1) TinyLFU (Count-Min Sketch) for long-term frequency estimation (size-aware scoring)
#   2) Window segment W (recency-biased) that admits all new items (scan-resistant)
#   3) Main segment M (frequency- and size-aware) using GreedyDual-Size with TinyLFU scores
#
# Eviction:
#   - Prefer evicting from W if W exceeds its adaptive byte target.
#   - Otherwise compare the incoming object's score (est_freq/size) with M's weakest item score.
#     If the incoming object is weaker, evict from W to protect M; else evict from M.
#   - Within W: evict LRU. Within M: evict min H, where H = L_M + (est_freq/size). Ties use LRU.
#
# Updates:
#   - On every access (hit or miss), increment TinyLFU.
#   - On hit in W: promote to M and set its GDS priority using TinyLFU estimate.
#   - On hit in M: refresh its GDS priority.
#   - On insert: admit to W, adapt W/M split using ARC-like ghosts.
#   - On evict: age L_M to evicted H for M, update ghosts, and adjust bytes.
#
# Adaptation of W/M split:
#   - If a newly inserted key is found in W-ghost => increase window target (recency pressure).
#   - If found in M-ghost => decrease window target (frequency pressure).
#
# This design is scan-resistant (small W), size-aware (freq/size), adapts between recency and
# frequency, and ages stale priorities via GDS in the main segment.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_priority = dict()      # key -> float priority H (only meaningful for M)
m_key_last_access = dict()   # key -> int access_count (for LRU tie-breaks)
m_key_segment = dict()       # key -> 'W' (window) or 'M' (main)

# Main segment GreedyDual age
m_age_M = 0.0

# Current resident bytes per segment
m_bytes_W = 0
m_bytes_M = 0

# Adaptive target for window bytes (W); M target = capacity - target_W
m_target_W_bytes = None

# Ghost lists for ARC-like adaptation of W/M split; store key -> (size, last_time)
m_ghost_W = dict()
m_ghost_M = dict()
m_ghost_W_bytes = 0
m_ghost_M_bytes = 0
m_ghost_limit_bytes = None

# -----------------------------
# TinyLFU (Count-Min Sketch)
# -----------------------------
m_cm_depth = None
m_cm_width = None
m_cm_mask = None
m_cm = None                 # 2D list: depth x width
m_cm_seeds = None
m_cm_inserts = 0
m_cm_sample = None          # when total increments exceed this, perform aging (halve)

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)

def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_W_bytes, m_ghost_limit_bytes
    global m_cm_depth, m_cm_width, m_cm_mask, m_cm, m_cm_seeds, m_cm_sample

    cap = cache_snapshot.capacity
    if m_target_W_bytes is None:
        # Start with a small window (10% of capacity), typical for WTinyLFU
        m_target_W_bytes = cap * 0.10
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cap

    # Initialize TinyLFU CM sketch parameters once
    if m_cm is None:
        # Depth x Width (power-of-two width for fast masking)
        m_cm_depth = 4
        # Width tuned by capacity; keep reasonable memory footprint
        # Aim for a few thousand counters; use 4096 default, scaled a bit by cap
        base = 4096
        if cap > 0:
            # scale to ~1 counter per ~ (cap/64) bytes, clamped to [2048, 16384]
            scaled = 1
            try:
                scaled = int(1 << max(11, min(14, (cap.bit_length() - 6))))
            except Exception:
                scaled = base
            m_cm_width = _clamp(scaled, 2048, 16384)
        else:
            m_cm_width = base
        # round width to power of two
        pw = 1
        while pw < m_cm_width:
            pw <<= 1
        m_cm_width = pw
        m_cm_mask = m_cm_width - 1
        m_cm = [[0] * m_cm_width for _ in range(m_cm_depth)]
        # Fixed seeds for hash mixing
        m_cm_seeds = [0x27d4eb2d, 0x85ebca6b, 0xc2b2ae35, 0x165667b1]
        # Sampling window before aging; higher than width to reduce aging overhead
        m_cm_sample = m_cm_width * 20  # e.g., 4096*20 = 81,920 increments between halvings

def _hash_idx(seed, key_str):
    # Simple mixed hash -> index [0..width-1]
    h = hash(str(seed) + '|' + key_str)
    return h & m_cm_mask

def _cm_increment(key, delta=1):
    # Increment TinyLFU counters for key; perform periodic aging
    global m_cm_inserts
    if m_cm is None:
        return
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key)
        # Saturate at a large value to avoid overflow
        if m_cm[d][idx] < 0x7fffffff:
            m_cm[d][idx] += delta
    m_cm_inserts += delta
    if m_cm_inserts >= (m_cm_sample or 1):
        # Halve all counters (right shift by 1) to age history
        for d in range(m_cm_depth):
            row = m_cm[d]
            for i in range(m_cm_width):
                row[i] >>= 1
        m_cm_inserts >>= 1  # approximate total after halving

def _cm_estimate(key):
    if m_cm is None:
        return 0
    est = None
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key)
        val = m_cm[d][idx]
        est = val if est is None else (val if val < est else est)
    return est or 0

def _score_freq_size(key, size):
    # Size-aware frequency score: est_freq / size
    if size <= 0:
        return 0.0
    est = _cm_estimate(key)
    return float(est) / float(size)

def _pick_oldest_in_segment(cache_snapshot, seg_tag):
    # Returns (key, last_time) of the oldest (LRU) key in a segment
    oldest_key = None
    oldest_time = None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != seg_tag:
            continue
        last = m_key_last_access.get(key, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = key
    return (oldest_key, oldest_time)

def _pick_min_in_main(cache_snapshot):
    # Returns (key, prio, last_time) of the minimum-priority key in main (M)
    min_key = None
    min_prio = None
    min_time = None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != 'M':
            continue
        # Use stored H if present; otherwise compute on-the-fly using current TinyLFU score
        prio = m_key_priority.get(key)
        if prio is None:
            obj = cache_snapshot.cache.get(key)
            if obj is None:
                continue
            prio = m_age_M + _score_freq_size(key, obj.size)
            m_key_priority[key] = prio
        last = m_key_last_access.get(key, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_prio = prio
            min_time = last
            min_key = key
    return (min_key, min_prio, min_time)

def _ghost_add(ghost_dict, key, size, time_now, is_W):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_W_bytes, m_ghost_M_bytes, m_ghost_limit_bytes

    if is_W:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_W_bytes += size
        else:
            old_size, _ = prev
            m_ghost_W_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_W_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_W_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_M_bytes += size
        else:
            old_size, _ = prev
            m_ghost_M_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_M_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_M_bytes -= sz

def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation of window target based on which ghost contains the new key
    global m_ghost_W, m_ghost_M, m_ghost_W_bytes, m_ghost_M_bytes, m_target_W_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step sized by object size; clamp to [1%, 10%] of capacity to avoid huge jumps
    step = _clamp(obj.size, int(0.01 * cap), int(0.10 * cap))

    if obj.key in m_ghost_W:
        # Recency pressure ↑ => increase window size target
        m_target_W_bytes = _clamp(m_target_W_bytes + step, 0, cap)
        sz, _ = m_ghost_W.pop(obj.key)
        m_ghost_W_bytes -= sz
    elif obj.key in m_ghost_M:
        # Frequency pressure ↑ => decrease window, giving more to main
        m_target_W_bytes = _clamp(m_target_W_bytes - step, 0, cap)
        sz, _ = m_ghost_M.pop(obj.key)
        m_ghost_M_bytes -= sz

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using a WTinyLFU-inspired policy:
      - Evict from W if W exceeds its adaptive target (recency window).
      - Else compare incoming score vs weakest main (M) item:
          * If incoming score < weakest main score => evict from W (protect main)
          * Else evict from M
      - Within W: LRU. Within M: Segmented GreedyDual-Size with TinyLFU scores and aging.
    '''
    global m_bytes_W, m_bytes_M, m_target_W_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Clamp window target to [1% cap, 50% cap]
    min_w = int(max(1, cap * 0.01))
    max_w = int(cap * 0.50)
    target_W = int(_clamp(int(m_target_W_bytes), min_w, max_w))

    # Candidates
    w_key, w_lru = _pick_oldest_in_segment(cache_snapshot, 'W')
    m_key, m_prio, m_lru = _pick_min_in_main(cache_snapshot)

    # Prefer evicting from W when it exceeds target
    if m_bytes_W > target_W and w_key is not None:
        return w_key

    # If either segment has no candidates, evict from the other
    if w_key is None and m_key is None:
        # Fallback: global LRU
        min_key, min_time = None, None
        for key in cache_snapshot.cache.keys():
            t = m_key_last_access.get(key, -1)
            if min_time is None or t < min_time:
                min_key, min_time = key, t
        return min_key if min_key is not None else next(iter(cache_snapshot.cache))
    if w_key is None:
        return m_key
    if m_key is None:
        return w_key

    # Decide based on admission: compare incoming vs weakest M's score
    incoming_score = _score_freq_size(obj.key, obj.size)
    m_victim_obj = cache_snapshot.cache.get(m_key)
    m_victim_score = _score_freq_size(m_key, m_victim_obj.size) if m_victim_obj is not None else 0.0

    # If incoming is weaker than weakest main item, protect main by evicting from window
    if incoming_score < m_victim_score:
        return w_key
    else:
        return m_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU
      - If in window (W), promote to main (M)
      - In main (M), recompute priority H = L_M + est_freq/size
      - Refresh last-access time
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_age_M, m_bytes_W, m_bytes_M

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Record access in TinyLFU
    _cm_increment(k, 1)

    # Update last access time
    m_key_last_access[k] = cache_snapshot.access_count

    seg = m_key_segment.get(k)
    if seg == 'W':
        # Promote to main (M)
        m_key_segment[k] = 'M'
        # Adjust bytes
        m_bytes_W = max(0, m_bytes_W - sz)
        m_bytes_M += sz
        # Set main priority using current TinyLFU estimate and M's age
        m_key_priority[k] = m_age_M + _score_freq_size(k, sz)
    else:
        # Already in main: refresh priority with current TinyLFU estimate
        m_key_priority[k] = m_age_M + _score_freq_size(k, sz)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU (record this access)
      - Adapt the W/M byte split using ARC-like ghosts
      - Admit the new object into window (W)
      - Record last access
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_bytes_W

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Record this access in TinyLFU
    _cm_increment(k, 1)

    # Adapt window target based on ghosts
    _adapt_targets_on_insert(cache_snapshot, obj)

    # Initialize metadata in window
    m_key_segment[k] = 'W'
    m_key_last_access[k] = cache_snapshot.access_count
    # No priority needed in W; clear any stale
    m_key_priority.pop(k, None)

    # Account bytes in window
    m_bytes_W += sz


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - If victim was in main (M), set L_M to victim's priority (GreedyDual aging)
      - Remove resident metadata
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_age_M, m_bytes_W, m_bytes_M
    global m_ghost_W, m_ghost_M

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'W')  # default to window if unknown
    # Use stored priority for main; if missing, approximate using current age + TinyLFU score
    if seg == 'M':
        evicted_prio = m_key_priority.get(ek)
        if evicted_prio is None:
            evicted_prio = m_age_M + _score_freq_size(ek, esz)
        # Age update for main
        m_age_M = evicted_prio

    # Cleanup resident metadata
    m_key_priority.pop(ek, None)
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes and add to appropriate ghost
    if seg == 'M':
        m_bytes_M = max(0, m_bytes_M - esz)
        _ghost_add(m_ghost_M, ek, esz, cache_snapshot.access_count, is_W=False)
    else:
        m_bytes_W = max(0, m_bytes_W - esz)
        _ghost_add(m_ghost_W, ek, esz, cache_snapshot.access_count, is_W=True)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 7
- Hit Rate: 0.4607

Example 2:
- Trace ID: 33
- Hit Rate: 0.7432

Example 3:
- Trace ID: 34
- Hit Rate: 0.0833

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m18:10:08 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 18:10:08,886 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m18:12:11 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 18:12:11,024 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 18:12:11,025 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Dynamic WTinyLFU + GDS with Gated Promotion and Size-Sensitive Admission (DTinyLFU-GDS+)
# - Three components:
#   1) TinyLFU (Count-Min Sketch) for long-term frequency estimation (size-aware scoring)
#   2) Window segment W (recency-biased) that admits all new items (scan-resilient)
#   3) Main segment M (frequency- and size-aware) using GreedyDual-Size (GDS) with TinyLFU scores
#
# Key improvements over baseline:
#   - Size-sensitive scoring est / size^alpha (alpha ~ 0.85) to better balance large objects
#   - Admission decision uses consistent GDS terms: compare H_in = L + score_in vs min(H_M)
#   - Gated promotion: a hit in W promotes to M only if its H_in surpasses current M min(H)
#     (reduces pollution of M and improves scan resistance)
#   - Large-object streaming guard: very large, low-frequency newcomers favor evicting from W
#   - Ghost-biased admission: if newcomer present in M-ghost, bias to admit (evict from M);
#     if in W-ghost, bias to protect recency (evict from W)
#   - Safer window target clamping; consistent byte accounting; better tie-breaking
#
# Eviction:
#   - Evict from W if W exceeds its adaptive target, or large-object streaming guard triggers.
#   - Otherwise compute H_incoming and compare to main's minimum H:
#       * If H_incoming <= min(H_M) => evict from W (protect M)
#       * Else evict from M
#   - Within W: LRU. Within M: evict min H (GDS). Ties broken by LRU.
#
# Updates:
#   - On every access (hit or miss), increment TinyLFU.
#   - On hit in W: gated promotion to M if strong enough; otherwise remain in W.
#   - On hit in M: refresh its GDS priority H = L_M + score.
#   - On insert: admit to W; adapt W target using ARC-like ghosts.
#   - On evict: if M victim, set L_M to victim's H (GDS aging); record ghosts.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_priority = dict()      # key -> float priority H (only meaningful for M)
m_key_last_access = dict()   # key -> int access_count (for LRU tie-breaks)
m_key_segment = dict()       # key -> 'W' (window) or 'M' (main)

# Main segment GreedyDual age
m_age_M = 0.0

# Current resident bytes per segment
m_bytes_W = 0
m_bytes_M = 0

# Adaptive target for window bytes (W); M target = capacity - target_W
m_target_W_bytes = None

# Ghost lists for ARC-like adaptation of W/M split; store key -> (size, last_time)
m_ghost_W = dict()
m_ghost_M = dict()
m_ghost_W_bytes = 0
m_ghost_M_bytes = 0
m_ghost_limit_bytes = None

# -----------------------------
# TinyLFU (Count-Min Sketch)
# -----------------------------
m_cm_depth = None
m_cm_width = None
m_cm_mask = None
m_cm = None                 # 2D list: depth x width
m_cm_seeds = None
m_cm_inserts = 0
m_cm_sample = None          # when total increments exceed this, perform aging (halve)

# -----------------------------
# Tunables
# -----------------------------
SIZE_ALPHA = 0.85                  # exponent for size-aware score: est / size^alpha
MIN_SIZE_UNIT = 1                  # minimum divisor in bytes to avoid div-by-zero
LARGE_OBJ_FRAC = 0.25              # fraction of capacity considered "very large"
LARGE_OBJ_FREQ_CUTOFF = 2          # TinyLFU estimate threshold to consider "hot"
ADMIT_BIAS = 0.10                  # +/-10% bias based on ghosts when comparing H_in vs min(H_M)

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)

def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_W_bytes, m_ghost_limit_bytes
    global m_cm_depth, m_cm_width, m_cm_mask, m_cm, m_cm_seeds, m_cm_sample

    cap = cache_snapshot.capacity
    if m_target_W_bytes is None:
        # Start with a modest window (10% of capacity), typical for WTinyLFU
        m_target_W_bytes = cap * 0.10
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cap

    # Initialize TinyLFU CM sketch parameters once
    if m_cm is None:
        m_cm_depth = 4
        # Width tuned by capacity; enforce power-of-two for fast masking
        base = 4096
        try:
            # scale to ~2^k with k ~ [11..14] based on capacity bits
            scaled_pow = max(11, min(14, (cap.bit_length() - 6)))
            width = 1 << scaled_pow
        except Exception:
            width = base
        m_cm_width = _clamp(width, 2048, 16384)
        # round to power of two
        pw = 1
        while pw < m_cm_width:
            pw <<= 1
        m_cm_width = pw
        m_cm_mask = m_cm_width - 1
        m_cm = [[0] * m_cm_width for _ in range(m_cm_depth)]
        # Fixed seeds for hash mixing
        m_cm_seeds = [0x27d4eb2d, 0x85ebca6b, 0xc2b2ae35, 0x165667b1]
        # Sampling window before aging
        m_cm_sample = m_cm_width * 20  # e.g., 4096*20 = 81,920 increments between halvings

def _hash_idx(seed, key_str):
    # Simple mixed hash -> index [0..width-1]
    h = hash(str(seed) + '|' + key_str)
    return h & m_cm_mask

def _cm_increment(key, delta=1):
    # Increment TinyLFU counters for key; perform periodic aging
    global m_cm_inserts
    if m_cm is None:
        return
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key)
        # Saturate at a large value to avoid overflow
        if m_cm[d][idx] < 0x7fffffff:
            m_cm[d][idx] += delta
    m_cm_inserts += delta
    if m_cm_inserts >= (m_cm_sample or 1):
        # Halve all counters (right shift by 1) to age history
        for d in range(m_cm_depth):
            row = m_cm[d]
            for i in range(m_cm_width):
                row[i] >>= 1
        m_cm_inserts >>= 1  # approximate total after halving

def _cm_estimate(key):
    if m_cm is None:
        return 0
    est = None
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key)
        val = m_cm[d][idx]
        est = val if est is None else (val if val < est else est)
    return est or 0

def _score_freq_size(key, size):
    # Size-aware frequency score: est_freq / size^alpha
    if size <= 0:
        return 0.0
    denom = max(MIN_SIZE_UNIT, float(size)) ** float(SIZE_ALPHA)
    est = _cm_estimate(key)
    if est <= 0:
        return 0.0
    return float(est) / denom

def _pick_oldest_in_segment(cache_snapshot, seg_tag):
    # Returns (key, last_time) of the oldest (LRU) key in a segment
    oldest_key = None
    oldest_time = None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != seg_tag:
            continue
        last = m_key_last_access.get(key, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = key
    return (oldest_key, oldest_time)

def _pick_min_in_main(cache_snapshot):
    # Returns (key, prio, last_time) of the minimum-priority key in main (M)
    min_key = None
    min_prio = None
    min_time = None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != 'M':
            continue
        prio = m_key_priority.get(key)
        if prio is None:
            obj = cache_snapshot.cache.get(key)
            if obj is None:
                continue
            prio = m_age_M + _score_freq_size(key, obj.size)
            m_key_priority[key] = prio
        last = m_key_last_access.get(key, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_prio = prio
            min_time = last
            min_key = key
    return (min_key, min_prio, min_time)

def _ghost_add(ghost_dict, key, size, time_now, is_W):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_W_bytes, m_ghost_M_bytes, m_ghost_limit_bytes

    if is_W:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_W_bytes += size
        else:
            old_size, _ = prev
            m_ghost_W_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_W_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_W_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_M_bytes += size
        else:
            old_size, _ = prev
            m_ghost_M_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_M_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_M_bytes -= sz

def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation of window target based on which ghost contains the new key
    global m_ghost_W, m_ghost_M, m_ghost_W_bytes, m_ghost_M_bytes, m_target_W_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step sized by object size; clamp to [1%, 10%] of capacity to avoid huge jumps
    step = _clamp(obj.size, int(0.01 * cap), int(0.10 * cap))

    if obj.key in m_ghost_W:
        # Recency pressure ↑ => increase window size target
        m_target_W_bytes = _clamp(m_target_W_bytes + step, 0, cap)
        sz, _ = m_ghost_W.pop(obj.key)
        m_ghost_W_bytes -= sz
    elif obj.key in m_ghost_M:
        # Frequency pressure ↑ => decrease window, giving more to main
        m_target_W_bytes = _clamp(m_target_W_bytes - step, 0, cap)
        sz, _ = m_ghost_M.pop(obj.key)
        m_ghost_M_bytes -= sz

def _prefer_w_due_to_large_stream(cache_snapshot, obj):
    # For very large, low-frequency objects that are not hinted by M-ghost, prefer to evict from W
    cap = cache_snapshot.capacity or 1
    large = obj.size >= int(cap * LARGE_OBJ_FRAC)
    if not large:
        return False
    # If it's not frequent and not seen in M-ghost before, treat as likely stream
    if _cm_estimate(obj.key) < LARGE_OBJ_FREQ_CUTOFF and (obj.key not in m_ghost_M):
        return True
    return False

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using DTinyLFU-GDS+ policy:
      - Evict from W if W exceeds its adaptive target (recency window) or large-object stream guard triggers.
      - Else compute H_incoming and compare to M's weakest H:
          * If H_incoming <= weakest main H (after ghost bias) => evict from W (protect M)
          * Else evict from M
      - Within W: LRU. Within M: evict min H (GDS). Ties use LRU.
    '''
    global m_bytes_W, m_bytes_M, m_target_W_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Clamp window target to [1% cap, 50% cap]
    min_w = int(max(1, cap * 0.01))
    max_w = int(cap * 0.50)
    target_W = int(_clamp(int(m_target_W_bytes), min_w, max_w))

    # Candidates
    w_key, _ = _pick_oldest_in_segment(cache_snapshot, 'W')
    m_key, m_prio, _ = _pick_min_in_main(cache_snapshot)

    # If nothing to evict, fallback to global LRU
    if w_key is None and m_key is None:
        min_key, min_time = None, None
        for key in cache_snapshot.cache.keys():
            t = m_key_last_access.get(key, -1)
            if min_time is None or t < min_time:
                min_key, min_time = key, t
        return min_key if min_key is not None else next(iter(cache_snapshot.cache))

    # Prefer evicting from W when it exceeds target or large streaming guard applies
    if (m_bytes_W > target_W and w_key is not None) or _prefer_w_due_to_large_stream(cache_snapshot, obj):
        return w_key if w_key is not None else m_key

    # If one segment is empty, evict from the other
    if w_key is None:
        return m_key
    if m_key is None:
        return w_key

    # Admission decision based on GDS-consistent comparison
    incoming_score = _score_freq_size(obj.key, obj.size)
    H_incoming = m_age_M + incoming_score

    # Ghost-based bias: if in M-ghost, bias towards admitting (evict M); if in W-ghost, bias to protect W
    bias = 0.0
    if obj.key in m_ghost_M:
        bias += ADMIT_BIAS
    if obj.key in m_ghost_W:
        bias -= ADMIT_BIAS
    # Apply bias by stretching/shrinking the threshold (min H)
    threshold = m_prio * (1.0 - bias)

    # If incoming not strong enough, protect main by evicting from window
    if H_incoming <= threshold:
        return w_key
    else:
        return m_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU
      - If in window (W), gated promotion to main (M) if H_incoming > min(H_M)
      - In main (M), refresh its GDS priority H = L_M + est_freq/size^alpha
      - Refresh last-access time
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_age_M, m_bytes_W, m_bytes_M

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Record access in TinyLFU
    _cm_increment(k, 1)

    # Update last access time
    m_key_last_access[k] = cache_snapshot.access_count

    seg = m_key_segment.get(k)
    if seg == 'W':
        # Gated promotion: move to M only if H_incoming surpasses current min in M
        H_incoming = m_age_M + _score_freq_size(k, sz)
        m_key, m_prio, _ = _pick_min_in_main(cache_snapshot)
        # If M empty or newcomer stronger than weakest M item, promote
        should_promote = (m_key is None) or (H_incoming > m_prio)
        if should_promote:
            m_key_segment[k] = 'M'
            # Adjust bytes
            m_bytes_W = max(0, m_bytes_W - sz)
            m_bytes_M += sz
            # Set main priority
            m_key_priority[k] = H_incoming
        else:
            # Stay in W; no priority in W
            m_key_priority.pop(k, None)
    else:
        # Already in main: refresh priority with current TinyLFU estimate
        m_key_priority[k] = m_age_M + _score_freq_size(k, sz)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU (record this access)
      - Adapt the W/M byte split using ARC-like ghosts
      - Admit the new object into window (W)
      - Record last access
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_bytes_W

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Record this access in TinyLFU
    _cm_increment(k, 1)

    # Adapt window target based on ghosts
    _adapt_targets_on_insert(cache_snapshot, obj)

    # Initialize metadata in window
    m_key_segment[k] = 'W'
    m_key_last_access[k] = cache_snapshot.access_count
    # No priority needed in W; clear any stale
    m_key_priority.pop(k, None)

    # Account bytes in window
    m_bytes_W += sz


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - If victim was in main (M), set L_M to victim's priority (GreedyDual aging)
      - Remove resident metadata
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_age_M, m_bytes_W, m_bytes_M
    global m_ghost_W, m_ghost_M

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'W')  # default to window if unknown
    # Use stored priority for main; if missing, approximate using current age + TinyLFU score
    if seg == 'M':
        evicted_prio = m_key_priority.get(ek)
        if evicted_prio is None:
            evicted_prio = m_age_M + _score_freq_size(ek, esz)
        # Age update for main
        m_age_M = evicted_prio

    # Cleanup resident metadata
    m_key_priority.pop(ek, None)
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes and add to appropriate ghost
    if seg == 'M':
        m_bytes_M = max(0, m_bytes_M - esz)
        _ghost_add(m_ghost_M, ek, esz, cache_snapshot.access_count, is_W=False)
    else:
        m_bytes_W = max(0, m_bytes_W - esz)
        _ghost_add(m_ghost_W, ek, esz, cache_snapshot.access_count, is_W=True)
```
2025-11-27 18:15:15,963 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented GreedyDual-Size-Frequency (SGDSF) with ARC-style adaptive split
# - Two resident segments by bytes:
#     P (probation): admits all new objects; mostly recency-driven
#     S (protected): holds objects that hit at least once; more frequency-driven
# - Within each segment, eviction is GreedyDual-Size-Frequency:
#     H = L_seg + freq/size, with L_seg aged to the evicted item's priority
# - Adaptive split between P and S using ARC-like ghost lists:
#     On insert of a key found in P-ghost (recency ghost) => increase probation share
#     On insert of a key found in S-ghost (frequency ghost) => increase protected share
# - LRU tie-breaks within the chosen segment
#
# This design protects repeatedly-used items (S) from one-hit-wonders (P),
# is size-aware, ages priorities to combat stale items, and adapts online
# between recency- and frequency-friendly behavior.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_priority = dict()      # key -> float priority H
m_key_freq = dict()          # key -> int (resident frequency, incremented on hits)
m_key_last_access = dict()   # key -> int access_count (for LRU tie-breaks)
m_key_segment = dict()       # key -> 'P' (probation) or 'S' (protected)

# Segment ages (for GreedyDual aging)
m_age_P = 0.0
m_age_S = 0.0

# Current resident bytes per segment
m_bytes_P = 0
m_bytes_S = 0

# Adaptive target for protected bytes (S); probation target = capacity - target_S
m_target_S_bytes = None

# Ghost lists (non-resident metadata) to adapt split; store key -> (size, last_time)
m_ghost_P = dict()
m_ghost_S = dict()
m_ghost_P_bytes = 0
m_ghost_S_bytes = 0

# Ghost size limit (in bytes) per list; lazily set to capacity
m_ghost_limit_bytes = None


# -----------------------------
# Helpers
# -----------------------------

def _compute_priority(size, freq, age_L):
    # Priority H = L + freq/size
    return age_L + (float(freq) / float(size))


def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_S_bytes, m_ghost_limit_bytes
    if m_target_S_bytes is None:
        # Start with 50% protected, 50% probation by bytes; will adapt online
        m_target_S_bytes = cache_snapshot.capacity * 0.5
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cache_snapshot.capacity


def _pick_min_in_segment(cache_snapshot, seg_tag):
    # Returns (key, prio, last_time) of the minimum-priority key in a segment
    global m_key_priority, m_key_last_access, m_key_segment, m_age_P, m_age_S

    min_key = None
    min_prio = None
    min_time = None

    # Default age if priority missing (rare): use segment age so missing ones compare fairly
    default_age = m_age_P if seg_tag == 'P' else m_age_S

    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        prio = m_key_priority.get(key, default_age)
        last = m_key_last_access.get(key, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_prio = prio
            min_time = last
            min_key = key

    return (min_key, min_prio, min_time)


def _ghost_add(ghost_dict, key, size, time_now, is_P):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_P_bytes, m_ghost_S_bytes, m_ghost_limit_bytes

    if is_P:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_P_bytes += size
        else:
            # refresh time; adjust bytes if size changed (unlikely)
            old_size, _ = prev
            m_ghost_P_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_P_bytes > (m_ghost_limit_bytes or 0):
            # evict oldest by time
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_P_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_S_bytes += size
        else:
            old_size, _ = prev
            m_ghost_S_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_S_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_S_bytes -= sz


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    global m_ghost_P, m_ghost_S, m_ghost_P_bytes, m_ghost_S_bytes, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step size proportional to object size (bounded), which is standard in size-aware ARC variants
    step = obj.size

    if obj.key in m_ghost_P:
        # Recent ghost hit: recency pressure -> increase probation share (decrease protected target)
        m_target_S_bytes = _clamp(m_target_S_bytes - step, 0, cap)
        # Remove from ghost_P to avoid repeated adjustments
        sz, _ = m_ghost_P.pop(obj.key)
        m_ghost_P_bytes -= sz
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: frequency pressure -> increase protected share
        m_target_S_bytes = _clamp(m_target_S_bytes + step, 0, cap)
        sz, _ = m_ghost_S.pop(obj.key)
        m_ghost_S_bytes -= sz


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using Segmented GDSF with adaptive split.
    Prefer evicting from the segment exceeding its byte target, else evict the global min H.
    LRU is used as a tie-breaker within each segment.
    '''
    global m_bytes_P, m_bytes_S, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    # Compute segment byte targets
    cap = cache_snapshot.capacity
    target_S = _clamp(m_target_S_bytes, 0, cap)
    target_P = cap - target_S

    # Find min in each segment
    p_key, p_prio, p_lru = _pick_min_in_segment(cache_snapshot, 'P')
    s_key, s_prio, s_lru = _pick_min_in_segment(cache_snapshot, 'S')

    # Decide which segment to evict from
    evict_from_P = False
    evict_from_S = False

    # If a segment is over its byte target, evict from it
    if m_bytes_P > target_P and p_key is not None:
        evict_from_P = True
    elif m_bytes_S > target_S and s_key is not None:
        evict_from_S = True
    else:
        # Neither segment over target; choose the global minimum priority among available candidates
        if p_key is not None and s_key is not None:
            if (p_prio < s_prio) or (p_prio == s_prio and p_lru < s_lru):
                evict_from_P = True
            else:
                evict_from_S = True
        elif p_key is not None:
            evict_from_P = True
        elif s_key is not None:
            evict_from_S = True

    candid_key = None
    if evict_from_P and p_key is not None:
        candid_key = p_key
    elif evict_from_S and s_key is not None:
        candid_key = s_key

    # Fallback: if no segment candidate found (should not happen), fall back to global min over all
    if candid_key is None:
        # Choose the least priority over both segments
        min_key, min_prio, min_time = None, None, None
        for key in cache_snapshot.cache.keys():
            prio = m_key_priority.get(key, 0.0)
            last = m_key_last_access.get(key, -1)
            if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
                min_key, min_prio, min_time = key, prio, last
        candid_key = min_key if min_key is not None else next(iter(cache_snapshot.cache))

    return candid_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment resident frequency
      - If in probation (P), promote to protected (S)
      - Recompute priority using the segment's current age L
      - Refresh last-access time
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_age_P, m_age_S, m_bytes_P, m_bytes_S

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size
    m_key_last_access[k] = cache_snapshot.access_count
    m_key_freq[k] = m_key_freq.get(k, 0) + 1

    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        # Promote on first re-reference to protected segment
        m_key_segment[k] = 'S'
        # Move bytes P -> S (guard against negatives)
        m_bytes_P = max(0, m_bytes_P - sz)
        m_bytes_S += sz
        # Recompute priority in S with S's age
        m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_S)
    else:
        # Already protected: reinforce priority with current S age
        m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_S)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S byte split using ARC-like ghosts
      - Add the new object to probation (P) with freq = 1, priority H = L_P + 1/size
      - Record last access
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_bytes_P

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists (ARC-like)
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    sz = obj.size

    # Initialize metadata (new admit to probation)
    m_key_freq[k] = 1
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_P)

    # Account bytes in probation
    m_bytes_P += sz


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Update the corresponding segment age L to the victim's priority (GreedyDual aging)
      - Remove resident metadata for that key
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_age_P, m_age_S, m_bytes_P, m_bytes_S
    global m_ghost_P, m_ghost_S

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown
    # Use the stored priority or the segment age as a fallback
    evicted_prio = m_key_priority.get(ek, m_age_P if seg == 'P' else m_age_S)

    # Age update for the evicting segment
    if seg == 'S':
        m_age_S = evicted_prio
    else:
        m_age_P = evicted_prio

    # Cleanup resident metadata
    m_key_priority.pop(ek, None)
    m_key_freq.pop(ek, None)
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes
    if seg == 'S':
        m_bytes_S = max(0, m_bytes_S - esz)
        # Add to S ghost
        _ghost_add(m_ghost_S, ek, esz, cache_snapshot.access_count, is_P=False)
    else:
        m_bytes_P = max(0, m_bytes_P - esz)
        # Add to P ghost
        _ghost_add(m_ghost_P, ek, esz, cache_snapshot.access_count, is_P=True)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 20
- Hit Rate: 0.3913

Example 2:
- Trace ID: 24
- Hit Rate: 0.274

Example 3:
- Trace ID: 5
- Hit Rate: 0.4155

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m18:15:15 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 18:15:15,964 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m18:17:38 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 18:17:38,808 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 18:17:38,809 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Size-aware SLRU with decayed frequency in protected segment and ARC-style adaptive split
#
# Design summary:
# - Two resident byte-segments:
#     P (probation): all new objects enter here, managed by LRU (recency-driven).
#     S (protected): objects promoted from P on a hit, managed by LFU-style utility
#       (frequency per byte) with exponential decay to avoid stale pinning.
# - Eviction preference:
#     Prefer evicting from P. If P is empty or S exceeds its byte target, evict from S.
# - In S, we evict the object with the smallest decayed utility = freq / size.
# - Adaptive byte split between P and S (ARC-like):
#     On insert, if the key appears in P-ghost => increase P share (decrease S target).
#                if the key appears in S-ghost => increase S share (increase S target).
# - On hit in P, promote to S; if S exceeds its byte target, demote S's LRU item back to P.
# - Exponential decay of per-key frequency (in S) using epochs to control staleness without
#   global scans. Frequencies are floats and decayed lazily on touch and when comparing victims.
#
# This policy keeps a large protected region for repeatedly-used items, uses size-aware
# LFU-like eviction in S, keeps admission simple (SLRU), and prevents stale items from
# pinning via decay. Ghost lists adapt the P/S split online between recency and frequency.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_freq = dict()            # key -> float (decayed frequency)
m_key_freq_epoch = dict()      # key -> int (epoch when freq was last refreshed)
m_key_last_access = dict()     # key -> int access_count (LRU)
m_key_segment = dict()         # key -> 'P' or 'S'

# Current resident bytes per segment
m_bytes_P = 0
m_bytes_S = 0

# Adaptive target for protected bytes (S); probation target = capacity - target_S
m_target_S_bytes = None

# Ghost lists (non-resident metadata) for adaptive split; key -> (size, last_time)
m_ghost_P = dict()
m_ghost_S = dict()
m_ghost_P_bytes = 0
m_ghost_S_bytes = 0
m_ghost_limit_bytes = None

# Frequency decay parameters (epoch-based)
m_epoch_span = 4096            # accesses per epoch (power-of-two friendly)
m_decay_factor = 0.5           # freq *= (0.5)^(delta_epochs)

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_target_S_bytes, m_ghost_limit_bytes
    if m_target_S_bytes is None:
        # Start with 80% protected; adapts online via ghosts
        m_target_S_bytes = cache_snapshot.capacity * 0.8
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cache_snapshot.capacity


def _current_epoch(cache_snapshot):
    # Integer epoch index derived from access count
    return int(cache_snapshot.access_count // max(1, m_epoch_span))


def _decay_key_freq_if_needed(k, now_epoch):
    # Lazily decay the key's frequency to the current epoch
    last_ep = m_key_freq_epoch.get(k, now_epoch)
    delta = now_epoch - last_ep
    if delta > 0:
        # Apply decay
        f = m_key_freq.get(k, 0.0)
        if f > 0.0:
            f *= (m_decay_factor ** delta)
            # Floor small noise
            if f < 1e-6:
                f = 0.0
            m_key_freq[k] = f
        m_key_freq_epoch[k] = now_epoch


def _ghost_add(ghost_dict, key, size, time_now, is_P):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_P_bytes, m_ghost_S_bytes, m_ghost_limit_bytes

    limit = (m_ghost_limit_bytes or 0)
    if is_P:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_P_bytes += size
        else:
            old_size, _ = prev
            m_ghost_P_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim oldest by time
        while m_ghost_P_bytes > limit and ghost_dict:
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_P_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_S_bytes += size
        else:
            old_size, _ = prev
            m_ghost_S_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        while m_ghost_S_bytes > limit and ghost_dict:
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_S_bytes -= sz


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    global m_target_S_bytes, m_ghost_P, m_ghost_S, m_ghost_P_bytes, m_ghost_S_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step size proportional to object size but capped to 10% of capacity
    step = min(obj.size, max(1, int(0.1 * cap)))

    if obj.key in m_ghost_P:
        # Recent eviction from probation => increase P share (reduce S target)
        m_target_S_bytes = _clamp(m_target_S_bytes - step, 0, cap)
        sz, _ = m_ghost_P.pop(obj.key)
        m_ghost_P_bytes -= sz
    elif obj.key in m_ghost_S:
        # Eviction from protected followed by reuse => increase S share
        m_target_S_bytes = _clamp(m_target_S_bytes + step, 0, cap)
        sz, _ = m_ghost_S.pop(obj.key)
        m_ghost_S_bytes -= sz


def _pick_lru_in_segment(cache_snapshot, seg_tag):
    # Returns (key, last_time) of the oldest (LRU) key in the segment
    min_key, min_time = None, None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != seg_tag:
            continue
        last = m_key_last_access.get(key, -1)
        if (min_time is None) or (last < min_time):
            min_key, min_time = key, last
    return (min_key, min_time)


def _pick_min_utility_in_S(cache_snapshot):
    # Choose S victim by minimum decayed utility = freq / size; tie-break by LRU
    now_epoch = _current_epoch(cache_snapshot)
    min_key, min_util, min_time = None, None, None
    for key, obj in cache_snapshot.cache.items():
        if m_key_segment.get(key) != 'S':
            continue
        _decay_key_freq_if_needed(key, now_epoch)
        f = m_key_freq.get(key, 0.0)
        sz = obj.size if obj is not None else 1
        util = f / float(sz)
        last = m_key_last_access.get(key, -1)
        if (min_util is None) or (util < min_util) or (util == min_util and last < min_time):
            min_key, min_util, min_time = key, util, last
    return (min_key, min_util, min_time)


def _demote_from_S_to_P_if_needed(cache_snapshot):
    # If S is over target, demote S's LRU item(s) to P to respect target split
    global m_bytes_S, m_bytes_P
    _init_if_needed(cache_snapshot)
    cap = cache_snapshot.capacity
    target_S = _clamp(m_target_S_bytes, 0, cap)

    # Demote until S within target or S empty
    # To avoid thrashing, demote at most a few items per call
    max_moves = 2
    moves = 0
    while m_bytes_S > target_S and moves < max_moves:
        key, _ = _pick_lru_in_segment(cache_snapshot, 'S')
        if key is None:
            break
        # Move metadata and bytes
        obj = cache_snapshot.cache.get(key)
        if obj is None:
            break
        sz = obj.size
        m_key_segment[key] = 'P'
        m_bytes_S = max(0, m_bytes_S - sz)
        m_bytes_P += sz
        # Slightly dampen its frequency to reflect demotion
        now_epoch = _current_epoch(cache_snapshot)
        _decay_key_freq_if_needed(key, now_epoch)
        m_key_freq[key] = max(0.0, m_key_freq.get(key, 0.0) * 0.5)
        moves += 1


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Eviction policy:
      - Prefer evicting from probation (P) using LRU.
      - If P is empty OR S is above its target, evict from protected (S) the key with
        the lowest decayed utility (freq/size). Tie-break by LRU.
    '''
    global m_bytes_P, m_bytes_S, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    target_S = _clamp(m_target_S_bytes, 0, cap)

    # Decide which segment to evict from
    evict_from_S = False
    if m_bytes_P <= 0:
        evict_from_S = True
    elif m_bytes_S > target_S:
        evict_from_S = True

    if evict_from_S:
        s_key, _, _ = _pick_min_utility_in_S(cache_snapshot)
        if s_key is not None:
            return s_key
        # Fallback to P if S is empty
        p_key, _ = _pick_lru_in_segment(cache_snapshot, 'P')
        if p_key is not None:
            return p_key
    else:
        p_key, _ = _pick_lru_in_segment(cache_snapshot, 'P')
        if p_key is not None:
            return p_key
        # Fallback to S if P is empty
        s_key, _, _ = _pick_min_utility_in_S(cache_snapshot)
        if s_key is not None:
            return s_key

    # Final fallback: return any key
    for k in cache_snapshot.cache.keys():
        return k
    return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Refresh last-access time.
      - Decay and then increment frequency by 1.
      - If in probation (P), promote to protected (S).
      - If S exceeds its target bytes, demote S's LRU back to P to honor the split.
    '''
    global m_key_freq, m_key_freq_epoch, m_key_last_access, m_key_segment
    global m_bytes_P, m_bytes_S

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size
    now = cache_snapshot.access_count
    now_epoch = _current_epoch(cache_snapshot)

    m_key_last_access[k] = now

    # Update decayed frequency then increment
    _decay_key_freq_if_needed(k, now_epoch)
    m_key_freq[k] = m_key_freq.get(k, 0.0) + 1.0
    m_key_freq_epoch[k] = now_epoch

    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        # Promote to protected
        m_key_segment[k] = 'S'
        m_bytes_P = max(0, m_bytes_P - sz)
        m_bytes_S += sz
        # Keep last_access and frequency as updated
        _demote_from_S_to_P_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S byte split using ARC-like ghosts.
      - Place the new object in probation (P) with freq = 1 (decayed freq framework).
      - Initialize last-access and epoch metadata.
    '''
    global m_key_freq, m_key_freq_epoch, m_key_last_access, m_key_segment
    global m_bytes_P

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists (ARC-like)
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    now = cache_snapshot.access_count
    now_epoch = _current_epoch(cache_snapshot)

    # Initialize metadata for new admit to probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = now
    m_key_freq[k] = 1.0
    m_key_freq_epoch[k] = now_epoch

    # Account bytes in probation
    m_bytes_P += obj.size


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key.
      - Update segment byte counters.
      - Add the key to the corresponding ghost list (P-ghost or S-ghost) to guide adaptation.
    '''
    global m_key_freq, m_key_freq_epoch, m_key_last_access, m_key_segment
    global m_bytes_P, m_bytes_S
    global m_ghost_P, m_ghost_S

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size
    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Cleanup resident metadata
    m_key_freq.pop(ek, None)
    m_key_freq_epoch.pop(ek, None)
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes
    if seg == 'S':
        m_bytes_S = max(0, m_bytes_S - esz)
        _ghost_add(m_ghost_S, ek, esz, cache_snapshot.access_count, is_P=False)
    else:
        m_bytes_P = max(0, m_bytes_P - esz)
        _ghost_add(m_ghost_P, ek, esz, cache_snapshot.access_count, is_P=True)
```
2025-11-27 18:18:12,321 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented GreedyDual-Size-Frequency (SGDSF) with ARC-style adaptive split
# - Two resident segments by bytes:
#     P (probation): admits all new objects; mostly recency-driven
#     S (protected): holds objects that hit at least once; more frequency-driven
# - Within each segment, eviction is GreedyDual-Size-Frequency:
#     H = L_seg + freq/size, with L_seg aged to the evicted item's priority
# - Adaptive split between P and S using ARC-like ghost lists:
#     On insert of a key found in P-ghost (recency ghost) => increase probation share
#     On insert of a key found in S-ghost (frequency ghost) => increase protected share
# - LRU tie-breaks within the chosen segment
#
# This design protects repeatedly-used items (S) from one-hit-wonders (P),
# is size-aware, ages priorities to combat stale items, and adapts online
# between recency- and frequency-friendly behavior.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_priority = dict()      # key -> float priority H
m_key_freq = dict()          # key -> int (resident frequency, incremented on hits)
m_key_last_access = dict()   # key -> int access_count (for LRU tie-breaks)
m_key_segment = dict()       # key -> 'P' (probation) or 'S' (protected)

# Segment ages (for GreedyDual aging)
m_age_P = 0.0
m_age_S = 0.0

# Current resident bytes per segment
m_bytes_P = 0
m_bytes_S = 0

# Adaptive target for protected bytes (S); probation target = capacity - target_S
m_target_S_bytes = None

# Ghost lists (non-resident metadata) to adapt split; store key -> (size, last_time)
m_ghost_P = dict()
m_ghost_S = dict()
m_ghost_P_bytes = 0
m_ghost_S_bytes = 0

# Ghost size limit (in bytes) per list; lazily set to capacity
m_ghost_limit_bytes = None


# -----------------------------
# Helpers
# -----------------------------

def _compute_priority(size, freq, age_L):
    # Priority H = L + freq/size
    return age_L + (float(freq) / float(size))


def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_S_bytes, m_ghost_limit_bytes
    if m_target_S_bytes is None:
        # Start with 50% protected, 50% probation by bytes; will adapt online
        m_target_S_bytes = cache_snapshot.capacity * 0.5
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cache_snapshot.capacity


def _pick_min_in_segment(cache_snapshot, seg_tag):
    # Returns (key, prio, last_time) of the minimum-priority key in a segment
    global m_key_priority, m_key_last_access, m_key_segment, m_age_P, m_age_S

    min_key = None
    min_prio = None
    min_time = None

    # Default age if priority missing (rare): use segment age so missing ones compare fairly
    default_age = m_age_P if seg_tag == 'P' else m_age_S

    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        prio = m_key_priority.get(key, default_age)
        last = m_key_last_access.get(key, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_prio = prio
            min_time = last
            min_key = key

    return (min_key, min_prio, min_time)


def _ghost_add(ghost_dict, key, size, time_now, is_P):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_P_bytes, m_ghost_S_bytes, m_ghost_limit_bytes

    if is_P:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_P_bytes += size
        else:
            # refresh time; adjust bytes if size changed (unlikely)
            old_size, _ = prev
            m_ghost_P_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_P_bytes > (m_ghost_limit_bytes or 0):
            # evict oldest by time
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_P_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_S_bytes += size
        else:
            old_size, _ = prev
            m_ghost_S_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_S_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_S_bytes -= sz


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    global m_ghost_P, m_ghost_S, m_ghost_P_bytes, m_ghost_S_bytes, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step size proportional to object size (bounded), which is standard in size-aware ARC variants
    step = obj.size

    if obj.key in m_ghost_P:
        # Recent ghost hit: recency pressure -> increase probation share (decrease protected target)
        m_target_S_bytes = _clamp(m_target_S_bytes - step, 0, cap)
        # Remove from ghost_P to avoid repeated adjustments
        sz, _ = m_ghost_P.pop(obj.key)
        m_ghost_P_bytes -= sz
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: frequency pressure -> increase protected share
        m_target_S_bytes = _clamp(m_target_S_bytes + step, 0, cap)
        sz, _ = m_ghost_S.pop(obj.key)
        m_ghost_S_bytes -= sz


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using Segmented GDSF with adaptive split.
    Prefer evicting from the segment exceeding its byte target, else evict the global min H.
    LRU is used as a tie-breaker within each segment.
    '''
    global m_bytes_P, m_bytes_S, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    # Compute segment byte targets
    cap = cache_snapshot.capacity
    target_S = _clamp(m_target_S_bytes, 0, cap)
    target_P = cap - target_S

    # Find min in each segment
    p_key, p_prio, p_lru = _pick_min_in_segment(cache_snapshot, 'P')
    s_key, s_prio, s_lru = _pick_min_in_segment(cache_snapshot, 'S')

    # Decide which segment to evict from
    evict_from_P = False
    evict_from_S = False

    # If a segment is over its byte target, evict from it
    if m_bytes_P > target_P and p_key is not None:
        evict_from_P = True
    elif m_bytes_S > target_S and s_key is not None:
        evict_from_S = True
    else:
        # Neither segment over target; choose the global minimum priority among available candidates
        if p_key is not None and s_key is not None:
            if (p_prio < s_prio) or (p_prio == s_prio and p_lru < s_lru):
                evict_from_P = True
            else:
                evict_from_S = True
        elif p_key is not None:
            evict_from_P = True
        elif s_key is not None:
            evict_from_S = True

    candid_key = None
    if evict_from_P and p_key is not None:
        candid_key = p_key
    elif evict_from_S and s_key is not None:
        candid_key = s_key

    # Fallback: if no segment candidate found (should not happen), fall back to global min over all
    if candid_key is None:
        # Choose the least priority over both segments
        min_key, min_prio, min_time = None, None, None
        for key in cache_snapshot.cache.keys():
            prio = m_key_priority.get(key, 0.0)
            last = m_key_last_access.get(key, -1)
            if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
                min_key, min_prio, min_time = key, prio, last
        candid_key = min_key if min_key is not None else next(iter(cache_snapshot.cache))

    return candid_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment resident frequency
      - If in probation (P), promote to protected (S)
      - Recompute priority using the segment's current age L
      - Refresh last-access time
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_age_P, m_age_S, m_bytes_P, m_bytes_S

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size
    m_key_last_access[k] = cache_snapshot.access_count
    m_key_freq[k] = m_key_freq.get(k, 0) + 1

    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        # Promote on first re-reference to protected segment
        m_key_segment[k] = 'S'
        # Move bytes P -> S (guard against negatives)
        m_bytes_P = max(0, m_bytes_P - sz)
        m_bytes_S += sz
        # Recompute priority in S with S's age
        m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_S)
    else:
        # Already protected: reinforce priority with current S age
        m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_S)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S byte split using ARC-like ghosts
      - Add the new object to probation (P) with freq = 1, priority H = L_P + 1/size
      - Record last access
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_bytes_P

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists (ARC-like)
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    sz = obj.size

    # Initialize metadata (new admit to probation)
    m_key_freq[k] = 1
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_P)

    # Account bytes in probation
    m_bytes_P += sz


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Update the corresponding segment age L to the victim's priority (GreedyDual aging)
      - Remove resident metadata for that key
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_age_P, m_age_S, m_bytes_P, m_bytes_S
    global m_ghost_P, m_ghost_S

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown
    # Use the stored priority or the segment age as a fallback
    evicted_prio = m_key_priority.get(ek, m_age_P if seg == 'P' else m_age_S)

    # Age update for the evicting segment
    if seg == 'S':
        m_age_S = evicted_prio
    else:
        m_age_P = evicted_prio

    # Cleanup resident metadata
    m_key_priority.pop(ek, None)
    m_key_freq.pop(ek, None)
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes
    if seg == 'S':
        m_bytes_S = max(0, m_bytes_S - esz)
        # Add to S ghost
        _ghost_add(m_ghost_S, ek, esz, cache_snapshot.access_count, is_P=False)
    else:
        m_bytes_P = max(0, m_bytes_P - esz)
        # Add to P ghost
        _ghost_add(m_ghost_P, ek, esz, cache_snapshot.access_count, is_P=True)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 38
- Hit Rate: 0.1255

Example 2:
- Trace ID: 11
- Hit Rate: 0.2735

Example 3:
- Trace ID: 23
- Hit Rate: 0.0587

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m18:18:12 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 18:18:12,322 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m18:20:25 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 18:20:25,842 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 18:20:25,843 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# W-TinyLFU-style SLRU with size-aware eviction and ARC-like adaptive P/S split
# - Two resident segments by bytes:
#     P (probation): admits all new objects; managed by LRU (via last_access timestamps)
#     S (protected): objects that hit at least once; also LRU-managed
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction is size-aware: minimize estimated harm est_freq(key)/size(key)
#   and bias toward evicting from P unless S object is clearly worse.
# - ARC-like ghost lists adapt the byte split between P and S online.
#
# This design captures:
#   - Recency (via LRU within segments)
#   - Frequency (via TinyLFU)
#   - Size-awareness (benefit ~ freq/size)
#   - Adaptivity between recency-friendly and frequency-friendly behavior

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU)
m_key_segment = dict()       # key -> 'P' or 'S'

# Current resident bytes per segment
m_bytes_P = 0
m_bytes_S = 0

# Adaptive target for protected bytes (S); probation target = capacity - target_S
m_target_S_bytes = None

# Ghost lists (non-resident metadata) to adapt split; store key -> (size, last_time)
m_ghost_P = dict()
m_ghost_S = dict()
m_ghost_P_bytes = 0
m_ghost_S_bytes = 0
m_ghost_limit_bytes = None

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)


# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_S_bytes, m_ghost_limit_bytes
    global m_sketch_tables, m_sketch_mask

    if m_target_S_bytes is None:
        # Start a bit frequency-friendly; adapt online
        m_target_S_bytes = cache_snapshot.capacity * 0.6
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cache_snapshot.capacity

    if m_sketch_tables is None:
        # Width scales with capacity; choose power of two near capacity/64 (to limit memory)
        # Minimum width to keep estimates reasonably stable.
        cap = max(1, cache_snapshot.capacity)
        width = 1
        target = max(1024, min(1 << 16, cap // 64))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        # Increment with cap
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        # Halve all counters (right-shift by 1)
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _pick_min_score_in_segment(cache_snapshot, seg_tag):
    # Returns (key, score, last_time) for the minimum TinyLFU score in a segment
    # Score = est_freq(key) / size(key); tie-break by LRU (older first)
    min_key = None
    min_score = None
    min_time = None

    for key, obj in cache_snapshot.cache.items():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        sz = max(1, obj.size)
        est = _sketch_estimate(key)
        score = float(est) / float(sz)
        last = m_key_last_access.get(key, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = key
            min_score = score
            min_time = last

    return (min_key, min_score, min_time)


def _ghost_add(ghost_dict, key, size, time_now, is_P):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_P_bytes, m_ghost_S_bytes, m_ghost_limit_bytes

    if is_P:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_P_bytes += size
        else:
            old_size, _ = prev
            m_ghost_P_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim oldest by time
        while m_ghost_P_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_P_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_S_bytes += size
        else:
            old_size, _ = prev
            m_ghost_S_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        while m_ghost_S_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_S_bytes -= sz


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    global m_ghost_P, m_ghost_S, m_ghost_P_bytes, m_ghost_S_bytes, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step size proportional to object size, bounded to avoid huge jumps
    step = min(obj.size, cap // 4 if cap >= 4 else obj.size)

    if obj.key in m_ghost_P:
        # Recent ghost hit: increase P share (decrease protected)
        m_target_S_bytes = _clamp(m_target_S_bytes - step, 0, cap)
        sz, _ = m_ghost_P.pop(obj.key)
        m_ghost_P_bytes -= sz
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: increase S share
        m_target_S_bytes = _clamp(m_target_S_bytes + step, 0, cap)
        sz, _ = m_ghost_S.pop(obj.key)
        m_ghost_S_bytes -= sz


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using size-aware SLRU + TinyLFU.
    - Compute candidate with minimal TinyLFU score (est_freq/size) in each segment.
    - Bias to evict from the segment exceeding its byte target.
    - Protect S moderately by adding a small bias compared to P.
    - Size-aware: lower freq and larger size are preferred victims.
    '''
    global m_bytes_P, m_bytes_S, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    target_S = _clamp(m_target_S_bytes, 0, cap)
    target_P = cap - target_S

    # Find min-score candidate in each segment
    p_key, p_score, p_lru = _pick_min_score_in_segment(cache_snapshot, 'P')
    s_key, s_score, s_lru = _pick_min_score_in_segment(cache_snapshot, 'S')

    # Estimate the incoming object's benefit (normalized by size)
    incoming_score = float(_sketch_estimate(obj.key) + 1) / float(max(1, obj.size))

    # Segment bias and overweight nudges scaled to incoming_score for stability
    protect_S_bias = incoming_score * 0.15   # discourage evicting S slightly
    overweight_nudge = incoming_score * 0.10 # encourage evicting overweight segment

    # Compute adjusted scores for decision
    best_key = None
    best_adj = None

    if p_key is not None:
        adj_p = p_score
        if m_bytes_P > target_P:
            adj_p -= overweight_nudge
        # Tie-break: older gets slight advantage
        adj_p -= 1e-12 * (p_lru if p_lru is not None else 0)
        best_key = p_key
        best_adj = adj_p

    if s_key is not None:
        adj_s = s_score + protect_S_bias
        if m_bytes_S > target_S:
            adj_s -= overweight_nudge
        adj_s -= 1e-12 * (s_lru if s_lru is not None else 0)
        if (best_adj is None) or (adj_s < best_adj):
            best_adj = adj_s
            best_key = s_key

    # Fallback: if we somehow didn't find any key (shouldn't happen), pick oldest globally
    if best_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        best_key = oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - If in probation (P), promote to protected (S) and move bytes
    '''
    global m_key_last_access, m_key_segment
    global m_bytes_P, m_bytes_S

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Update TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    # Promote from P to S on hit
    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        m_key_segment[k] = 'S'
        # Move bytes P -> S
        m_bytes_P = max(0, m_bytes_P - sz)
        m_bytes_S += sz


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S byte split using ARC-like ghosts
      - Increment TinyLFU for the key (TinyLFU trains on both hits and misses)
      - Add the new object to probation (P)
      - Record last access time
    '''
    global m_key_last_access, m_key_segment
    global m_bytes_P

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    sz = obj.size

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_bytes_P += sz


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
    '''
    global m_key_last_access, m_key_segment
    global m_bytes_P, m_bytes_S
    global m_ghost_P, m_ghost_S

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes and add to appropriate ghost
    if seg == 'S':
        m_bytes_S = max(0, m_bytes_S - esz)
        _ghost_add(m_ghost_S, ek, esz, cache_snapshot.access_count, is_P=False)
    else:
        m_bytes_P = max(0, m_bytes_P - esz)
        _ghost_add(m_ghost_P, ek, esz, cache_snapshot.access_count, is_P=True)
```
2025-11-27 18:26:09,159 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented GreedyDual-Size-Frequency (SGDSF) with ARC-style adaptive split
# - Two resident segments by bytes:
#     P (probation): admits all new objects; mostly recency-driven
#     S (protected): holds objects that hit at least once; more frequency-driven
# - Within each segment, eviction is GreedyDual-Size-Frequency:
#     H = L_seg + freq/size, with L_seg aged to the evicted item's priority
# - Adaptive split between P and S using ARC-like ghost lists:
#     On insert of a key found in P-ghost (recency ghost) => increase probation share
#     On insert of a key found in S-ghost (frequency ghost) => increase protected share
# - LRU tie-breaks within the chosen segment
#
# This design protects repeatedly-used items (S) from one-hit-wonders (P),
# is size-aware, ages priorities to combat stale items, and adapts online
# between recency- and frequency-friendly behavior.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_priority = dict()      # key -> float priority H
m_key_freq = dict()          # key -> int (resident frequency, incremented on hits)
m_key_last_access = dict()   # key -> int access_count (for LRU tie-breaks)
m_key_segment = dict()       # key -> 'P' (probation) or 'S' (protected)

# Segment ages (for GreedyDual aging)
m_age_P = 0.0
m_age_S = 0.0

# Current resident bytes per segment
m_bytes_P = 0
m_bytes_S = 0

# Adaptive target for protected bytes (S); probation target = capacity - target_S
m_target_S_bytes = None

# Ghost lists (non-resident metadata) to adapt split; store key -> (size, last_time)
m_ghost_P = dict()
m_ghost_S = dict()
m_ghost_P_bytes = 0
m_ghost_S_bytes = 0

# Ghost size limit (in bytes) per list; lazily set to capacity
m_ghost_limit_bytes = None


# -----------------------------
# Helpers
# -----------------------------

def _compute_priority(size, freq, age_L):
    # Priority H = L + freq/size
    return age_L + (float(freq) / float(size))


def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_S_bytes, m_ghost_limit_bytes
    if m_target_S_bytes is None:
        # Start with 50% protected, 50% probation by bytes; will adapt online
        m_target_S_bytes = cache_snapshot.capacity * 0.5
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cache_snapshot.capacity


def _pick_min_in_segment(cache_snapshot, seg_tag):
    # Returns (key, prio, last_time) of the minimum-priority key in a segment
    global m_key_priority, m_key_last_access, m_key_segment, m_age_P, m_age_S

    min_key = None
    min_prio = None
    min_time = None

    # Default age if priority missing (rare): use segment age so missing ones compare fairly
    default_age = m_age_P if seg_tag == 'P' else m_age_S

    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        prio = m_key_priority.get(key, default_age)
        last = m_key_last_access.get(key, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_prio = prio
            min_time = last
            min_key = key

    return (min_key, min_prio, min_time)


def _ghost_add(ghost_dict, key, size, time_now, is_P):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_P_bytes, m_ghost_S_bytes, m_ghost_limit_bytes

    if is_P:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_P_bytes += size
        else:
            # refresh time; adjust bytes if size changed (unlikely)
            old_size, _ = prev
            m_ghost_P_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_P_bytes > (m_ghost_limit_bytes or 0):
            # evict oldest by time
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_P_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_S_bytes += size
        else:
            old_size, _ = prev
            m_ghost_S_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_S_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_S_bytes -= sz


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    global m_ghost_P, m_ghost_S, m_ghost_P_bytes, m_ghost_S_bytes, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step size proportional to object size (bounded), which is standard in size-aware ARC variants
    step = obj.size

    if obj.key in m_ghost_P:
        # Recent ghost hit: recency pressure -> increase probation share (decrease protected target)
        m_target_S_bytes = _clamp(m_target_S_bytes - step, 0, cap)
        # Remove from ghost_P to avoid repeated adjustments
        sz, _ = m_ghost_P.pop(obj.key)
        m_ghost_P_bytes -= sz
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: frequency pressure -> increase protected share
        m_target_S_bytes = _clamp(m_target_S_bytes + step, 0, cap)
        sz, _ = m_ghost_S.pop(obj.key)
        m_ghost_S_bytes -= sz


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using Segmented GDSF with adaptive split.
    Prefer evicting from the segment exceeding its byte target, else evict the global min H.
    LRU is used as a tie-breaker within each segment.
    '''
    global m_bytes_P, m_bytes_S, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    # Compute segment byte targets
    cap = cache_snapshot.capacity
    target_S = _clamp(m_target_S_bytes, 0, cap)
    target_P = cap - target_S

    # Find min in each segment
    p_key, p_prio, p_lru = _pick_min_in_segment(cache_snapshot, 'P')
    s_key, s_prio, s_lru = _pick_min_in_segment(cache_snapshot, 'S')

    # Decide which segment to evict from
    evict_from_P = False
    evict_from_S = False

    # If a segment is over its byte target, evict from it
    if m_bytes_P > target_P and p_key is not None:
        evict_from_P = True
    elif m_bytes_S > target_S and s_key is not None:
        evict_from_S = True
    else:
        # Neither segment over target; choose the global minimum priority among available candidates
        if p_key is not None and s_key is not None:
            if (p_prio < s_prio) or (p_prio == s_prio and p_lru < s_lru):
                evict_from_P = True
            else:
                evict_from_S = True
        elif p_key is not None:
            evict_from_P = True
        elif s_key is not None:
            evict_from_S = True

    candid_key = None
    if evict_from_P and p_key is not None:
        candid_key = p_key
    elif evict_from_S and s_key is not None:
        candid_key = s_key

    # Fallback: if no segment candidate found (should not happen), fall back to global min over all
    if candid_key is None:
        # Choose the least priority over both segments
        min_key, min_prio, min_time = None, None, None
        for key in cache_snapshot.cache.keys():
            prio = m_key_priority.get(key, 0.0)
            last = m_key_last_access.get(key, -1)
            if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
                min_key, min_prio, min_time = key, prio, last
        candid_key = min_key if min_key is not None else next(iter(cache_snapshot.cache))

    return candid_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment resident frequency
      - If in probation (P), promote to protected (S)
      - Recompute priority using the segment's current age L
      - Refresh last-access time
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_age_P, m_age_S, m_bytes_P, m_bytes_S

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size
    m_key_last_access[k] = cache_snapshot.access_count
    m_key_freq[k] = m_key_freq.get(k, 0) + 1

    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        # Promote on first re-reference to protected segment
        m_key_segment[k] = 'S'
        # Move bytes P -> S (guard against negatives)
        m_bytes_P = max(0, m_bytes_P - sz)
        m_bytes_S += sz
        # Recompute priority in S with S's age
        m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_S)
    else:
        # Already protected: reinforce priority with current S age
        m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_S)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S byte split using ARC-like ghosts
      - Add the new object to probation (P) with freq = 1, priority H = L_P + 1/size
      - Record last access
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_bytes_P

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists (ARC-like)
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    sz = obj.size

    # Initialize metadata (new admit to probation)
    m_key_freq[k] = 1
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_key_priority[k] = _compute_priority(sz, m_key_freq[k], m_age_P)

    # Account bytes in probation
    m_bytes_P += sz


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Update the corresponding segment age L to the victim's priority (GreedyDual aging)
      - Remove resident metadata for that key
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
    '''
    global m_key_priority, m_key_freq, m_key_last_access, m_key_segment
    global m_age_P, m_age_S, m_bytes_P, m_bytes_S
    global m_ghost_P, m_ghost_S

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown
    # Use the stored priority or the segment age as a fallback
    evicted_prio = m_key_priority.get(ek, m_age_P if seg == 'P' else m_age_S)

    # Age update for the evicting segment
    if seg == 'S':
        m_age_S = evicted_prio
    else:
        m_age_P = evicted_prio

    # Cleanup resident metadata
    m_key_priority.pop(ek, None)
    m_key_freq.pop(ek, None)
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes
    if seg == 'S':
        m_bytes_S = max(0, m_bytes_S - esz)
        # Add to S ghost
        _ghost_add(m_ghost_S, ek, esz, cache_snapshot.access_count, is_P=False)
    else:
        m_bytes_P = max(0, m_bytes_P - esz)
        # Add to P ghost
        _ghost_add(m_ghost_P, ek, esz, cache_snapshot.access_count, is_P=True)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 40
- Hit Rate: 0.0379

Example 2:
- Trace ID: 15
- Hit Rate: 0.0206

Example 3:
- Trace ID: 10
- Hit Rate: 0.075

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m18:26:09 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 18:26:09,161 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m18:30:10 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 18:30:10,624 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 18:30:10,626 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```
2025-11-27 18:36:03,800 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 21
- Error: Error - Timeout

Example 2:
- Trace ID: 46
- Hit Rate: 0.4663

Example 3:
- Trace ID: 3
- Hit Rate: 0.4404

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m18:36:03 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 18:36:03,802 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m18:39:03 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 18:39:03,158 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 18:39:03,159 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# W-TinyLFU + Segmented protection + Size-aware retention
# - Two logical segments:
#     1) probation (new/resurrected items)
#     2) protected (promoted on hit; byte-quota limited)
# - TinyLFU frequency counters with lazy epoch decay (8-bit saturating)
# - Size-aware retention: benefit = log1p(freq) / normalized_size
# - Recency bonus added (not subtracted) to protect recent items
# - Protected segment gets an extra bonus; demoted by LRU when over target bytes
# - Eviction uses lazy min-heaps (probation first, then protected) to avoid full scans
#   with lazy invalidation via per-key stamps; periodic score refresh on pop.
#
# This design:
#   - Dramatically reduces per-eviction cost (avoids O(n) scans) -> fewer timeouts
#   - Corrects recency sign (recent items are now protected, not penalized)
#   - Uses size-aware TinyLFU benefit and a protected segment to cut miss rate

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Cache identity (to reset between runs if needed)
m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting
m_prot_bytes = 0
m_prot_target_bytes = 0

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_probation = []           # retention score (lower => more evictable) for probation
h_protected = []           # retention score for protected (used when probation empty)
h_prot_lru = []            # last_access (min-heap) for protected demotions

# TinyLFU counters (lazy decay with epochs; per-key to keep it simple)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Protected segment target (bytes)
PROT_FRAC = 0.80           # target fraction of capacity for protected bytes

# Recency window and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 3           # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.60     # recency weight in probation
REC_WEIGHT_PROT = 0.40     # recency weight in protected
PROT_BONUS = 0.60          # extra benefit for protected segment
MULTI_HIT_BONUS = 0.30     # extra benefit for items with >=2 resident hits

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16  # bound reheap/refresh work per eviction

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC * cache_snapshot.capacity)

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Return size as percentage of capacity to keep scales stable
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _retention_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # treat missing as extremely good (will be filtered by validity)
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)

    seg = m_segment.get(key, 0)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    # Size-aware frequency benefit
    benefit = math.log1p(float(freq)) / size_norm

    # Multi-hit bias
    if m_resident_hits.get(key, 0) >= 2:
        benefit += MULTI_HIT_BONUS

    # Recency bonus
    if seg == 1:
        benefit += PROT_BONUS + REC_WEIGHT_PROT * rec_bonus
    else:
        benefit += REC_WEIGHT_PROB * rec_bonus

    return benefit


# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    # Compute score at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    score = _retention_score(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (score, s, key))
    else:
        heapq.heappush(h_protected, (score, s, key))
        # Also maintain LRU heap for protected demotions
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot, heap_ref, expected_seg):
    # Return a valid key from the given heap, refreshing stale scores when needed.
    # Limit work per call to avoid long stalls.
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        # Skip invalid/stale entries
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Opportunistically refresh score if it drifted
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            # Reinsert with a new stamp
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key
    return None


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        # Push into probation heap with updated score/stamp
        _push_key(cache_snapshot, key)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim:
      1) Pop the weakest from probation heap (lowest retention)
      2) If probation empty, pop the weakest from protected heap
      3) Fallback: any resident key
    '''
    _init_if_needed(cache_snapshot)

    # Prefer evicting from probation
    victim = _pop_best_candidate(cache_snapshot, h_probation, expected_seg=0)
    if victim is None:
        victim = _pop_best_candidate(cache_snapshot, h_protected, expected_seg=1)

    if victim is not None:
        return victim

    # Fallback: arbitrary key (should be rare)
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote probation -> protected on first resident hit
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with new score/recency
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote to protected
        m_segment[k] = 1
        # Account protected bytes
        global m_prot_bytes
        m_prot_bytes += obj.size
        # Push into protected heaps
        _push_key(cache_snapshot, k)
        # Enforce protected target
        _maybe_demote_protected(cache_snapshot)
    else:
        # Already protected: refresh heaps
        _push_key(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place into probation segment and push to heap
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation
    _push_key(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Adjust protected bytes if it was protected
    seg = m_segment.pop(ek, None)
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```
2025-11-27 18:41:51,522 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 9
- Hit Rate: 0.531

Example 2:
- Trace ID: 4
- Hit Rate: 0.5002

Example 3:
- Trace ID: 41
- Hit Rate: 0.178

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m18:41:51 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 18:41:51,523 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m18:45:15 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 18:45:15,814 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 18:45:15,815 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Segmented LRU + TinyLFU + Size-Aware (SLRU-TFS) eviction
# - 2 segments: probation (new/1-hit) and protected (multi-hit)
# - Evict from probation first; fallback to protected if probation empty
# - Priority blends TinyLFU frequency, LRU-2 recency, and size penalty
# - Lazy decayed TinyLFU (4-bit counters) remembered across evictions
# - Shadow queue (ghost entries) gives a second-chance boost on reappear
# - Incoming object's size biases toward evicting larger, colder objects

import math
from collections import deque

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()    # key -> last access time (int)
m_prev_access = dict()    # key -> previous access time (int) if any
m_resident_hits = dict()  # key -> int resident hit count (>=1 once inserted)
m_seg = dict()            # key -> 0 (probation) or 1 (protected)

# Shadow queue (ghost entries of recently evicted keys)
SHADOW_CAP = 8192
m_shadow = dict()         # key -> last seen time
m_shadow_fifo = deque()   # FIFO order for shadow eviction
m_shadow_hits = 0         # count of shadow hits (for potential future tuning)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()      # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # accesses between epochs (power of two recommended)

# -----------------------------
# Tunables (robust defaults)
# -----------------------------

# SLRU protected fraction (by item count)
PROT_FRAC = 0.80

# Recency windows
REC_WIN_MIN = 500
REC_WIN_MULT_PROB = 2      # probation recency normalization window
REC_WIN_MULT_PROT = 6      # protected recency normalization window

# Recency weights per segment (how much recentness protects)
REC_WEIGHT_PROB = 0.35
REC_WEIGHT_PROT = 0.18

# Frequency and multi-hit boost
MULTI_HIT_BONUS = 0.55     # extra benefit for items with >=2 resident hits

# Size penalty
SIZE_PENALTY_ALPHA_BASE = 1.10  # base exponent for size penalty
NEW_SIZE_BIAS_FACTOR = 0.90     # extra exponent proportional to incoming obj size (% of cap)

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Utilities
# -----------------------------

def _normalized_size(size, capacity):
    # Return percentage of capacity (0..100] but as float (>= tiny epsilon)
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, when, window):
    if when is None:
        return 1.0
    age = max(0, now - when)
    if window <= 0:
        return 1.0
    return min(1.0, float(age) / float(window))


def _seg_quota(n_items):
    # Protected item count target (by items, not bytes)
    return max(0, int(PROT_FRAC * n_items))


def _rebalance_segments(cache_snapshot):
    # Ensure protected segment does not exceed its quota
    n_items = len(cache_snapshot.cache)
    if n_items == 0:
        return
    quota = _seg_quota(n_items)

    # Count protected keys
    prot_keys = [k for k in cache_snapshot.cache.keys() if m_seg.get(k, 0) == 1]
    while len(prot_keys) > quota:
        # Demote the LRU in protected (smallest last access)
        victim = min(prot_keys, key=lambda k: m_last_access.get(k, -1))
        m_seg[victim] = 0
        prot_keys.remove(victim)


def _shadow_add(now, key):
    m_shadow[key] = now
    m_shadow_fifo.append(key)
    # Trim shadow capacity
    while len(m_shadow) > SHADOW_CAP and m_shadow_fifo:
        old = m_shadow_fifo.popleft()
        # May contain duplicates; remove only if matches current stored time or just exists
        m_shadow.pop(old, None)


def _retention_score(cache_snapshot, key, incoming_size_norm):
    # Compute eviction retention score for a resident key: smaller -> evict first
    # score = benefit - recency_gain
    # benefit      = (log2(1 + freq) + multi_hit_bonus) / (size_norm ** alpha)
    # recency_gain = W_seg * (1 - normalized_age), age based on LRU-2 (prev access if available)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen

    size_norm = _normalized_size(robj.size, cap)
    seg = m_seg.get(key, 0)

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)

    # Multi-hit bonus
    mh_bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0

    # Size penalty exponent adapts with incoming object's relative size
    # Larger incoming objects push eviction to favor freeing larger/colder bytes.
    alpha = SIZE_PENALTY_ALPHA_BASE + NEW_SIZE_BIAS_FACTOR * incoming_size_norm

    benefit = (math.log2(1.0 + float(freq)) + mh_bonus) / (size_norm ** alpha)

    # LRU-2 recency: use previous access for multi-hit items; else last
    prev = m_prev_access.get(key)
    last = m_last_access.get(key)
    ref_time = prev if (prev is not None and m_resident_hits.get(key, 1) >= 2) else last

    n_items = max(1, len(cache_snapshot.cache))
    if seg == 1:
        window = max(REC_WIN_MIN, REC_WIN_MULT_PROT * n_items)
        rec_w = REC_WEIGHT_PROT
    else:
        window = max(REC_WIN_MIN, REC_WIN_MULT_PROB * n_items)
        rec_w = REC_WEIGHT_PROB

    a_norm = _recency_normalized(now, ref_time, window)
    recency_gain = rec_w * (1.0 - a_norm)

    return benefit - recency_gain

# -----------------------------
# Entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict using SLRU-TFS:
      - Prefer evicting from probation (segment 0); fallback to protected
      - Within a segment, choose the key with the smallest retention score
      - Tie-break by oldest (LRU-2 reference time)
    '''
    _lfu_maybe_advance_epoch(cache_snapshot)

    # Keep protected within quota so eviction has probation victims
    _rebalance_segments(cache_snapshot)

    incoming_size_norm = _normalized_size(obj.size, cache_snapshot.capacity)

    # Partition keys by segment
    probation_keys = []
    protected_keys = []
    for k in cache_snapshot.cache.keys():
        if m_seg.get(k, 0) == 1:
            protected_keys.append(k)
        else:
            probation_keys.append(k)

    search_keys = probation_keys if probation_keys else protected_keys

    min_key = None
    min_score = None
    min_time = None  # tie-breaker based on LRU-2 reference

    for k in search_keys:
        score = _retention_score(cache_snapshot, k, incoming_size_norm)

        # LRU-2 reference for tie-break: previous if exists and multi-hit, else last
        prev = m_prev_access.get(k)
        last = m_last_access.get(k)
        ref_time = prev if (prev is not None and m_resident_hits.get(k, 1) >= 2) else last
        ref_time = -1 if ref_time is None else ref_time

        if (min_score is None) or (score < min_score) or (score == min_score and ref_time < min_time):
            min_score = score
            min_time = ref_time
            min_key = k

    # Fallback: arbitrary key (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Update LRU-2 timestamps (prev <- last, last <- now)
      - Increment resident hit count
      - Promote from probation to protected on 2nd hit
      - Rebalance segments to maintain protected quota
    '''
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update LRU-2 timestamps
    last = m_last_access.get(k)
    if last is not None:
        m_prev_access[k] = last
    m_last_access[k] = now

    # Update hits and promote if appropriate
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    if m_seg.get(k, 0) == 0 and m_resident_hits[k] >= 2:
        m_seg[k] = 1  # promote to protected

    # Keep protected under quota
    _rebalance_segments(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: segment=probation, last_access=now, prev_access unset
      - If found in shadow (ghost), boost to protected and treat as multi-hit
    '''
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access.pop(k, None)

    # Default: probation, single-hit
    seg = 0
    hits = 1

    # Shadow boost: item was recently evicted and reappeared
    ghost_time = m_shadow.pop(k, None)
    if ghost_time is not None:
        # Treat as multi-hit and seed previous access for LRU-2
        m_shadow_hits += 1
        hits = 2
        seg = 1
        # Use the remembered time as previous reference to protect against scans
        m_prev_access[k] = ghost_time

    m_resident_hits[k] = hits
    m_seg[k] = seg

    # Ensure protected quota not exceeded
    _rebalance_segments(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Record victim in shadow queue (ghost) for potential second-chance on reappearance
    '''
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key

    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_seg.pop(ek, None)

    # Remember as ghost
    _shadow_add(cache_snapshot.access_count, ek)
```
2025-11-27 18:45:22,706 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# W-TinyLFU + Segmented protection + Size-aware retention
# - Two logical segments:
#     1) probation (new/resurrected items)
#     2) protected (promoted on hit; byte-quota limited)
# - TinyLFU frequency counters with lazy epoch decay (8-bit saturating)
# - Size-aware retention: benefit = log1p(freq) / normalized_size
# - Recency bonus added (not subtracted) to protect recent items
# - Protected segment gets an extra bonus; demoted by LRU when over target bytes
# - Eviction uses lazy min-heaps (probation first, then protected) to avoid full scans
#   with lazy invalidation via per-key stamps; periodic score refresh on pop.
#
# This design:
#   - Dramatically reduces per-eviction cost (avoids O(n) scans) -> fewer timeouts
#   - Corrects recency sign (recent items are now protected, not penalized)
#   - Uses size-aware TinyLFU benefit and a protected segment to cut miss rate

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Cache identity (to reset between runs if needed)
m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting
m_prot_bytes = 0
m_prot_target_bytes = 0

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_probation = []           # retention score (lower => more evictable) for probation
h_protected = []           # retention score for protected (used when probation empty)
h_prot_lru = []            # last_access (min-heap) for protected demotions

# TinyLFU counters (lazy decay with epochs; per-key to keep it simple)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Protected segment target (bytes)
PROT_FRAC = 0.80           # target fraction of capacity for protected bytes

# Recency window and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 3           # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.60     # recency weight in probation
REC_WEIGHT_PROT = 0.40     # recency weight in protected
PROT_BONUS = 0.60          # extra benefit for protected segment
MULTI_HIT_BONUS = 0.30     # extra benefit for items with >=2 resident hits

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16  # bound reheap/refresh work per eviction

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC * cache_snapshot.capacity)

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Return size as percentage of capacity to keep scales stable
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _retention_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # treat missing as extremely good (will be filtered by validity)
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)

    seg = m_segment.get(key, 0)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    # Size-aware frequency benefit
    benefit = math.log1p(float(freq)) / size_norm

    # Multi-hit bias
    if m_resident_hits.get(key, 0) >= 2:
        benefit += MULTI_HIT_BONUS

    # Recency bonus
    if seg == 1:
        benefit += PROT_BONUS + REC_WEIGHT_PROT * rec_bonus
    else:
        benefit += REC_WEIGHT_PROB * rec_bonus

    return benefit


# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    # Compute score at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    score = _retention_score(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (score, s, key))
    else:
        heapq.heappush(h_protected, (score, s, key))
        # Also maintain LRU heap for protected demotions
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot, heap_ref, expected_seg):
    # Return a valid key from the given heap, refreshing stale scores when needed.
    # Limit work per call to avoid long stalls.
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        # Skip invalid/stale entries
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Opportunistically refresh score if it drifted
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            # Reinsert with a new stamp
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key
    return None


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        # Push into probation heap with updated score/stamp
        _push_key(cache_snapshot, key)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim:
      1) Pop the weakest from probation heap (lowest retention)
      2) If probation empty, pop the weakest from protected heap
      3) Fallback: any resident key
    '''
    _init_if_needed(cache_snapshot)

    # Prefer evicting from probation
    victim = _pop_best_candidate(cache_snapshot, h_probation, expected_seg=0)
    if victim is None:
        victim = _pop_best_candidate(cache_snapshot, h_protected, expected_seg=1)

    if victim is not None:
        return victim

    # Fallback: arbitrary key (should be rare)
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote probation -> protected on first resident hit
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with new score/recency
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote to protected
        m_segment[k] = 1
        # Account protected bytes
        global m_prot_bytes
        m_prot_bytes += obj.size
        # Push into protected heaps
        _push_key(cache_snapshot, k)
        # Enforce protected target
        _maybe_demote_protected(cache_snapshot)
    else:
        # Already protected: refresh heaps
        _push_key(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place into probation segment and push to heap
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation
    _push_key(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Adjust protected bytes if it was protected
    seg = m_segment.pop(ek, None)
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 42
- Hit Rate: 0.051

Example 2:
- Trace ID: 39
- Hit Rate: 0.1076

Example 3:
- Trace ID: 17
- Hit Rate: 0.0238

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m18:45:22 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 18:45:22,707 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m18:47:42 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 18:47:42,687 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 18:47:42,689 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Simplified SLRU + TinyLFU (lazy-decayed) with size-aware retention and LRU-driven eviction
# - Two segments:
#     0) probation: new/resurrected items (evict from here)
#     1) protected: items promoted on hit (demoted by LRU to maintain byte quota)
# - Eviction:
#     * Always evict from probation. If empty, demote oldest protected to probation.
#     * Among the oldest probation items, sample a small set and evict the one with lowest size-aware TinyLFU benefit.
# - TinyLFU:
#     * 8-bit saturating counters with lazy epoch-based decay.
# - Size-aware retention benefit:
#     * benefit = log1p(freq_adjusted) / (size / capacity)
#     * Larger objects need proportionally higher frequency to be retained.
# - Resident hits are counted only on cache hits (not on initial miss).
# - Fast, heap-stamped LRU queues avoid full scans and minimize stale work.

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Cache identity (to reset between runs if needed)
m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count (hits while resident)
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting
m_prot_bytes = 0
m_prot_target_bytes = 0

# LRU Heaps (lazy invalidation; tuples hold (last_access, stamp, key))
h_prob_lru = []            # probation LRU (min-heap by last_access)
h_prot_lru = []            # protected LRU (min-heap by last_access)

# TinyLFU counters (lazy decay with epochs; per-key)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Protected segment target (bytes)
PROT_FRAC = 0.70           # target fraction of capacity for protected bytes

# Eviction sampling
EVICT_SAMPLE = 8           # how many oldest probation items to consider
MAX_LRU_FIX_PER_POP = 32   # bound per-pop cleanup of stale LRU entries

# Benefit shaping
MULTI_HIT_FREQ_BONUS = 1.0  # extra virtual frequency for items with >=2 resident hits
FREQ_EPS = 0.0              # optional floor on frequency before log1p

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_prob_lru, h_prot_lru
    global m_lfu_count, m_lfu_epoch

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC * cache_snapshot.capacity)

    h_prob_lru.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # size normalized to capacity [0..1], with tiny floor to avoid div-by-zero
    return max(1e-12, float(size) / float(capacity))


def _retention_benefit(cache_snapshot, key):
    # Higher benefit = more worth keeping. Evict the minimum benefit.
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # treat missing as extremely good (filtered by validity check)
    size_norm = _normalized_size(obj.size, cache_snapshot.capacity)

    freq = float(_lfu_peek(cache_snapshot, key))
    if m_resident_hits.get(key, 0) >= 2:
        freq += MULTI_HIT_FREQ_BONUS

    # Size-aware TinyLFU: logarithmic frequency gain, linear size penalty
    benefit = math.log1p(max(freq, FREQ_EPS)) / size_norm
    return benefit

# -----------------------------
# LRU heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_lru(cache_snapshot, key):
    # Push key with current last_access into its segment LRU
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    last = m_last_access.get(key, -1)
    if seg == 0:
        heapq.heappush(h_prob_lru, (last, s, key))
    else:
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_oldest_from(heap, expected_seg):
    # Pop until a valid entry is found or the heap is exhausted.
    attempts = 0
    while heap and attempts < MAX_LRU_FIX_PER_POP:
        last, stamp, key = heapq.heappop(heap)
        if _is_valid(None if False else heap, key, expected_seg, stamp):  # trick to avoid unused var warnings
            # Validate using actual snapshot field values; we don't need cache_snapshot here.
            return key
        attempts += 1
    return None

# -----------------------------
# Segment management
# -----------------------------

def _rebalance_protected_quota(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes:
        # Pop oldest protected
        key = _pop_oldest_valid_protected(cache_snapshot)
        if key is None:
            break
        # Demote
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        _push_lru(cache_snapshot, key)


def _pop_oldest_valid_protected(cache_snapshot):
    attempts = 0
    while h_prot_lru and attempts < MAX_LRU_FIX_PER_POP:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            return key
        attempts += 1
    return None


def _collect_probation_candidates(cache_snapshot, k_wanted):
    # Collect up to k_wanted oldest valid probation keys.
    candidates = []
    attempts = 0
    while len(candidates) < k_wanted and attempts < k_wanted * (MAX_LRU_FIX_PER_POP + 1):
        key = None
        # Try to pop oldest probation entry
        while h_prob_lru and key is None and attempts < MAX_LRU_FIX_PER_POP:
            last, stamp, k = heapq.heappop(h_prob_lru)
            if _is_valid(cache_snapshot, k, expected_seg=0, stamp=stamp):
                key = k
                break
            attempts += 1

        if key is None:
            # Probation appears empty; attempt to demote one protected item to probation
            demoted = _pop_oldest_valid_protected(cache_snapshot)
            if demoted is None:
                break
            # Demote
            m_segment[demoted] = 0
            obj = cache_snapshot.cache.get(demoted)
            if obj is not None:
                global m_prot_bytes
                m_prot_bytes = max(0, m_prot_bytes - obj.size)
            _push_lru(cache_snapshot, demoted)
            continue

        candidates.append(key)
    return candidates

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Eviction strategy:
      - Keep protected bytes under target by LRU demotion.
      - Evict from probation only. If empty, demote oldest protected into probation.
      - Among up to EVICT_SAMPLE oldest probation items, evict the one with lowest size-aware TinyLFU benefit.
    '''
    _init_if_needed(cache_snapshot)

    # Enforce protected-byte target first
    _rebalance_protected_quota(cache_snapshot)

    # Gather candidates from probation (demote from protected if needed)
    candidates = _collect_probation_candidates(cache_snapshot, EVICT_SAMPLE)

    if not candidates:
        # Fallback: any resident key (should be rare)
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Choose the candidate with the lowest benefit
    best_key = None
    best_benefit = float('inf')
    for k in candidates:
        b = _retention_benefit(cache_snapshot, k)
        if b < best_benefit:
            best_benefit = b
            best_key = k

    # Requeue non-selected candidates with fresh stamps
    for k in candidates:
        if k != best_key:
            _push_lru(cache_snapshot, k)

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time and segment LRU
      - Promote probation -> protected on first resident hit
      - Maintain protected-byte quota via LRU demotion
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote to protected on first hit
        m_segment[k] = 1
        global m_prot_bytes
        m_prot_bytes += obj.size
        _push_lru(cache_snapshot, k)
        _rebalance_protected_quota(cache_snapshot)
    else:
        # Already protected: refresh LRU
        _push_lru(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (counts this access)
      - Initialize resident metadata: last_access, resident_hits = 0
      - Place into probation segment and push to LRU
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 0
    m_segment[k] = 0  # probation
    _push_lru(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    seg = m_segment.pop(ek, None)
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; TinyLFU counters persist
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```
2025-11-27 18:47:50,592 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 29
- Hit Rate: 0.0386

Example 2:
- Trace ID: 45
- Hit Rate: 0.1719

Example 3:
- Trace ID: 6
- Hit Rate: 0.2775

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m18:47:50 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 18:47:50,593 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m18:50:16 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 18:50:16,711 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 18:50:16,712 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# GDSF-TinyLFU (GreedyDual-Size with TinyLFU frequency)
# - Size-aware priority with aging via GreedyDual's watermark (H)
# - Popularity from TinyLFU (lazy-decayed counters; 8-bit to reduce saturation)
# - Recency is captured implicitly by H: every re-reference reinserts with +H
# - Eviction: smallest priority first (ties -> oldest last-access)
# - Size exponent (gamma) tempers tiny-object dominance
#
# Priority for key k:
#   P[k] = H + ( log2(1 + freq_k) + multi_hit_bonus ) / ( (size_k / capacity)^gamma )
#
# On hit or insert:
#   - Increment TinyLFU
#   - Update resident metadata
#   - Recompute P[k] with current H
#
# On evict:
#   - Choose key with smallest P[k] (recompute lazily to reflect decay)
#   - Set H = P[victim]
#   - Drop resident metadata (keep TinyLFU for admission memory)

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU-ish timestamp)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_priority = dict()        # key -> float priority used for eviction

# GreedyDual watermark
m_gds_H = 0.0              # aging watermark; increases to evicted item's priority

# TinyLFU sketch (lazy-decayed 8-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0
LFU_BITS = 8
LFU_MAX = (1 << LFU_BITS) - 1
LFU_DECAY_INTERVAL = 4096  # accesses per epoch (power of two recommended)

# Tunables
SIZE_GAMMA = 0.85          # 0=no size penalty, 1=full 1/size; 0.8~0.9 is robust
MULTI_HIT_BONUS = 0.50     # extra value for items with >=2 resident hits
MIN_SIZE_FRAC = 1e-9       # guard for tiny sizes in normalization


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; counters decay on next read/increment


def _lfu_peek(cache_snapshot, key):
    # Return decayed counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers (GDSF priority)
# -----------------------------

def _size_frac(size, capacity):
    # Normalize size as a fraction of capacity (>= MIN_SIZE_FRAC)
    return max(MIN_SIZE_FRAC, float(size) / float(capacity))


def _value_for(cache_snapshot, key, size):
    # Popularity value adjusted by size and multi-hit bonus (no watermark here)
    freq = _lfu_peek(cache_snapshot, key)
    val = math.log2(1.0 + float(freq))
    if m_resident_hits.get(key, 0) >= 2:
        val += MULTI_HIT_BONUS
    denom = _size_frac(size, cache_snapshot.capacity) ** SIZE_GAMMA
    return val / denom


def _recompute_priority(cache_snapshot, key):
    # Recompute and store the current priority for a resident key (lazy decay aware)
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('inf')
    global m_gds_H
    prio = m_gds_H + _value_for(cache_snapshot, key, robj.size)
    m_priority[key] = prio
    return prio


def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest GDSF-TinyLFU priority.
    Ties are broken by oldest last-access time.
    After selecting a victim, raise H to the victim's priority.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_prio = None
    min_time = None

    # Recompute priorities lazily while scanning to reflect any LFU decay since last update
    for k, robj in cache_snapshot.cache.items():
        prio = _recompute_priority(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_prio = prio
            min_time = last
            min_key = k

    # Fallback
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Advance GreedyDual watermark to the evicted priority
    global m_gds_H
    if min_prio is not None and min_prio > m_gds_H:
        m_gds_H = min_prio

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Increment resident hit count
      - Refresh last-access time
      - Recompute priority with current H
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Update priority with current H
    _recompute_priority(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata
      - Initialize priority with current H
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # New entry gets a fresh priority including current H
    _recompute_priority(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Resident metadata is removed (TinyLFU counters are retained)
      - H was already raised in evict()
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_priority.pop(ek, None)
    # Keep m_lfu_count[ek] to preserve TinyLFU memory across evictions
```
2025-11-27 18:50:33,175 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 35
- Hit Rate: 0.1562

Example 2:
- Trace ID: 18
- Hit Rate: 0.024

Example 3:
- Trace ID: 8
- Hit Rate: 0.5223

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m18:50:33 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 18:50:33,176 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m18:53:37 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 18:53:37,643 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 18:53:37,644 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Segmented TinyLFU-Recency-Size (sTFRS)
# - Two segments (probation/protected) like SLRU to limit scan pollution
# - TinyLFU 4-bit counters with lazy epoch decay
# - Size-aware benefit: log2(1+freq) / (size/capacity)
# - Recency bonus depends on segment:
#     * probation: weak recency (new items are easy to evict unless re-referenced)
#     * protected: stronger recency; but very stale protected items are demoted by score
# - Eviction prefers probation unless protected is oversized, then evict from protected
# - Metadata kept only for residents; TinyLFU counts persist for non-residents

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Resident metadata
m_last_access = dict()     # key -> int access_count (LRU clock)
m_resident_hits = dict()   # key -> int resident hit count (only increments on hits)
m_stage = dict()           # key -> 0 probation, 1 protected
m_promoted_at = dict()     # key -> int access_count when promoted to protected

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096  # shorter interval for better adaptivity

# Tunables
REC_WIN_MIN = 800          # normalization floor for the recency window
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
PROT_FRAC = 0.80           # target fraction of resident items in protected segment

# Recency weights by segment
REC_WEIGHT_PROB = 0.06     # weak MRU protection for probation (new/unproven)
REC_WEIGHT_PROT = 0.33     # stronger MRU protection for protected

# Benefit tweaks
MULTI_HIT_BONUS_PROB = 0.0
MULTI_HIT_BONUS_PROT = 0.55

# Staleness handling for protected: demote-by-score if far beyond window
PROT_STALE_MULT = 6.0      # if age/window > this, treat as very stale
STALE_PEN_MULT = 0.45      # penalty added to score for stale protected items

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _recency_weight_for(key, size_norm, stage):
    # Reduce recency protection for large objects
    size_dampen = 1.0 / (1.0 + size_norm)  # in (0,1]
    if stage >= 1:
        base = REC_WEIGHT_PROT
    else:
        base = REC_WEIGHT_PROB
    return base * size_dampen

def _benefit_for(cache_snapshot, key, size_norm, stage):
    freq = _lfu_peek(cache_snapshot, key)
    if stage >= 1:
        bonus = MULTI_HIT_BONUS_PROT if m_resident_hits.get(key, 0) >= 1 else 0.0
    else:
        bonus = MULTI_HIT_BONUS_PROB
    return (math.log2(1.0 + float(freq)) + bonus) / size_norm

def _retention_score(cache_snapshot, key):
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # safety; should not happen
    size = robj.size
    size_norm = _normalized_size(size, cap)

    stage = m_stage.get(key, 0)
    last = m_last_access.get(key)
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    benefit = _benefit_for(cache_snapshot, key, size_norm, stage)

    a_norm = _recency_normalized(now, last, window)
    rec_w = _recency_weight_for(key, size_norm, stage)
    recency_gain = rec_w * (1.0 - a_norm)

    # Penalize stale protected items so they can be reclaimed eventually
    # without fully discarding their frequency.
    staleness_pen = 0.0
    if stage >= 1 and last is not None:
        age = max(0, now - last)
        if window > 0 and (float(age) / float(window)) > PROT_STALE_MULT:
            staleness_pen = STALE_PEN_MULT * math.log2(1.0 + float(age) / float(window))

    # Lower score => weaker retention => better eviction candidate
    return benefit - recency_gain - staleness_pen

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    sTFRS eviction:
      - Prefer evicting from probation unless protected is oversized
      - Use TinyLFU-Recency-Size retention score within the chosen segment
      - Ties broken by older last-access
    '''
    _lfu_maybe_advance_epoch(cache_snapshot)

    n_items = len(cache_snapshot.cache)
    if n_items == 0:
        return None

    prot_target = max(0, int(PROT_FRAC * n_items))
    prot_keys = []
    prob_keys = []
    for k in cache_snapshot.cache.keys():
        if m_stage.get(k, 0) >= 1:
            prot_keys.append(k)
        else:
            prob_keys.append(k)

    prot_cnt = len(prot_keys)
    prob_cnt = len(prob_keys)

    # Decide preferred segment to draw a victim from
    if prob_cnt > 0 and prot_cnt <= prot_target:
        pools = [prob_keys, prot_keys]  # try probation first
    elif prot_cnt > 0 and prot_cnt > prot_target:
        pools = [prot_keys, prob_keys]  # trim protected if oversized
    else:
        # Fallback: whichever is non-empty
        pools = [prob_keys if prob_cnt > 0 else prot_keys]

    min_key = None
    min_score = None
    min_time = None

    for pool in pools:
        for k in pool:
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
        if min_key is not None:
            break  # found victim in preferred segment

    if min_key is None:
        # Very unlikely, but ensure a victim is chosen
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key

def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote from probation to protected on first resident hit
    '''
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)

    # Refresh recency and hits
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # Promote to protected upon first resident hit
    if m_stage.get(k, 0) == 0 and m_resident_hits[k] >= 1:
        m_stage[k] = 1
        m_promoted_at[k] = cache_snapshot.access_count

def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter (we count every request)
      - Initialize resident metadata:
          * last_access = now
          * resident_hits = 0 (insert is not a hit)
          * stage = probation
    '''
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)

    now = cache_snapshot.access_count
    m_last_access[k] = now
    m_resident_hits[k] = 0
    m_stage[k] = 0  # probation
    m_promoted_at.pop(k, None)  # clear any stale promotion info

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    # Retain TinyLFU history for admission-style learning
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stage.pop(ek, None)
    m_promoted_at.pop(ek, None)
```
2025-11-27 18:54:08,397 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 44
- Hit Rate: 0.1881

Example 2:
- Trace ID: 13
- Hit Rate: 0.0

Example 3:
- Trace ID: 37
- Hit Rate: 0.6388

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m18:54:08 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 18:54:08,397 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m18:56:34 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 18:56:34,822 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 18:56:34,823 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# GreedyDual-TinyLFU-Size (GDTLS)
# - GreedyDual priority with decay (L) + size-aware TinyLFU frequency
# - Priority H(k) is set only on (hit|insert): H(k) = L + value(k)
#     value(k) = (BASE + FREQ_W * log2(1 + lfu_count) + multi_hit_bonus) / size_pct(size)
# - Evict: remove the resident key with the smallest H; advance L to H(evicted)
# - TinyLFU via lazy-epoch 4-bit counters (no global sweep); counters persist across evictions
# - Tie-breaker: oldest last-access time
#
# Rationale:
#   GreedyDual provides robust recency decay without global scans; TinyLFU supplies frequency
#   discrimination; dividing by normalized size makes the policy byte-aware. This combination
#   is resilient to scans and balances recency, frequency, and size, improving hit rates across
#   diverse workloads.

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access   = dict()    # key -> int access_count (for LRU tie-break)
m_resident_hits = dict()    # key -> int resident hit count (>=1 once inserted)
m_priority_H    = dict()    # key -> float GreedyDual priority H

# GreedyDual global "age"
m_L = 0.0                   # float, increases only when evicting

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()        # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192   # access-counts per epoch (power of two recommended)

# Tunables (conservatively chosen)
BASE_COST        = 1.0      # baseline value for all items
FREQ_W           = 1.6      # weight of frequency in value()
MULTI_HIT_BONUS  = 0.6      # extra numerator for resident items with >=2 hits
SIZE_EXP         = 0.9      # exponent for size normalization (reduces tiny-item dominance)
MIN_SIZE_PCT     = 1e-6     # floor to avoid division by zero


# -----------------------------
# Helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


def _size_pct(size, capacity):
    # Normalize size to "percent of capacity", then apply exponent to moderate extremes
    pct = (float(size) * 100.0) / float(capacity)
    pct = max(MIN_SIZE_PCT, pct)
    return pct ** SIZE_EXP


def _value_for(cache_snapshot, key, size, resident_hits):
    # GreedyDual value contribution (without L)
    freq = _lfu_peek(cache_snapshot, key)
    bonus = MULTI_HIT_BONUS if resident_hits >= 2 else 0.0
    numerator = BASE_COST + FREQ_W * math.log2(1.0 + float(freq)) + bonus
    denom = _size_pct(size, cache_snapshot.capacity)
    return numerator / denom


def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)
    # m_L is lazily updated on evictions; no extra init needed


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest GreedyDual priority H.
    After choosing the victim, advance L to H(victim).
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    global m_L

    min_key = None
    min_H = None
    min_time = None

    for k, robj in cache_snapshot.cache.items():
        H = m_priority_H.get(k)
        if H is None:
            # Fallback if a key lacks H due to prior policy: give minimal protection (≈ L)
            H = m_L
        last = m_last_access.get(k, -1)

        if (min_H is None) or (H < min_H) or (H == min_H and last < min_time):
            min_H = H
            min_time = last
            min_key = k

    if min_key is None:
        # Empty cache edge-case
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Advance GreedyDual age to the evicted priority (monotonic non-decreasing)
    if min_H is not None and min_H > m_L:
        m_L = min_H

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Update last-access time
      - Refresh GreedyDual priority H = L + value(k)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)

    # Update resident stats
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Recompute GreedyDual priority
    rh = m_resident_hits.get(k, 1)
    val = _value_for(cache_snapshot, k, obj.size, rh)
    m_priority_H[k] = m_L + val


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - Set GreedyDual priority H = L + value(k)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    val = _value_for(cache_snapshot, k, obj.size, resident_hits=1)
    m_priority_H[k] = m_L + val


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - L (GreedyDual age) was already advanced in evict()
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_priority_H.pop(ek, None)
    # Keep m_lfu_count[ek] to preserve TinyLFU memory across residency
```
2025-11-27 18:56:43,256 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 22
- Hit Rate: 0.06

Example 2:
- Trace ID: 30
- Hit Rate: 0.0524

Example 3:
- Trace ID: 19
- Hit Rate: 0.2722

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m18:56:43 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 18:56:43,257 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 19:06:59,460 [INFO] openai._base_client: Retrying request to /chat/completions in 0.381695 seconds
[92m19:10:57 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 19:10:57,454 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 19:10:57,455 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive SLRU + TinyLFU + Size-aware (ARC-style admission)
# - Two resident segments: PROBATION (recency) and PROTECTED (frequency)
# - Adaptive target size for PROTECTED via ARC ghost hits (B1, B2)
# - TinyLFU (lazy-decayed 4-bit) to capture long-term popularity
# - Size-aware: favor keeping smaller objects for the same usefulness
# - Evict primarily from PROBATION unless PROTECTED exceeds its adaptive target
#   * PROBATION victim: oldest (LRU), tie-broken by lower size-adjusted TinyLFU benefit
#   * PROTECTED victim: lowest size-adjusted TinyLFU benefit, tie-broken by oldest
# - Ghost lists (B1 for PROBATION evictions, B2 for PROTECTED evictions) bound to ~2x resident

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_seg = dict()             # key -> 0 (PROBATION) or 1 (PROTECTED)

# Ghost lists for ARC-style adaptation (store last seen time)
g_prob = dict()            # B1: keys recently evicted from PROBATION -> last_time
g_prot = dict()            # B2: keys recently evicted from PROTECTED -> last_time

# Adaptive target size (in items) for PROTECTED segment
g_target_protected = 0.0   # dynamically adjusted with ghost hits

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Percentage of capacity, safely bounded away from zero
    return max(1e-9, (float(size) * 100.0) / float(max(1, capacity)))

def _benefit(cache_snapshot, key, size):
    # Size-aware TinyLFU benefit
    freq = _lfu_peek(cache_snapshot, key)
    # Additional small boost if item has >=2 resident hits
    extra = 0.35 if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cache_snapshot.capacity)
    return (math.log2(1.0 + float(freq)) + extra) / size_norm

def _resident_segment_counts(cache_snapshot):
    prot = 0
    for k in cache_snapshot.cache.keys():
        if m_seg.get(k, 0) == 1:
            prot += 1
    total = len(cache_snapshot.cache)
    return prot, total

def _prune_ghosts(cache_snapshot):
    # Keep total size of ghost lists bounded (~2x resident items)
    limit = max(1000, 2 * max(1, len(cache_snapshot.cache)))
    # prune oldest across both lists until within limit
    def oldest_entry(d):
        if not d:
            return None, None
        # find key with minimum timestamp
        min_k, min_t = None, None
        for k, t in d.items():
            if min_t is None or t < min_t:
                min_k, min_t = k, t
        return min_k, min_t

    while (len(g_prob) + len(g_prot)) > limit:
        # remove the absolute oldest between the two lists
        k1, t1 = oldest_entry(g_prob)
        k2, t2 = oldest_entry(g_prot)
        if k1 is None and k2 is None:
            break
        if k2 is None or (k1 is not None and t1 <= t2):
            g_prob.pop(k1, None)
        else:
            g_prot.pop(k2, None)

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)
    global g_target_protected
    # Initialize target_protected to a reasonable fraction on first use
    if g_target_protected == 0.0 and len(cache_snapshot.cache) > 0:
        # start with 40% protected as a balanced default
        g_target_protected = 0.4 * len(cache_snapshot.cache)

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one key using Adaptive SLRU with TinyLFU and size-awareness.
    Prefer evicting from PROBATION unless PROTECTED exceeds its target.
    '''
    _init_if_needed(cache_snapshot)

    now = cache_snapshot.access_count
    prot_count, total = _resident_segment_counts(cache_snapshot)
    target_prot = int(max(0, min(total, round(g_target_protected))))

    # Choose segment to evict from
    evict_from_seg = None
    if prot_count > max(0, target_prot):
        # PROTECTED too large: evict from PROTECTED
        evict_from_seg = 1
    else:
        # Otherwise evict from PROBATION
        evict_from_seg = 0
        # fallback if empty
        if all(m_seg.get(k, 0) != 0 for k in cache_snapshot.cache.keys()):
            evict_from_seg = 1

    min_key = None
    min_score = None
    min_time = None

    if evict_from_seg == 0:
        # PROBATION: choose LRU (oldest last_access),
        # tie-break by lower benefit (size-adjusted frequency)
        for k, robj in cache_snapshot.cache.items():
            if m_seg.get(k, 0) != 0:
                continue
            last = m_last_access.get(k, -1)
            ben = _benefit(cache_snapshot, k, robj.size)
            # Score primarily by last access time (older -> better candidate)
            # Use tuple for comparison: (older first, then lower benefit)
            # We convert to a scalar with a large weight on recency ordering.
            score = (last, ben)
            if (min_score is None) or (score[0] < min_score[0]) or (score[0] == min_score[0] and score[1] < min_score[1]):
                min_score = score
                min_time = last
                min_key = k
    else:
        # PROTECTED: choose minimal TinyLFU size-adjusted benefit, tie-break by LRU
        for k, robj in cache_snapshot.cache.items():
            if m_seg.get(k, 0) != 1:
                continue
            ben = _benefit(cache_snapshot, k, robj.size)
            last = m_last_access.get(k, -1)
            # Lower benefit => weaker candidate
            score = (ben, last)
            if (min_score is None) or (score[0] < min_score[0]) or (score[0] == min_score[0] and score[1] < min_score[1]):
                min_score = score
                min_time = last
                min_key = k

    if min_key is None:
        # Fallback: evict absolute oldest
        oldest_key = None
        oldest_time = None
        for k in cache_snapshot.cache.keys():
            last = m_last_access.get(k, -1)
            if oldest_time is None or last < oldest_time:
                oldest_time = last
                oldest_key = k
        if oldest_key is not None:
            return oldest_key
        # Final fallback
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key

def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Refresh last-access time
      - Promote from PROBATION to PROTECTED on first hit
      - Track resident hit count
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count

    # Resident hits
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promote to PROTECTED on hit if currently in PROBATION
    if m_seg.get(k, 0) == 0:
        m_seg[k] = 1  # promote

def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - ARC-style adaptation using ghost lists:
          * If key in B1 (probation ghost): increase target PROTECTED
          * If key in B2 (protected ghost): decrease target PROTECTED
      - Place key into PROTECTED if it was in any ghost; else into PROBATION
    '''
    _init_if_needed(cache_snapshot)

    now = cache_snapshot.access_count
    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = now
    m_resident_hits[k] = 1

    global g_target_protected

    in_b1 = k in g_prob
    in_b2 = k in g_prot

    # Adapt target protected based on ghost hits (ARC heuristic)
    b1 = len(g_prob)
    b2 = len(g_prot)
    if in_b1:
        delta = max(1, b2 // max(1, b1))
        g_target_protected += float(delta)
        g_prob.pop(k, None)
    elif in_b2:
        delta = max(1, b1 // max(1, b2))
        g_target_protected -= float(delta)
        g_prot.pop(k, None)

    # Clamp target to [0, current items]
    _, total = _resident_segment_counts(cache_snapshot)
    g_target_protected = max(0.0, min(float(total + 1), g_target_protected))  # +1 anticipating this insertion

    # Placement: if returning from ghosts, treat as PROTECTED; else PROBATION
    if in_b1 or in_b2:
        m_seg[k] = 1
    else:
        m_seg[k] = 0

    # Keep ghosts bounded
    _prune_ghosts(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Add it to appropriate ghost list (B1 if from PROBATION, B2 if from PROTECTED)
      - Remove resident-only metadata (TinyLFU counters are retained)
      - Prune ghost lists to keep them bounded
    '''
    _init_if_needed(cache_snapshot)

    now = cache_snapshot.access_count
    ek = evicted_obj.key
    seg = m_seg.pop(ek, 0)

    # Record in correct ghost list
    if seg == 1:
        g_prot[ek] = now
    else:
        g_prob[ek] = now

    # Do NOT delete LFU counters; TinyLFU remembers non-resident popularity
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # Bound ghost sizes
    _prune_ghosts(cache_snapshot)
```
2025-11-27 19:11:10,461 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# W-TinyLFU-style SLRU with size-aware eviction and ARC-like adaptive P/S split
# - Two resident segments by bytes:
#     P (probation): admits all new objects; managed by LRU (via last_access timestamps)
#     S (protected): objects that hit at least once; also LRU-managed
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction is size-aware: minimize estimated harm est_freq(key)/size(key)
#   and bias toward evicting from P unless S object is clearly worse.
# - ARC-like ghost lists adapt the byte split between P and S online.
#
# This design captures:
#   - Recency (via LRU within segments)
#   - Frequency (via TinyLFU)
#   - Size-awareness (benefit ~ freq/size)
#   - Adaptivity between recency-friendly and frequency-friendly behavior

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU)
m_key_segment = dict()       # key -> 'P' or 'S'

# Current resident bytes per segment
m_bytes_P = 0
m_bytes_S = 0

# Adaptive target for protected bytes (S); probation target = capacity - target_S
m_target_S_bytes = None

# Ghost lists (non-resident metadata) to adapt split; store key -> (size, last_time)
m_ghost_P = dict()
m_ghost_S = dict()
m_ghost_P_bytes = 0
m_ghost_S_bytes = 0
m_ghost_limit_bytes = None

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)


# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_S_bytes, m_ghost_limit_bytes
    global m_sketch_tables, m_sketch_mask

    if m_target_S_bytes is None:
        # Start a bit frequency-friendly; adapt online
        m_target_S_bytes = cache_snapshot.capacity * 0.6
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cache_snapshot.capacity

    if m_sketch_tables is None:
        # Width scales with capacity; choose power of two near capacity/64 (to limit memory)
        # Minimum width to keep estimates reasonably stable.
        cap = max(1, cache_snapshot.capacity)
        width = 1
        target = max(1024, min(1 << 16, cap // 64))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        # Increment with cap
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        # Halve all counters (right-shift by 1)
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _pick_min_score_in_segment(cache_snapshot, seg_tag):
    # Returns (key, score, last_time) for the minimum TinyLFU score in a segment
    # Score = est_freq(key) / size(key); tie-break by LRU (older first)
    min_key = None
    min_score = None
    min_time = None

    for key, obj in cache_snapshot.cache.items():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        sz = max(1, obj.size)
        est = _sketch_estimate(key)
        score = float(est) / float(sz)
        last = m_key_last_access.get(key, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = key
            min_score = score
            min_time = last

    return (min_key, min_score, min_time)


def _ghost_add(ghost_dict, key, size, time_now, is_P):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_P_bytes, m_ghost_S_bytes, m_ghost_limit_bytes

    if is_P:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_P_bytes += size
        else:
            old_size, _ = prev
            m_ghost_P_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim oldest by time
        while m_ghost_P_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_P_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_S_bytes += size
        else:
            old_size, _ = prev
            m_ghost_S_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        while m_ghost_S_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_S_bytes -= sz


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    global m_ghost_P, m_ghost_S, m_ghost_P_bytes, m_ghost_S_bytes, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step size proportional to object size, bounded to avoid huge jumps
    step = min(obj.size, cap // 4 if cap >= 4 else obj.size)

    if obj.key in m_ghost_P:
        # Recent ghost hit: increase P share (decrease protected)
        m_target_S_bytes = _clamp(m_target_S_bytes - step, 0, cap)
        sz, _ = m_ghost_P.pop(obj.key)
        m_ghost_P_bytes -= sz
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: increase S share
        m_target_S_bytes = _clamp(m_target_S_bytes + step, 0, cap)
        sz, _ = m_ghost_S.pop(obj.key)
        m_ghost_S_bytes -= sz


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using size-aware SLRU + TinyLFU.
    - Compute candidate with minimal TinyLFU score (est_freq/size) in each segment.
    - Bias to evict from the segment exceeding its byte target.
    - Protect S moderately by adding a small bias compared to P.
    - Size-aware: lower freq and larger size are preferred victims.
    '''
    global m_bytes_P, m_bytes_S, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    target_S = _clamp(m_target_S_bytes, 0, cap)
    target_P = cap - target_S

    # Find min-score candidate in each segment
    p_key, p_score, p_lru = _pick_min_score_in_segment(cache_snapshot, 'P')
    s_key, s_score, s_lru = _pick_min_score_in_segment(cache_snapshot, 'S')

    # Estimate the incoming object's benefit (normalized by size)
    incoming_score = float(_sketch_estimate(obj.key) + 1) / float(max(1, obj.size))

    # Segment bias and overweight nudges scaled to incoming_score for stability
    protect_S_bias = incoming_score * 0.15   # discourage evicting S slightly
    overweight_nudge = incoming_score * 0.10 # encourage evicting overweight segment

    # Compute adjusted scores for decision
    best_key = None
    best_adj = None

    if p_key is not None:
        adj_p = p_score
        if m_bytes_P > target_P:
            adj_p -= overweight_nudge
        # Tie-break: older gets slight advantage
        adj_p -= 1e-12 * (p_lru if p_lru is not None else 0)
        best_key = p_key
        best_adj = adj_p

    if s_key is not None:
        adj_s = s_score + protect_S_bias
        if m_bytes_S > target_S:
            adj_s -= overweight_nudge
        adj_s -= 1e-12 * (s_lru if s_lru is not None else 0)
        if (best_adj is None) or (adj_s < best_adj):
            best_adj = adj_s
            best_key = s_key

    # Fallback: if we somehow didn't find any key (shouldn't happen), pick oldest globally
    if best_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        best_key = oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - If in probation (P), promote to protected (S) and move bytes
    '''
    global m_key_last_access, m_key_segment
    global m_bytes_P, m_bytes_S

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Update TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    # Promote from P to S on hit
    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        m_key_segment[k] = 'S'
        # Move bytes P -> S
        m_bytes_P = max(0, m_bytes_P - sz)
        m_bytes_S += sz


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S byte split using ARC-like ghosts
      - Increment TinyLFU for the key (TinyLFU trains on both hits and misses)
      - Add the new object to probation (P)
      - Record last access time
    '''
    global m_key_last_access, m_key_segment
    global m_bytes_P

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    sz = obj.size

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_bytes_P += sz


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
    '''
    global m_key_last_access, m_key_segment
    global m_bytes_P, m_bytes_S
    global m_ghost_P, m_ghost_S

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes and add to appropriate ghost
    if seg == 'S':
        m_bytes_S = max(0, m_bytes_S - esz)
        _ghost_add(m_ghost_S, ek, esz, cache_snapshot.access_count, is_P=False)
    else:
        m_bytes_P = max(0, m_bytes_P - esz)
        _ghost_add(m_ghost_P, ek, esz, cache_snapshot.access_count, is_P=True)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 25
- Hit Rate: 0.2742

Example 2:
- Trace ID: 31
- Hit Rate: 0.0439

Example 3:
- Trace ID: 32
- Hit Rate: 0.0658

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m19:11:10 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 19:11:10,462 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 19:21:20,673 [INFO] openai._base_client: Retrying request to /chat/completions in 0.473970 seconds
[92m19:23:33 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 19:23:33,279 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 19:23:33,280 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Improved: Count-based SLRU with TinyLFU, ARC-style adaptive split, and recency-aware scoring
# - Two resident segments by item count, not by bytes:
#     P (probation): admits all new objects; managed by LRU (via last_access timestamps)
#     S (protected): objects that hit at least once; also LRU-managed
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction score blends frequency and recency (recency matters beyond tie-break)
# - ARC-like ghost lists adapt the item split between P and S online (by counts)
#
# This design captures:
#   - Recency (via LRU timestamps and explicit recency in eviction score)
#   - Frequency (via TinyLFU)
#   - Adaptivity between recency-friendly and frequency-friendly behavior
#   - Correctness for caches limited by number of items (not bytes)

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU)
m_key_segment = dict()       # key -> 'P' or 'S'

# Current resident ITEM COUNTS per segment
m_cnt_P = 0
m_cnt_S = 0

# Adaptive target for protected items (S); probation target = capacity_items - target_S
m_target_S_items = None
m_cap_items_est = 0  # our estimate of capacity in number of items (learned at evict time)

# Ghost lists (non-resident metadata) to adapt split; store key -> last_time
m_ghost_P = dict()  # B1
m_ghost_S = dict()  # B2
m_ghost_limit_items = None

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)

# ---------------
# Scoring params
# ---------------
# Recency blend: score = est_freq + rec_weight * min(recency / half_life, rec_cap)
m_rec_half_life = 500.0  # accesses; tune to make recency effect comparable to est_freq
m_rec_cap = 10.0         # cap normalized recency contribution
m_rec_weight_P = 1.0     # probation recency weight
m_rec_weight_S = 0.6     # protected recency weight (S is more persistent)
m_protect_S_bias = 0.25  # additive bias to S candidates to modestly protect them
m_overweight_nudge = 0.2 # when a segment exceeds target, nudge its candidate to be more evictable

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_target_S_items, m_ghost_limit_items
    global m_sketch_tables, m_sketch_mask
    global m_cap_items_est

    # Learn capacity in items opportunistically; on evict() we'll update more accurately.
    if m_cap_items_est < len(cache_snapshot.cache):
        m_cap_items_est = len(cache_snapshot.cache)

    if m_target_S_items is None:
        # Start slightly frequency-friendly; adapt online
        base_items = max(1, len(cache_snapshot.cache))
        m_target_S_items = int(base_items * 0.6)

    if m_ghost_limit_items is None:
        # Each ghost list limited to approximately the cache capacity in items (we adjust later)
        m_ghost_limit_items = max(1, len(cache_snapshot.cache))

    if m_sketch_tables is None:
        # Width scales with estimated items; choose power of two near items*4 (empirical)
        # Minimum width to keep estimates reasonably stable.
        items = max(1, len(cache_snapshot.cache))
        width = 1
        target = max(1024, min(1 << 16, items * 4))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        # Halve all counters (right-shift by 1)
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _normalized_recency(now, last):
    if last is None or last < 0:
        return m_rec_cap
    age = max(0, now - last)
    norm = age / m_rec_half_life
    if norm > m_rec_cap:
        norm = m_rec_cap
    return norm


def _pick_min_score_in_segment(cache_snapshot, seg_tag, now):
    # Returns (key, score, last_time) that minimizes blended score within a segment
    # Score = est_freq + rec_weight * normalized_recency; tie-break by older first
    min_key = None
    min_score = None
    min_time = None

    rec_w = m_rec_weight_S if seg_tag == 'S' else m_rec_weight_P

    for key, obj in cache_snapshot.cache.items():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        est = float(_sketch_estimate(key))
        last = m_key_last_access.get(key, -1)
        rec = _normalized_recency(now, last)
        score = est + rec_w * rec
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = key
            min_score = score
            min_time = last

    return (min_key, min_score, min_time)


def _find_oldest_in_segment(cache_snapshot, seg_tag):
    oldest_key, oldest_time = None, None
    for k in cache_snapshot.cache.keys():
        if m_key_segment.get(k, 'P') != seg_tag:
            continue
        t = m_key_last_access.get(k, -1)
        if oldest_time is None or t < oldest_time:
            oldest_key, oldest_time = k, t
    return oldest_key


def _ghost_add(ghost_dict, key, time_now, which):
    # Add key->time to chosen ghost (which in {'P','S'}), trimming if exceeds limit
    global m_ghost_limit_items

    # Insert/update
    ghost_dict[key] = time_now

    # Trim to limit by evicting oldest
    limit = m_ghost_limit_items or 0
    if limit <= 0:
        return

    while len(ghost_dict) > limit:
        oldest_key, oldest_time = None, None
        for k, t in ghost_dict.items():
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        if oldest_key is None:
            break
        ghost_dict.pop(oldest_key, None)


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    # If key in P-ghost (B1): increase probation share (decrease S target)
    # If key in S-ghost (B2): increase protected share (increase S target)
    global m_target_S_items, m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Update our item-capacity estimate when cache is likely full (best signal: on evict call, but keep here too)
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)

    # Keep ghost size limits around capacity in items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est

    cap_items = max(1, m_cap_items_est)

    # Step size: 1 item per signal (conservative, stable)
    step = 1

    if obj.key in m_ghost_P:
        # Recent ghost hit: favor recency -> increase P share (decrease S)
        m_target_S_items = _clamp((m_target_S_items or 0) - step, 0, cap_items)
        m_ghost_P.pop(obj.key, None)
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: favor frequency -> increase S share
        m_target_S_items = _clamp((m_target_S_items or 0) + step, 0, cap_items)
        m_ghost_S.pop(obj.key, None)


def _maybe_demote_from_S_to_P(cache_snapshot):
    # If S exceeds its target, demote oldest S item to P
    global m_cnt_P, m_cnt_S, m_target_S_items
    if m_target_S_items is None:
        return
    if m_cnt_S > m_target_S_items:
        demote_key = _find_oldest_in_segment(cache_snapshot, 'S')
        if demote_key is not None:
            m_key_segment[demote_key] = 'P'
            m_cnt_S = max(0, m_cnt_S - 1)
            m_cnt_P += 1


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using count-based SLRU + TinyLFU with recency-aware scoring.
    - Compute candidate with minimal blended score in each segment:
        score = est_freq(key) + rec_weight * normalized_recency
    - Bias to evict from the segment exceeding its item-count target.
    - Protect S moderately by adding a small bias compared to P.
    '''
    global m_cnt_P, m_cnt_S, m_target_S_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Learn/refresh capacity in number of items at the moment of eviction (cache is full now)
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    cap_items = max(1, m_cap_items_est)
    if m_target_S_items is None:
        m_target_S_items = int(0.6 * cap_items)
    target_S = _clamp(m_target_S_items, 0, cap_items)
    target_P = cap_items - target_S

    now = cache_snapshot.access_count

    # Find min-score candidate in each segment
    p_key, p_score, p_lru = _pick_min_score_in_segment(cache_snapshot, 'P', now)
    s_key, s_score, s_lru = _pick_min_score_in_segment(cache_snapshot, 'S', now)

    # Prepare adjusted scores
    best_key = None
    best_adj = None

    if p_key is not None:
        adj_p = p_score
        # If P is overweight, make it slightly more likely to evict from P
        if m_cnt_P > target_P:
            adj_p -= m_overweight_nudge
        # No extra protection bias for P
        best_key = p_key
        best_adj = adj_p

    if s_key is not None:
        adj_s = s_score + m_protect_S_bias
        # If S is overweight, encourage eviction from S
        if m_cnt_S > target_S:
            adj_s -= m_overweight_nudge
        if (best_adj is None) or (adj_s < best_adj):
            best_adj = adj_s
            best_key = s_key

    # Fallback: if we somehow didn't find any key (shouldn't happen), pick oldest globally
    if best_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        best_key = oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - If in probation (P), promote to protected (S); if S exceeds target, demote oldest S to P
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    k = obj.key

    # Update TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    # Promote from P to S on hit
    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        m_key_segment[k] = 'S'
        m_cnt_P = max(0, m_cnt_P - 1)
        m_cnt_S += 1
        # If S above target, demote oldest S back to P
        _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S item split using ARC-like ghosts
      - Increment TinyLFU for the key (TinyLFU trains on both hits and misses)
      - Add the new object to probation (P)
      - Record last access time
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_cnt_P += 1

    # Keep S from drifting above target if previous operations changed target
    _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key
      - Update segment item counters
      - Add the key to the corresponding ghost list (count-limited) to guide future adaptation
      - Keep ghost sizes roughly equal to estimated cache capacity in items
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S
    global m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust item counts and add to appropriate ghost
    now = cache_snapshot.access_count
    if seg == 'S':
        m_cnt_S = max(0, m_cnt_S - 1)
        _ghost_add(m_ghost_S, ek, now, which='S')
    else:
        m_cnt_P = max(0, m_cnt_P - 1)
        _ghost_add(m_ghost_P, ek, now, which='P')

    # Update ghost limits to approximate current capacity in items
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est
```
2025-11-27 19:29:25,474 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# W-TinyLFU + Segmented protection + Size-aware retention
# - Two logical segments:
#     1) probation (new/resurrected items)
#     2) protected (promoted on hit; byte-quota limited)
# - TinyLFU frequency counters with lazy epoch decay (8-bit saturating)
# - Size-aware retention: benefit = log1p(freq) / normalized_size
# - Recency bonus added (not subtracted) to protect recent items
# - Protected segment gets an extra bonus; demoted by LRU when over target bytes
# - Eviction uses lazy min-heaps (probation first, then protected) to avoid full scans
#   with lazy invalidation via per-key stamps; periodic score refresh on pop.
#
# This design:
#   - Dramatically reduces per-eviction cost (avoids O(n) scans) -> fewer timeouts
#   - Corrects recency sign (recent items are now protected, not penalized)
#   - Uses size-aware TinyLFU benefit and a protected segment to cut miss rate

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Cache identity (to reset between runs if needed)
m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting
m_prot_bytes = 0
m_prot_target_bytes = 0

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_probation = []           # retention score (lower => more evictable) for probation
h_protected = []           # retention score for protected (used when probation empty)
h_prot_lru = []            # last_access (min-heap) for protected demotions

# TinyLFU counters (lazy decay with epochs; per-key to keep it simple)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Protected segment target (bytes)
PROT_FRAC = 0.80           # target fraction of capacity for protected bytes

# Recency window and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 3           # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.60     # recency weight in probation
REC_WEIGHT_PROT = 0.40     # recency weight in protected
PROT_BONUS = 0.60          # extra benefit for protected segment
MULTI_HIT_BONUS = 0.30     # extra benefit for items with >=2 resident hits

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16  # bound reheap/refresh work per eviction

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC * cache_snapshot.capacity)

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Return size as percentage of capacity to keep scales stable
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _retention_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # treat missing as extremely good (will be filtered by validity)
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)

    seg = m_segment.get(key, 0)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    # Size-aware frequency benefit
    benefit = math.log1p(float(freq)) / size_norm

    # Multi-hit bias
    if m_resident_hits.get(key, 0) >= 2:
        benefit += MULTI_HIT_BONUS

    # Recency bonus
    if seg == 1:
        benefit += PROT_BONUS + REC_WEIGHT_PROT * rec_bonus
    else:
        benefit += REC_WEIGHT_PROB * rec_bonus

    return benefit


# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    # Compute score at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    score = _retention_score(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (score, s, key))
    else:
        heapq.heappush(h_protected, (score, s, key))
        # Also maintain LRU heap for protected demotions
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot, heap_ref, expected_seg):
    # Return a valid key from the given heap, refreshing stale scores when needed.
    # Limit work per call to avoid long stalls.
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        # Skip invalid/stale entries
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Opportunistically refresh score if it drifted
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            # Reinsert with a new stamp
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key
    return None


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        # Push into probation heap with updated score/stamp
        _push_key(cache_snapshot, key)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim:
      1) Pop the weakest from probation heap (lowest retention)
      2) If probation empty, pop the weakest from protected heap
      3) Fallback: any resident key
    '''
    _init_if_needed(cache_snapshot)

    # Prefer evicting from probation
    victim = _pop_best_candidate(cache_snapshot, h_probation, expected_seg=0)
    if victim is None:
        victim = _pop_best_candidate(cache_snapshot, h_protected, expected_seg=1)

    if victim is not None:
        return victim

    # Fallback: arbitrary key (should be rare)
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote probation -> protected on first resident hit
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with new score/recency
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote to protected
        m_segment[k] = 1
        # Account protected bytes
        global m_prot_bytes
        m_prot_bytes += obj.size
        # Push into protected heaps
        _push_key(cache_snapshot, k)
        # Enforce protected target
        _maybe_demote_protected(cache_snapshot)
    else:
        # Already protected: refresh heaps
        _push_key(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place into probation segment and push to heap
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation
    _push_key(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Adjust protected bytes if it was protected
    seg = m_segment.pop(ek, None)
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 16
- Hit Rate: 0.0206

Example 2:
- Trace ID: 2
- Hit Rate: 0.4805

Example 3:
- Trace ID: 26
- Hit Rate: 0.7905

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m19:29:25 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 19:29:25,475 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m19:32:45 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 19:32:45,145 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 19:32:45,146 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive, size-aware TinyLFU with ARC-style protection sizing
# - Two logical resident segments:
#     0) probation (new/resurrected)
#     1) protected (promoted on hit; byte-quota limited, LRU demoted)
# - TinyLFU frequency with lazy epoch decay (8-bit saturating)
# - Size-aware retention: benefit ~ log1p(freq)/size_norm + recency bonus
# - ARC-style ghost histories to adapt protected quota between [MIN..MAX]
# - Eviction chooses the globally weakest between probation and protected
#   (still biased by protected bonus), with lazy heaps and stamped entries
# - Periodic gentle drift of protected target back to base fraction
#
# Goals:
#   - Better across patterns by adapting protected share (recency vs frequency)
#   - More precise victim choice (cross-segment min) with size-awareness
#   - Keep per-op overhead bounded via lazy heaps and stamps

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Cache identity (to reset between runs if needed)
m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting and target (adaptive)
m_prot_bytes = 0
m_prot_target_bytes = 0
m_last_adapt_access = 0

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_probation = []           # retention score (lower => more evictable) for probation
h_protected = []           # retention score for protected
h_prot_lru = []            # last_access (min-heap) for protected demotions

# TinyLFU counters (lazy decay with epochs; per-key to keep it simple)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# Ghost histories for ARC-style adaptation (LRU via heaps, with stamps)
gP = dict()                # probation ghost: key -> (size:int, last:int, stamp:int)
gT = dict()                # protected ghost: key -> (size:int, last:int, stamp:int)
gP_heap = []               # (last, stamp, key)
gT_heap = []               # (last, stamp, key)
gP_bytes = 0
gT_bytes = 0
gP_stamp = dict()
gT_stamp = dict()

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Protected segment target (adaptive)
PROT_BASE_FRAC = 0.75      # base target fraction for protected bytes
PROT_MIN_FRAC = 0.30
PROT_MAX_FRAC = 0.92
ADAPT_STEP_FRAC = 0.05     # step per ghost hit (of capacity)
ADAPT_DECAY_INTERVAL = 8192  # accesses between gentle drift towards base
ADAPT_DECAY_STEP_FRAC = 0.02 # drift step (of capacity)

# Recency window and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 3           # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.70     # recency weight in probation
REC_WEIGHT_PROT = 0.25     # recency weight in protected
PROT_BONUS = 0.35          # extra benefit for protected segment
MULTI_HIT_BONUS_2 = 0.30   # extra benefit for items with >=2 resident hits
MULTI_HIT_BONUS_4 = 0.20   # extra benefit for items with >=4 resident hits

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16  # bound reheap/refresh work per eviction

# Ghost history budget (bytes)
GHOST_FRAC = 0.50          # total ghost bytes ~= GHOST_FRAC * capacity, split evenly
# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes, m_last_adapt_access
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch
    global gP, gT, gP_heap, gT_heap, gP_bytes, gT_bytes, gP_stamp, gT_stamp

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_BASE_FRAC * cache_snapshot.capacity)
    m_last_adapt_access = cache_snapshot.access_count

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0

    gP.clear()
    gT.clear()
    gP_heap.clear()
    gT_heap.clear()
    gP_bytes = 0
    gT_bytes = 0
    gP_stamp.clear()
    gT_stamp.clear()


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)
    _adapt_periodic(cache_snapshot)

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Ghost history helpers (ARC adaptation)
# -----------------------------

def _g_stamp_next(gstamp_map, key):
    s = gstamp_map.get(key, 0) + 1
    gstamp_map[key] = s
    return s

def _ghost_target_bytes(cache_snapshot):
    # Split evenly between probation/protected ghosts
    total = int(GHOST_FRAC * cache_snapshot.capacity)
    return total // 2

def _ghost_add(cache_snapshot, seg, key, size, last):
    # seg=0 -> probation ghost, seg=1 -> protected ghost
    global gP_bytes, gT_bytes
    target = _ghost_target_bytes(cache_snapshot)
    if seg == 0:
        s = _g_stamp_next(gP_stamp, key)
        gP[key] = (size, last, s)
        gP_bytes += size
        heapq.heappush(gP_heap, (last, s, key))
        # trim
        while gP_bytes > target and gP_heap:
            l, st, k = heapq.heappop(gP_heap)
            entry = gP.get(k)
            if entry is None:
                continue
            sz, la, s_expect = entry
            if s_expect != st or la != l:
                continue
            gP_bytes = max(0, gP_bytes - sz)
            gP.pop(k, None)
    else:
        s = _g_stamp_next(gT_stamp, key)
        gT[key] = (size, last, s)
        gT_bytes += size
        heapq.heappush(gT_heap, (last, s, key))
        # trim
        while gT_bytes > target and gT_heap:
            l, st, k = heapq.heappop(gT_heap)
            entry = gT.get(k)
            if entry is None:
                continue
            sz, la, s_expect = entry
            if s_expect != st or la != l:
                continue
            gT_bytes = max(0, gT_bytes - sz)
            gT.pop(k, None)

def _ghost_check_and_adapt(cache_snapshot, key):
    # If key seen in ghost, adapt protected target toward that segment
    # - if in probation ghost: need more recency -> decrease protected target
    # - if in protected ghost: need more frequency -> increase protected target
    global m_prot_target_bytes, gP_bytes, gT_bytes
    cap = cache_snapshot.capacity
    step = max(1, int(ADAPT_STEP_FRAC * cap))
    if key in gP:
        # decrease protected target
        m_prot_target_bytes = max(int(PROT_MIN_FRAC * cap), m_prot_target_bytes - step)
        # remove this ghost record to avoid repeated pushes on same key
        sz, _, _ = gP.pop(key)
        gP_bytes = max(0, gP_bytes - sz)
    elif key in gT:
        m_prot_target_bytes = min(int(PROT_MAX_FRAC * cap), m_prot_target_bytes + step)
        sz, _, _ = gT.pop(key)
        gT_bytes = max(0, gT_bytes - sz)

def _adapt_periodic(cache_snapshot):
    # Gentle drift back towards base fraction periodically
    global m_last_adapt_access, m_prot_target_bytes
    if cache_snapshot.access_count - m_last_adapt_access < ADAPT_DECAY_INTERVAL:
        return
    m_last_adapt_access = cache_snapshot.access_count
    cap = cache_snapshot.capacity
    base = int(PROT_BASE_FRAC * cap)
    if m_prot_target_bytes == base:
        return
    step = max(1, int(ADAPT_DECAY_STEP_FRAC * cap))
    if m_prot_target_bytes < base:
        m_prot_target_bytes = min(base, m_prot_target_bytes + step)
    else:
        m_prot_target_bytes = max(base, m_prot_target_bytes - step)

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Return size as percentage of capacity to keep scales stable
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))

def _retention_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # non-resident; will be filtered
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)

    seg = m_segment.get(key, 0)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    # Size-aware frequency benefit
    benefit = math.log1p(float(freq)) / size_norm

    # Multi-hit bias
    rh = m_resident_hits.get(key, 0)
    if rh >= 2:
        benefit += MULTI_HIT_BONUS_2
    if rh >= 4:
        benefit += MULTI_HIT_BONUS_4

    # Recency bonus
    if seg == 1:
        benefit += PROT_BONUS + REC_WEIGHT_PROT * rec_bonus
    else:
        benefit += REC_WEIGHT_PROB * rec_bonus

    return benefit

# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s

def _push_key(cache_snapshot, key):
    # Compute score at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    score = _retention_score(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (score, s, key))
    else:
        heapq.heappush(h_protected, (score, s, key))
        # Also maintain LRU heap for protected demotions
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))

def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True

def _pop_best_with_score(cache_snapshot, heap_ref, expected_seg):
    # Pop a valid key from the given heap and return (key, refreshed_score).
    # May perform limited refresh/reinsert attempts.
    attempts = 0
    heap = heap_ref
    sel = None
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Refresh score; if drifted, reinsert and continue
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        sel = (key, new_score)
        break
    return sel  # (key, score) or None

def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        # Push into probation heap with updated score/stamp
        _push_key(cache_snapshot, key)

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim:
      - Enforce protected-byte target via LRU demotions
      - Select the globally weakest between probation and protected
        using their refreshed retention scores
      - Reinsert the non-chosen candidate back into its heap
      - Fallback: any resident key (rare)
    '''
    _init_if_needed(cache_snapshot)

    # Keep protected within its adaptive target
    _maybe_demote_protected(cache_snapshot)

    # Pop best candidates from both segments
    cand_prob = _pop_best_with_score(cache_snapshot, h_probation, expected_seg=0)
    cand_prot = _pop_best_with_score(cache_snapshot, h_protected, expected_seg=1)

    victim_key = None
    # Choose the lower score (weaker retention)
    if cand_prob is not None and cand_prot is not None:
        kp, sp = cand_prob
        kt, st = cand_prot
        if sp <= st:
            victim_key = kp
            # reinsert the protected candidate back
            _push_key(cache_snapshot, kt)
        else:
            victim_key = kt
            # reinsert the probation candidate back
            _push_key(cache_snapshot, kp)
    elif cand_prob is not None:
        victim_key = cand_prob[0]
    elif cand_prot is not None:
        victim_key = cand_prot[0]

    if victim_key is not None:
        return victim_key

    # Fallback: arbitrary key
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote probation -> protected on first resident hit
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with new score/recency
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote to protected on first resident hit
        m_segment[k] = 1
        # Account protected bytes
        global m_prot_bytes
        m_prot_bytes += obj.size
        # Push into protected heaps
        _push_key(cache_snapshot, k)
        # Enforce protected target
        _maybe_demote_protected(cache_snapshot)
    else:
        # Already protected: refresh heaps and LRU
        _push_key(cache_snapshot, k)
        # Maintain protected target (if fell behind)
        _maybe_demote_protected(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling)
      - ARC-style adaptation: if the key appears in a ghost list, adjust protected target
      - Initialize resident metadata: last_access, resident_hits = 0
      - Place into probation segment and push to heap
      - Enforce protected target in case prior promotions exceeded target
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)

    # ARC-style adaptation using ghost histories
    _ghost_check_and_adapt(cache_snapshot, k)

    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 0  # start at 0; first hit -> 1
    m_segment[k] = 0  # probation
    _push_key(cache_snapshot, k)

    # Ensure protected target respected (if previous hits/promotions inflated it)
    _maybe_demote_protected(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Record into appropriate ghost history for ARC-style adaptation
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    last = m_last_access.get(ek, cache_snapshot.access_count)
    seg = m_segment.pop(ek, None)

    # Ghost history insertion (size and last access)
    if seg is not None:
        _ghost_add(cache_snapshot, seg, ek, evicted_obj.size, last)

    # Adjust protected bytes if it was protected
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```
2025-11-27 19:33:05,764 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# W-TinyLFU + Segmented protection + Size-aware retention
# - Two logical segments:
#     1) probation (new/resurrected items)
#     2) protected (promoted on hit; byte-quota limited)
# - TinyLFU frequency counters with lazy epoch decay (8-bit saturating)
# - Size-aware retention: benefit = log1p(freq) / normalized_size
# - Recency bonus added (not subtracted) to protect recent items
# - Protected segment gets an extra bonus; demoted by LRU when over target bytes
# - Eviction uses lazy min-heaps (probation first, then protected) to avoid full scans
#   with lazy invalidation via per-key stamps; periodic score refresh on pop.
#
# This design:
#   - Dramatically reduces per-eviction cost (avoids O(n) scans) -> fewer timeouts
#   - Corrects recency sign (recent items are now protected, not penalized)
#   - Uses size-aware TinyLFU benefit and a protected segment to cut miss rate

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Cache identity (to reset between runs if needed)
m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting
m_prot_bytes = 0
m_prot_target_bytes = 0

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_probation = []           # retention score (lower => more evictable) for probation
h_protected = []           # retention score for protected (used when probation empty)
h_prot_lru = []            # last_access (min-heap) for protected demotions

# TinyLFU counters (lazy decay with epochs; per-key to keep it simple)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Protected segment target (bytes)
PROT_FRAC = 0.80           # target fraction of capacity for protected bytes

# Recency window and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 3           # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.60     # recency weight in probation
REC_WEIGHT_PROT = 0.40     # recency weight in protected
PROT_BONUS = 0.60          # extra benefit for protected segment
MULTI_HIT_BONUS = 0.30     # extra benefit for items with >=2 resident hits

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16  # bound reheap/refresh work per eviction

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC * cache_snapshot.capacity)

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Return size as percentage of capacity to keep scales stable
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _retention_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # treat missing as extremely good (will be filtered by validity)
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)

    seg = m_segment.get(key, 0)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    # Size-aware frequency benefit
    benefit = math.log1p(float(freq)) / size_norm

    # Multi-hit bias
    if m_resident_hits.get(key, 0) >= 2:
        benefit += MULTI_HIT_BONUS

    # Recency bonus
    if seg == 1:
        benefit += PROT_BONUS + REC_WEIGHT_PROT * rec_bonus
    else:
        benefit += REC_WEIGHT_PROB * rec_bonus

    return benefit


# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    # Compute score at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    score = _retention_score(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (score, s, key))
    else:
        heapq.heappush(h_protected, (score, s, key))
        # Also maintain LRU heap for protected demotions
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot, heap_ref, expected_seg):
    # Return a valid key from the given heap, refreshing stale scores when needed.
    # Limit work per call to avoid long stalls.
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        # Skip invalid/stale entries
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Opportunistically refresh score if it drifted
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            # Reinsert with a new stamp
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key
    return None


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        # Push into probation heap with updated score/stamp
        _push_key(cache_snapshot, key)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim:
      1) Pop the weakest from probation heap (lowest retention)
      2) If probation empty, pop the weakest from protected heap
      3) Fallback: any resident key
    '''
    _init_if_needed(cache_snapshot)

    # Prefer evicting from probation
    victim = _pop_best_candidate(cache_snapshot, h_probation, expected_seg=0)
    if victim is None:
        victim = _pop_best_candidate(cache_snapshot, h_protected, expected_seg=1)

    if victim is not None:
        return victim

    # Fallback: arbitrary key (should be rare)
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote probation -> protected on first resident hit
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with new score/recency
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote to protected
        m_segment[k] = 1
        # Account protected bytes
        global m_prot_bytes
        m_prot_bytes += obj.size
        # Push into protected heaps
        _push_key(cache_snapshot, k)
        # Enforce protected target
        _maybe_demote_protected(cache_snapshot)
    else:
        # Already protected: refresh heaps
        _push_key(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place into probation segment and push to heap
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation
    _push_key(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Adjust protected bytes if it was protected
    seg = m_segment.pop(ek, None)
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 36
- Hit Rate: 0.2115

Example 2:
- Trace ID: 27
- Hit Rate: 0.8923

Example 3:
- Trace ID: 17
- Hit Rate: 0.0238

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m19:33:05 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 19:33:05,765 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m19:35:34 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 19:35:34,321 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 19:35:34,322 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# W-TinyLFU + 3-segment SLRU (Window/Probation/Protected) + Size-aware retention
# - Segments (by bytes):
#     0) window: small, pure LRU for recency sampling; all new items start here
#     1) probation: candidates promoted from window upon first hit; scored by TinyLFU+size+recency
#     2) protected: promoted on second hit; scored; demoted by LRU to stay within byte target
#
# - TinyLFU per-key counters with lazy epoch decay (8-bit saturating)
# - Size-aware retention: benefit = log1p(freq) / normalized_size
# - Recency bonus protects recent items; protected gets extra protection
# - Eviction order:
#     a) If window exceeds its byte target: evict LRU from window
#     b) Else evict lowest-score from probation
#     c) Else evict lowest-score from protected
#     d) Fallback: arbitrary resident key
#
# This design aims to:
#   - Greatly improve scan resistance with a dedicated recency window (prevents scans from polluting main space)
#   - Use TinyLFU frequency signal and size-awareness to retain high-value items
#   - Reduce miss rate on diverse traces by balancing recency (window) and frequency (probation/protected)
#   - Keep per-eviction overhead low via lazy heaps and stamped invalidation

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Cache identity (to reset between runs if needed)
m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count (while resident)
# Segment: 0=window, 1=probation, 2=protected
m_segment = dict()         # key -> int segment id
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Segment bytes accounting and targets
m_win_bytes = 0
m_prot_bytes = 0
m_win_target_bytes = 0
m_prot_target_bytes = 0    # target for protected within (capacity - window_target)

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_window_lru = []          # (last_access, stamp, key) for window LRU
h_probation = []           # (retention score, stamp, key) for probation
h_protected = []           # (retention score, stamp, key) for protected
h_prot_lru = []            # (last_access, stamp, key) for protected demotions

# TinyLFU counters (lazy decay with epochs; per-key)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Segment byte targets
WIN_FRAC = 0.10            # window LRU fraction of capacity (bytes)
PROT_MAIN_FRAC = 0.80      # protected fraction of non-window bytes (bytes)

# Recency window and weights (for scored segments)
REC_WIN_MIN = 512
REC_WIN_MULT = 3           # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.65     # recency weight in probation
REC_WEIGHT_PROT = 0.40     # recency weight in protected
PROT_BONUS = 0.60          # extra benefit for protected segment
MULTI_HIT_BONUS = 0.30     # extra benefit for items with >=2 resident hits

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16  # bound reheap/refresh work per eviction

# Admission tweak: if LFU >= this on insert, bypass window into probation
ADMIT_TO_PROB_LFU = 2

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_win_bytes, m_prot_bytes, m_win_target_bytes, m_prot_target_bytes
    global h_window_lru, h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_win_bytes = 0
    m_prot_bytes = 0

    cap = max(1, cache_snapshot.capacity)
    m_win_target_bytes = int(WIN_FRAC * cap)
    main_bytes = cap - m_win_target_bytes
    m_prot_target_bytes = int(PROT_MAIN_FRAC * max(0, main_bytes))

    h_window_lru.clear()
    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Return size as percentage of capacity to keep scales stable
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _retention_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # treat missing as extremely good (filtered by validity)
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)

    seg = m_segment.get(key, 1)  # default to probation for safety
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    # Size-aware frequency benefit
    benefit = math.log1p(float(freq)) / size_norm

    # Multi-hit bias
    if m_resident_hits.get(key, 0) >= 2:
        benefit += MULTI_HIT_BONUS

    # Recency bonus and segment protection
    if seg == 2:  # protected
        benefit += PROT_BONUS + REC_WEIGHT_PROT * rec_bonus
    else:         # probation
        benefit += REC_WEIGHT_PROB * rec_bonus

    return benefit


# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    # Compute score at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 1)
    s = _next_stamp(key)
    if seg == 0:
        # window LRU only
        last = m_last_access.get(key, -1)
        heapq.heappush(h_window_lru, (last, s, key))
    elif seg == 1:
        score = _retention_score(cache_snapshot, key)
        heapq.heappush(h_probation, (score, s, key))
    else:
        score = _retention_score(cache_snapshot, key)
        heapq.heappush(h_protected, (score, s, key))
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot, heap_ref, expected_seg):
    # Return a valid key from the given heap, refreshing stale scores when needed.
    # Limit work per call to avoid long stalls.
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        # Skip invalid/stale entries
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Opportunistically refresh score if it drifted
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            # Reinsert with a new stamp
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key
    return None


def _pop_oldest_window(cache_snapshot):
    attempts = 0
    while h_window_lru and attempts < MAX_HEAP_FIX_PER_EVICT:
        last, stamp, key = heapq.heappop(h_window_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=0, stamp=stamp):
            attempts += 1
            continue
        return key
    return None


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=2, stamp=stamp):
            continue
        # Demote to probation
        m_segment[key] = 1
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        # Push into probation heap with updated score/stamp
        _push_key(cache_snapshot, key)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim:
      1) If window is over its byte target, evict its LRU
      2) Else pop the weakest from probation heap (lowest retention)
      3) If probation empty, pop the weakest from protected heap
      4) Fallback: any resident key
    '''
    _init_if_needed(cache_snapshot)

    # Keep protected within target (demote if needed)
    _maybe_demote_protected(cache_snapshot)

    # Prefer evicting from window if it's above target
    global m_win_bytes
    if m_win_bytes > m_win_target_bytes:
        victim = _pop_oldest_window(cache_snapshot)
        if victim is not None:
            return victim

    # Otherwise evict from scored segments
    victim = _pop_best_candidate(cache_snapshot, h_probation, expected_seg=1)
    if victim is None:
        victim = _pop_best_candidate(cache_snapshot, h_protected, expected_seg=2)

    if victim is not None:
        return victim

    # Fallback: arbitrary key (should be rare)
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote:
          window -> probation on 1st hit
          probation -> protected on subsequent hit
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with new score/recency
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote window -> probation
        m_segment[k] = 1
        # Account bytes: leave window
        global m_win_bytes
        m_win_bytes = max(0, m_win_bytes - obj.size)
        # Push into probation heap
        _push_key(cache_snapshot, k)
    elif seg == 1:
        # Promote probation -> protected
        m_segment[k] = 2
        global m_prot_bytes
        m_prot_bytes += obj.size
        # Push into protected heaps
        _push_key(cache_snapshot, k)
        # Enforce protected target
        _maybe_demote_protected(cache_snapshot)
    else:
        # Already protected: refresh heaps (score and LRU)
        _push_key(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place into window segment by default (pure LRU)
      - If LFU evidence already strong (>= ADMIT_TO_PROB_LFU), bypass to probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    freq = _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    global m_win_bytes, m_prot_bytes

    if freq >= ADMIT_TO_PROB_LFU:
        # Bypass window into probation (strong prior)
        m_segment[k] = 1
        _push_key(cache_snapshot, k)
    else:
        # Window admission
        m_segment[k] = 0
        m_win_bytes += obj.size
        _push_key(cache_snapshot, k)

    # Keep protected in check if needed
    _maybe_demote_protected(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust segment bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    seg = m_segment.pop(ek, None)

    global m_win_bytes, m_prot_bytes
    if seg == 0:
        m_win_bytes = max(0, m_win_bytes - evicted_obj.size)
    elif seg == 2:
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```
2025-11-27 19:36:08,221 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# W-TinyLFU-style SLRU with size-aware eviction and ARC-like adaptive P/S split
# - Two resident segments by bytes:
#     P (probation): admits all new objects; managed by LRU (via last_access timestamps)
#     S (protected): objects that hit at least once; also LRU-managed
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction is size-aware: minimize estimated harm est_freq(key)/size(key)
#   and bias toward evicting from P unless S object is clearly worse.
# - ARC-like ghost lists adapt the byte split between P and S online.
#
# This design captures:
#   - Recency (via LRU within segments)
#   - Frequency (via TinyLFU)
#   - Size-awareness (benefit ~ freq/size)
#   - Adaptivity between recency-friendly and frequency-friendly behavior

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU)
m_key_segment = dict()       # key -> 'P' or 'S'

# Current resident bytes per segment
m_bytes_P = 0
m_bytes_S = 0

# Adaptive target for protected bytes (S); probation target = capacity - target_S
m_target_S_bytes = None

# Ghost lists (non-resident metadata) to adapt split; store key -> (size, last_time)
m_ghost_P = dict()
m_ghost_S = dict()
m_ghost_P_bytes = 0
m_ghost_S_bytes = 0
m_ghost_limit_bytes = None

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)


# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_S_bytes, m_ghost_limit_bytes
    global m_sketch_tables, m_sketch_mask

    if m_target_S_bytes is None:
        # Start a bit frequency-friendly; adapt online
        m_target_S_bytes = cache_snapshot.capacity * 0.6
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cache_snapshot.capacity

    if m_sketch_tables is None:
        # Width scales with capacity; choose power of two near capacity/64 (to limit memory)
        # Minimum width to keep estimates reasonably stable.
        cap = max(1, cache_snapshot.capacity)
        width = 1
        target = max(1024, min(1 << 16, cap // 64))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        # Increment with cap
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        # Halve all counters (right-shift by 1)
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _pick_min_score_in_segment(cache_snapshot, seg_tag):
    # Returns (key, score, last_time) for the minimum TinyLFU score in a segment
    # Score = est_freq(key) / size(key); tie-break by LRU (older first)
    min_key = None
    min_score = None
    min_time = None

    for key, obj in cache_snapshot.cache.items():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        sz = max(1, obj.size)
        est = _sketch_estimate(key)
        score = float(est) / float(sz)
        last = m_key_last_access.get(key, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = key
            min_score = score
            min_time = last

    return (min_key, min_score, min_time)


def _ghost_add(ghost_dict, key, size, time_now, is_P):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_P_bytes, m_ghost_S_bytes, m_ghost_limit_bytes

    if is_P:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_P_bytes += size
        else:
            old_size, _ = prev
            m_ghost_P_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim oldest by time
        while m_ghost_P_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_P_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_S_bytes += size
        else:
            old_size, _ = prev
            m_ghost_S_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        while m_ghost_S_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_S_bytes -= sz


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    global m_ghost_P, m_ghost_S, m_ghost_P_bytes, m_ghost_S_bytes, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step size proportional to object size, bounded to avoid huge jumps
    step = min(obj.size, cap // 4 if cap >= 4 else obj.size)

    if obj.key in m_ghost_P:
        # Recent ghost hit: increase P share (decrease protected)
        m_target_S_bytes = _clamp(m_target_S_bytes - step, 0, cap)
        sz, _ = m_ghost_P.pop(obj.key)
        m_ghost_P_bytes -= sz
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: increase S share
        m_target_S_bytes = _clamp(m_target_S_bytes + step, 0, cap)
        sz, _ = m_ghost_S.pop(obj.key)
        m_ghost_S_bytes -= sz


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using size-aware SLRU + TinyLFU.
    - Compute candidate with minimal TinyLFU score (est_freq/size) in each segment.
    - Bias to evict from the segment exceeding its byte target.
    - Protect S moderately by adding a small bias compared to P.
    - Size-aware: lower freq and larger size are preferred victims.
    '''
    global m_bytes_P, m_bytes_S, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    target_S = _clamp(m_target_S_bytes, 0, cap)
    target_P = cap - target_S

    # Find min-score candidate in each segment
    p_key, p_score, p_lru = _pick_min_score_in_segment(cache_snapshot, 'P')
    s_key, s_score, s_lru = _pick_min_score_in_segment(cache_snapshot, 'S')

    # Estimate the incoming object's benefit (normalized by size)
    incoming_score = float(_sketch_estimate(obj.key) + 1) / float(max(1, obj.size))

    # Segment bias and overweight nudges scaled to incoming_score for stability
    protect_S_bias = incoming_score * 0.15   # discourage evicting S slightly
    overweight_nudge = incoming_score * 0.10 # encourage evicting overweight segment

    # Compute adjusted scores for decision
    best_key = None
    best_adj = None

    if p_key is not None:
        adj_p = p_score
        if m_bytes_P > target_P:
            adj_p -= overweight_nudge
        # Tie-break: older gets slight advantage
        adj_p -= 1e-12 * (p_lru if p_lru is not None else 0)
        best_key = p_key
        best_adj = adj_p

    if s_key is not None:
        adj_s = s_score + protect_S_bias
        if m_bytes_S > target_S:
            adj_s -= overweight_nudge
        adj_s -= 1e-12 * (s_lru if s_lru is not None else 0)
        if (best_adj is None) or (adj_s < best_adj):
            best_adj = adj_s
            best_key = s_key

    # Fallback: if we somehow didn't find any key (shouldn't happen), pick oldest globally
    if best_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        best_key = oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - If in probation (P), promote to protected (S) and move bytes
    '''
    global m_key_last_access, m_key_segment
    global m_bytes_P, m_bytes_S

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Update TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    # Promote from P to S on hit
    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        m_key_segment[k] = 'S'
        # Move bytes P -> S
        m_bytes_P = max(0, m_bytes_P - sz)
        m_bytes_S += sz


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S byte split using ARC-like ghosts
      - Increment TinyLFU for the key (TinyLFU trains on both hits and misses)
      - Add the new object to probation (P)
      - Record last access time
    '''
    global m_key_last_access, m_key_segment
    global m_bytes_P

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    sz = obj.size

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_bytes_P += sz


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
    '''
    global m_key_last_access, m_key_segment
    global m_bytes_P, m_bytes_S
    global m_ghost_P, m_ghost_S

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes and add to appropriate ghost
    if seg == 'S':
        m_bytes_S = max(0, m_bytes_S - esz)
        _ghost_add(m_ghost_S, ek, esz, cache_snapshot.access_count, is_P=False)
    else:
        m_bytes_P = max(0, m_bytes_P - esz)
        _ghost_add(m_ghost_P, ek, esz, cache_snapshot.access_count, is_P=True)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 3
- Hit Rate: 0.3583

Example 2:
- Trace ID: 45
- Hit Rate: 0.0592

Example 3:
- Trace ID: 12
- Error: Error - Timeout

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m19:36:08 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 19:36:08,222 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m19:38:17 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 19:38:17,192 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 19:38:17,193 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Improved: Size-aware SLRU + TinyLFU with O(log n) eviction via lazy heaps,
# ARC-like adaptive P/S split, and low-overhead ghosts.
# Key improvements over previous version:
#   - Eviction is O(log n) using two heaps (probation/protected) instead of O(n) scans.
#   - Count-Min Sketch width decoupled from byte capacity to avoid timeouts/memory blowups.
#   - Efficient ghost lists using lazy queues (no O(n) scans on trim).
#   - Smarter promotion from P->S using a size/frequency-aware threshold.
#   - Careful metadata updates to keep heaps in sync (lazy invalidation by generation).

from heapq import heappush, heappop

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()    # key -> int access_count (LRU stamp)
m_key_segment = dict()        # key -> 'P' or 'S'
m_key_gen = dict()            # key -> int generation for heap entries
m_key_hits_in_P = dict()      # key -> int hits while in P (for promotion threshold)

# Heaps for eviction: (score, last_access, gen, key)
m_heap_P = []
m_heap_S = []

# Current resident bytes per segment
m_bytes_P = 0
m_bytes_S = 0

# Adaptive target for protected bytes (S); probation target = capacity - target_S
m_target_S_bytes = None

# Ghost lists with lazy queues to adapt P/S split
# - map: key -> (size, token)
# - queue: list of (key, token); head index advances to lazily evict stale nodes
m_ghost_P_map = dict()
m_ghost_S_map = dict()
m_ghost_P_q = []
m_ghost_S_q = []
m_ghost_P_head = 0
m_ghost_S_head = 0
m_ghost_P_bytes = 0
m_ghost_S_bytes = 0
m_ghost_limit_bytes = None
m_next_token = 1

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops (halving all counters)
m_sketch_counter_cap = 255     # 8-bit style cap per counter


# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _next_power_of_two(x):
    if x <= 1:
        return 1
    x -= 1
    x |= x >> 1
    x |= x >> 2
    x |= x >> 4
    x |= x >> 8
    x |= x >> 16
    return x + 1


def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_S_bytes, m_ghost_limit_bytes
    global m_sketch_tables, m_sketch_mask

    cap = max(1, int(cache_snapshot.capacity))

    if m_target_S_bytes is None:
        # Start balanced; adapt online based on ghosts
        m_target_S_bytes = cap * 0.5
    if m_ghost_limit_bytes is None:
        # Each ghost list roughly limited to cache capacity in bytes
        m_ghost_limit_bytes = cap

    if m_sketch_tables is None:
        # Width decoupled from byte capacity to avoid huge memory/time on big caches.
        # Choose a modest width that works well in practice.
        #  - small caches: 2048 counters per row
        #  - medium: 4096
        #  - large: 8192 (max)
        if cap <= (1 << 20):         # <= 1 MiB
            target = 2048
        elif cap <= (1 << 24):       # <= 16 MiB
            target = 4096
        else:
            target = 8192

        width = _next_power_of_two(target)
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    if m_sketch_tables is None:
        return
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    if m_sketch_tables is None:
        return 0
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    mn = None
    for t, i in enumerate(idxs):
        v = m_sketch_tables[t][i]
        if mn is None or v < mn:
            mn = v
    return 0 if mn is None else mn


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_tables is None:
        return
    if m_sketch_ops >= m_sketch_age_interval:
        for t in range(4):
            row = m_sketch_tables[t]
            # Halve all counters (right shift by 1)
            for i in range(len(row)):
                row[i] = row[i] >> 1
        m_sketch_ops = 0


def _promotion_threshold(cache_snapshot, key, size):
    # Size/frequency-aware promotion threshold for P -> S:
    #   base = 1 (promote on first hit)
    #   +1 if very large (>= 1/32 cap)
    #   +1 if enormous (>= 1/8 cap)
    #   +1 if current TinyLFU estimate is very low (<= 1)
    cap = max(1, int(cache_snapshot.capacity))
    thr = 1
    if size >= cap // 32:
        thr += 1
    if size >= cap // 8:
        thr += 1
    if _sketch_estimate(key) <= 1:
        thr += 1
    # Clamp to reasonable bound
    if thr > 4:
        thr = 4
    return thr


def _push_heap(key, seg_tag):
    # Push a fresh heap entry for a key in given segment using lazy invalidation.
    # score = est_freq / size; tie-break by older last_access first.
    if seg_tag not in ('P', 'S'):
        seg_tag = 'P'
    # Determine size and last_access; if missing, default size=1 to avoid div by zero
    last = m_key_last_access.get(key, -1)
    # size must be taken from resident object; we rely on caller to have obj.size set in metadata flows.
    # As we do not keep a separate size map, we approximate via inbound flows:
    # We'll require the caller ensured a recent update tracked via bytes and heaps at insert/hit.
    # For score calculation, we cannot access obj directly; hence we derive from last known flows:
    # Use a tiny fallback if size unknown, but in practice, insert/hit will push with correct size.
    # To ensure size correctness, we add per-key size map maintained on insert/evict.
    sz = m_key_size.get(key, 1)
    est = _sketch_estimate(key)
    score = float(est) / float(sz if sz > 0 else 1)

    gen = m_key_gen.get(key, 0) + 1
    m_key_gen[key] = gen

    entry = (score, last, gen, key)
    if seg_tag == 'S':
        heappush(m_heap_S, entry)
    else:
        heappush(m_heap_P, entry)


def _heap_peek_valid(heap, seg_tag):
    # Return (key, score, last) of top valid entry in given heap; pop stale entries.
    while heap:
        score, last, gen, key = heap[0]
        cur_seg = m_key_segment.get(key)
        cur_gen = m_key_gen.get(key, -1)
        if cur_seg != seg_tag or cur_gen != gen:
            heappop(heap)
            continue
        return key, score, last
    return None, None, None


def _ghost_add(is_P, key, size):
    # Add key to chosen ghost (P or S) with lazy queue; trim if exceeds limit.
    global m_next_token
    global m_ghost_P_bytes, m_ghost_S_bytes
    global m_ghost_P_head, m_ghost_S_head

    if m_ghost_limit_bytes is None:
        return

    if is_P:
        # Update map and bytes
        prev = m_ghost_P_map.get(key)
        if prev is None:
            m_ghost_P_map[key] = (size, m_next_token)
            m_ghost_P_bytes += size
        else:
            old_size, _ = prev
            if size != old_size:
                m_ghost_P_bytes += (size - old_size)
            m_ghost_P_map[key] = (size, m_next_token)
        # Queue append
        m_ghost_P_q.append((key, m_next_token))
        m_next_token += 1
        # Trim over limit
        while m_ghost_P_bytes > m_ghost_limit_bytes and m_ghost_P_head < len(m_ghost_P_q):
            k, tok = m_ghost_P_q[m_ghost_P_head]
            m_ghost_P_head += 1
            cur = m_ghost_P_map.get(k)
            if cur is None:
                continue
            sz, cur_tok = cur
            if cur_tok != tok:
                continue
            # Remove current
            del m_ghost_P_map[k]
            m_ghost_P_bytes -= sz
        # Compact queue periodically
        if m_ghost_P_head > 1024 and m_ghost_P_head > len(m_ghost_P_q) // 2:
            m_ghost_P_q = m_ghost_P_q[m_ghost_P_head:]
            m_ghost_P_head = 0
    else:
        prev = m_ghost_S_map.get(key)
        if prev is None:
            m_ghost_S_map[key] = (size, m_next_token)
            m_ghost_S_bytes += size
        else:
            old_size, _ = prev
            if size != old_size:
                m_ghost_S_bytes += (size - old_size)
            m_ghost_S_map[key] = (size, m_next_token)
        m_ghost_S_q.append((key, m_next_token))
        m_next_token += 1
        while m_ghost_S_bytes > m_ghost_limit_bytes and m_ghost_S_head < len(m_ghost_S_q):
            k, tok = m_ghost_S_q[m_ghost_S_head]
            m_ghost_S_head += 1
            cur = m_ghost_S_map.get(k)
            if cur is None:
                continue
            sz, cur_tok = cur
            if cur_tok != tok:
                continue
            del m_ghost_S_map[k]
            m_ghost_S_bytes -= sz
        if m_ghost_S_head > 1024 and m_ghost_S_head > len(m_ghost_S_q) // 2:
            m_ghost_S_q = m_ghost_S_q[m_ghost_S_head:]
            m_ghost_S_head = 0


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    global m_target_S_bytes
    _init_if_needed(cache_snapshot)

    cap = max(1, int(cache_snapshot.capacity))
    # Step proportional to object size, bounded to avoid huge jumps
    step = obj.size
    cap_quarter = cap // 4 if cap >= 4 else 1
    if step > cap_quarter:
        step = cap_quarter

    k = obj.key
    if k in m_ghost_P_map:
        # Recent ghost hit: increase P share (decrease protected)
        m_target_S_bytes = _clamp(m_target_S_bytes - step, 0, cap)
        sz, _ = m_ghost_P_map.pop(k)
        # Adjust ghost bytes; lazy queues will drop stale nodes
        global m_ghost_P_bytes
        m_ghost_P_bytes -= sz
        if m_ghost_P_bytes < 0:
            m_ghost_P_bytes = 0
    elif k in m_ghost_S_map:
        # Frequent ghost hit: increase S share
        m_target_S_bytes = _clamp(m_target_S_bytes + step, 0, cap)
        sz, _ = m_ghost_S_map.pop(k)
        global m_ghost_S_bytes
        m_ghost_S_bytes -= sz
        if m_ghost_S_bytes < 0:
            m_ghost_S_bytes = 0


# Maintain per-key size to avoid relying on cache scan for size in heaps
m_key_size = dict()


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using:
      - Two heaps (P and S) keyed by TinyLFU score (est_freq/size) and last access (older first).
      - ARC-like bias: prefer evicting from overweight segment relative to target split.
      - Protect S slightly by adding a small bias to its adjusted score.
    This is O(log n) per eviction and avoids full scans.
    '''
    global m_bytes_P, m_bytes_S, m_target_S_bytes

    _init_if_needed(cache_snapshot)

    cap = max(1, int(cache_snapshot.capacity))
    target_S = _clamp(m_target_S_bytes, 0, cap)
    target_P = cap - target_S

    # Get best candidates from each segment
    p_key, p_score, p_lru = _heap_peek_valid(m_heap_P, 'P')
    s_key, s_score, s_lru = _heap_peek_valid(m_heap_S, 'S')

    # If heaps somehow empty (e.g., very early), fall back to oldest
    if p_key is None and s_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        return oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

    # Incoming object's normalized score (estimated benefit per byte)
    incoming_score = float(_sketch_estimate(obj.key) + 1) / float(max(1, obj.size))

    # Bias terms
    protect_S_bias = 0.05 + 0.10 * incoming_score  # discourage evicting S
    overweight_nudge = 0.05 + 0.10 * incoming_score  # encourage evicting overweight segment

    best_key = None
    best_adj = None

    if p_key is not None:
        adj_p = p_score
        if m_bytes_P > target_P:
            adj_p -= overweight_nudge
        # prefer older on tie
        if p_lru is not None:
            adj_p -= 1e-12 * p_lru
        best_key = p_key
        best_adj = adj_p

    if s_key is not None:
        adj_s = s_score + protect_S_bias
        if m_bytes_S > target_S:
            adj_s -= overweight_nudge
        if s_lru is not None:
            adj_s -= 1e-12 * s_lru
        if (best_adj is None) or (adj_s < best_adj):
            best_adj = adj_s
            best_key = s_key

    # As a safeguard, if best_key is still None (unlikely), fallback to any key
    if best_key is None:
        for k in cache_snapshot.cache.keys():
            best_key = k
            break

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - If in probation (P), increment its hit counter and promote to protected (S)
        only if it passes a size/frequency-aware threshold.
      - Push updated entry into the appropriate heap (lazy invalidation).
    '''
    global m_bytes_P, m_bytes_S

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size
    m_key_size[k] = sz

    # Train TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        # Increment hits in P
        cur_hits = m_key_hits_in_P.get(k, 0) + 1
        m_key_hits_in_P[k] = cur_hits
        # Promote if passes threshold
        if cur_hits >= _promotion_threshold(cache_snapshot, k, sz):
            m_key_segment[k] = 'S'
            # Move bytes P -> S
            if m_bytes_P >= sz:
                m_bytes_P -= sz
            else:
                m_bytes_P = 0
            m_bytes_S += sz
            # Clear P-hit counter
            m_key_hits_in_P.pop(k, None)
            # Push entry for S
            _push_heap(k, 'S')
        else:
            # Stay in P; push updated entry
            _push_heap(k, 'P')
    else:
        # Already protected; just push updated entry
        _push_heap(k, 'S')


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S byte split using ARC-like ghosts.
      - Increment TinyLFU for the key (TinyLFU trains on both hits and misses).
      - Add the new object to probation (P) with last access time.
      - Push into P-heap for efficient evictions.
    '''
    global m_bytes_P

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghosts
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    sz = obj.size
    m_key_size[k] = sz

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_key_hits_in_P[k] = 0
    m_bytes_P += sz

    # Push into P heap
    _push_heap(k, 'P')


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
      - Heaps are lazily cleaned via generation mismatch; no explicit heap removal needed
    '''
    global m_bytes_P, m_bytes_S

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    # Determine segment at eviction time (default to P)
    seg = m_key_segment.get(ek, 'P')

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)
    m_key_hits_in_P.pop(ek, None)
    m_key_size.pop(ek, None)
    # Do not clear m_key_gen: leaving it allows heap entries to become stale automatically.

    # Adjust bytes and add to appropriate ghost
    if seg == 'S':
        m_bytes_S = m_bytes_S - esz if m_bytes_S >= esz else 0
        _ghost_add(False, ek, esz)
    else:
        m_bytes_P = m_bytes_P - esz if m_bytes_P >= esz else 0
        _ghost_add(True, ek, esz)
```
2025-11-27 19:38:20,423 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved: Count-based SLRU with TinyLFU, ARC-style adaptive split, and recency-aware scoring
# - Two resident segments by item count, not by bytes:
#     P (probation): admits all new objects; managed by LRU (via last_access timestamps)
#     S (protected): objects that hit at least once; also LRU-managed
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction score blends frequency and recency (recency matters beyond tie-break)
# - ARC-like ghost lists adapt the item split between P and S online (by counts)
#
# This design captures:
#   - Recency (via LRU timestamps and explicit recency in eviction score)
#   - Frequency (via TinyLFU)
#   - Adaptivity between recency-friendly and frequency-friendly behavior
#   - Correctness for caches limited by number of items (not bytes)

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU)
m_key_segment = dict()       # key -> 'P' or 'S'

# Current resident ITEM COUNTS per segment
m_cnt_P = 0
m_cnt_S = 0

# Adaptive target for protected items (S); probation target = capacity_items - target_S
m_target_S_items = None
m_cap_items_est = 0  # our estimate of capacity in number of items (learned at evict time)

# Ghost lists (non-resident metadata) to adapt split; store key -> last_time
m_ghost_P = dict()  # B1
m_ghost_S = dict()  # B2
m_ghost_limit_items = None

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)

# ---------------
# Scoring params
# ---------------
# Recency blend: score = est_freq + rec_weight * min(recency / half_life, rec_cap)
m_rec_half_life = 500.0  # accesses; tune to make recency effect comparable to est_freq
m_rec_cap = 10.0         # cap normalized recency contribution
m_rec_weight_P = 1.0     # probation recency weight
m_rec_weight_S = 0.6     # protected recency weight (S is more persistent)
m_protect_S_bias = 0.25  # additive bias to S candidates to modestly protect them
m_overweight_nudge = 0.2 # when a segment exceeds target, nudge its candidate to be more evictable

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_target_S_items, m_ghost_limit_items
    global m_sketch_tables, m_sketch_mask
    global m_cap_items_est

    # Learn capacity in items opportunistically; on evict() we'll update more accurately.
    if m_cap_items_est < len(cache_snapshot.cache):
        m_cap_items_est = len(cache_snapshot.cache)

    if m_target_S_items is None:
        # Start slightly frequency-friendly; adapt online
        base_items = max(1, len(cache_snapshot.cache))
        m_target_S_items = int(base_items * 0.6)

    if m_ghost_limit_items is None:
        # Each ghost list limited to approximately the cache capacity in items (we adjust later)
        m_ghost_limit_items = max(1, len(cache_snapshot.cache))

    if m_sketch_tables is None:
        # Width scales with estimated items; choose power of two near items*4 (empirical)
        # Minimum width to keep estimates reasonably stable.
        items = max(1, len(cache_snapshot.cache))
        width = 1
        target = max(1024, min(1 << 16, items * 4))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        # Halve all counters (right-shift by 1)
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _normalized_recency(now, last):
    if last is None or last < 0:
        return m_rec_cap
    age = max(0, now - last)
    norm = age / m_rec_half_life
    if norm > m_rec_cap:
        norm = m_rec_cap
    return norm


def _pick_min_score_in_segment(cache_snapshot, seg_tag, now):
    # Returns (key, score, last_time) that minimizes blended score within a segment
    # Score = est_freq + rec_weight * normalized_recency; tie-break by older first
    min_key = None
    min_score = None
    min_time = None

    rec_w = m_rec_weight_S if seg_tag == 'S' else m_rec_weight_P

    for key, obj in cache_snapshot.cache.items():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        est = float(_sketch_estimate(key))
        last = m_key_last_access.get(key, -1)
        rec = _normalized_recency(now, last)
        score = est + rec_w * rec
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = key
            min_score = score
            min_time = last

    return (min_key, min_score, min_time)


def _find_oldest_in_segment(cache_snapshot, seg_tag):
    oldest_key, oldest_time = None, None
    for k in cache_snapshot.cache.keys():
        if m_key_segment.get(k, 'P') != seg_tag:
            continue
        t = m_key_last_access.get(k, -1)
        if oldest_time is None or t < oldest_time:
            oldest_key, oldest_time = k, t
    return oldest_key


def _ghost_add(ghost_dict, key, time_now, which):
    # Add key->time to chosen ghost (which in {'P','S'}), trimming if exceeds limit
    global m_ghost_limit_items

    # Insert/update
    ghost_dict[key] = time_now

    # Trim to limit by evicting oldest
    limit = m_ghost_limit_items or 0
    if limit <= 0:
        return

    while len(ghost_dict) > limit:
        oldest_key, oldest_time = None, None
        for k, t in ghost_dict.items():
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        if oldest_key is None:
            break
        ghost_dict.pop(oldest_key, None)


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    # If key in P-ghost (B1): increase probation share (decrease S target)
    # If key in S-ghost (B2): increase protected share (increase S target)
    global m_target_S_items, m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Update our item-capacity estimate when cache is likely full (best signal: on evict call, but keep here too)
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)

    # Keep ghost size limits around capacity in items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est

    cap_items = max(1, m_cap_items_est)

    # Step size: 1 item per signal (conservative, stable)
    step = 1

    if obj.key in m_ghost_P:
        # Recent ghost hit: favor recency -> increase P share (decrease S)
        m_target_S_items = _clamp((m_target_S_items or 0) - step, 0, cap_items)
        m_ghost_P.pop(obj.key, None)
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: favor frequency -> increase S share
        m_target_S_items = _clamp((m_target_S_items or 0) + step, 0, cap_items)
        m_ghost_S.pop(obj.key, None)


def _maybe_demote_from_S_to_P(cache_snapshot):
    # If S exceeds its target, demote oldest S item to P
    global m_cnt_P, m_cnt_S, m_target_S_items
    if m_target_S_items is None:
        return
    if m_cnt_S > m_target_S_items:
        demote_key = _find_oldest_in_segment(cache_snapshot, 'S')
        if demote_key is not None:
            m_key_segment[demote_key] = 'P'
            m_cnt_S = max(0, m_cnt_S - 1)
            m_cnt_P += 1


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using count-based SLRU + TinyLFU with recency-aware scoring.
    - Compute candidate with minimal blended score in each segment:
        score = est_freq(key) + rec_weight * normalized_recency
    - Bias to evict from the segment exceeding its item-count target.
    - Protect S moderately by adding a small bias compared to P.
    '''
    global m_cnt_P, m_cnt_S, m_target_S_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Learn/refresh capacity in number of items at the moment of eviction (cache is full now)
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    cap_items = max(1, m_cap_items_est)
    if m_target_S_items is None:
        m_target_S_items = int(0.6 * cap_items)
    target_S = _clamp(m_target_S_items, 0, cap_items)
    target_P = cap_items - target_S

    now = cache_snapshot.access_count

    # Find min-score candidate in each segment
    p_key, p_score, p_lru = _pick_min_score_in_segment(cache_snapshot, 'P', now)
    s_key, s_score, s_lru = _pick_min_score_in_segment(cache_snapshot, 'S', now)

    # Prepare adjusted scores
    best_key = None
    best_adj = None

    if p_key is not None:
        adj_p = p_score
        # If P is overweight, make it slightly more likely to evict from P
        if m_cnt_P > target_P:
            adj_p -= m_overweight_nudge
        # No extra protection bias for P
        best_key = p_key
        best_adj = adj_p

    if s_key is not None:
        adj_s = s_score + m_protect_S_bias
        # If S is overweight, encourage eviction from S
        if m_cnt_S > target_S:
            adj_s -= m_overweight_nudge
        if (best_adj is None) or (adj_s < best_adj):
            best_adj = adj_s
            best_key = s_key

    # Fallback: if we somehow didn't find any key (shouldn't happen), pick oldest globally
    if best_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        best_key = oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - If in probation (P), promote to protected (S); if S exceeds target, demote oldest S to P
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    k = obj.key

    # Update TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    # Promote from P to S on hit
    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        m_key_segment[k] = 'S'
        m_cnt_P = max(0, m_cnt_P - 1)
        m_cnt_S += 1
        # If S above target, demote oldest S back to P
        _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S item split using ARC-like ghosts
      - Increment TinyLFU for the key (TinyLFU trains on both hits and misses)
      - Add the new object to probation (P)
      - Record last access time
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_cnt_P += 1

    # Keep S from drifting above target if previous operations changed target
    _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key
      - Update segment item counters
      - Add the key to the corresponding ghost list (count-limited) to guide future adaptation
      - Keep ghost sizes roughly equal to estimated cache capacity in items
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S
    global m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust item counts and add to appropriate ghost
    now = cache_snapshot.access_count
    if seg == 'S':
        m_cnt_S = max(0, m_cnt_S - 1)
        _ghost_add(m_ghost_S, ek, now, which='S')
    else:
        m_cnt_P = max(0, m_cnt_P - 1)
        _ghost_add(m_ghost_P, ek, now, which='P')

    # Update ghost limits to approximate current capacity in items
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 33
- Hit Rate: 0.6945

Example 2:
- Trace ID: 22
- Hit Rate: 0.0567

Example 3:
- Trace ID: 30
- Hit Rate: 0.0683

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m19:38:20 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 19:38:20,424 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m19:40:43 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 19:40:43,557 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 19:40:43,558 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# W-TinyLFU-inspired SLRU with size-aware, freshness-based keep score and ARC-style adaptation
# - Three resident segments, tracked by BYTES (since the cache is byte-capacity limited):
#     W (window): all new objects go here; pure LRU; small byte budget to absorb scans
#     Q (probation): items that left the window; candidates for eviction
#     S (protected): items that have hit; more strongly protected than Q
#
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Keep score blends frequency and freshness; eviction chooses item with MIN keep score
#     keep_score = (freq_weight * est_freq + rec_weight * freshness) / size^alpha + segment_bias
#   where freshness = 1 / (1 + age / half_life), age in accesses since last touch
#   This favors evicting large low-frequency stale items first, and retaining recent/frequent small ones.
#
# - ARC-like ghost lists (Q-ghost B1 and S-ghost B2) adapt the S byte target:
#     hit in B1 -> decrease S bytes (favor recency)
#     hit in B2 -> increase S bytes (favor frequency)
#
# Why this design:
#   - Fixes previous recency bug (older items now have LOWER freshness, thus LOWER keep score, thus are evicted sooner)
#   - Window W confines one-hit wonders and scans, reducing pollution
#   - Size-aware scoring improves hits-per-byte by preferring to keep small yet useful items
#   - Adaptation adjusts protected vs. probation share online per workload

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU/freshness)
m_key_segment = dict()       # key -> 'W' (window), 'Q' (probation), 'S' (protected)

# Segment byte usage and counts
m_bytes_W = 0
m_bytes_Q = 0
m_bytes_S = 0
m_cnt_W = 0
m_cnt_Q = 0
m_cnt_S = 0

# Targets (in bytes)
m_target_W_bytes = None
m_target_S_bytes = None
m_cap_bytes = 0  # cache capacity in bytes (learned from snapshot)

# Ghost lists (non-resident, by keys -> last_time)
#   B1 ~ Q-ghost (recently evicted probation/window-like)
#   B2 ~ S-ghost (recently evicted protected)
m_ghost_Q = dict()  # B1
m_ghost_S = dict()  # B2
m_ghost_limit_items = None  # cap number of ghost entries (approximate to current number of resident items)

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of rows
m_sketch_mask = None
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0
m_sketch_age_interval = 100000  # age less frequently (stability)
m_sketch_counter_cap = 255

# ---------------
# Scoring params
# ---------------
# Freshness: f = 1 / (1 + age / half_life); range (0,1], with 1 being most recent
m_rec_half_life = 800.0

# Segment-specific recency weights (freshness importance)
m_rec_weight_W = 2.0
m_rec_weight_Q = 1.2
m_rec_weight_S = 0.8

# Frequency weight (relative to freshness)
m_freq_weight = 1.0

# Size normalization: divide by size^alpha
m_size_alpha = 0.75

# Biases and nudges (applied to keep_score)
m_protect_S_bias = 0.15   # raise S keep score -> less likely to be evicted
m_overweight_nudge = 0.10 # lower keep score if segment exceeds its byte target -> more likely to evict from it

# Window fraction of capacity (bytes)
m_window_frac = 0.05  # 5% window by bytes

# ARC adaptation step (bytes)
m_adapt_step_frac = 0.02  # 2% capacity per signal (clamped)

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_cap_bytes, m_target_W_bytes, m_target_S_bytes, m_ghost_limit_items
    global m_sketch_tables, m_sketch_mask

    if m_cap_bytes <= 0:
        m_cap_bytes = max(1, int(cache_snapshot.capacity))

    if m_target_W_bytes is None:
        m_target_W_bytes = _clamp(int(m_window_frac * m_cap_bytes), 0, m_cap_bytes // 2)

    if m_target_S_bytes is None:
        # Start moderately frequency-friendly on remaining capacity
        residual = max(0, m_cap_bytes - m_target_W_bytes)
        m_target_S_bytes = int(residual * 0.6)

    # Keep ghost limit roughly around resident item count
    if m_ghost_limit_items is None:
        m_ghost_limit_items = max(1, len(cache_snapshot.cache))

    if m_sketch_tables is None:
        # Count-Min width scales with resident item count (power of 2 near n*4; min 1024)
        n = max(1, len(cache_snapshot.cache))
        width = 1
        target = max(1024, min(1 << 16, n * 4))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        v = m_sketch_tables[t][i]
        nv = v + delta
        m_sketch_tables[t][i] = m_sketch_counter_cap if nv > m_sketch_counter_cap else nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _freshness(now, last):
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    return 1.0 / (1.0 + (age / m_rec_half_life))


def _size_norm(sz):
    try:
        if sz <= 0:
            return 1.0
        return pow(float(sz), m_size_alpha)
    except Exception:
        return 1.0


def _ghost_add(ghost_dict, key, time_now):
    # Add key with timestamp; trim to limit by dropping oldest
    global m_ghost_limit_items
    ghost_dict[key] = time_now
    limit = m_ghost_limit_items or 0
    if limit <= 0:
        return
    while len(ghost_dict) > limit:
        oldest_key, oldest_time = None, None
        for k, t in ghost_dict.items():
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        if oldest_key is None:
            break
        ghost_dict.pop(oldest_key, None)


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost contains the key
    global m_target_S_bytes, m_ghost_Q, m_ghost_S, m_cap_bytes

    _init_if_needed(cache_snapshot)
    capB = max(1, int(cache_snapshot.capacity))
    m_cap_bytes = capB  # refresh

    step = max(1, int(m_adapt_step_frac * capB))
    # S target can vary in [0, cap - W]
    max_S = max(0, capB - (m_target_W_bytes or 0))

    if obj.key in m_ghost_Q:
        # Favor recency: reduce S budget
        m_target_S_bytes = _clamp((m_target_S_bytes or 0) - step, 0, max_S)
        m_ghost_Q.pop(obj.key, None)
    elif obj.key in m_ghost_S:
        # Favor frequency: increase S budget
        m_target_S_bytes = _clamp((m_target_S_bytes or 0) + step, 0, max_S)
        m_ghost_S.pop(obj.key, None)


def _find_oldest_in_segment(cache_snapshot, seg_tag):
    oldest_key, oldest_time = None, None
    for k in cache_snapshot.cache.keys():
        if m_key_segment.get(k) != seg_tag:
            continue
        t = m_key_last_access.get(k, -1)
        if oldest_time is None or t < oldest_time:
            oldest_key, oldest_time = k, t
    return oldest_key


def _maybe_demote_S_to_Q_by_bytes(cache_snapshot):
    # If S exceeds its byte target, demote oldest S keys to Q until within target
    global m_bytes_S, m_bytes_Q, m_cnt_S, m_cnt_Q
    capB = max(1, int(cache_snapshot.capacity))
    target_S = _clamp(m_target_S_bytes or 0, 0, max(0, capB - (m_target_W_bytes or 0)))
    while m_bytes_S > target_S:
        demote_key = _find_oldest_in_segment(cache_snapshot, 'S')
        if demote_key is None:
            break
        obj = cache_snapshot.cache.get(demote_key)
        if obj is None:
            break
        sz = max(1, int(obj.size))
        # Demote S -> Q
        m_key_segment[demote_key] = 'Q'
        m_bytes_S -= sz
        m_bytes_Q += sz
        m_cnt_S = max(0, m_cnt_S - 1)
        m_cnt_Q += 1


def _keep_score_for_key(cache_snapshot, key, now, seg_tag):
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf'), -1  # should not happen
    sz = max(1, int(obj.size))
    est = float(_sketch_estimate(key))
    last = m_key_last_access.get(key, -1)
    fresh = _freshness(now, last)

    # Segment weights
    if seg_tag == 'S':
        rec_w = m_rec_weight_S
        seg_bias = m_protect_S_bias  # protect S
    elif seg_tag == 'Q':
        rec_w = m_rec_weight_Q
        seg_bias = 0.0
    else:  # 'W' should not be scored here; W is evicted by pure LRU when needed
        rec_w = m_rec_weight_W
        seg_bias = 0.0

    keep_raw = m_freq_weight * est + rec_w * fresh
    keep = (keep_raw / _size_norm(sz)) + seg_bias
    return keep, last


def _pick_min_keep_in_segment(cache_snapshot, seg_tag, now, target_Q, target_S):
    # Returns (key, keep_score, last_time)
    min_key, min_score, min_time = None, None, None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != seg_tag:
            continue
        score, last = _keep_score_for_key(cache_snapshot, key, now, seg_tag)
        # Apply overweight nudge: make eviction from overweight segment a bit more likely
        if seg_tag == 'Q' and m_bytes_Q > target_Q:
            score -= m_overweight_nudge
        elif seg_tag == 'S' and m_bytes_S > target_S:
            score -= m_overweight_nudge

        if (min_score is None) or (score < min_score) or (score == min_score and last < (min_time if min_time is not None else last)):
            min_key = key
            min_score = score
            min_time = last
    return (min_key, min_score, min_time)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim:
      - If window W exceeds its byte target, evict LRU in W (pure recency)
      - Otherwise, evict the key with MIN keep score among Q and S
            keep_score = (freq_weight * est_freq + rec_weight * freshness) / size^alpha + seg_bias
        with protection bias for S and overweight nudge for segments exceeding targets.
    '''
    global m_cap_bytes

    _init_if_needed(cache_snapshot)

    # Refresh capacity and targets
    capB = max(1, int(cache_snapshot.capacity))
    m_cap_bytes = capB
    target_W = _clamp(m_target_W_bytes or 0, 0, capB)
    max_S = max(0, capB - target_W)
    target_S = _clamp(m_target_S_bytes or 0, 0, max_S)
    target_Q = max(0, capB - target_W - target_S)

    now = cache_snapshot.access_count

    # 1) Window pressure: evict LRU in W if W is overweight
    if m_bytes_W > target_W:
        victim = _find_oldest_in_segment(cache_snapshot, 'W')
        if victim is not None:
            return victim
        # fall through if W empty by metadata mismatch

    # 2) Otherwise, pick min keep score across Q and S
    q_key, q_score, _ = _pick_min_keep_in_segment(cache_snapshot, 'Q', now, target_Q, target_S)
    s_key, s_score, _ = _pick_min_keep_in_segment(cache_snapshot, 'S', now, target_Q, target_S)

    # Prefer available candidate with lower keep score
    if q_key is not None and s_key is not None:
        return q_key if q_score <= s_score else s_key
    elif q_key is not None:
        return q_key
    elif s_key is not None:
        return s_key

    # 3) Fallback: evict globally oldest key
    oldest_key, oldest_time = None, None
    for k in cache_snapshot.cache.keys():
        t = m_key_last_access.get(k, -1)
        if oldest_time is None or t < oldest_time:
            oldest_key, oldest_time = k, t
    return oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - Promote to protected S if current segment is W or Q
      - If S exceeds its byte target, demote oldest S back to Q (no eviction)
    '''
    global m_bytes_W, m_bytes_Q, m_bytes_S
    global m_cnt_W, m_cnt_Q, m_cnt_S

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = max(1, int(obj.size))

    # Train TinyLFU on the hit
    _sketch_inc(k, 1)

    # Refresh timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    seg = m_key_segment.get(k)
    if seg is None:
        # If unknown (shouldn't happen), treat as W
        m_key_segment[k] = 'W'
        m_bytes_W += sz
        m_cnt_W += 1
        seg = 'W'

    if seg == 'W':
        # Promote W -> S on hit
        m_key_segment[k] = 'S'
        m_bytes_W = max(0, m_bytes_W - sz)
        m_cnt_W = max(0, m_cnt_W - 1)
        m_bytes_S += sz
        m_cnt_S += 1
        _maybe_demote_S_to_Q_by_bytes(cache_snapshot)
    elif seg == 'Q':
        # Promote Q -> S on hit
        m_key_segment[k] = 'S'
        m_bytes_Q = max(0, m_bytes_Q - sz)
        m_cnt_Q = max(0, m_cnt_Q - 1)
        m_bytes_S += sz
        m_cnt_S += 1
        _maybe_demote_S_to_Q_by_bytes(cache_snapshot)
    else:
        # seg == 'S': just refreshed
        pass


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt S byte target based on ghosts (ARC-style)
      - Increment TinyLFU for the key (TinyLFU learns from both hits and misses)
      - Place the new object in window W
      - Record last access
    '''
    global m_bytes_W, m_cnt_W

    _init_if_needed(cache_snapshot)

    # Adapt targets using ghost lists (B1/B2)
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    sz = max(1, int(obj.size))

    # Train TinyLFU on the miss
    _sketch_inc(k, 1)

    # Admit into window W
    m_key_segment[k] = 'W'
    m_key_last_access[k] = cache_snapshot.access_count
    m_bytes_W += sz
    m_cnt_W += 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting:
      - Remove resident metadata
      - Update segment byte usage and counts
      - Add evicted key to appropriate ghost:
            from S -> B2
            from Q or W -> B1
      - Keep ghost sizes bounded by a limit ~ current item count
    '''
    global m_bytes_W, m_bytes_Q, m_bytes_S
    global m_cnt_W, m_cnt_Q, m_cnt_S
    global m_ghost_limit_items, m_cap_bytes

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = max(1, int(evicted_obj.size))
    seg = m_key_segment.get(ek)

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust counters and add to appropriate ghost
    now = cache_snapshot.access_count
    if seg == 'S':
        m_bytes_S = max(0, m_bytes_S - esz)
        m_cnt_S = max(0, m_cnt_S - 1)
        _ghost_add(m_ghost_S, ek, now)  # B2
    elif seg == 'Q':
        m_bytes_Q = max(0, m_bytes_Q - esz)
        m_cnt_Q = max(0, m_cnt_Q - 1)
        _ghost_add(m_ghost_Q, ek, now)  # B1
    else:
        # Treat W or unknown as B1
        m_bytes_W = max(0, m_bytes_W - esz)
        m_cnt_W = max(0, m_cnt_W - 1)
        _ghost_add(m_ghost_Q, ek, now)  # B1

    # Update ghost limits to approximate current resident item count
    m_ghost_limit_items = max(1, len(cache_snapshot.cache))
    # Refresh capacity
    m_cap_bytes = max(1, int(cache_snapshot.capacity))
```
2025-11-27 19:40:47,135 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 25
- Hit Rate: 0.3317

Example 2:
- Trace ID: 47
- Hit Rate: 0.1732

Example 3:
- Trace ID: 11
- Hit Rate: 0.3814

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m19:40:47 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 19:40:47,136 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m19:42:24 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 19:42:24,245 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 19:42:24,246 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```
2025-11-27 19:47:16,833 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 23
- Hit Rate: 0.06

Example 2:
- Trace ID: 0
- Hit Rate: 0.5038

Example 3:
- Trace ID: 14
- Error: Error - Timeout

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m19:47:16 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 19:47:16,835 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m19:49:10 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 19:49:10,267 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 19:49:10,268 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Lightweight Segmented Size-Aware TinyLFU (LS-SA-TinyLFU)
# Goals:
#   - High hit rates via: SLRU (probation/protected) + TinyLFU frequency + size-awareness
#   - Fast: O(1) updates; O(sample) eviction (no full scans) to avoid timeouts
#   - Robust metadata maintenance across hits/inserts/evictions/promotions/demotions
#
# Main ideas:
#   - Two resident segments maintained with O(1) OrderedDicts:
#       * probation: newly admitted and single-hit items (LRU-managed)
#       * protected: items promoted upon hit; gets most capacity (LRU-managed)
#   - Eviction uses a small candidate sample from the LRU-end(s) to choose the
#     weakest retention by a unified score:
#       score = (log2(1+freq) + multi_hit_bonus - recency_gain - predicted_reuse_gain) / size_penalty
#       Lower score -> evict sooner
#   - TinyLFU uses lazy epochs (4-bit saturating counters)
#   - Inter-arrival time (IRT) EMA predicts reuse; smaller is better
#   - Size penalty discourages oversized items from crowding the cache
#   - Protected segment kept near a target fraction of bytes via demotion of its LRU

import math
from collections import OrderedDict

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)
m_size_map = dict()        # key -> size in bytes (for fast accounting, incl. demotions)

# Inter-arrival time (IRT) EMA
m_irt = dict()             # key -> float EMA of reuse distance (access_count units)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power-of-two recommended)

# SLRU using OrderedDicts for O(1) LRU maintenance; left=oldest, right=newest
q_probation = OrderedDict()  # key -> None
q_protected = OrderedDict()  # key -> None

# Segment capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80
g_protected_bytes = 0

# Scoring tunables
SIZE_ALPHA = 1.12          # >1 penalizes large objects more
MULTI_HIT_BONUS = 0.35     # bonus for resident multi-hit items

# Recency/predicted-reuse weights (probation vs protected)
# Keep recency moderates since we already sample from LRU side
W_REC_PROB = 0.50
W_REC_PROT = 0.12
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# Recency windows
REC_WIN_MIN = 1024
REC_WIN_MULT = 4

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40

# Eviction candidate sampling
PROBATION_SAMPLE = 12
PROTECTED_SAMPLE = 6

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _prune_stale_head(q, cache_snapshot):
    # Remove non-resident keys from the head (oldest) until head is resident or q is empty
    changed = False
    while q:
        head = next(iter(q))
        if head in cache_snapshot.cache:
            break
        # stale entry; remove and clean up basic metadata
        q.pop(head, None)
        # Adjust protected bytes if this was counted as protected
        if m_segment.get(head) == 1:
            sz = m_size_map.get(head, 0)
            global g_protected_bytes
            g_protected_bytes = max(0, g_protected_bytes - sz)
        m_segment.pop(head, None)
        m_last_access.pop(head, None)
        m_prev_access.pop(head, None)
        m_resident_hits.pop(head, None)
        m_irt.pop(head, None)
        changed = True
    return changed

def _demote_protected_to_target(cache_snapshot):
    # Demote oldest protected items to probation until protected bytes <= target
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    while g_protected_bytes > target and q_protected:
        _prune_stale_head(q_protected, cache_snapshot)
        if not q_protected:
            break
        k = next(iter(q_protected))  # oldest protected
        q_protected.pop(k, None)
        # If it disappeared from cache, cleanup was done by prune; skip
        if k not in cache_snapshot.cache:
            # ensure segment cleared
            m_segment.pop(k, None)
            continue
        m_segment[k] = 0  # probation
        # Insert as oldest in probation
        q_probation[k] = None
        q_probation.move_to_end(k, last=False)
        sz = m_size_map.get(k, cache_snapshot.cache[k].size)
        g_protected_bytes = max(0, g_protected_bytes - sz)

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return -1e9  # should not happen; treat as very weak

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed) + multi-hit bonus
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    freq_gain = math.log2(1.0 + freq) + extra

    # Recency/predicted reuse
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    benefit = freq_gain + recency_gain + predicted_gain

    return benefit / size_penalty

# -----------------------------
# Candidate selection
# -----------------------------

def _collect_candidates(cache_snapshot, from_probation=True):
    # Collect a small sample of oldest keys from the requested segment
    candidates = []
    if from_probation:
        _prune_stale_head(q_probation, cache_snapshot)
        it = iter(q_probation)
        sample = PROBATION_SAMPLE
    else:
        _prune_stale_head(q_protected, cache_snapshot)
        it = iter(q_protected)
        sample = PROTECTED_SAMPLE
    while sample > 0:
        try:
            k = next(it)
        except StopIteration:
            break
        if k in cache_snapshot.cache:
            candidates.append(k)
            sample -= 1
        else:
            # clean stale on-the-fly
            if from_probation:
                q_probation.pop(k, None)
            else:
                q_protected.pop(k, None)
    return candidates

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Choose victim from a small LRU-side sample using the retention score
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized (may need multiple demotions)
    _demote_protected_to_target(cache_snapshot)

    # Prefer probation
    candidates = _collect_candidates(cache_snapshot, from_probation=True)
    if not candidates:
        # Fall back to protected (rare)
        candidates = _collect_candidates(cache_snapshot, from_probation=False)
        if not candidates:
            # As a last resort, any key in cache
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    # Choose weakest retention among candidates
    weakest_key = None
    weakest_score = None
    for k in candidates:
        s = _retention_score(cache_snapshot, k)
        if weakest_score is None or s < weakest_score:
            weakest_score = s
            weakest_key = k

    return weakest_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected; else refresh protected LRU
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive accesses
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = prev if prev is not None else now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1
    m_size_map[k] = obj.size  # keep up-to-date

    seg = _segment_of(k)
    if seg == 0:
        # Promote to protected on hit
        q_probation.pop(k, None)
        m_segment[k] = 1
        q_protected[k] = None
        q_protected.move_to_end(k, last=True)
        global g_protected_bytes
        g_protected_bytes += obj.size
    else:
        # Refresh protected LRU
        if k in q_protected:
            q_protected.move_to_end(k, last=True)
        else:
            # Defensive: ensure present
            m_segment[k] = 1
            q_protected[k] = None
            q_protected.move_to_end(k, last=True)

    # Enforce protected target (may demote multiple)
    _demote_protected_to_target(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the key
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
      - Insert into probation as most-recent (right end)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation
    m_size_map[k] = obj.size

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # Insert into probation LRU as most-recent
    q_probation[k] = None
    q_probation.move_to_end(k, last=True)
    # No change to protected bytes on insert


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
      - Remove from the appropriate LRU queue
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = evicted_obj.size

    # Adjust protected bytes if needed and remove from queues
    if m_segment.get(ek) == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - esize)
        q_protected.pop(ek, None)
    else:
        q_probation.pop(ek, None)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    m_size_map.pop(ek, None)

    # Optionally prune stale heads to keep queues tidy (cheap, amortized)
    _prune_stale_head(q_probation, cache_snapshot)
    _prune_stale_head(q_protected, cache_snapshot)
```
2025-11-27 19:50:01,440 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 16
- Error: Error - Timeout

Example 2:
- Trace ID: 4
- Hit Rate: 0.5002

Example 3:
- Trace ID: 29
- Hit Rate: 0.0386

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m19:50:01 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 19:50:01,441 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 19:50:01,476 [INFO] openai._base_client: Retrying request to /chat/completions in 0.419194 seconds
[92m19:52:25 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 19:52:25,272 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 19:52:25,273 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Improved policy: Heap-Accelerated TinyLFU with Size and Recency (HALO-TFS)
# - Fast eviction via a lazy min-heap of retention scores (no full scans)
# - TinyLFU with lazy epoch decay (per-key small counters remembered across evictions)
# - Size-aware, recency-aware scoring with multi-hit boost
# - Robust to workload shifts; avoids timeouts via O(log n) victim selection and periodic heap rebuilds

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_resident_hits = dict()    # key -> int resident hit count (>=1 once inserted)

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096   # accesses per epoch (power of two recommended)
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192  # how often to check if heap needs rebuilding
HEAP_GROWTH_FACTOR = 4       # if heap > factor * resident_count, rebuild

# Tunables for scoring
SIZE_ALPHA = 0.75           # size normalization exponent; smaller favors small objects
REC_WIN_MIN = 64            # minimum recency window
REC_WIN_MULT = 8            # recency window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.75           # strength of recency term added to frequency
MULTI_HIT_BONUS = 0.50      # multiplicative boost for items with >=2 hits while resident


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # no sweeping; decay handled lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring
# -----------------------------

def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency component
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    r_term = _recency_term(now, m_last_access.get(key), window)

    # Multi-hit boost (stronger protection after the second hit)
    mh = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    mult = 1.0 + mh

    # Final score: combine frequency and recency, then size-normalize
    score = ((f_term + REC_WEIGHT * r_term) * mult) / size_norm
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    # Rebuild heap from current residents with fresh scores/versions
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    Lazy invalidation ensures correctness despite changing scores/epochs.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., unusual bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            if k not in m_ver:
                # Initialize resident metadata if missing (best effort)
                m_last_access.setdefault(k, cache_snapshot.access_count)
                m_resident_hits.setdefault(k, 1)
            _heap_push(cache_snapshot, k)

    # Candidate's "would-be" score (informal comparison; does not affect required eviction)
    # This is used only to help prefer weaker residents when ties occur.
    cand_freq = _lfu_peek(cache_snapshot, obj.key) + 1  # will be incremented on insert
    cand_f_term = math.log1p(float(cand_freq))
    cand_size_norm = max(1.0, float(obj.size)) ** SIZE_ALPHA
    cand_score = (cand_f_term + REC_WEIGHT * 1.0) / cand_size_norm  # recency ~1 on insert

    # Pop until we find a valid, up-to-date victim
    while m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            continue
        # Skip if stale entry
        if m_ver.get(k, 0) != v:
            continue
        # Recompute current score to account for epoch/window changes
        new_sc = _score_key(cache_snapshot, k)
        # If the score drifted upward (got better), reinsert with new score
        if new_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            continue
        # Optional tie-breaker with candidate: if resident clearly stronger than candidate,
        # try to find a weaker one by peeking more; but if none, return this one.
        if new_sc >= cand_score:
            # Keep searching a bit for something weaker; cap extra attempts to avoid overhead
            attempts = 0
            tmp = [(sc, last, k, v)]
            victim = None
            while attempts < 8 and m_heap:
                sc2, last2, k2, v2 = heapq.heappop(m_heap)
                if k2 not in cache_snapshot.cache or m_ver.get(k2, 0) != v2:
                    attempts += 1
                    continue
                cur_sc2 = _score_key(cache_snapshot, k2)
                if cur_sc2 > sc2 + 1e-12:
                    _heap_push(cache_snapshot, k2)
                    attempts += 1
                    continue
                if cur_sc2 < cand_score or cur_sc2 < new_sc:
                    victim = (cur_sc2, last2, k2, v2)
                    break
                tmp.append((sc2, last2, k2, v2))
                attempts += 1
            # Push back any entries we popped but didn't choose
            for ent in tmp:
                heapq.heappush(m_heap, ent)
            if victim is not None:
                return victim[2]
            # Fall back to the original k
        return k

    # Fallback: choose the oldest resident if heap is somehow empty
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch and increment counter for requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember its popularity)
      - Invalidate its heap version (lazy: stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_ver.pop(ek, None)
    _touch_and_maybe_rebuild(cache_snapshot)
```
2025-11-27 19:55:28,494 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved: Count-based SLRU with TinyLFU, ARC-style adaptive split, and recency-aware scoring
# - Two resident segments by item count, not by bytes:
#     P (probation): admits all new objects; managed by LRU (via last_access timestamps)
#     S (protected): objects that hit at least once; also LRU-managed
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction score blends frequency and recency (recency matters beyond tie-break)
# - ARC-like ghost lists adapt the item split between P and S online (by counts)
#
# This design captures:
#   - Recency (via LRU timestamps and explicit recency in eviction score)
#   - Frequency (via TinyLFU)
#   - Adaptivity between recency-friendly and frequency-friendly behavior
#   - Correctness for caches limited by number of items (not bytes)

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU)
m_key_segment = dict()       # key -> 'P' or 'S'

# Current resident ITEM COUNTS per segment
m_cnt_P = 0
m_cnt_S = 0

# Adaptive target for protected items (S); probation target = capacity_items - target_S
m_target_S_items = None
m_cap_items_est = 0  # our estimate of capacity in number of items (learned at evict time)

# Ghost lists (non-resident metadata) to adapt split; store key -> last_time
m_ghost_P = dict()  # B1
m_ghost_S = dict()  # B2
m_ghost_limit_items = None

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)

# ---------------
# Scoring params
# ---------------
# Recency blend: score = est_freq + rec_weight * min(recency / half_life, rec_cap)
m_rec_half_life = 500.0  # accesses; tune to make recency effect comparable to est_freq
m_rec_cap = 10.0         # cap normalized recency contribution
m_rec_weight_P = 1.0     # probation recency weight
m_rec_weight_S = 0.6     # protected recency weight (S is more persistent)
m_protect_S_bias = 0.25  # additive bias to S candidates to modestly protect them
m_overweight_nudge = 0.2 # when a segment exceeds target, nudge its candidate to be more evictable

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_target_S_items, m_ghost_limit_items
    global m_sketch_tables, m_sketch_mask
    global m_cap_items_est

    # Learn capacity in items opportunistically; on evict() we'll update more accurately.
    if m_cap_items_est < len(cache_snapshot.cache):
        m_cap_items_est = len(cache_snapshot.cache)

    if m_target_S_items is None:
        # Start slightly frequency-friendly; adapt online
        base_items = max(1, len(cache_snapshot.cache))
        m_target_S_items = int(base_items * 0.6)

    if m_ghost_limit_items is None:
        # Each ghost list limited to approximately the cache capacity in items (we adjust later)
        m_ghost_limit_items = max(1, len(cache_snapshot.cache))

    if m_sketch_tables is None:
        # Width scales with estimated items; choose power of two near items*4 (empirical)
        # Minimum width to keep estimates reasonably stable.
        items = max(1, len(cache_snapshot.cache))
        width = 1
        target = max(1024, min(1 << 16, items * 4))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        # Halve all counters (right-shift by 1)
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _normalized_recency(now, last):
    if last is None or last < 0:
        return m_rec_cap
    age = max(0, now - last)
    norm = age / m_rec_half_life
    if norm > m_rec_cap:
        norm = m_rec_cap
    return norm


def _pick_min_score_in_segment(cache_snapshot, seg_tag, now):
    # Returns (key, score, last_time) that minimizes blended score within a segment
    # Score = est_freq + rec_weight * normalized_recency; tie-break by older first
    min_key = None
    min_score = None
    min_time = None

    rec_w = m_rec_weight_S if seg_tag == 'S' else m_rec_weight_P

    for key, obj in cache_snapshot.cache.items():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        est = float(_sketch_estimate(key))
        last = m_key_last_access.get(key, -1)
        rec = _normalized_recency(now, last)
        score = est + rec_w * rec
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = key
            min_score = score
            min_time = last

    return (min_key, min_score, min_time)


def _find_oldest_in_segment(cache_snapshot, seg_tag):
    oldest_key, oldest_time = None, None
    for k in cache_snapshot.cache.keys():
        if m_key_segment.get(k, 'P') != seg_tag:
            continue
        t = m_key_last_access.get(k, -1)
        if oldest_time is None or t < oldest_time:
            oldest_key, oldest_time = k, t
    return oldest_key


def _ghost_add(ghost_dict, key, time_now, which):
    # Add key->time to chosen ghost (which in {'P','S'}), trimming if exceeds limit
    global m_ghost_limit_items

    # Insert/update
    ghost_dict[key] = time_now

    # Trim to limit by evicting oldest
    limit = m_ghost_limit_items or 0
    if limit <= 0:
        return

    while len(ghost_dict) > limit:
        oldest_key, oldest_time = None, None
        for k, t in ghost_dict.items():
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        if oldest_key is None:
            break
        ghost_dict.pop(oldest_key, None)


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    # If key in P-ghost (B1): increase probation share (decrease S target)
    # If key in S-ghost (B2): increase protected share (increase S target)
    global m_target_S_items, m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Update our item-capacity estimate when cache is likely full (best signal: on evict call, but keep here too)
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)

    # Keep ghost size limits around capacity in items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est

    cap_items = max(1, m_cap_items_est)

    # Step size: 1 item per signal (conservative, stable)
    step = 1

    if obj.key in m_ghost_P:
        # Recent ghost hit: favor recency -> increase P share (decrease S)
        m_target_S_items = _clamp((m_target_S_items or 0) - step, 0, cap_items)
        m_ghost_P.pop(obj.key, None)
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: favor frequency -> increase S share
        m_target_S_items = _clamp((m_target_S_items or 0) + step, 0, cap_items)
        m_ghost_S.pop(obj.key, None)


def _maybe_demote_from_S_to_P(cache_snapshot):
    # If S exceeds its target, demote oldest S item to P
    global m_cnt_P, m_cnt_S, m_target_S_items
    if m_target_S_items is None:
        return
    if m_cnt_S > m_target_S_items:
        demote_key = _find_oldest_in_segment(cache_snapshot, 'S')
        if demote_key is not None:
            m_key_segment[demote_key] = 'P'
            m_cnt_S = max(0, m_cnt_S - 1)
            m_cnt_P += 1


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using count-based SLRU + TinyLFU with recency-aware scoring.
    - Compute candidate with minimal blended score in each segment:
        score = est_freq(key) + rec_weight * normalized_recency
    - Bias to evict from the segment exceeding its item-count target.
    - Protect S moderately by adding a small bias compared to P.
    '''
    global m_cnt_P, m_cnt_S, m_target_S_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Learn/refresh capacity in number of items at the moment of eviction (cache is full now)
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    cap_items = max(1, m_cap_items_est)
    if m_target_S_items is None:
        m_target_S_items = int(0.6 * cap_items)
    target_S = _clamp(m_target_S_items, 0, cap_items)
    target_P = cap_items - target_S

    now = cache_snapshot.access_count

    # Find min-score candidate in each segment
    p_key, p_score, p_lru = _pick_min_score_in_segment(cache_snapshot, 'P', now)
    s_key, s_score, s_lru = _pick_min_score_in_segment(cache_snapshot, 'S', now)

    # Prepare adjusted scores
    best_key = None
    best_adj = None

    if p_key is not None:
        adj_p = p_score
        # If P is overweight, make it slightly more likely to evict from P
        if m_cnt_P > target_P:
            adj_p -= m_overweight_nudge
        # No extra protection bias for P
        best_key = p_key
        best_adj = adj_p

    if s_key is not None:
        adj_s = s_score + m_protect_S_bias
        # If S is overweight, encourage eviction from S
        if m_cnt_S > target_S:
            adj_s -= m_overweight_nudge
        if (best_adj is None) or (adj_s < best_adj):
            best_adj = adj_s
            best_key = s_key

    # Fallback: if we somehow didn't find any key (shouldn't happen), pick oldest globally
    if best_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        best_key = oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - If in probation (P), promote to protected (S); if S exceeds target, demote oldest S to P
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    k = obj.key

    # Update TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    # Promote from P to S on hit
    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        m_key_segment[k] = 'S'
        m_cnt_P = max(0, m_cnt_P - 1)
        m_cnt_S += 1
        # If S above target, demote oldest S back to P
        _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S item split using ARC-like ghosts
      - Increment TinyLFU for the key (TinyLFU trains on both hits and misses)
      - Add the new object to probation (P)
      - Record last access time
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_cnt_P += 1

    # Keep S from drifting above target if previous operations changed target
    _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key
      - Update segment item counters
      - Add the key to the corresponding ghost list (count-limited) to guide future adaptation
      - Keep ghost sizes roughly equal to estimated cache capacity in items
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S
    global m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust item counts and add to appropriate ghost
    now = cache_snapshot.access_count
    if seg == 'S':
        m_cnt_S = max(0, m_cnt_S - 1)
        _ghost_add(m_ghost_S, ek, now, which='S')
    else:
        m_cnt_P = max(0, m_cnt_P - 1)
        _ghost_add(m_ghost_P, ek, now, which='P')

    # Update ghost limits to approximate current capacity in items
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 2
- Error: Error - Timeout

Example 2:
- Trace ID: 15
- Hit Rate: 0.0213

Example 3:
- Trace ID: 8
- Hit Rate: 0.5166

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m19:55:28 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 19:55:28,495 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m19:57:19 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 19:57:19,086 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 19:57:19,087 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Fast SLRU with TinyLFU and lightweight ARC-style adaptation
# - Two LRU segments by item count:
#     P (probation): all new objects; on hit -> promote to S
#     S (protected): items that hit at least once
# - Victim selection is O(1) to O(k): evict from segment tail; optionally sample the k oldest
#   keys in the chosen segment and evict the one with the lowest TinyLFU estimate.
# - TinyLFU estimates global popularity with periodic aging (Count-Min Sketch).
# - ARC-like ghost lists adapt the target split between P and S online (by item counts).
# - No full-cache scans, avoiding timeouts on large traces.

from collections import OrderedDict

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Segment membership and order (LRU: left=oldest, right=MRU)
m_ord_P = OrderedDict()      # probation LRU: key -> None
m_ord_S = OrderedDict()      # protected LRU: key -> None
m_key_segment = dict()       # key -> 'P' or 'S'

# Adaptive target for protected items (S); P target = cap_items - target_S
m_target_S_items = None
m_cap_items_est = 0          # our estimate of capacity in number of items (learned at evict time)

# Ghost lists (non-resident) for online adaptation
m_ghost_P = OrderedDict()    # B1: keys recently evicted from P
m_ghost_S = OrderedDict()    # B2: keys recently evicted from S
m_ghost_limit_items = None

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)

# ---------------
# Params
# ---------------
m_sample_k = 6  # sample size among the oldest items in chosen segment for eviction


# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_target_S_items, m_ghost_limit_items
    global m_sketch_tables, m_sketch_mask
    global m_cap_items_est

    # Learn capacity in items opportunistically
    if m_cap_items_est < len(cache_snapshot.cache):
        m_cap_items_est = len(cache_snapshot.cache)

    if m_target_S_items is None:
        # Start somewhat frequency-friendly; will adapt online
        base_items = max(1, len(cache_snapshot.cache))
        m_target_S_items = int(base_items * 0.6)

    if m_ghost_limit_items is None:
        # Approx equal to the cache capacity in items (refined later on evictions)
        m_ghost_limit_items = max(1, len(cache_snapshot.cache))

    if m_sketch_tables is None:
        # Width scales with estimated items; power-of-two near items*4, min 1024
        items = max(1, len(cache_snapshot.cache))
        width = 1
        target = max(1024, min(1 << 16, items * 4))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    if m_sketch_tables is None:
        return
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    if m_sketch_tables is None:
        return 0
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        # Halve all counters
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _ghost_add(ghost_odict, key):
    # Add to ghost (most recent at right), trim oldest to limit
    global m_ghost_limit_items
    if key in ghost_odict:
        # refresh position to MRU
        ghost_odict.move_to_end(key, last=True)
    else:
        ghost_odict[key] = None
    limit = m_ghost_limit_items or 0
    while limit > 0 and len(ghost_odict) > limit:
        ghost_odict.popitem(last=False)  # drop LRU


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    global m_target_S_items, m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Update our item-capacity estimate when cache is likely full (best signal is in evict)
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)

    # Keep ghost size limits around capacity in items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est

    cap_items = max(1, m_cap_items_est)
    step = 1  # conservative step per signal

    if obj.key in m_ghost_P:
        # Favor recency -> increase P share (decrease S)
        m_target_S_items = _clamp((m_target_S_items or 0) - step, 0, cap_items)
        # Refresh/remove handled by insert path below
        try:
            del m_ghost_P[obj.key]
        except KeyError:
            pass
    elif obj.key in m_ghost_S:
        # Favor frequency -> increase S share
        m_target_S_items = _clamp((m_target_S_items or 0) + step, 0, cap_items)
        try:
            del m_ghost_S[obj.key]
        except KeyError:
            pass


def _rebalance_S_if_needed():
    # If S exceeds its target, demote LRU from S to P
    global m_target_S_items
    if m_target_S_items is None:
        return
    target_S = m_target_S_items
    while len(m_ord_S) > target_S:
        k_demote, _ = m_ord_S.popitem(last=False)  # LRU of S
        m_key_segment[k_demote] = 'P'
        # Insert as MRU in P
        if k_demote in m_ord_P:
            m_ord_P.move_to_end(k_demote, last=True)
        else:
            m_ord_P[k_demote] = None


def _choose_victim_from_segment(seg_tag):
    # Choose a victim from the chosen segment with TinyLFU sampling among oldest items
    od = m_ord_S if seg_tag == 'S' else m_ord_P
    if not od:
        return None

    # Sample last m_sample_k keys (oldest first via reversed od gives MRU->LRU; we want LRU side)
    # OrderedDict iterates left->right; reversed() gives right->left (MRU to LRU).
    # To sample among oldest, we can iterate forward and take first k keys (LRU side).
    # Forward iteration gives oldest-first already, which is what we need.
    best_key = None
    best_score = None

    cnt = 0
    for k in od.keys():  # LRU to MRU
        est = _sketch_estimate(k)
        if (best_score is None) or (est < best_score):
            best_score = est
            best_key = k
        cnt += 1
        if cnt >= m_sample_k:
            break

    # If for any reason best_key is None (shouldn't), fall back to plain LRU
    if best_key is None:
        best_key = next(iter(od))
    return best_key


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim:
      - Maintain SLRU segments with LRU order per segment.
      - Evict primarily from probation (P); if P is under target or empty, evict from S.
      - Within the chosen segment, sample the k oldest and evict the one with the lowest TinyLFU estimate.
    This avoids full-cache scans and balances recency/frequency efficiently.
    '''
    global m_target_S_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Learn/refresh capacity in number of items at the moment of eviction (cache is full now)
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    cap_items = max(1, m_cap_items_est)
    if m_target_S_items is None:
        m_target_S_items = int(0.6 * cap_items)
    target_S = _clamp(m_target_S_items, 0, cap_items)
    target_P = cap_items - target_S

    cntP = len(m_ord_P)
    cntS = len(m_ord_S)

    # Choose segment to evict from:
    # - Prefer P when available
    # - If P is under its target and S is above, evict from S
    if cntP > 0 and (cntP >= target_P or cntS == 0):
        seg = 'P'
    else:
        seg = 'S' if cntS > 0 else 'P'

    victim = _choose_victim_from_segment(seg)

    # Fallback: if somehow none, evict oldest globally by looking at the global cache dict
    if victim is None:
        try:
            # Attempt oldest in P then S
            if m_ord_P:
                victim = next(iter(m_ord_P))
            elif m_ord_S:
                victim = next(iter(m_ord_S))
            else:
                victim = next(iter(cache_snapshot.cache))
        except StopIteration:
            victim = None

    return victim


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh LRU position in its segment
      - If in probation (P), promote to protected (S); keep S within target by demoting its LRU into P
    '''
    global m_target_S_items

    _init_if_needed(cache_snapshot)

    k = obj.key
    _sketch_inc(k, 1)

    seg = m_key_segment.get(k)
    if seg == 'S':
        # Refresh S LRU position
        if k in m_ord_S:
            m_ord_S.move_to_end(k, last=True)
        else:
            # In rare mismatch, reinsert into S
            m_ord_S[k] = None
            m_ord_S.move_to_end(k, last=True)
    else:
        # Default or explicit P: promote to S
        if k in m_ord_P:
            del m_ord_P[k]
        # Insert/update in S as MRU
        if k in m_ord_S:
            m_ord_S.move_to_end(k, last=True)
        else:
            m_ord_S[k] = None
        m_key_segment[k] = 'S'
        # Keep S within target
        _rebalance_S_if_needed()


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S item split using ARC-like ghosts (B1/B2)
      - Train TinyLFU on the access (miss)
      - Add the new object to probation (P) as MRU
      - Keep S within target (in case target shrank)
    '''
    global m_target_S_items

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghosts
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation MRU
    if k in m_ord_P:
        m_ord_P.move_to_end(k, last=True)
    else:
        m_ord_P[k] = None
    m_key_segment[k] = 'P'

    # S target might have decreased; ensure S respects target
    _rebalance_S_if_needed()


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key (from segment LRU and maps)
      - Add the key to the corresponding ghost list (count-limited) to guide future adaptation
      - Update ghost size limits to approximate current capacity in items
    '''
    global m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Remove from resident structures
    if ek in m_ord_P:
        try:
            del m_ord_P[ek]
        except KeyError:
            pass
    if ek in m_ord_S:
        try:
            del m_ord_S[ek]
        except KeyError:
            pass
    m_key_segment.pop(ek, None)

    # Add to appropriate ghost
    if seg == 'S':
        _ghost_add(m_ghost_S, ek)
    else:
        _ghost_add(m_ghost_P, ek)

    # Update ghost limits to approximate current capacity in items
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est
```
2025-11-27 20:00:03,642 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 38
- Hit Rate: 0.1255

Example 2:
- Trace ID: 43
- Hit Rate: 0.3667

Example 3:
- Trace ID: 1
- Hit Rate: 0.4792

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:00:03 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:00:03,643 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:02:12 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:02:12,499 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:02:12,500 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Weighted W-TinyLFU with Window + Segmented SLRU (by bytes)
# - Three resident segments (by bytes):
#     * window (very small, recency-biased): new inserts
#     * probation (main): single-hit items admitted from window on hit
#     * protected (main): multi-hit items
# - Eviction order:
#     1) Prefer evicting from window if it exceeds its byte target (scan-resistant)
#     2) Otherwise evict from probation using a size-aware TinyLFU+recency+reuse score
#     3) If probation empty, demote oldest protected until protected meets its target,
#        then evict from probation; if still empty, evict lowest-score protected
# - TinyLFU uses lazy-decayed 4-bit counters (epoch based)
# - EMA of inter-arrival time (IRT) for predicted reuse
# - All targets are handled in BYTES, not by item count
#
# Notes:
# - This design approximates Caffeine’s W-TinyLFU while accommodating the single-victim API.
# - The small window absorbs scans; frequent items quickly move to protected and are shielded.

import math

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count
# Segment: -1 (window), 0 (probation), 1 (protected)
m_segment = dict()         # key -> int

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented capacity targeting (by bytes)
WINDOW_FRACTION = 0.06         # 6% window for recency
MAIN_PROTECTED_FRACTION = 0.80 # protected share of MAIN (capacity - window)
g_window_bytes = 0
g_protected_bytes = 0

# Scoring tunables
SIZE_ALPHA = 1.20          # >1 penalizes large objects more
MULTI_HIT_BONUS = 0.50     # extra benefit for items with >=2 resident hits

# Recency/Predicted reuse windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4

# Segment-specific weights
W_REC_WIN  = 0.95
W_PRED_WIN = 0.05

W_REC_PROB = 0.55
W_PRED_PROB = 0.25

W_REC_PROT = 0.15
W_PRED_PROT = 0.15

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.45

# --------------------------------
# TinyLFU helpers (lazy decay)
# --------------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# --------------------------------
# General helpers
# --------------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    return m_segment.get(key, 0)  # default probation if unknown

def _targets(cache_snapshot):
    cap = cache_snapshot.capacity
    win_target = int(WINDOW_FRACTION * float(cap))
    main_target = max(0, cap - win_target)
    prot_target = int(MAIN_PROTECTED_FRACTION * float(main_target))
    return win_target, prot_target

def _find_oldest_in_segment(cache_snapshot, segment_id):
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected(cache_snapshot):
    # Demote the oldest protected item to probation
    global g_protected_bytes
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return False
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return False
    g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0
    return True

def _enforce_protected_target(cache_snapshot):
    # Keep protected at/below its target by demotions
    win_target, prot_target = _targets(cache_snapshot)
    while g_protected_bytes > prot_target:
        if not _demote_one_from_protected(cache_snapshot):
            break

# --------------------------------
# Scoring (eviction priority)
# --------------------------------

def _retention_score(cache_snapshot, key):
    # Higher score => stronger retention (harder to evict)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    base_benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    elif seg == -1:
        w_rec = W_REC_WIN
        w_pred = W_PRED_WIN
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    # Recent and soon-to-reuse -> larger gain
    recency_gain = w_rec * (1.0 - age_norm)
    predicted_gain = w_pred * (1.0 - irt_norm)

    return base_benefit + recency_gain + predicted_gain

# --------------------------------
# Policy entry points
# --------------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - If window exceeds target bytes, evict its LRU (scan resistance)
      - Else demote protected until within target
      - Prefer evicting from probation; fall back to protected
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Segment targets
    win_target, prot_target = _targets(cache_snapshot)

    # 1) If window is oversized, evict LRU from window first
    if g_window_bytes > win_target:
        k, _ = _find_oldest_in_segment(cache_snapshot, segment_id=-1)
        if k is not None:
            return k

    # 2) Keep protected within target by demotions (promotes more eviction from probation)
    _enforce_protected_target(cache_snapshot)

    # Helper: select the weakest key (min retention score) within a segment
    def select_min_in_segment(seg_id):
        min_key = None
        min_score = None
        min_time = None
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_key = k
                min_score = score
                min_time = last
                found = True
        return min_key

    # 3) Evict from probation if possible
    victim = select_min_in_segment(0)
    if victim is not None:
        return victim

    # 4) If no probation items, evict from protected (rare, tiny caches or long runs)
    victim = select_min_in_segment(1)
    if victim is not None:
        return victim

    # 5) Fallback: evict oldest from window if exists, else any key
    k, _ = _find_oldest_in_segment(cache_snapshot, segment_id=-1)
    if k is not None:
        return k
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - Promotions:
          * window -> probation
          * probation -> protected
        (protected stays)
      - Keep protected within target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count
    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize conservatively
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = prev if prev is not None else now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = _segment_of(k)
    # Promotions across segments
    global g_window_bytes, g_protected_bytes
    if seg == -1:
        # window -> probation
        m_segment[k] = 0
        g_window_bytes = max(0, g_window_bytes - obj.size)
    elif seg == 0:
        # probation -> protected
        m_segment[k] = 1
        g_protected_bytes += obj.size
    # seg == 1 stays

    # Enforce protected target (demote oldest protected if oversized)
    _enforce_protected_target(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = window
      - Track window bytes
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = -1  # window

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    global g_window_bytes
    g_window_bytes += obj.size


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Adjust segment byte counters
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    seg = _segment_of(ek)

    global g_window_bytes, g_protected_bytes
    if seg == -1:
        g_window_bytes = max(0, g_window_bytes - evicted_obj.size)
    elif seg == 1:
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)
    # probation bytes are implicit (total - window - protected)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Keep m_lfu_count[ek] for admission/frequency memory
```
2025-11-27 20:02:21,569 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Dynamic WTinyLFU + GDS with Gated Promotion and Size-Sensitive Admission (DTinyLFU-GDS+)
# - Three components:
#   1) TinyLFU (Count-Min Sketch) for long-term frequency estimation (size-aware scoring)
#   2) Window segment W (recency-biased) that admits all new items (scan-resilient)
#   3) Main segment M (frequency- and size-aware) using GreedyDual-Size (GDS) with TinyLFU scores
#
# Key improvements over baseline:
#   - Size-sensitive scoring est / size^alpha (alpha ~ 0.85) to better balance large objects
#   - Admission decision uses consistent GDS terms: compare H_in = L + score_in vs min(H_M)
#   - Gated promotion: a hit in W promotes to M only if its H_in surpasses current M min(H)
#     (reduces pollution of M and improves scan resistance)
#   - Large-object streaming guard: very large, low-frequency newcomers favor evicting from W
#   - Ghost-biased admission: if newcomer present in M-ghost, bias to admit (evict from M);
#     if in W-ghost, bias to protect recency (evict from W)
#   - Safer window target clamping; consistent byte accounting; better tie-breaking
#
# Eviction:
#   - Evict from W if W exceeds its adaptive target, or large-object streaming guard triggers.
#   - Otherwise compute H_incoming and compare to main's minimum H:
#       * If H_incoming <= min(H_M) => evict from W (protect M)
#       * Else evict from M
#   - Within W: LRU. Within M: evict min H (GDS). Ties broken by LRU.
#
# Updates:
#   - On every access (hit or miss), increment TinyLFU.
#   - On hit in W: gated promotion to M if strong enough; otherwise remain in W.
#   - On hit in M: refresh its GDS priority H = L_M + score.
#   - On insert: admit to W; adapt W target using ARC-like ghosts.
#   - On evict: if M victim, set L_M to victim's H (GDS aging); record ghosts.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_priority = dict()      # key -> float priority H (only meaningful for M)
m_key_last_access = dict()   # key -> int access_count (for LRU tie-breaks)
m_key_segment = dict()       # key -> 'W' (window) or 'M' (main)

# Main segment GreedyDual age
m_age_M = 0.0

# Current resident bytes per segment
m_bytes_W = 0
m_bytes_M = 0

# Adaptive target for window bytes (W); M target = capacity - target_W
m_target_W_bytes = None

# Ghost lists for ARC-like adaptation of W/M split; store key -> (size, last_time)
m_ghost_W = dict()
m_ghost_M = dict()
m_ghost_W_bytes = 0
m_ghost_M_bytes = 0
m_ghost_limit_bytes = None

# -----------------------------
# TinyLFU (Count-Min Sketch)
# -----------------------------
m_cm_depth = None
m_cm_width = None
m_cm_mask = None
m_cm = None                 # 2D list: depth x width
m_cm_seeds = None
m_cm_inserts = 0
m_cm_sample = None          # when total increments exceed this, perform aging (halve)

# -----------------------------
# Tunables
# -----------------------------
SIZE_ALPHA = 0.85                  # exponent for size-aware score: est / size^alpha
MIN_SIZE_UNIT = 1                  # minimum divisor in bytes to avoid div-by-zero
LARGE_OBJ_FRAC = 0.25              # fraction of capacity considered "very large"
LARGE_OBJ_FREQ_CUTOFF = 2          # TinyLFU estimate threshold to consider "hot"
ADMIT_BIAS = 0.10                  # +/-10% bias based on ghosts when comparing H_in vs min(H_M)

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)

def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_W_bytes, m_ghost_limit_bytes
    global m_cm_depth, m_cm_width, m_cm_mask, m_cm, m_cm_seeds, m_cm_sample

    cap = cache_snapshot.capacity
    if m_target_W_bytes is None:
        # Start with a modest window (10% of capacity), typical for WTinyLFU
        m_target_W_bytes = cap * 0.10
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cap

    # Initialize TinyLFU CM sketch parameters once
    if m_cm is None:
        m_cm_depth = 4
        # Width tuned by capacity; enforce power-of-two for fast masking
        base = 4096
        try:
            # scale to ~2^k with k ~ [11..14] based on capacity bits
            scaled_pow = max(11, min(14, (cap.bit_length() - 6)))
            width = 1 << scaled_pow
        except Exception:
            width = base
        m_cm_width = _clamp(width, 2048, 16384)
        # round to power of two
        pw = 1
        while pw < m_cm_width:
            pw <<= 1
        m_cm_width = pw
        m_cm_mask = m_cm_width - 1
        m_cm = [[0] * m_cm_width for _ in range(m_cm_depth)]
        # Fixed seeds for hash mixing
        m_cm_seeds = [0x27d4eb2d, 0x85ebca6b, 0xc2b2ae35, 0x165667b1]
        # Sampling window before aging
        m_cm_sample = m_cm_width * 20  # e.g., 4096*20 = 81,920 increments between halvings

def _hash_idx(seed, key_str):
    # Simple mixed hash -> index [0..width-1]
    h = hash(str(seed) + '|' + key_str)
    return h & m_cm_mask

def _cm_increment(key, delta=1):
    # Increment TinyLFU counters for key; perform periodic aging
    global m_cm_inserts
    if m_cm is None:
        return
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key)
        # Saturate at a large value to avoid overflow
        if m_cm[d][idx] < 0x7fffffff:
            m_cm[d][idx] += delta
    m_cm_inserts += delta
    if m_cm_inserts >= (m_cm_sample or 1):
        # Halve all counters (right shift by 1) to age history
        for d in range(m_cm_depth):
            row = m_cm[d]
            for i in range(m_cm_width):
                row[i] >>= 1
        m_cm_inserts >>= 1  # approximate total after halving

def _cm_estimate(key):
    if m_cm is None:
        return 0
    est = None
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key)
        val = m_cm[d][idx]
        est = val if est is None else (val if val < est else est)
    return est or 0

def _score_freq_size(key, size):
    # Size-aware frequency score: est_freq / size^alpha
    if size <= 0:
        return 0.0
    denom = max(MIN_SIZE_UNIT, float(size)) ** float(SIZE_ALPHA)
    est = _cm_estimate(key)
    if est <= 0:
        return 0.0
    return float(est) / denom

def _pick_oldest_in_segment(cache_snapshot, seg_tag):
    # Returns (key, last_time) of the oldest (LRU) key in a segment
    oldest_key = None
    oldest_time = None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != seg_tag:
            continue
        last = m_key_last_access.get(key, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = key
    return (oldest_key, oldest_time)

def _pick_min_in_main(cache_snapshot):
    # Returns (key, prio, last_time) of the minimum-priority key in main (M)
    min_key = None
    min_prio = None
    min_time = None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != 'M':
            continue
        prio = m_key_priority.get(key)
        if prio is None:
            obj = cache_snapshot.cache.get(key)
            if obj is None:
                continue
            prio = m_age_M + _score_freq_size(key, obj.size)
            m_key_priority[key] = prio
        last = m_key_last_access.get(key, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_prio = prio
            min_time = last
            min_key = key
    return (min_key, min_prio, min_time)

def _ghost_add(ghost_dict, key, size, time_now, is_W):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_W_bytes, m_ghost_M_bytes, m_ghost_limit_bytes

    if is_W:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_W_bytes += size
        else:
            old_size, _ = prev
            m_ghost_W_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_W_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_W_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_M_bytes += size
        else:
            old_size, _ = prev
            m_ghost_M_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_M_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_M_bytes -= sz

def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation of window target based on which ghost contains the new key
    global m_ghost_W, m_ghost_M, m_ghost_W_bytes, m_ghost_M_bytes, m_target_W_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step sized by object size; clamp to [1%, 10%] of capacity to avoid huge jumps
    step = _clamp(obj.size, int(0.01 * cap), int(0.10 * cap))

    if obj.key in m_ghost_W:
        # Recency pressure ↑ => increase window size target
        m_target_W_bytes = _clamp(m_target_W_bytes + step, 0, cap)
        sz, _ = m_ghost_W.pop(obj.key)
        m_ghost_W_bytes -= sz
    elif obj.key in m_ghost_M:
        # Frequency pressure ↑ => decrease window, giving more to main
        m_target_W_bytes = _clamp(m_target_W_bytes - step, 0, cap)
        sz, _ = m_ghost_M.pop(obj.key)
        m_ghost_M_bytes -= sz

def _prefer_w_due_to_large_stream(cache_snapshot, obj):
    # For very large, low-frequency objects that are not hinted by M-ghost, prefer to evict from W
    cap = cache_snapshot.capacity or 1
    large = obj.size >= int(cap * LARGE_OBJ_FRAC)
    if not large:
        return False
    # If it's not frequent and not seen in M-ghost before, treat as likely stream
    if _cm_estimate(obj.key) < LARGE_OBJ_FREQ_CUTOFF and (obj.key not in m_ghost_M):
        return True
    return False

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using DTinyLFU-GDS+ policy:
      - Evict from W if W exceeds its adaptive target (recency window) or large-object stream guard triggers.
      - Else compute H_incoming and compare to M's weakest H:
          * If H_incoming <= weakest main H (after ghost bias) => evict from W (protect M)
          * Else evict from M
      - Within W: LRU. Within M: evict min H (GDS). Ties use LRU.
    '''
    global m_bytes_W, m_bytes_M, m_target_W_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Clamp window target to [1% cap, 50% cap]
    min_w = int(max(1, cap * 0.01))
    max_w = int(cap * 0.50)
    target_W = int(_clamp(int(m_target_W_bytes), min_w, max_w))

    # Candidates
    w_key, _ = _pick_oldest_in_segment(cache_snapshot, 'W')
    m_key, m_prio, _ = _pick_min_in_main(cache_snapshot)

    # If nothing to evict, fallback to global LRU
    if w_key is None and m_key is None:
        min_key, min_time = None, None
        for key in cache_snapshot.cache.keys():
            t = m_key_last_access.get(key, -1)
            if min_time is None or t < min_time:
                min_key, min_time = key, t
        return min_key if min_key is not None else next(iter(cache_snapshot.cache))

    # Prefer evicting from W when it exceeds target or large streaming guard applies
    if (m_bytes_W > target_W and w_key is not None) or _prefer_w_due_to_large_stream(cache_snapshot, obj):
        return w_key if w_key is not None else m_key

    # If one segment is empty, evict from the other
    if w_key is None:
        return m_key
    if m_key is None:
        return w_key

    # Admission decision based on GDS-consistent comparison
    incoming_score = _score_freq_size(obj.key, obj.size)
    H_incoming = m_age_M + incoming_score

    # Ghost-based bias: if in M-ghost, bias towards admitting (evict M); if in W-ghost, bias to protect W
    bias = 0.0
    if obj.key in m_ghost_M:
        bias += ADMIT_BIAS
    if obj.key in m_ghost_W:
        bias -= ADMIT_BIAS
    # Apply bias by stretching/shrinking the threshold (min H)
    threshold = m_prio * (1.0 - bias)

    # If incoming not strong enough, protect main by evicting from window
    if H_incoming <= threshold:
        return w_key
    else:
        return m_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU
      - If in window (W), gated promotion to main (M) if H_incoming > min(H_M)
      - In main (M), refresh its GDS priority H = L_M + est_freq/size^alpha
      - Refresh last-access time
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_age_M, m_bytes_W, m_bytes_M

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Record access in TinyLFU
    _cm_increment(k, 1)

    # Update last access time
    m_key_last_access[k] = cache_snapshot.access_count

    seg = m_key_segment.get(k)
    if seg == 'W':
        # Gated promotion: move to M only if H_incoming surpasses current min in M
        H_incoming = m_age_M + _score_freq_size(k, sz)
        m_key, m_prio, _ = _pick_min_in_main(cache_snapshot)
        # If M empty or newcomer stronger than weakest M item, promote
        should_promote = (m_key is None) or (H_incoming > m_prio)
        if should_promote:
            m_key_segment[k] = 'M'
            # Adjust bytes
            m_bytes_W = max(0, m_bytes_W - sz)
            m_bytes_M += sz
            # Set main priority
            m_key_priority[k] = H_incoming
        else:
            # Stay in W; no priority in W
            m_key_priority.pop(k, None)
    else:
        # Already in main: refresh priority with current TinyLFU estimate
        m_key_priority[k] = m_age_M + _score_freq_size(k, sz)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU (record this access)
      - Adapt the W/M byte split using ARC-like ghosts
      - Admit the new object into window (W)
      - Record last access
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_bytes_W

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Record this access in TinyLFU
    _cm_increment(k, 1)

    # Adapt window target based on ghosts
    _adapt_targets_on_insert(cache_snapshot, obj)

    # Initialize metadata in window
    m_key_segment[k] = 'W'
    m_key_last_access[k] = cache_snapshot.access_count
    # No priority needed in W; clear any stale
    m_key_priority.pop(k, None)

    # Account bytes in window
    m_bytes_W += sz


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - If victim was in main (M), set L_M to victim's priority (GreedyDual aging)
      - Remove resident metadata
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_age_M, m_bytes_W, m_bytes_M
    global m_ghost_W, m_ghost_M

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'W')  # default to window if unknown
    # Use stored priority for main; if missing, approximate using current age + TinyLFU score
    if seg == 'M':
        evicted_prio = m_key_priority.get(ek)
        if evicted_prio is None:
            evicted_prio = m_age_M + _score_freq_size(ek, esz)
        # Age update for main
        m_age_M = evicted_prio

    # Cleanup resident metadata
    m_key_priority.pop(ek, None)
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes and add to appropriate ghost
    if seg == 'M':
        m_bytes_M = max(0, m_bytes_M - esz)
        _ghost_add(m_ghost_M, ek, esz, cache_snapshot.access_count, is_W=False)
    else:
        m_bytes_W = max(0, m_bytes_W - esz)
        _ghost_add(m_ghost_W, ek, esz, cache_snapshot.access_count, is_W=True)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 26
- Hit Rate: 0.7507

Example 2:
- Trace ID: 44
- Hit Rate: 0.0419

Example 3:
- Trace ID: 46
- Hit Rate: 0.4417

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:02:21 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:02:21,570 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:05:04 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:05:04,198 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:05:04,199 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Improved: WTinyLFU + Byte-SLRU (Window + Main: Probation/Protected) with GDSF aging
# Key changes vs previous version:
# 1) Consistent admission: if evict() chose an M victim, the next insert is admitted directly into M (probation).
#    This fixes a critical mismatch where M shrank over time because inserts always went to W.
# 2) W hits promote to M (probation) on first repeat (2nd touch). This boosts recency on scan-like workloads.
# 3) Main (M) is a two-queue SLRU: probation (MP) and protected (MR). A hit in MP moves to MR.
#    Eviction within M prefers MP; ties broken by GreedyDual-Size-Frequency (GDSF) priority H = L + est/size^alpha.
# 4) Gentler size penalty (alpha=0.5) to avoid over-penalizing large but popular objects.
# 5) Ghost-based dynamic window sizing remains, with direct M admission bias if M-ghost hit.
# 6) Large-object streaming guard preserved but toned by TinyLFU estimates.
#
# Interface assumptions:
# - evict(snapshot, obj) returns victim-key.
# - update_after_insert runs after the object is inserted and should assign it to W or M consistently with evict()'s choice.
# - update_after_evict runs after the victim is removed.
# - update_after_hit runs after a hit on a resident object.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_priority = dict()       # key -> float H (only meaningful for M)
m_key_last_access = dict()    # key -> int access_count (for LRU / SLRU ordering)
m_key_segment = dict()        # key -> 'W' or 'M'
m_key_m_state = dict()        # key -> 'P' (probation) or 'R' (protected) for M only
m_w_hits = dict()             # window repeat counter since admission (k -> count)

# Main segment GDSF age
m_age_M = 0.0

# Current resident bytes per segment
m_bytes_W = 0
m_bytes_M = 0

# Adaptive target for window bytes (W); M target = capacity - target_W
m_target_W_bytes = None

# Ghost lists for ARC-like adaptation; store key -> (size, last_time)
m_ghost_W = dict()
m_ghost_M = dict()
m_ghost_W_bytes = 0
m_ghost_M_bytes = 0
m_ghost_limit_bytes = None

# Admission signal from evict() to update_after_insert()
m_admit_to_M_next = False     # True if evict() chose an M victim for the current insert

# -----------------------------
# TinyLFU (Count-Min Sketch)
# -----------------------------
m_cm_depth = None
m_cm_width = None
m_cm_mask = None
m_cm = None
m_cm_seeds = None
m_cm_inserts = 0
m_cm_sample = None  # when total increments exceed this, perform aging (halve)

# -----------------------------
# Tunables
# -----------------------------
SIZE_ALPHA = 0.50                  # gentler exponent for size-aware score: est / size^alpha
MIN_SIZE_UNIT = 1
LARGE_OBJ_FRAC = 0.50              # very large if >= 50% of capacity
LARGE_OBJ_FREQ_CUTOFF = 2          # TinyLFU estimate threshold to consider "hot"
ADMIT_BIAS_MGHOST = 0.20           # +20% bias if key in M-ghost (favor admitting to M)
ADMIT_BIAS_WGHOST = 0.10           # -10% bias if key in W-ghost (favor protecting W)

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)

def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_W_bytes, m_ghost_limit_bytes
    global m_cm_depth, m_cm_width, m_cm_mask, m_cm, m_cm_seeds, m_cm_sample

    cap = cache_snapshot.capacity
    if m_target_W_bytes is None:
        # Start with 20% window; adaptively tuned via ghosts
        m_target_W_bytes = cap * 0.20
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cap

    if m_cm is None:
        m_cm_depth = 4
        # Width tuned by capacity; enforce power-of-two for fast masking
        try:
            scaled_pow = max(11, min(14, (cap.bit_length() - 5)))
            width = 1 << scaled_pow
        except Exception:
            width = 4096
        m_cm_width = _clamp(width, 2048, 16384)
        # round to power of two
        pw = 1
        while pw < m_cm_width:
            pw <<= 1
        m_cm_width = pw
        m_cm_mask = m_cm_width - 1
        m_cm = [[0] * m_cm_width for _ in range(m_cm_depth)]
        m_cm_seeds = [0x27d4eb2d, 0x85ebca6b, 0xc2b2ae35, 0x165667b1]
        m_cm_sample = m_cm_width * 20  # e.g., ~80k increments between halvings

def _hash_idx(seed, key_str):
    h = hash(str(seed) + '|' + key_str)
    return h & m_cm_mask

def _cm_increment(key, delta=1):
    global m_cm_inserts
    if m_cm is None:
        return
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key)
        if m_cm[d][idx] < 0x7fffffff:
            m_cm[d][idx] += delta
    m_cm_inserts += delta
    if m_cm_inserts >= (m_cm_sample or 1):
        for d in range(m_cm_depth):
            row = m_cm[d]
            for i in range(m_cm_width):
                row[i] >>= 1
        m_cm_inserts >>= 1

def _cm_estimate(key):
    if m_cm is None:
        return 0
    est = None
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key)
        val = m_cm[d][idx]
        est = val if est is None else (val if val < est else est)
    return est or 0

def _score_freq_size(key, size):
    if size <= 0:
        return 0.0
    denom = max(MIN_SIZE_UNIT, float(size)) ** float(SIZE_ALPHA)
    est = _cm_estimate(key)
    if est <= 0:
        return 0.0
    return float(est) / denom

def _pick_oldest_in_segment(cache_snapshot, seg_tag):
    # Returns (key, last_time) of oldest (LRU) key in a segment
    oldest_key = None
    oldest_time = None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != seg_tag:
            continue
        last = m_key_last_access.get(key, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = key
    return (oldest_key, oldest_time)

def _pick_min_in_main(cache_snapshot):
    # Returns (key, prio, last_time) of the minimum-priority key in main (M),
    # preferring probation (MP) over protected (MR). Ties by LRU.
    min_key = None
    min_prio = None
    min_time = None

    # First pass: probation
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != 'M' or m_key_m_state.get(key) != 'P':
            continue
        prio = m_key_priority.get(key)
        if prio is None:
            obj = cache_snapshot.cache.get(key)
            if obj is None:
                continue
            prio = m_age_M + _score_freq_size(key, obj.size)
            m_key_priority[key] = prio
        last = m_key_last_access.get(key, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_prio = prio
            min_time = last
            min_key = key

    if min_key is not None:
        return (min_key, min_prio, min_time)

    # Second pass: protected
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != 'M' or m_key_m_state.get(key) != 'R':
            continue
        prio = m_key_priority.get(key)
        if prio is None:
            obj = cache_snapshot.cache.get(key)
            if obj is None:
                continue
            prio = m_age_M + _score_freq_size(key, obj.size)
            m_key_priority[key] = prio
        last = m_key_last_access.get(key, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_prio = prio
            min_time = last
            min_key = key

    return (min_key, min_prio, min_time)

def _ghost_add(ghost_dict, key, size, time_now, is_W):
    global m_ghost_W_bytes, m_ghost_M_bytes, m_ghost_limit_bytes
    if is_W:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_W_bytes += size
        else:
            old_size, _ = prev
            m_ghost_W_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        while m_ghost_W_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_W_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_M_bytes += size
        else:
            old_size, _ = prev
            m_ghost_M_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        while m_ghost_M_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_M_bytes -= sz

def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation of window target based on which ghost contains the new key
    global m_ghost_W, m_ghost_M, m_ghost_W_bytes, m_ghost_M_bytes, m_target_W_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step sized by object size; clamp to [1%, 15%] of capacity
    step = _clamp(obj.size, int(0.01 * cap), int(0.15 * cap))

    if obj.key in m_ghost_W:
        # More recency pressure -> increase window
        m_target_W_bytes = _clamp(m_target_W_bytes + step, 0, cap)
        sz, _ = m_ghost_W.pop(obj.key)
        m_ghost_W_bytes -= sz
    elif obj.key in m_ghost_M:
        # More frequency pressure -> decrease window
        m_target_W_bytes = _clamp(m_target_W_bytes - step, 0, cap)
        sz, _ = m_ghost_M.pop(obj.key)
        m_ghost_M_bytes -= sz

def _prefer_w_due_to_large_stream(cache_snapshot, obj):
    cap = cache_snapshot.capacity or 1
    large = obj.size >= int(cap * LARGE_OBJ_FRAC)
    if not large:
        return False
    # If it's not frequent and not seen in M-ghost, treat as likely stream
    if _cm_estimate(obj.key) < LARGE_OBJ_FREQ_CUTOFF and (obj.key not in m_ghost_M):
        return True
    return False

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim:
      - If W exceeds its adaptive target (bytes), evict LRU from W.
      - Else compute TinyLFU+size score for incoming and compare to weakest in M (GDSF):
          * If H_incoming <= threshold => evict from W (protect M)
          * Else evict from M (admit new object directly into M probation)
      - Within W: LRU. Within M: prefer probation; GDSF min priority; ties by LRU.
      - Large-object streaming guard biases toward evicting from W.
    Also sets m_admit_to_M_next to ensure update_after_insert assigns segment consistently.
    '''
    global m_bytes_W, m_admit_to_M_next, m_target_W_bytes

    _init_if_needed(cache_snapshot)
    m_admit_to_M_next = False  # default

    cap = cache_snapshot.capacity
    # Clamp window target to [5%, 80%] of capacity
    min_w = int(max(1, cap * 0.05))
    max_w = int(cap * 0.80)
    target_W = int(_clamp(int(m_target_W_bytes), min_w, max_w))

    # Candidates
    w_key, _ = _pick_oldest_in_segment(cache_snapshot, 'W')
    m_key, m_prio, _ = _pick_min_in_main(cache_snapshot)

    # Fallback if nothing known
    if w_key is None and m_key is None:
        # global LRU
        min_key, min_time = None, None
        for key in cache_snapshot.cache.keys():
            t = m_key_last_access.get(key, -1)
            if min_time is None or t < min_time:
                min_key, min_time = key, t
        return min_key if min_key is not None else next(iter(cache_snapshot.cache))

    # If window over target or large-object stream guard applies, evict from W
    if (m_bytes_W > target_W and w_key is not None) or _prefer_w_due_to_large_stream(cache_snapshot, obj):
        m_admit_to_M_next = False
        return w_key if w_key is not None else (m_key if m_key is not None else w_key)

    # If one segment empty, evict from the other
    if w_key is None and m_key is not None:
        m_admit_to_M_next = True  # we'll admit incoming to M to keep M size stable
        return m_key
    if m_key is None and w_key is not None:
        m_admit_to_M_next = False
        return w_key

    # Admission decision based on GDSF comparison
    incoming_score = _score_freq_size(obj.key, obj.size)
    H_incoming = m_age_M + incoming_score

    # Ghost-based bias
    bias = 0.0
    if obj.key in m_ghost_M:
        bias += ADMIT_BIAS_MGHOST
    if obj.key in m_ghost_W:
        bias -= ADMIT_BIAS_WGHOST
    threshold = m_prio * (1.0 - bias)

    if H_incoming > threshold:
        m_admit_to_M_next = True
        return m_key
    else:
        m_admit_to_M_next = False
        return w_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU.
      - Update last access time.
      - If in W: promote to M (probation) on first repeat (second touch).
      - If in M: refresh GDSF priority; if in probation, move to protected.
    '''
    global m_key_priority, m_key_last_access, m_key_segment, m_key_m_state
    global m_bytes_W, m_bytes_M

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Record access in TinyLFU
    _cm_increment(k, 1)
    # Update last access time
    m_key_last_access[k] = cache_snapshot.access_count

    seg = m_key_segment.get(k)
    if seg == 'W':
        # Count repeats since admission; promote on first repeat
        cnt = m_w_hits.get(k, 0) + 1
        m_w_hits[k] = cnt
        if cnt >= 1:
            # Promote to M probation
            m_key_segment[k] = 'M'
            m_key_m_state[k] = 'P'
            # Adjust bytes
            m_bytes_W = max(0, m_bytes_W - sz)
            m_bytes_M += sz
            # Initialize priority
            m_key_priority[k] = m_age_M + _score_freq_size(k, sz)
            # Clear window hit counter
            m_w_hits.pop(k, None)
        else:
            # remain in W; no priority tracked
            m_key_priority.pop(k, None)
    else:
        # Already in main: refresh priority
        m_key_priority[k] = m_age_M + _score_freq_size(k, sz)
        # If in probation, move to protected on hit
        if m_key_m_state.get(k) == 'P':
            m_key_m_state[k] = 'R'


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU.
      - Adapt W/M split using ghosts.
      - Assign to W or M consistently with evict()'s decision:
          * If m_admit_to_M_next True or key present in M-ghost: admit to M (probation).
          * Else admit to W.
      - Record last access time; initialize per-segment metadata.
    '''
    global m_key_priority, m_key_last_access, m_key_segment, m_key_m_state, m_w_hits
    global m_bytes_W, m_bytes_M, m_admit_to_M_next

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Record this access in TinyLFU
    _cm_increment(k, 1)

    # Adapt window target based on ghosts
    _adapt_targets_on_insert(cache_snapshot, obj)

    # Decide segment
    admit_to_M = m_admit_to_M_next or (k in m_ghost_M)

    if admit_to_M:
        # Admit directly to main (probation)
        m_key_segment[k] = 'M'
        m_key_m_state[k] = 'P'
        m_key_last_access[k] = cache_snapshot.access_count
        m_key_priority[k] = m_age_M + _score_freq_size(k, sz)
        m_bytes_M += sz
        m_w_hits.pop(k, None)
    else:
        # Admit to window
        m_key_segment[k] = 'W'
        m_key_m_state.pop(k, None)
        m_key_last_access[k] = cache_snapshot.access_count
        m_key_priority.pop(k, None)
        m_w_hits[k] = 0
        m_bytes_W += sz

    # Clear the signal; it's single-use
    m_admit_to_M_next = False


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - If victim was in M, set L_M to victim's H (GDSF aging).
      - Remove resident metadata for victim; update segment/state byte counters.
      - Add victim key to corresponding ghost list for adaptation.
    '''
    global m_key_priority, m_key_last_access, m_key_segment, m_key_m_state, m_w_hits
    global m_age_M, m_bytes_W, m_bytes_M
    global m_ghost_W, m_ghost_M

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'W')  # default to W if unknown

    if seg == 'M':
        evicted_prio = m_key_priority.get(ek)
        if evicted_prio is None:
            evicted_prio = m_age_M + _score_freq_size(ek, esz)
        # GreedyDual age update for main
        m_age_M = evicted_prio

    # Cleanup resident metadata
    m_key_priority.pop(ek, None)
    m_key_last_access.pop(ek, None)
    m_key_m_state.pop(ek, None)
    m_key_segment.pop(ek, None)
    m_w_hits.pop(ek, None)

    # Adjust bytes and add to ghosts
    if seg == 'M':
        m_bytes_M = max(0, m_bytes_M - esz)
        _ghost_add(m_ghost_M, ek, esz, cache_snapshot.access_count, is_W=False)
    else:
        m_bytes_W = max(0, m_bytes_W - esz)
        _ghost_add(m_ghost_W, ek, esz, cache_snapshot.access_count, is_W=True)
```
2025-11-27 20:07:43,519 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# W-TinyLFU + Segmented protection + Size-aware retention
# - Two logical segments:
#     1) probation (new/resurrected items)
#     2) protected (promoted on hit; byte-quota limited)
# - TinyLFU frequency counters with lazy epoch decay (8-bit saturating)
# - Size-aware retention: benefit = log1p(freq) / normalized_size
# - Recency bonus added (not subtracted) to protect recent items
# - Protected segment gets an extra bonus; demoted by LRU when over target bytes
# - Eviction uses lazy min-heaps (probation first, then protected) to avoid full scans
#   with lazy invalidation via per-key stamps; periodic score refresh on pop.
#
# This design:
#   - Dramatically reduces per-eviction cost (avoids O(n) scans) -> fewer timeouts
#   - Corrects recency sign (recent items are now protected, not penalized)
#   - Uses size-aware TinyLFU benefit and a protected segment to cut miss rate

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Cache identity (to reset between runs if needed)
m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting
m_prot_bytes = 0
m_prot_target_bytes = 0

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_probation = []           # retention score (lower => more evictable) for probation
h_protected = []           # retention score for protected (used when probation empty)
h_prot_lru = []            # last_access (min-heap) for protected demotions

# TinyLFU counters (lazy decay with epochs; per-key to keep it simple)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Protected segment target (bytes)
PROT_FRAC = 0.80           # target fraction of capacity for protected bytes

# Recency window and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 3           # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.60     # recency weight in probation
REC_WEIGHT_PROT = 0.40     # recency weight in protected
PROT_BONUS = 0.60          # extra benefit for protected segment
MULTI_HIT_BONUS = 0.30     # extra benefit for items with >=2 resident hits

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16  # bound reheap/refresh work per eviction

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC * cache_snapshot.capacity)

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Return size as percentage of capacity to keep scales stable
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _retention_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # treat missing as extremely good (will be filtered by validity)
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)

    seg = m_segment.get(key, 0)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    # Size-aware frequency benefit
    benefit = math.log1p(float(freq)) / size_norm

    # Multi-hit bias
    if m_resident_hits.get(key, 0) >= 2:
        benefit += MULTI_HIT_BONUS

    # Recency bonus
    if seg == 1:
        benefit += PROT_BONUS + REC_WEIGHT_PROT * rec_bonus
    else:
        benefit += REC_WEIGHT_PROB * rec_bonus

    return benefit


# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    # Compute score at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    score = _retention_score(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (score, s, key))
    else:
        heapq.heappush(h_protected, (score, s, key))
        # Also maintain LRU heap for protected demotions
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot, heap_ref, expected_seg):
    # Return a valid key from the given heap, refreshing stale scores when needed.
    # Limit work per call to avoid long stalls.
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        # Skip invalid/stale entries
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Opportunistically refresh score if it drifted
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            # Reinsert with a new stamp
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key
    return None


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        # Push into probation heap with updated score/stamp
        _push_key(cache_snapshot, key)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim:
      1) Pop the weakest from probation heap (lowest retention)
      2) If probation empty, pop the weakest from protected heap
      3) Fallback: any resident key
    '''
    _init_if_needed(cache_snapshot)

    # Prefer evicting from probation
    victim = _pop_best_candidate(cache_snapshot, h_probation, expected_seg=0)
    if victim is None:
        victim = _pop_best_candidate(cache_snapshot, h_protected, expected_seg=1)

    if victim is not None:
        return victim

    # Fallback: arbitrary key (should be rare)
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote probation -> protected on first resident hit
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with new score/recency
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote to protected
        m_segment[k] = 1
        # Account protected bytes
        global m_prot_bytes
        m_prot_bytes += obj.size
        # Push into protected heaps
        _push_key(cache_snapshot, k)
        # Enforce protected target
        _maybe_demote_protected(cache_snapshot)
    else:
        # Already protected: refresh heaps
        _push_key(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place into probation segment and push to heap
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation
    _push_key(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Adjust protected bytes if it was protected
    seg = m_segment.pop(ek, None)
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 9
- Hit Rate: 0.531

Example 2:
- Trace ID: 40
- Hit Rate: 0.0874

Example 3:
- Trace ID: 37
- Hit Rate: 0.6399

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:07:43 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:07:43,520 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:09:45 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:09:45,363 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:09:45,364 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive W-TinyLFU + Segmented protection + Size-aware, cross-segment victim selection
# - Two segments: probation (new/resurrected) and protected (promoted on hit)
# - TinyLFU with lazy epoch decay (8-bit saturating), retained across evictions
# - Size-aware retention: benefit = log1p(freq) / size_norm^SIZE_EXP
# - Recency bonus scaled down for large objects
# - Cross-segment eviction: choose the globally weakest item (probation vs protected)
# - Protected target bytes adaptively tuned based on where hits occur (probation vs protected)
# - Heaps with lazy invalidation via per-key stamps; protected LRU heap for demotion

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count (in-cache hits)
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting
m_prot_bytes = 0
m_prot_target_bytes = 0

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_probation = []           # (retention score, stamp, key)
h_protected = []           # (retention score, stamp, key)
h_prot_lru = []            # (last_access, stamp, key) for protected demotions (LRU)

# TinyLFU counters (lazy decay with epochs; per-key)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# Adaptation counters
m_hits_prob = 0
m_hits_prot = 0
m_last_adapt_access = 0

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096   # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Protected segment target (bytes), initial; will adapt between min/max
PROT_FRAC_INIT = 0.70
PROT_FRAC_MIN = 0.20
PROT_FRAC_MAX = 0.90
ADAPT_INTERVAL = 8192       # accesses between target adjustments
ADAPT_STEP_FRAC = 0.05      # +/- 5% of capacity
ADAPT_EPS = 0.05            # hysteresis: require 5% imbalance

# Size sensitivity
SIZE_EXP = 1.15             # exponent for size penalty in frequency benefit
REC_SIZE_EXP = 0.65         # exponent scaling for recency/protected bonuses
NON_CACHEABLE_FRAC = 0.50   # if obj.size > this * capacity and freq<2, strongly penalize
BIG_OBJ_PENALTY = 1.00      # subtract from benefit for very large, cold objects

# Recency window and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 3            # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.55      # recency weight in probation
REC_WEIGHT_PROT = 0.40      # recency weight in protected
PROT_BONUS = 0.50           # extra benefit for protected segment (scaled by size)
MULTI_HIT_BONUS = 0.25      # bonus if resident_hits >= 2 (scaled by size)

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16  # bound reheap/refresh work per eviction

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch
    global m_hits_prob, m_hits_prot, m_last_adapt_access

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC_INIT * cache_snapshot.capacity)

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0

    m_hits_prob = 0
    m_hits_prot = 0
    m_last_adapt_access = cache_snapshot.access_count


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Return size as percent-of-capacity to keep scales stable and >0
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _retention_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # treat missing as extremely good (caller will filter)
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)
    seg = m_segment.get(key, 0)

    # Base size-aware frequency benefit
    benefit = math.log1p(float(freq)) / (size_norm ** SIZE_EXP)

    # Multi-hit bias (scaled by size to avoid over-protecting big objs)
    if m_resident_hits.get(key, 0) >= 2:
        benefit += MULTI_HIT_BONUS / (size_norm ** REC_SIZE_EXP)

    # Recency bonus (scaled down for big objects)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)
    if seg == 1:
        benefit += (PROT_BONUS / (size_norm ** REC_SIZE_EXP)) + REC_WEIGHT_PROT * (rec_bonus / (size_norm ** REC_SIZE_EXP))
    else:
        benefit += REC_WEIGHT_PROB * (rec_bonus / (size_norm ** REC_SIZE_EXP))

    # Penalize very large, cold objects to reduce cache pollution
    if size > NON_CACHEABLE_FRAC * cap and freq < 2:
        benefit -= BIG_OBJ_PENALTY

    return benefit


# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    # Compute score at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    score = _retention_score(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (score, s, key))
    else:
        heapq.heappush(h_protected, (score, s, key))
        # Also maintain LRU heap for protected demotions
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_valid_entry(cache_snapshot, heap_ref, expected_seg):
    # Return a valid (score, key) from heap, refreshing stale scores when needed.
    # Limit work per call to avoid long stalls.
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Refresh score if it drifted; return refreshed value; caller will push back if needed
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            # We return refreshed score and let caller reinsert if not evicted
            return (new_score, key)
        return (score, key)
    return (None, None)


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        # Push into probation heap with updated score/stamp
        _push_key(cache_snapshot, key)


# -----------------------------
# Adaptation helpers
# -----------------------------

def _maybe_adapt_protected_target(cache_snapshot):
    global m_hits_prob, m_hits_prot, m_last_adapt_access, m_prot_target_bytes
    if cache_snapshot.access_count - m_last_adapt_access < ADAPT_INTERVAL:
        return
    total_hits = m_hits_prob + m_hits_prot
    if total_hits == 0:
        # Decay/inertia even without hits
        m_last_adapt_access = cache_snapshot.access_count
        m_hits_prob = 0
        m_hits_prot = 0
        return

    cap = cache_snapshot.capacity
    step = int(max(1, ADAPT_STEP_FRAC * cap))
    # Compare segments with hysteresis
    if m_hits_prot > (1.0 + ADAPT_EPS) * m_hits_prob:
        # Frequency dominates -> grow protected
        m_prot_target_bytes = min(int(PROT_FRAC_MAX * cap), m_prot_target_bytes + step)
    elif m_hits_prob > (1.0 + ADAPT_EPS) * m_hits_prot:
        # Recency dominates -> shrink protected to free space for probation
        m_prot_target_bytes = max(int(PROT_FRAC_MIN * cap), m_prot_target_bytes - step)

    # Reset window
    m_last_adapt_access = cache_snapshot.access_count
    m_hits_prob = 0
    m_hits_prot = 0


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim via cross-segment comparison:
      - Ensure protected not exceeding target via LRU demotion
      - Pop best candidate from each heap (probation and protected), compare scores
      - Evict the globally weaker one; reinsert the other
      - Fallback: any resident key
    '''
    _init_if_needed(cache_snapshot)

    # Keep protected within target
    _maybe_demote_protected(cache_snapshot)

    # Get one candidate from each segment
    prob_score, prob_key = _pop_valid_entry(cache_snapshot, h_probation, expected_seg=0)
    prot_score, prot_key = _pop_valid_entry(cache_snapshot, h_protected, expected_seg=1)

    victim = None
    keep_back_key = None

    if prob_key is not None and prot_key is not None:
        # Evict the globally weakest (lower score = less worth keeping)
        if prob_score <= prot_score:
            victim = prob_key
            keep_back_key = prot_key
        else:
            victim = prot_key
            keep_back_key = prob_key
    elif prob_key is not None:
        victim = prob_key
    elif prot_key is not None:
        victim = prot_key

    # Reinsert the non-victim candidate (with a fresh stamp/score)
    if keep_back_key is not None:
        _push_key(cache_snapshot, keep_back_key)

    if victim is not None:
        return victim

    # Fallback: arbitrary key (should be rare)
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote probation -> protected on first resident hit
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with new score/recency
      - Adapt protected target based on segment hit mix
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Count hit in probation for adaptation
        global m_hits_prob
        m_hits_prob += 1
        # Promote to protected on hit
        m_segment[k] = 1
        global m_prot_bytes
        m_prot_bytes += obj.size
        # Push into protected heaps with updated stamps/scores
        _push_key(cache_snapshot, k)
        # Enforce protected target
        _maybe_demote_protected(cache_snapshot)
    else:
        # Count hit in protected for adaptation
        global m_hits_prot
        m_hits_prot += 1
        # Already protected: refresh heaps (score and LRU)
        _push_key(cache_snapshot, k)

    # Periodically adapt protected target based on recent hit mix
    _maybe_adapt_protected_target(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling)
      - Initialize resident metadata
      - Place into probation segment and push to heap
      - Adapt target occasionally (misses count as accesses for timing)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    # Start at 0 resident hits; promote to protected only after first in-cache reuse
    m_resident_hits[k] = 0
    m_segment[k] = 0  # probation
    _push_key(cache_snapshot, k)

    # Occasional adaptation tick due to access-time progression
    _maybe_adapt_protected_target(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Adjust protected bytes if it was protected
    seg = m_segment.pop(ek, None)
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```
2025-11-27 20:10:54,379 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved: Count-based SLRU with TinyLFU, ARC-style adaptive split, and recency-aware scoring
# - Two resident segments by item count, not by bytes:
#     P (probation): admits all new objects; managed by LRU (via last_access timestamps)
#     S (protected): objects that hit at least once; also LRU-managed
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction score blends frequency and recency (recency matters beyond tie-break)
# - ARC-like ghost lists adapt the item split between P and S online (by counts)
#
# This design captures:
#   - Recency (via LRU timestamps and explicit recency in eviction score)
#   - Frequency (via TinyLFU)
#   - Adaptivity between recency-friendly and frequency-friendly behavior
#   - Correctness for caches limited by number of items (not bytes)

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU)
m_key_segment = dict()       # key -> 'P' or 'S'

# Current resident ITEM COUNTS per segment
m_cnt_P = 0
m_cnt_S = 0

# Adaptive target for protected items (S); probation target = capacity_items - target_S
m_target_S_items = None
m_cap_items_est = 0  # our estimate of capacity in number of items (learned at evict time)

# Ghost lists (non-resident metadata) to adapt split; store key -> last_time
m_ghost_P = dict()  # B1
m_ghost_S = dict()  # B2
m_ghost_limit_items = None

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)

# ---------------
# Scoring params
# ---------------
# Recency blend: score = est_freq + rec_weight * min(recency / half_life, rec_cap)
m_rec_half_life = 500.0  # accesses; tune to make recency effect comparable to est_freq
m_rec_cap = 10.0         # cap normalized recency contribution
m_rec_weight_P = 1.0     # probation recency weight
m_rec_weight_S = 0.6     # protected recency weight (S is more persistent)
m_protect_S_bias = 0.25  # additive bias to S candidates to modestly protect them
m_overweight_nudge = 0.2 # when a segment exceeds target, nudge its candidate to be more evictable

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_target_S_items, m_ghost_limit_items
    global m_sketch_tables, m_sketch_mask
    global m_cap_items_est

    # Learn capacity in items opportunistically; on evict() we'll update more accurately.
    if m_cap_items_est < len(cache_snapshot.cache):
        m_cap_items_est = len(cache_snapshot.cache)

    if m_target_S_items is None:
        # Start slightly frequency-friendly; adapt online
        base_items = max(1, len(cache_snapshot.cache))
        m_target_S_items = int(base_items * 0.6)

    if m_ghost_limit_items is None:
        # Each ghost list limited to approximately the cache capacity in items (we adjust later)
        m_ghost_limit_items = max(1, len(cache_snapshot.cache))

    if m_sketch_tables is None:
        # Width scales with estimated items; choose power of two near items*4 (empirical)
        # Minimum width to keep estimates reasonably stable.
        items = max(1, len(cache_snapshot.cache))
        width = 1
        target = max(1024, min(1 << 16, items * 4))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        # Halve all counters (right-shift by 1)
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _normalized_recency(now, last):
    if last is None or last < 0:
        return m_rec_cap
    age = max(0, now - last)
    norm = age / m_rec_half_life
    if norm > m_rec_cap:
        norm = m_rec_cap
    return norm


def _pick_min_score_in_segment(cache_snapshot, seg_tag, now):
    # Returns (key, score, last_time) that minimizes blended score within a segment
    # Score = est_freq + rec_weight * normalized_recency; tie-break by older first
    min_key = None
    min_score = None
    min_time = None

    rec_w = m_rec_weight_S if seg_tag == 'S' else m_rec_weight_P

    for key, obj in cache_snapshot.cache.items():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        est = float(_sketch_estimate(key))
        last = m_key_last_access.get(key, -1)
        rec = _normalized_recency(now, last)
        score = est + rec_w * rec
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = key
            min_score = score
            min_time = last

    return (min_key, min_score, min_time)


def _find_oldest_in_segment(cache_snapshot, seg_tag):
    oldest_key, oldest_time = None, None
    for k in cache_snapshot.cache.keys():
        if m_key_segment.get(k, 'P') != seg_tag:
            continue
        t = m_key_last_access.get(k, -1)
        if oldest_time is None or t < oldest_time:
            oldest_key, oldest_time = k, t
    return oldest_key


def _ghost_add(ghost_dict, key, time_now, which):
    # Add key->time to chosen ghost (which in {'P','S'}), trimming if exceeds limit
    global m_ghost_limit_items

    # Insert/update
    ghost_dict[key] = time_now

    # Trim to limit by evicting oldest
    limit = m_ghost_limit_items or 0
    if limit <= 0:
        return

    while len(ghost_dict) > limit:
        oldest_key, oldest_time = None, None
        for k, t in ghost_dict.items():
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        if oldest_key is None:
            break
        ghost_dict.pop(oldest_key, None)


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    # If key in P-ghost (B1): increase probation share (decrease S target)
    # If key in S-ghost (B2): increase protected share (increase S target)
    global m_target_S_items, m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Update our item-capacity estimate when cache is likely full (best signal: on evict call, but keep here too)
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)

    # Keep ghost size limits around capacity in items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est

    cap_items = max(1, m_cap_items_est)

    # Step size: 1 item per signal (conservative, stable)
    step = 1

    if obj.key in m_ghost_P:
        # Recent ghost hit: favor recency -> increase P share (decrease S)
        m_target_S_items = _clamp((m_target_S_items or 0) - step, 0, cap_items)
        m_ghost_P.pop(obj.key, None)
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: favor frequency -> increase S share
        m_target_S_items = _clamp((m_target_S_items or 0) + step, 0, cap_items)
        m_ghost_S.pop(obj.key, None)


def _maybe_demote_from_S_to_P(cache_snapshot):
    # If S exceeds its target, demote oldest S item to P
    global m_cnt_P, m_cnt_S, m_target_S_items
    if m_target_S_items is None:
        return
    if m_cnt_S > m_target_S_items:
        demote_key = _find_oldest_in_segment(cache_snapshot, 'S')
        if demote_key is not None:
            m_key_segment[demote_key] = 'P'
            m_cnt_S = max(0, m_cnt_S - 1)
            m_cnt_P += 1


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using count-based SLRU + TinyLFU with recency-aware scoring.
    - Compute candidate with minimal blended score in each segment:
        score = est_freq(key) + rec_weight * normalized_recency
    - Bias to evict from the segment exceeding its item-count target.
    - Protect S moderately by adding a small bias compared to P.
    '''
    global m_cnt_P, m_cnt_S, m_target_S_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Learn/refresh capacity in number of items at the moment of eviction (cache is full now)
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    cap_items = max(1, m_cap_items_est)
    if m_target_S_items is None:
        m_target_S_items = int(0.6 * cap_items)
    target_S = _clamp(m_target_S_items, 0, cap_items)
    target_P = cap_items - target_S

    now = cache_snapshot.access_count

    # Find min-score candidate in each segment
    p_key, p_score, p_lru = _pick_min_score_in_segment(cache_snapshot, 'P', now)
    s_key, s_score, s_lru = _pick_min_score_in_segment(cache_snapshot, 'S', now)

    # Prepare adjusted scores
    best_key = None
    best_adj = None

    if p_key is not None:
        adj_p = p_score
        # If P is overweight, make it slightly more likely to evict from P
        if m_cnt_P > target_P:
            adj_p -= m_overweight_nudge
        # No extra protection bias for P
        best_key = p_key
        best_adj = adj_p

    if s_key is not None:
        adj_s = s_score + m_protect_S_bias
        # If S is overweight, encourage eviction from S
        if m_cnt_S > target_S:
            adj_s -= m_overweight_nudge
        if (best_adj is None) or (adj_s < best_adj):
            best_adj = adj_s
            best_key = s_key

    # Fallback: if we somehow didn't find any key (shouldn't happen), pick oldest globally
    if best_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        best_key = oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - If in probation (P), promote to protected (S); if S exceeds target, demote oldest S to P
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    k = obj.key

    # Update TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    # Promote from P to S on hit
    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        m_key_segment[k] = 'S'
        m_cnt_P = max(0, m_cnt_P - 1)
        m_cnt_S += 1
        # If S above target, demote oldest S back to P
        _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S item split using ARC-like ghosts
      - Increment TinyLFU for the key (TinyLFU trains on both hits and misses)
      - Add the new object to probation (P)
      - Record last access time
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_cnt_P += 1

    # Keep S from drifting above target if previous operations changed target
    _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key
      - Update segment item counters
      - Add the key to the corresponding ghost list (count-limited) to guide future adaptation
      - Keep ghost sizes roughly equal to estimated cache capacity in items
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S
    global m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust item counts and add to appropriate ghost
    now = cache_snapshot.access_count
    if seg == 'S':
        m_cnt_S = max(0, m_cnt_S - 1)
        _ghost_add(m_ghost_S, ek, now, which='S')
    else:
        m_cnt_P = max(0, m_cnt_P - 1)
        _ghost_add(m_ghost_P, ek, now, which='P')

    # Update ghost limits to approximate current capacity in items
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 10
- Hit Rate: 0.1167

Example 2:
- Trace ID: 24
- Hit Rate: 0.3313

Example 3:
- Trace ID: 5
- Error: Error - Timeout

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:10:54 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:10:54,380 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:13:09 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:13:09,457 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:13:09,475 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Size-aware W-TinyLFU with GDSF-style main eviction and lazy heaps
# - Two resident segments by BYTES:
#     W (window/probation): all new items; evict by LRU when W exceeds its target bytes.
#     M (main/protected): items that hit at least once; evict by GreedyDual-Size-Frequency (GDSF).
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging.
# - GDSF in M: priority H = log1p(freq_est)/size + L, where L is a global inflation set to the
#   last evicted M-item's H. This blends recency with frequency and size awareness at O(log n).
# - ARC-style adaptive split between W and M by BYTES using ghost lists (non-resident keys).
# - Heaps (lazy) ensure O(log n) eviction decision instead of scanning all items.

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (monotonic)
m_key_segment = dict()       # key -> 'W' or 'M'
m_key_size = dict()          # key -> int size in bytes

# Segment byte usage
m_bytes_W = 0
m_bytes_M = 0

# Window target in BYTES (adaptive)
m_target_W_bytes = None

# Heaps (lazy):
#   W: min-heap of (last_access, uid, key)
#   M: min-heap of (priority, uid, key)
m_heap_W = []
m_heap_M = []
m_uid_counter = 0

# GDSF inflation for M
m_L_M = 0.0

# Ghost lists (non-resident) to adapt W/M split; key -> time
m_ghost_W = dict()  # B1: evicted from W
m_ghost_M = dict()  # B2: evicted from M
m_ghost_limit_keys = None     # max entries per ghost

# Count-Min Sketch (TinyLFU)
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0
m_sketch_age_interval = 50000
m_sketch_counter_cap = 255

# Params
m_beta_size = 1.0         # exponent for size penalty in M priority
m_default_W_fraction = 0.2  # initial window fraction by bytes
m_adapt_step_div = 64       # target W adjust step = capacity_bytes // this (>= 1)
m_eps = 1e-12               # numeric epsilon for lazy heap comparisons

# Capacity/item estimates for limits
m_cap_bytes = 0
m_cap_items_est = 0

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)

def _next_uid():
    global m_uid_counter
    m_uid_counter += 1
    return m_uid_counter

def _init_if_needed(cache_snapshot):
    global m_target_W_bytes, m_ghost_limit_keys
    global m_sketch_tables, m_sketch_mask
    global m_cap_bytes, m_cap_items_est

    cap_bytes = max(1, cache_snapshot.capacity)
    if cap_bytes != m_cap_bytes:
        m_cap_bytes = cap_bytes
        # Recompute default target only if not set yet
        if m_target_W_bytes is None:
            m_target_W_bytes = int(cap_bytes * m_default_W_fraction)

    # Keep an estimate of item capacity (by count) to size ghost lists
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)
    if m_ghost_limit_keys is None:
        m_ghost_limit_keys = max(64, m_cap_items_est)

    if m_sketch_tables is None:
        # Width scales with capacity (bytes) but ensure reasonable default
        width = 1
        target = 2048
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1

def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]

def _sketch_inc(key, delta=1):
    global m_sketch_ops
    if m_sketch_tables is None:
        return
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()

def _sketch_estimate(key):
    if m_sketch_tables is None:
        return 0
    idxs = _hash_indices(key)
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))

def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0

def _gdsf_priority_for_key(key):
    # Priority used in main segment M
    # H = log1p(freq_est) / size^beta + L_M
    est = float(_sketch_estimate(key))
    w = math.log1p(est)
    sz = float(max(1, m_key_size.get(key, 1)))
    denom = sz ** m_beta_size
    return (w / denom) + m_L_M

def _heapW_push(key):
    # Push current LRU entry for W
    t = m_key_last_access.get(key, -1)
    heapq.heappush(m_heap_W, (t, _next_uid(), key))

def _heapM_push(key):
    # Push current priority entry for M
    p = _gdsf_priority_for_key(key)
    heapq.heappush(m_heap_M, (p, _next_uid(), key))

def _heapW_pop_valid():
    # Pop until a valid W entry matches current last_access & residency
    while m_heap_W:
        t, _, k = heapq.heappop(m_heap_W)
        if m_key_segment.get(k) != 'W':
            continue
        # validate timestamp
        if t != m_key_last_access.get(k, None):
            # stale
            continue
        return k
    return None

def _heapM_pop_valid():
    # Pop until a valid M entry that is up-to-date w.r.t current priority
    while m_heap_M:
        p_old, _, k = heapq.heappop(m_heap_M)
        if m_key_segment.get(k) != 'M':
            continue
        p_cur = _gdsf_priority_for_key(k)
        # If the current priority increased (due to hits), the old entry is stale
        if p_cur > p_old + m_eps:
            # reinsert with updated priority; continue popping
            heapq.heappush(m_heap_M, (p_cur, _next_uid(), k))
            continue
        return k, p_old if p_old <= p_cur + m_eps else p_cur
    return None, None

def _ghost_add(ghost_dict, key, time_now, limit_keys):
    ghost_dict[key] = time_now
    # Trim to key-count limit by removing oldest
    if limit_keys is None or limit_keys <= 0:
        return
    while len(ghost_dict) > limit_keys:
        oldest_key, oldest_time = None, None
        for k, t in ghost_dict.items():
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        if oldest_key is None:
            break
        ghost_dict.pop(oldest_key, None)

def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style: if new key is in W-ghost => increase W target; if in M-ghost => decrease W target
    global m_target_W_bytes, m_ghost_W, m_ghost_M, m_ghost_limit_keys

    _init_if_needed(cache_snapshot)

    # Keep ghost limit roughly near cache size in items
    if m_ghost_limit_keys is None or m_ghost_limit_keys < m_cap_items_est:
        m_ghost_limit_keys = m_cap_items_est

    capB = max(1, cache_snapshot.capacity)
    step = max(1, capB // m_adapt_step_div)

    if obj.key in m_ghost_W:
        # Favor recency: expand window
        m_target_W_bytes = _clamp((m_target_W_bytes or 0) + step, 0, capB)
        m_ghost_W.pop(obj.key, None)
    elif obj.key in m_ghost_M:
        # Favor frequency: shrink window
        m_target_W_bytes = _clamp((m_target_W_bytes or 0) - step, 0, capB)
        m_ghost_M.pop(obj.key, None)

def _ensure_targets(cache_snapshot):
    global m_target_W_bytes
    _init_if_needed(cache_snapshot)
    capB = max(1, cache_snapshot.capacity)
    if m_target_W_bytes is None:
        m_target_W_bytes = int(capB * m_default_W_fraction)
    m_target_W_bytes = _clamp(m_target_W_bytes, 0, capB)

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim:
      - If W (window) exceeds its byte target, evict LRU from W.
      - Else prefer evicting from M (main) using GDSF priority (size-aware, freq-aware, recency via L).
      - If M empty, evict from W.
      - Update GDSF inflation L when evicting from M.
    '''
    global m_L_M, m_cap_items_est

    _ensure_targets(cache_snapshot)

    # Maintain item-capacity estimate at the moment of eviction
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items

    # Decide segment to evict from
    # Prefer W if it is overweight; otherwise prefer M
    victim_key = None
    from_seg = None
    evicted_priority = None

    if m_bytes_W > m_target_W_bytes:
        k = _heapW_pop_valid()
        if k is not None:
            victim_key = k
            from_seg = 'W'
        else:
            # fallback to M
            k, p = _heapM_pop_valid()
            if k is not None:
                victim_key, from_seg, evicted_priority = k, 'M', p
    else:
        k, p = _heapM_pop_valid()
        if k is not None:
            victim_key, from_seg, evicted_priority = k, 'M', p
        else:
            k2 = _heapW_pop_valid()
            if k2 is not None:
                victim_key = k2
                from_seg = 'W'

    # Absolute fallback: if heaps empty or inconsistent, evict the oldest by last_access
    if victim_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        victim_key = oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

        # Determine segment for correct L update (if applicable)
        from_seg = m_key_segment.get(victim_key, 'W')

    # Update GDSF inflation if evicting from M
    if from_seg == 'M':
        # If we computed evicted_priority, set L to it; else compute now
        if evicted_priority is None:
            evicted_priority = _gdsf_priority_for_key(victim_key)
        m_L_M = evicted_priority

    return victim_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time and update W-heap
      - If in W, promote to M and push to M-heap (update segment bytes)
      - If in M, recompute and push updated GDSF priority (lazy heap will ignore stale)
    '''
    global m_bytes_W, m_bytes_M

    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Train TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = now

    seg = m_key_segment.get(k, 'W')
    sz = m_key_size.get(k, obj.size)

    if seg == 'W':
        # Promote to M
        m_key_segment[k] = 'M'
        m_bytes_W = max(0, m_bytes_W - sz)
        m_bytes_M += sz
        # Update heaps
        _heapM_push(k)
    else:
        # Stay in M; boost priority
        _heapM_push(k)

    # Always keep W-heap timestamp updated for potential future demotion logic
    # (not demoting here, but maintain for consistency)
    _heapW_push(k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt W/M split based on ghosts
      - Increment TinyLFU for the key (TinyLFU trains on misses)
      - Add to window (W), record last access and size, push to W-heap
    '''
    global m_bytes_W

    _ensure_targets(cache_snapshot)

    # Adapt split
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    now = cache_snapshot.access_count

    # Train TinyLFU on the access
    _sketch_inc(k, 1)

    # Admit into W
    m_key_segment[k] = 'W'
    m_key_last_access[k] = now
    m_key_size[k] = int(obj.size)
    m_bytes_W += int(obj.size)

    _heapW_push(k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After victim is evicted:
      - Remove resident metadata and adjust segment bytes
      - Add to corresponding ghost (B1 for W, B2 for M)
      - Maintain ghost size limits
    '''
    global m_bytes_W, m_bytes_M, m_cap_items_est, m_ghost_limit_keys

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    sz = m_key_size.get(ek, evicted_obj.size)
    seg = m_key_segment.get(ek, 'W')  # default to W

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)
    m_key_size.pop(ek, None)

    # Adjust segment bytes
    if seg == 'M':
        m_bytes_M = max(0, m_bytes_M - sz)
        _ghost_add(m_ghost_M, ek, cache_snapshot.access_count, m_ghost_limit_keys)
    else:
        m_bytes_W = max(0, m_bytes_W - sz)
        _ghost_add(m_ghost_W, ek, cache_snapshot.access_count, m_ghost_limit_keys)

    # Update estimates for limits
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)
    if m_ghost_limit_keys is None or m_ghost_limit_keys < m_cap_items_est:
        m_ghost_limit_keys = m_cap_items_est
```
2025-11-27 20:18:00,287 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 28
- Hit Rate: 0.1767

Example 2:
- Trace ID: 41
- Hit Rate: 0.178

Example 3:
- Trace ID: 39
- Hit Rate: 0.1541

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:18:00 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:18:00,288 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:19:36 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:19:36,686 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:19:36,687 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Segmented Size-Aware TinyLFU (S2-TinyLFU)
# - Two resident segments (SLRU-style):
#     0) Probation: newly inserted items; eviction prefers here
#     1) Protected: items promoted on hit; eviction avoids here
# - Size-aware TinyLFU benefit: log2(1+freq) / (size/capacity)^SIZE_EXP
# - Segment-aware recency bonus:
#     Probation: strong recency protection
#     Protected: light recency protection (frequency dominates)
# - Lazy-decayed LFU counters (8-bit) via epochs (no sweeps)
# - Promotion/demotion to maintain protected budget (bytes/items)
# - Eviction scoring also includes a small "fit" pressure to prefer evicting
#   larger items when the incoming object is large (to reduce multi-evict chains)

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_seg = dict()             # key -> 0 (probation) or 1 (protected)

# Protected segment accounting (for quick budget checks)
m_prot_bytes = 0           # total bytes in protected
m_prot_items = 0           # total items in protected

# TinyLFU sketch (lazy-decayed 8-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0
LFU_BITS = 8
LFU_MAX = (1 << LFU_BITS) - 1  # 255
LFU_DECAY_INTERVAL = 16384     # accesses per epoch (power of two recommended)

# Tunables
# Segment budgets (bytes and items)
PROTECTED_FRAC_BYTES = 0.80  # target fraction of capacity for protected bytes
PROTECTED_FRAC_ITEMS = 0.80  # target fraction of resident items for protected

# Recency window
REC_WIN_MIN = 512
REC_WIN_MULT = 5

# Segment-specific recency weights
REC_WEIGHT_PROB = 0.80      # strong recency in probation
REC_WEIGHT_PROT = 0.20      # light recency in protected

# Size sensitivity exponent in benefit denominator
SIZE_EXP = 1.10

# Multi-hit frequency bonus (helps items that prove usefulness)
MULTI_HIT_BONUS = 0.60

# "Fit" pressure weight: prefer evicting larger items when large space needed
FIT_WEIGHT = 0.12


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)


def _normalized_size_ratio(size, capacity):
    # ratio in (0, 1]
    return max(1e-12, float(size) / float(capacity))


def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _protected_targets(cache_snapshot):
    # Compute target budgets for protected segment
    targ_bytes = int(PROTECTED_FRAC_BYTES * cache_snapshot.capacity)
    targ_items = max(1, int(PROTECTED_FRAC_ITEMS * max(1, len(cache_snapshot.cache))))
    return targ_bytes, targ_items


def _protected_counts_adjust(delta_bytes, delta_items):
    global m_prot_bytes, m_prot_items
    m_prot_bytes = max(0, m_prot_bytes + int(delta_bytes))
    m_prot_items = max(0, m_prot_items + int(delta_items))


def _find_lru_in_segment(cache_snapshot, seg_val):
    # Returns (key, last_access) of the LRU item in the given segment, or (None, None)
    lru_key = None
    lru_ts = None
    for k in cache_snapshot.cache.keys():
        if m_seg.get(k, 0) != seg_val:
            continue
        ts = m_last_access.get(k, -1)
        if lru_key is None or ts < lru_ts:
            lru_key = k
            lru_ts = ts
    return lru_key, lru_ts


def _enforce_protected_budget(cache_snapshot):
    # Demote LRU items from protected to probation until within budget
    targ_bytes, targ_items = _protected_targets(cache_snapshot)
    while (m_prot_bytes > targ_bytes) or (m_prot_items > targ_items):
        victim_key, _ = _find_lru_in_segment(cache_snapshot, 1)
        if victim_key is None:
            break
        robj = cache_snapshot.cache.get(victim_key)
        if robj is None:
            # stale; just demote metadata
            size = 0
        else:
            size = robj.size
        # Demote
        if m_seg.get(victim_key, 0) == 1:
            m_seg[victim_key] = 0
            _protected_counts_adjust(-size, -1)


def _retention_score(cache_snapshot, key, incoming_obj, seg_val):
    # Compute eviction score for a resident key: lower -> more evictable
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen

    size = robj.size
    size_ratio = _normalized_size_ratio(size, cap)

    # TinyLFU frequency with multi-hit bonus
    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + float(freq)) + extra) / (size_ratio ** SIZE_EXP)

    # Recency protection: stronger in probation, weaker in protected
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    rec_w = REC_WEIGHT_PROB if seg_val == 0 else REC_WEIGHT_PROT
    recency_gain = rec_w * (1.0 - a_norm)

    # Fit pressure: when a large incoming object arrives, prefer larger evictions
    need = max(0, cache_snapshot.size + incoming_obj.size - cache_snapshot.capacity)
    if need > 0:
        fit_pressure = FIT_WEIGHT * min(1.0, float(size) / float(need))
    else:
        fit_pressure = 0.0

    # Lower score -> weaker retention -> better eviction candidate
    return benefit - recency_gain - fit_pressure


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict from probation first (segment 0) using size-aware TinyLFU + recency.
    If probation is empty, evict from protected (segment 1) using the same score
    but with lighter recency weight.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    # Partition keys by segment
    probation_keys = []
    protected_keys = []
    for k in cache_snapshot.cache.keys():
        if m_seg.get(k, 0) == 1:
            protected_keys.append(k)
        else:
            probation_keys.append(k)

    # Prefer evicting from probation
    candidate_sets = [probation_keys, protected_keys]

    min_key = None
    min_score = None
    min_time = None

    for idx, keys in enumerate(candidate_sets):
        if not keys:
            continue
        seg_val = 0 if idx == 0 else 1
        for k in keys:
            score = _retention_score(cache_snapshot, k, obj, seg_val)
            last = m_last_access.get(k, -1)
            if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
        # If we found a candidate in probation, stop (don't look at protected)
        if idx == 0 and min_key is not None:
            break

    # Fallback: arbitrary key if none found
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Increment resident hit count
      - Refresh last-access time
      - Promote to protected if in probation
      - Enforce protected budget by demoting protected LRU if needed
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    if m_seg.get(k, 0) == 0:
        # Promote to protected
        m_seg[k] = 1
        _protected_counts_adjust(obj.size, +1)
        _enforce_protected_budget(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place into probation segment
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    # Newly inserted -> probation
    if m_seg.get(k, 0) == 1:
        # If somehow marked protected from an earlier residency, reset to probation
        # and adjust protected accounting.
        m_seg[k] = 0
        _protected_counts_adjust(-obj.size, -1)
    else:
        m_seg[k] = 0


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters to remember popularity across evictions
      - Update protected accounting if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    if m_seg.get(ek, 0) == 1:
        _protected_counts_adjust(-evicted_obj.size, -1)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_seg.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```
2025-11-27 20:19:53,019 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved policy: Heap-Accelerated TinyLFU with Size and Recency (HALO-TFS)
# - Fast eviction via a lazy min-heap of retention scores (no full scans)
# - TinyLFU with lazy epoch decay (per-key small counters remembered across evictions)
# - Size-aware, recency-aware scoring with multi-hit boost
# - Robust to workload shifts; avoids timeouts via O(log n) victim selection and periodic heap rebuilds

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_resident_hits = dict()    # key -> int resident hit count (>=1 once inserted)

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096   # accesses per epoch (power of two recommended)
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192  # how often to check if heap needs rebuilding
HEAP_GROWTH_FACTOR = 4       # if heap > factor * resident_count, rebuild

# Tunables for scoring
SIZE_ALPHA = 0.75           # size normalization exponent; smaller favors small objects
REC_WIN_MIN = 64            # minimum recency window
REC_WIN_MULT = 8            # recency window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.75           # strength of recency term added to frequency
MULTI_HIT_BONUS = 0.50      # multiplicative boost for items with >=2 hits while resident


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # no sweeping; decay handled lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring
# -----------------------------

def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency component
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    r_term = _recency_term(now, m_last_access.get(key), window)

    # Multi-hit boost (stronger protection after the second hit)
    mh = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    mult = 1.0 + mh

    # Final score: combine frequency and recency, then size-normalize
    score = ((f_term + REC_WEIGHT * r_term) * mult) / size_norm
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    # Rebuild heap from current residents with fresh scores/versions
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    Lazy invalidation ensures correctness despite changing scores/epochs.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., unusual bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            if k not in m_ver:
                # Initialize resident metadata if missing (best effort)
                m_last_access.setdefault(k, cache_snapshot.access_count)
                m_resident_hits.setdefault(k, 1)
            _heap_push(cache_snapshot, k)

    # Candidate's "would-be" score (informal comparison; does not affect required eviction)
    # This is used only to help prefer weaker residents when ties occur.
    cand_freq = _lfu_peek(cache_snapshot, obj.key) + 1  # will be incremented on insert
    cand_f_term = math.log1p(float(cand_freq))
    cand_size_norm = max(1.0, float(obj.size)) ** SIZE_ALPHA
    cand_score = (cand_f_term + REC_WEIGHT * 1.0) / cand_size_norm  # recency ~1 on insert

    # Pop until we find a valid, up-to-date victim
    while m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            continue
        # Skip if stale entry
        if m_ver.get(k, 0) != v:
            continue
        # Recompute current score to account for epoch/window changes
        new_sc = _score_key(cache_snapshot, k)
        # If the score drifted upward (got better), reinsert with new score
        if new_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            continue
        # Optional tie-breaker with candidate: if resident clearly stronger than candidate,
        # try to find a weaker one by peeking more; but if none, return this one.
        if new_sc >= cand_score:
            # Keep searching a bit for something weaker; cap extra attempts to avoid overhead
            attempts = 0
            tmp = [(sc, last, k, v)]
            victim = None
            while attempts < 8 and m_heap:
                sc2, last2, k2, v2 = heapq.heappop(m_heap)
                if k2 not in cache_snapshot.cache or m_ver.get(k2, 0) != v2:
                    attempts += 1
                    continue
                cur_sc2 = _score_key(cache_snapshot, k2)
                if cur_sc2 > sc2 + 1e-12:
                    _heap_push(cache_snapshot, k2)
                    attempts += 1
                    continue
                if cur_sc2 < cand_score or cur_sc2 < new_sc:
                    victim = (cur_sc2, last2, k2, v2)
                    break
                tmp.append((sc2, last2, k2, v2))
                attempts += 1
            # Push back any entries we popped but didn't choose
            for ent in tmp:
                heapq.heappush(m_heap, ent)
            if victim is not None:
                return victim[2]
            # Fall back to the original k
        return k

    # Fallback: choose the oldest resident if heap is somehow empty
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch and increment counter for requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember its popularity)
      - Invalidate its heap version (lazy: stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_ver.pop(ek, None)
    _touch_and_maybe_rebuild(cache_snapshot)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 13
- Hit Rate: 0.0

Example 2:
- Trace ID: 34
- Hit Rate: 0.0833

Example 3:
- Trace ID: 21
- Hit Rate: 0.0264

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:19:53 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:19:53,020 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:22:10 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:22:10,900 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:22:10,901 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# ARC-TLFU: Adaptive Replacement Cache with TinyLFU guidance (item-based)
# - Two resident segments (probation and protected) managed via ARC-style target sizing
# - Two ghost lists to adapt the protected size target based on re-references
# - TinyLFU with lazy epoch decay to remember popularity across evictions
# - O(1) updates via OrderedDicts; no full scans or heavy heaps
#
# Notes:
# - This policy treats capacity as number of items (count-based), aligning with the task context.
# - Object sizes are ignored for decisions (robust when capacity is item-count). If your runtime is
#   byte-capacity, this still performs reasonably since ARC primarily optimizes recency/frequency.

from collections import OrderedDict

# -----------------------------
# Global metadata
# -----------------------------

# Resident segments
_prob = OrderedDict()   # probationary segment (newly inserted, LRU -> MRU via order)
_prot = OrderedDict()   # protected segment (promoted on first hit)

# Ghost lists (non-resident history)
_ghost1 = OrderedDict()  # keys evicted from probation
_ghost2 = OrderedDict()  # keys evicted from protected

# Location map: key -> 'prob' or 'prot' (only for current residents we know about)
_loc = {}

# Adaptive target size for protected segment (#items)
_target_prot = 0.0

# Track from which segment an eviction happened (to place into the right ghost)
_evicted_from = {}  # key -> 'prob' or 'prot'

# TinyLFU counters with lazy epoch decay
_lfu = {}                 # key -> (count:int[0..LFU_MAX], epoch:int)
_lfu_epoch = 0
LFU_DECAY_INTERVAL = 2048  # accesses per epoch; power of two recommended
LFU_MAX = 15               # 4-bit saturating counter


# -----------------------------
# Helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global _lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != _lfu_epoch:
        _lfu_epoch = cur  # decay applied lazily per key on access


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = _lfu.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = _lfu.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    _lfu[key] = (c, cur_epoch)
    return c


def _ensure_known(cache_snapshot):
    """
    Ensure all current residents appear in our metadata. Unknown keys are added to probation (MRU).
    This handles bootstrap and any out-of-band changes by the harness.
    """
    for k in cache_snapshot.cache.keys():
        if k not in _loc:
            _prob[k] = None
            _loc[k] = 'prob'


def _trim_ghosts(max_ghost):
    """
    Bound the size of ghost lists to avoid unbounded growth. Trim oldest entries.
    max_ghost is the per-ghost cap (each ghost list trimmed to this size).
    """
    while len(_ghost1) > max_ghost:
        _ghost1.popitem(last=False)
    while len(_ghost2) > max_ghost:
        _ghost2.popitem(last=False)


def _clamp_target(target, C):
    # Clamp target protected size between 0 and C (exclusive upper bound safe as int)
    if C <= 0:
        return 0.0
    return max(0.0, min(float(C), float(target)))


def _promote_to_protected(key):
    """Move key from probation to protected MRU."""
    if key in _prob:
        _prob.pop(key, None)
    _prot.pop(key, None)  # idempotent
    _prot[key] = None
    _loc[key] = 'prot'


def _move_to_probation_mru(key):
    """Place or move key into probation MRU."""
    _prot.pop(key, None)
    _prob.pop(key, None)
    _prob[key] = None
    _loc[key] = 'prob'


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose a victim using ARC's replacement: prefer evicting from probation unless it is
    smaller than the adaptive protected target, in which case evict from protected.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)
    _ensure_known(cache_snapshot)

    # If for some reason our structures are empty, fall back to evicting the oldest arbitrary key
    if not _prob and not _prot:
        for k in cache_snapshot.cache.keys():
            _evicted_from[k] = 'prob'
            return k
        return None  # Should not happen

    # Determine sizes and target
    C = max(1, len(cache_snapshot.cache))  # count-based capacity proxy
    tp = int(round(_clamp_target(_target_prot, C)))

    # Pick segment to evict from (ARC replacement policy)
    victim_seg = None
    if len(_prob) == 0 and len(_prot) == 0:
        # nothing tracked; emergency fallback
        for k in cache_snapshot.cache.keys():
            _evicted_from[k] = 'prob'
            return k
    elif len(_prob) > tp or len(_prot) == 0:
        victim_seg = 'prob'
    else:
        victim_seg = 'prot'

    # Select LRU from chosen segment
    if victim_seg == 'prob' and _prob:
        victim_key = next(iter(_prob))
    elif victim_seg == 'prot' and _prot:
        victim_key = next(iter(_prot))
    else:
        # Fallback to the other if chosen is empty
        if _prob:
            victim_seg = 'prob'
            victim_key = next(iter(_prob))
        else:
            victim_seg = 'prot'
            victim_key = next(iter(_prot))

    _evicted_from[victim_key] = victim_seg
    return victim_key


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter (with lazy decay)
      - If in probation, promote to protected MRU
      - If in protected, refresh MRU position
      - If unseen in our metadata (bootstrap), place into protected (it's hot)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)
    k = obj.key
    _lfu_inc(cache_snapshot, k)

    # Ensure resident known
    if k not in _loc:
        # Unknown resident; consider it hot on hit
        _promote_to_protected(k)
        return

    where = _loc.get(k)
    if where == 'prob':
        _promote_to_protected(k)
    else:
        # Refresh MRU in protected
        if k in _prot:
            _prot.move_to_end(k, last=True)
        else:
            # Inconsistent; add to protected
            _promote_to_protected(k)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Increment TinyLFU counter
      - If key is in a ghost list, adapt target protected size (ARC adaptation)
        and place into protected MRU.
      - Otherwise, place into probation MRU.
      - Optionally demote from protected to probation if protected exceeds target.
      - Trim ghost lists periodically.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)
    k = obj.key
    _lfu_inc(cache_snapshot, k)

    C = max(1, len(cache_snapshot.cache))
    global _target_prot

    in_b1 = k in _ghost1
    in_b2 = k in _ghost2

    if in_b1 or in_b2:
        # ARC adaptation: adjust target based on which ghost was hit
        b1 = len(_ghost1)
        b2 = len(_ghost2)
        if in_b1:
            delta = max(1, b2 // max(1, b1))
            _target_prot = _clamp_target(_target_prot + delta, C)
            _ghost1.pop(k, None)
        if in_b2:
            delta = max(1, b1 // max(1, b2))
            _target_prot = _clamp_target(_target_prot - delta, C)
            _ghost2.pop(k, None)
        # Place into protected on re-reference
        _promote_to_protected(k)
    else:
        # First time seen recently: probation MRU
        _move_to_probation_mru(k)

    # Keep protected roughly at target by demoting its LRU(s) to probation if it grows too large
    tp = int(round(_clamp_target(_target_prot, C)))
    while len(_prot) > tp and len(_prot) > 0:
        demote_key, _ = _prot.popitem(last=False)  # LRU of protected
        _move_to_probation_mru(demote_key)

    # Trim ghosts to bounded size
    _trim_ghosts(max_ghost=2 * C)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After eviction:
      - Remove from resident structures
      - Place into the appropriate ghost list (B1 if from probation, B2 if from protected)
      - Keep ghost sizes bounded
      - Keep TinyLFU counts (do not clear) to remember popularity
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    where = _evicted_from.pop(ek, _loc.get(ek, 'prob'))

    # Remove from resident structures
    if where == 'prot':
        _prot.pop(ek, None)
    else:
        _prob.pop(ek, None)
    _loc.pop(ek, None)

    # Add to corresponding ghost
    if where == 'prot':
        _ghost2.pop(ek, None)
        _ghost2[ek] = None  # MRU
    else:
        _ghost1.pop(ek, None)
        _ghost1[ek] = None  # MRU

    # Trim ghosts
    C = max(1, len(cache_snapshot.cache))
    _trim_ghosts(max_ghost=2 * C)
```
2025-11-27 20:22:31,810 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved policy: Heap-Accelerated TinyLFU with Size and Recency (HALO-TFS)
# - Fast eviction via a lazy min-heap of retention scores (no full scans)
# - TinyLFU with lazy epoch decay (per-key small counters remembered across evictions)
# - Size-aware, recency-aware scoring with multi-hit boost
# - Robust to workload shifts; avoids timeouts via O(log n) victim selection and periodic heap rebuilds

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_resident_hits = dict()    # key -> int resident hit count (>=1 once inserted)

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096   # accesses per epoch (power of two recommended)
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192  # how often to check if heap needs rebuilding
HEAP_GROWTH_FACTOR = 4       # if heap > factor * resident_count, rebuild

# Tunables for scoring
SIZE_ALPHA = 0.75           # size normalization exponent; smaller favors small objects
REC_WIN_MIN = 64            # minimum recency window
REC_WIN_MULT = 8            # recency window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.75           # strength of recency term added to frequency
MULTI_HIT_BONUS = 0.50      # multiplicative boost for items with >=2 hits while resident


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # no sweeping; decay handled lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring
# -----------------------------

def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency component
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    r_term = _recency_term(now, m_last_access.get(key), window)

    # Multi-hit boost (stronger protection after the second hit)
    mh = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    mult = 1.0 + mh

    # Final score: combine frequency and recency, then size-normalize
    score = ((f_term + REC_WEIGHT * r_term) * mult) / size_norm
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    # Rebuild heap from current residents with fresh scores/versions
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    Lazy invalidation ensures correctness despite changing scores/epochs.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., unusual bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            if k not in m_ver:
                # Initialize resident metadata if missing (best effort)
                m_last_access.setdefault(k, cache_snapshot.access_count)
                m_resident_hits.setdefault(k, 1)
            _heap_push(cache_snapshot, k)

    # Candidate's "would-be" score (informal comparison; does not affect required eviction)
    # This is used only to help prefer weaker residents when ties occur.
    cand_freq = _lfu_peek(cache_snapshot, obj.key) + 1  # will be incremented on insert
    cand_f_term = math.log1p(float(cand_freq))
    cand_size_norm = max(1.0, float(obj.size)) ** SIZE_ALPHA
    cand_score = (cand_f_term + REC_WEIGHT * 1.0) / cand_size_norm  # recency ~1 on insert

    # Pop until we find a valid, up-to-date victim
    while m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            continue
        # Skip if stale entry
        if m_ver.get(k, 0) != v:
            continue
        # Recompute current score to account for epoch/window changes
        new_sc = _score_key(cache_snapshot, k)
        # If the score drifted upward (got better), reinsert with new score
        if new_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            continue
        # Optional tie-breaker with candidate: if resident clearly stronger than candidate,
        # try to find a weaker one by peeking more; but if none, return this one.
        if new_sc >= cand_score:
            # Keep searching a bit for something weaker; cap extra attempts to avoid overhead
            attempts = 0
            tmp = [(sc, last, k, v)]
            victim = None
            while attempts < 8 and m_heap:
                sc2, last2, k2, v2 = heapq.heappop(m_heap)
                if k2 not in cache_snapshot.cache or m_ver.get(k2, 0) != v2:
                    attempts += 1
                    continue
                cur_sc2 = _score_key(cache_snapshot, k2)
                if cur_sc2 > sc2 + 1e-12:
                    _heap_push(cache_snapshot, k2)
                    attempts += 1
                    continue
                if cur_sc2 < cand_score or cur_sc2 < new_sc:
                    victim = (cur_sc2, last2, k2, v2)
                    break
                tmp.append((sc2, last2, k2, v2))
                attempts += 1
            # Push back any entries we popped but didn't choose
            for ent in tmp:
                heapq.heappush(m_heap, ent)
            if victim is not None:
                return victim[2]
            # Fall back to the original k
        return k

    # Fallback: choose the oldest resident if heap is somehow empty
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch and increment counter for requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember its popularity)
      - Invalidate its heap version (lazy: stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_ver.pop(ek, None)
    _touch_and_maybe_rebuild(cache_snapshot)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 42
- Hit Rate: 0.0526

Example 2:
- Trace ID: 7
- Hit Rate: 0.4713

Example 3:
- Trace ID: 18
- Hit Rate: 0.0228

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:22:31 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:22:31,811 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:24:54 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:24:54,050 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:24:54,052 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Policy: HALO-TFSv2 — Heap-Accelerated LFU with Recency, Freshness, and Gap Prediction
# Key improvements over previous version:
# - Stronger recency sensitivity with adaptive windowing
# - Do not credit LFU on cold insert (reduces one-timer pollution)
# - Per-key EWMA of inter-arrival gaps to predict time-to-next access
# - Fresh-insert "grace" multiplier to avoid immediate churn
# - Multi-hit protection is stronger and starts after the second hit
# - Bounded-rescan victim search for better choices without full scans

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_birth_ts = dict()         # key -> int access_count at insertion
m_resident_hits = dict()    # key -> int resident hit count (starts at 0 on insert)
m_gap_ewma = dict()         # key -> float ≈ EWMA of inter-arrival gap while resident

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 2048   # faster adaptation to workload shifts
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192
HEAP_GROWTH_FACTOR = 4

# Tunables for scoring
SIZE_ALPHA = 0.80               # size normalization exponent; favors small objects
REC_WIN_MIN = 64                # minimum recency window in accesses
REC_WIN_MULT = 6                # recency window ~ REC_WIN_MULT * resident_items
FREQ_WEIGHT = 1.00              # weight of frequency (TinyLFU)
REC_WEIGHT = 1.10               # weight of observed recency
PRED_WEIGHT = 0.90              # weight of predicted return risk (via gap EWMA)
MH_MULT = 1.50                  # multiplicative boost after >=2 resident hits
FRESH_GRACE = 128               # accesses; grace period after insert
FRESH_MULT = 1.30               # multiplicative boost during grace
GAP_BETA = 0.30                 # EWMA smoothing factor for inter-arrival gap

# Victim selection
RESCAN_LIMIT = 12               # bounded extra pops from heap to improve victim choice


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # decay is applied lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)


def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _predicted_risk(now, last, gap_ewma, window):
    # Predict time-to-next using EWMA gap. Convert to risk in (0,1].
    if last is None or last < 0 or gap_ewma is None or gap_ewma <= 0.0:
        return 0.0
    age = max(0, now - last)
    ttn = gap_ewma - age  # time until next (can be <= 0 if due/overdue)
    # Map to (0,1], ≈1 when due/overdue, smaller when far in future
    return 1.0 / (1.0 + (max(0.0, ttn) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency and predicted risk
    window = _recency_window(cache_snapshot)
    r_term = _recency_term(now, m_last_access.get(key), window)
    p_term = _predicted_risk(now, m_last_access.get(key), m_gap_ewma.get(key), window)

    # Freshness and multi-hit multipliers
    birth = m_birth_ts.get(key)
    fresh = (1.0 if birth is None else (FRESH_MULT if (now - birth) <= FRESH_GRACE else 1.0))
    mhits = m_resident_hits.get(key, 0)
    mh_mult = (MH_MULT if mhits >= 2 else 1.0)

    # Final score: combine, then size-normalize, then apply multiplicative boosts
    base = (FREQ_WEIGHT * f_term) + (REC_WEIGHT * r_term) + (PRED_WEIGHT * p_term)
    score = (base / size_norm) * fresh * mh_mult
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    - Seed heap on first use
    - Pop and validate entries lazily (versioning)
    - Recompute scores to reflect latest epochs and metadata
    - Bounded rescan: consider a small set of candidates and pick the weakest
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            # Initialize missing resident metadata best-effort
            m_last_access.setdefault(k, cache_snapshot.access_count)
            m_birth_ts.setdefault(k, cache_snapshot.access_count)
            m_resident_hits.setdefault(k, 0)
            m_gap_ewma.setdefault(k, float(_recency_window(cache_snapshot)))
            _heap_push(cache_snapshot, k)

    # Bounded rescan to find the weakest valid candidate
    best_key = None
    best_tuple = None  # (adjusted_score, score_tuple)
    considered = []

    attempts = 0
    while attempts < RESCAN_LIMIT and m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            attempts += 1
            continue
        # Skip if stale heap entry
        if m_ver.get(k, 0) != v:
            attempts += 1
            continue
        # Recompute current score (reflect decay/window/metadata changes)
        cur_sc = _score_key(cache_snapshot, k)
        # If score drifted upward, reinsert with new score
        if cur_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            attempts += 1
            continue

        # Track the weakest (lowest score) candidate
        adj_sc = cur_sc  # adjustment slots available if needed later
        if (best_tuple is None) or (adj_sc < best_tuple[0]):
            best_key = k
            best_tuple = (adj_sc, (sc, last, k, v))
        considered.append((sc, last, k, v))
        attempts += 1

    # Push back all considered entries except the chosen victim
    for tup in considered:
        if best_tuple is not None and tup[2] == best_key:
            continue
        heapq.heappush(m_heap, tup)

    # Fallbacks
    if best_key is not None:
        return best_key

    # If heap is exhausted or empty, choose the oldest resident
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Update EWMA of inter-arrival gap
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Update frequency only on hits (not on cold insert)
    _lfu_inc(cache_snapshot, k)

    # Update inter-arrival EWMA
    prev = m_last_access.get(k)
    if prev is not None:
        gap = max(1.0, float(now - prev))
        old = m_gap_ewma.get(k)
        if old is None or old <= 0.0:
            m_gap_ewma[k] = gap
        else:
            m_gap_ewma[k] = (1.0 - GAP_BETA) * old + GAP_BETA * gap
    else:
        # Initialize conservatively
        m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    # Hits: increment resident hits
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # Refresh timestamps
    m_last_access[k] = now

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch
      - Do NOT increment LFU on cold insert (reduces one-timer pollution)
      - Initialize resident metadata: last_access, birth_ts, resident_hits = 0
      - Initialize EWMA gap conservatively to recency window
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # No _lfu_inc here: cold items must earn credit by hitting

    m_last_access[k] = now
    m_birth_ts[k] = now
    m_resident_hits[k] = 0
    m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember popularity)
      - Invalidate its heap version (stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_birth_ts.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_gap_ewma.pop(ek, None)
    m_ver.pop(ek, None)

    _touch_and_maybe_rebuild(cache_snapshot)
```
2025-11-27 20:27:51,849 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 35
- Hit Rate: 0.1562

Example 2:
- Trace ID: 19
- Hit Rate: 0.2722

Example 3:
- Trace ID: 6
- Hit Rate: 0.2775

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:27:51 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:27:51,850 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:30:35 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:30:35,755 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:30:35,756 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive Size-Aware W-TinyLFU with SLRU and GreedyDual aging (ASW-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon sufficient resident hits (size-aware threshold)
# - Adaptive protected target (bytes) using ARC-like feedback:
#     * probation hits increase protected target (favor recency)
#     * protected hits decrease target (favor frequency)
# - Eviction prefers probation; protected is shielded by target. Demote oldest
#   protected until within target when needed.
# - Within a segment, the victim minimizes a composite "retention score" that
#   combines:
#     * TinyLFU frequency (lazy-decayed counters)
#     * GreedyDual aging credit (global L with per-key H)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (strong in probation, weak in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * multi-hit bonus (for residents with >=2 hits)
# - Metadata is updated on hit/insert/evict, including adaptive target changes,
#   promotions/demotions, and GreedyDual L/H updates.

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0

# GreedyDual aging
m_gds_H = dict()           # key -> float priority H
g_gds_L = 0.0              # float global aging value

# Segmented SLRU capacity targeting (by bytes)
g_protected_bytes = 0                    # running total of bytes in protected
g_target_protected_bytes = None          # adaptive target in bytes (initialized lazily)
g_last_capacity = None                   # track capacity to re-init target if needed

# -----------------------------
# Tunables
# -----------------------------

# TinyLFU decay
LFU_DECAY_INTERVAL = 4096  # access-counts between epochs (power of two recommended)

# Size-awareness and bonuses
SIZE_ALPHA = 1.20          # >1 penalizes very large objects more
MULTI_HIT_BONUS = 0.50     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 2           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.55
W_REC_PROT = 0.12
W_PRED_PROB = 0.20
W_PRED_PROT = 0.10

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.50        # higher -> react faster to changing reuse intervals

# Protected-target adaptation (ARC-like)
PROTECTED_INIT_FRAC = 0.80
TARGET_BASE_DIV = 256      # base step ~ capacity / TARGET_BASE_DIV
TARGET_MAX_FRAC = 0.20     # cap step to this fraction of capacity
TARGET_SIZE_WEIGHT = 0.50  # step includes 50% of item size

# Promotion policy (size-aware)
def _promotion_hits_needed(size, capacity):
    s_norm = float(size) / float(max(1, capacity))
    if s_norm >= 0.10:
        return 3
    if s_norm >= 0.03:
        return 2
    return 1

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    global g_target_protected_bytes, g_last_capacity
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = cache_snapshot.capacity
    if g_target_protected_bytes is None or g_last_capacity != cap:
        g_last_capacity = cap
        g_target_protected_bytes = int(PROTECTED_INIT_FRAC * float(cap))
        # clamp
        g_target_protected_bytes = max(0, min(g_target_protected_bytes, cap))

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _protected_target_bytes(cache_snapshot):
    # Adaptive target already stored globally
    return max(0, min(g_target_protected_bytes or 0, cache_snapshot.capacity))

def _demote_until_target(cache_snapshot):
    # If protected exceeds its target, demote oldest protected items to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    # Demote oldest protected repeatedly until within target or no protected remain
    while g_protected_bytes > target:
        key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
        if key is None:
            break
        obj = cache_snapshot.cache.get(key)
        if obj is None:
            break
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
        m_segment[key] = 0  # probation

def _adaptive_target_step(cache_snapshot, size):
    cap = max(1, cache_snapshot.capacity)
    base = max(1, cap // TARGET_BASE_DIV)
    bonus = int(TARGET_SIZE_WEIGHT * float(size))
    step = base + bonus
    step_cap = int(TARGET_MAX_FRAC * cap)
    return min(step, step_cap)

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed) and multi-hit
    freq = float(_lfu_peek(cache_snapshot, key))
    hits = m_resident_hits.get(key, 1)
    extra = MULTI_HIT_BONUS if hits >= 2 else 0.0
    base_benefit = math.log2(1.0 + freq) + extra

    # GreedyDual residual credit
    gds_resid = max(0.0, m_gds_H.get(key, g_gds_L) - g_gds_L)

    # Combine benefit terms against size
    benefit = (base_benefit + gds_resid) / max(1e-12, size_penalty)

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    # Higher is better to keep; eviction picks min(score)
    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Adapt protected target to capacity; demote protected until within target
      - Prefer evicting from probation; if none, evict from protected
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
      - Update GreedyDual global L to the evicted key's H (in update_after_evict)
    '''
    _init_if_needed(cache_snapshot)

    # Keep protected within its adaptive target by demoting oldest protected(s)
    _demote_until_target(cache_snapshot)

    # Selection state
    min_key = None
    min_score = None
    min_time = None

    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - Size-aware promotion from probation to protected when hits threshold met
      - Adapt protected target:
          * probation hit -> increase target (favor recency)
          * protected hit -> decrease target (favor frequency)
      - Update GreedyDual H credit
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = prev if prev is not None else now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # GreedyDual H credit update (age-aware)
    cap = max(1, cache_snapshot.capacity)
    size_norm = _normalized_size(obj.size, cap)
    # increment scaled by frequency and inversely by size
    freq_now = _lfu_peek(cache_snapshot, k)
    inc = (1.0 + math.log1p(float(freq_now))) / (size_norm ** SIZE_ALPHA)
    m_gds_H[k] = max(m_gds_H.get(k, g_gds_L), g_gds_L) + inc

    # Promotion to protected if not already and hits threshold met (size-aware)
    seg = _segment_of(k)
    if seg == 0:
        needed = _promotion_hits_needed(obj.size, cap)
        if m_resident_hits[k] >= needed:
            m_segment[k] = 1
            # Track protected bytes
            global g_protected_bytes
            g_protected_bytes += obj.size
            seg = 1  # now protected

    # Adapt protected target based on where the hit occurred
    global g_target_protected_bytes
    step = _adaptive_target_step(cache_snapshot, obj.size)
    if seg == 0:
        g_target_protected_bytes = min(cache_snapshot.capacity, _protected_target_bytes(cache_snapshot) + step)
    else:
        # reduce faster on large targets; ensure non-negative
        g_target_protected_bytes = max(0, _protected_target_bytes(cache_snapshot) - step)

    # Enforce protected target (demote oldest protected if oversized)
    _demote_until_target(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
      - Initialize GreedyDual H with global L + base increment
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # Initialize GreedyDual priority (small items get higher base)
    cap = max(1, cache_snapshot.capacity)
    size_norm = _normalized_size(obj.size, cap)
    base_inc = 1.0 / (size_norm ** SIZE_ALPHA)
    m_gds_H[k] = max(m_gds_H.get(k, g_gds_L), g_gds_L) + base_inc
    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Update GreedyDual global L to victim's H
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Update GreedyDual global L using victim's H
    global g_gds_L
    g_gds_L = max(g_gds_L, m_gds_H.get(ek, g_gds_L))

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    m_gds_H.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```
2025-11-27 20:30:44,786 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 31
- Hit Rate: 0.0878

Example 2:
- Trace ID: 32
- Hit Rate: 0.0878

Example 3:
- Trace ID: 20
- Hit Rate: 0.4267

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:30:44 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:30:44,787 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:32:29 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:32:29,176 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:32:29,177 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# GreedyDual-Size + TinyLFU (GDS-TLFU)
# - Size-aware GreedyDual priority with global aging (L)
# - TinyLFU with 4-bit lazy-decayed counters provides the "value" signal
# - On insert: H[key] = L + (log2(1 + freq) + INSERT_BONUS) / size
# - On hit:    H[key] += (log2(1 + freq_new) - last_log) / size  [diminishing returns]
#              plus a one-time promotion bonus on the 2nd resident hit
# - Evict:     key with the smallest H; set L = H[victim]
# - Tie-breaks by oldest last-access when H ties
#
# Why this helps:
# - GreedyDual's L "ages" all items with evictions, providing a robust recency effect
# - Division by size aggressively prefers small-but-useful items (lower miss rate by bytes)
# - TinyLFU gives a long-range popularity signal that decays over time (adaptable)
# - One-time promotion makes multi-hit items significantly stickier (SLRU-like)
#
# Complexity: O(N) scan per eviction (N = resident items). No global sweeps.

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# GreedyDual key values and aging
m_key_value = dict()          # key -> float H (priority)
m_global_age = 0.0            # L in GreedyDual

# Per-key resident metadata
m_last_access = dict()        # key -> int access_count (for tie-break)
m_resident_hits = dict()      # key -> int resident hit count
m_last_log = dict()           # key -> last log2(1+freq) used for incremental H updates
m_promoted_once = set()       # keys that received the one-time promotion bonus

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192     # accesses between epochs (power of two recommended)

# Tunables
INSERT_BONUS = 0.20           # small recency boost at insert (in "log units")
PROMOTION_BONUS = 0.60        # one-time boost on 2nd resident hit (in "log units")

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Helpers
# -----------------------------

def _size_bytes(size):
    # Never divide by zero; sizes are positive by spec
    return float(max(1, int(size)))

def _log_score_from_freq(freq):
    # Smooth diminishing returns
    return math.log2(1.0 + float(freq))

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    GreedyDual-Size + TinyLFU eviction:
      - Evict the resident key with the smallest H (priority)
      - On eviction, advance global age L to H[victim]
      - Tie-break by oldest last-access
    '''
    _init_if_needed(cache_snapshot)

    victim = None
    victim_H = None
    victim_time = None

    for k in cache_snapshot.cache.keys():
        H = m_key_value.get(k)
        if H is None:
            # If somehow missing, treat as minimal priority
            H = m_global_age
        last = m_last_access.get(k, -1)
        if (victim_H is None) or (H < victim_H) or (H == victim_H and last < victim_time):
            victim = k
            victim_H = H
            victim_time = last

    # Advance global age to the victim's priority (GreedyDual)
    if victim is not None and victim_H is not None:
        # L is non-decreasing
        global m_global_age
        m_global_age = max(m_global_age, victim_H)

    # Fallback if needed
    if victim is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return victim


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Compute incremental log gain and add to H: delta = (log2(1+freq_new) - last_log)/size
      - One-time promotion bonus on the 2nd resident hit
      - Refresh last-access and resident hit count
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = _size_bytes(obj.size)

    # Increment TinyLFU and compute new log score
    new_freq = _lfu_inc(cache_snapshot, k)
    new_log = _log_score_from_freq(new_freq)
    prev_log = m_last_log.get(k, new_log)  # default to new_log if missing
    delta_log = max(0.0, new_log - prev_log)  # protect against epoch decay artifacts
    m_last_log[k] = new_log

    # Update priority H
    base_H = m_key_value.get(k, m_global_age)
    H_new = base_H + (delta_log / sz)

    # One-time promotion when it reaches its 2nd resident hit
    cur_hits = m_resident_hits.get(k, 1) + 1
    m_resident_hits[k] = cur_hits
    if cur_hits == 2 and k not in m_promoted_once:
        H_new += (PROMOTION_BONUS / sz)
        m_promoted_once.add(k)

    m_key_value[k] = H_new
    m_last_access[k] = cache_snapshot.access_count


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize H with GreedyDual value:
            H[k] = L + (log2(1+freq) + INSERT_BONUS) / size
      - Initialize last_log, last_access, resident_hits
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = _size_bytes(obj.size)

    freq = _lfu_inc(cache_snapshot, k)
    logv = _log_score_from_freq(freq)

    H_init = m_global_age + ((logv + INSERT_BONUS) / sz)
    m_key_value[k] = H_init
    m_last_log[k] = logv
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    # If key was evicted before, allow it to earn the promotion again
    m_promoted_once.discard(k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Keep TinyLFU counters to remember popularity across evictions
      - m_global_age (L) already advanced in evict()
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    m_key_value.pop(ek, None)
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_last_log.pop(ek, None)
    m_promoted_once.discard(ek)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```
2025-11-27 20:32:45,910 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 28
- Hit Rate: 0.1767

Example 2:
- Trace ID: 17
- Error: Error - Timeout

Example 3:
- Trace ID: 35
- Hit Rate: 0.1562

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:32:45 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:32:45,911 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:34:52 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:34:52,286 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:34:52,287 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Fast, size-aware Segmented TinyLFU (SLRU + sampling)
# Goals:
#   - Reduce CPU: O(1) metadata ops, O(sample) victim selection
#   - Keep protected segment near target using O(1) demotions
#   - Favor recency in probation and frequency in protected
#   - Size-aware scoring to avoid cache pollution by large objects
#
# Design:
#   - Two resident segments with LRU order (OrderedDict):
#       * probation: newly inserted and single-hit items
#       * protected: promoted upon hit
#   - Eviction prefers probation; protected is shielded except when above target bytes
#   - Victim chosen from a small sample of oldest items in the target segment
#     using a composite score (frequency + predicted reuse - recency, size-penalized)
#   - TinyLFU: lazy-decayed 4-bit counters keyed by object key (persist across eviction)
#   - Metadata is updated on hit/insert/evict; promotion/demotion maintains O(1) deques

import math
from collections import OrderedDict

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Predicted reuse (EMA of inter-arrival time, in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs

# Segmented LRU structures (residents only)
probation_lru = OrderedDict()  # key -> None (LRU at left, MRU at right)
protected_lru = OrderedDict()  # key -> None (LRU at left, MRU at right)

# Segment sizing (by bytes)
PROTECTED_FRACTION = 0.80
g_protected_bytes = 0  # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.15           # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.40      # boost for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1024
REC_WIN_MULT = 4            # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.70
W_REC_PROT = 0.15
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40         # higher -> react faster to changing reuse intervals

# Victim sampling
SAMPLE_OLD = 24             # sample this many oldest from chosen segment


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _ensure_structs_consistent(cache_snapshot, key):
    # Make sure a resident key has exactly one entry in the correct LRU
    seg = _segment_of(key)
    if seg == 0:
        if key in protected_lru:
            protected_lru.pop(key, None)
        if key not in probation_lru:
            probation_lru[key] = None
    else:
        if key in probation_lru:
            probation_lru.pop(key, None)
        if key not in protected_lru:
            protected_lru[key] = None

def _iter_oldest(od, limit):
    # Yield up to 'limit' oldest keys (LRU to newer)
    it = iter(od.keys())
    for _ in range(limit):
        try:
            yield next(it)
        except StopIteration:
            return

def _promote_to_protected(cache_snapshot, obj):
    global g_protected_bytes
    k = obj.key
    # Remove from probation if present
    if k in probation_lru:
        probation_lru.pop(k, None)
    # Add/move to protected MRU
    protected_lru[k] = None
    protected_lru.move_to_end(k, last=True)
    # Update segment and bytes
    if _segment_of(k) == 0:
        g_protected_bytes += obj.size
    m_segment[k] = 1

def _demote_one_from_protected_if_needed(cache_snapshot):
    # Demote oldest protected until within target bytes (O(1) per demotion)
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    while g_protected_bytes > target and protected_lru:
        # Oldest protected (LRU at left)
        demote_key, _ = protected_lru.popitem(last=False)
        # Move to probation MRU
        probation_lru[demote_key] = None
        probation_lru.move_to_end(demote_key, last=True)
        # Update bytes and segment
        robj = cache_snapshot.cache.get(demote_key)
        if robj is not None:
            g_protected_bytes = max(0, g_protected_bytes - robj.size)
        m_segment[demote_key] = 0


# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Lower score -> weaker retention -> more likely to be evicted
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # sooner expected reuse -> larger gain

    return benefit - recency_gain - predicted_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near target by demoting oldest protected (O(1))
      - Prefer an eviction from probation; fallback to protected if needed
      - Choose victim from a small sample of oldest items in the segment,
        minimizing the retention score (ties by oldest last-access)
    '''
    _init_if_needed(cache_snapshot)

    # Maintain protected size target by O(1) demotions, if needed
    _demote_one_from_protected_if_needed(cache_snapshot)

    # Choose segment to evict from
    choose_proba = True
    if not probation_lru:
        choose_proba = False
        if not protected_lru:
            # Fallback: cache is empty or LRU state is not initialized—pick any
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    # Gather candidates
    if choose_proba:
        candidates = list(_iter_oldest(probation_lru, SAMPLE_OLD))
    else:
        candidates = list(_iter_oldest(protected_lru, SAMPLE_OLD))

    # If sampling produced no candidates (shouldn't happen), fallback
    if not candidates:
        base = probation_lru if choose_proba else protected_lru
        try:
            # LRU victim
            return next(iter(base))
        except StopIteration:
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    # Select minimum retention score among candidates
    min_key = None
    min_score = None
    min_time = None
    for k in candidates:
        score = _retention_score(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if (min_key is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = k
            min_score = score
            min_time = last

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU
      - Update last access and IRT EMA
      - Increment resident hit count
      - Move to MRU of its segment; if in probation, promote to protected
      - Enforce protected target with O(1) demotions
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using time since last resident access
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = _segment_of(k)
    if seg == 0:
        # Promote to protected on first hit (SLRU behavior)
        _promote_to_protected(cache_snapshot, obj)
    else:
        # Touch: move to MRU within protected
        if k not in protected_lru:
            protected_lru[k] = None
        protected_lru.move_to_end(k, last=True)

    # Enforce protected target
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the key
      - Initialize resident metadata
      - Insert into probation MRU
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # Insert into probation MRU
    if k in protected_lru:
        protected_lru.pop(k, None)
    probation_lru[k] = None
    probation_lru.move_to_end(k, last=True)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata and LRU membership
      - Retain TinyLFU counters
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    if _segment_of(ek) == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove from LRU structures
    probation_lru.pop(ek, None)
    protected_lru.pop(ek, None)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
```
2025-11-27 20:35:04,369 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 32
- Hit Rate: 0.0878

Example 2:
- Trace ID: 38
- Hit Rate: 0.1255

Example 3:
- Trace ID: 25
- Hit Rate: 0.3317

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:35:04 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:35:04,370 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:37:19 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:37:19,795 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:37:19,796 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive Windowed TinyLFU + GreedyDual-Size with Aging (AW-TinyLFU-GDSF)
# - Two resident segments:
#     W (window/probation): protects very recent items by LRU
#     M (main/protected): ranked by GreedyDual-Size with TinyLFU benefit
# - TinyLFU frequency: lazy-decayed 8-bit counters (no global sweep)
# - GDSF priority: H = L + benefit, where
#       benefit = (log2(1 + TinyLFU(freq)) + multi_hit_bonus) / normalized_size
#   L is a global aging value set to the H of each GDSF eviction.
# - Eviction:
#     1) If window bytes > adaptive target, evict the LRU item in W (no L update)
#     2) Else, evict the item with the smallest H among all residents (set L = H_victim)
# - On hit:
#     - Increment TinyLFU count
#     - Refresh per-key priority H
#     - Promote from W→M when it proves reuse (size-aware threshold)
#     - Adapt window target: hits in W increase it; hits in M decrease it
# - On insert:
#     - Place in W, initialize metadata, set H = L + current benefit
# - On evict:
#     - Remove resident-only metadata (TinyLFU counters persist across evictions)

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Resident metadata
m_last_access = dict()     # key -> int access_count
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_seg = dict()             # key -> 0 for window (W), 1 for main (M)
m_H = dict()               # key -> float GDSF priority

# Global state
L_age = 0.0                # GDSF aging value (L)
window_target_bytes = 0    # adaptive target for window segment (bytes)
bytes_in_window = 0        # running total of bytes in W

# TinyLFU sketch (lazy-decayed 8-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096  # access-counts between epochs (power of two recommended)

# Adaptation & tuning
WINDOW_FRACTION_INIT = 0.20  # initial fraction of capacity as window target
WINDOW_MIN = 0.05            # min fraction for window
WINDOW_MAX = 0.45            # max fraction for window
ADAPT_STEP_FRAC = 0.02       # step for adapting window target (fraction of capacity)
MULTI_HIT_BONUS = 0.5        # extra benefit for items with >=2 resident hits

# Reset detection
_last_seen_capacity = None
_last_seen_access = -1

# -----------------------------
# Init and reset helpers
# -----------------------------

def _maybe_reset(cache_snapshot):
    global _last_seen_capacity, _last_seen_access
    global L_age, window_target_bytes, bytes_in_window
    global m_lfu_epoch

    cap = cache_snapshot.capacity
    now = cache_snapshot.access_count
    cap_changed = (_last_seen_capacity is None) or (cap != _last_seen_capacity)
    new_trace = (now < _last_seen_access)

    if cap_changed or new_trace:
        # Clear all resident metadata
        m_last_access.clear()
        m_resident_hits.clear()
        m_seg.clear()
        m_H.clear()
        # Reset TinyLFU sketch for a new run
        m_lfu_count.clear()
        m_lfu_epoch = 0

        L_age = 0.0
        window_target_bytes = max(int(cap * WINDOW_FRACTION_INIT), 1)
        bytes_in_window = 0

        _last_seen_capacity = cap

    _last_seen_access = now


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(255, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring and thresholds
# -----------------------------

def _size_norm_permille(size, capacity):
    # Normalize size to "permille of capacity" to keep values in a stable range
    denom = max(1.0, float(capacity) / 1000.0)
    return max(1.0, float(size) / denom)

def _benefit_value(cache_snapshot, size, freq, resident_hits):
    cap = cache_snapshot.capacity
    size_norm = _size_norm_permille(size, cap)
    bonus = MULTI_HIT_BONUS if resident_hits >= 2 else 0.0
    return (math.log2(1.0 + float(freq)) + bonus) / size_norm

def _promotion_threshold(capacity, size):
    # Size-aware promotion threshold (hits to move W -> M)
    # small objects promote quickly; large ones require more proof
    if size <= capacity * 0.01:  # <= 1% of capacity
        return 1
    elif size <= capacity * 0.05:  # <= 5% of capacity
        return 2
    else:
        return 3

def _adapt_step(capacity):
    return max(int(capacity * ADAPT_STEP_FRAC), 1)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict according to AW-TinyLFU-GDSF:
      - If window bytes exceed adaptive target, evict the LRU in window (no L update)
      - Else, evict the global min-H (and set L to that H)
    '''
    _maybe_reset(cache_snapshot)

    global L_age

    cap = cache_snapshot.capacity

    # 1) Prefer evicting from the window if it's oversized
    if bytes_in_window > window_target_bytes:
        victim_key = None
        victim_time = None
        # Choose the oldest (LRU) within window segment
        for k in cache_snapshot.cache.keys():
            if m_seg.get(k, 1) == 0:  # window
                last = m_last_access.get(k, -1)
                if victim_time is None or last < victim_time:
                    victim_key = k
                    victim_time = last
        if victim_key is not None:
            # Do not update L_age for window-overflow evictions
            return victim_key
        # Fall through if no window keys found (rare): use global min-H

    # 2) Otherwise, evict the item with the smallest H (GDSF)
    min_key = None
    min_H = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        # Cached priority or compute a reasonable one on the fly if missing
        H = m_H.get(k)
        if H is None:
            robj = cache_snapshot.cache.get(k)
            if robj is None:
                continue
            freq = _lfu_peek(cache_snapshot, k)
            rh = m_resident_hits.get(k, 1)
            H = L_age + _benefit_value(cache_snapshot, robj.size, freq, rh)
            m_H[k] = H  # cache it for future
        last = m_last_access.get(k, -1)
        if (min_H is None) or (H < min_H) or (H == min_H and last < min_time):
            min_H = H
            min_time = last
            min_key = k

    if min_key is None:
        # Fallback: arbitrary key
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # GDSF aging: advance L to victim's H
    if min_H is not None and min_H > L_age:
        L_age = min_H

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Refresh last-access time and resident hit count
      - Recompute H = L + benefit
      - Promote W -> M when hits reach size-aware threshold
      - Adapt window target: hits in W increase it; hits in M decrease it
    '''
    _maybe_reset(cache_snapshot)

    global bytes_in_window, window_target_bytes

    cap = cache_snapshot.capacity
    k = obj.key
    size = obj.size

    # Frequency update
    freq = _lfu_inc(cache_snapshot, k)

    # Refresh metadata
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promote if proven reuse (size-aware)
    seg = m_seg.get(k, 0)  # default to window if missing
    if seg == 0:
        thr = _promotion_threshold(cap, size)
        if m_resident_hits[k] >= thr:
            m_seg[k] = 1  # move to main
            bytes_in_window = max(0, bytes_in_window - size)

    # Recompute H priority
    rh = m_resident_hits.get(k, 1)
    benefit = _benefit_value(cache_snapshot, size, freq, rh)
    m_H[k] = L_age + benefit

    # Adapt window target based on where the hit occurred
    step = _adapt_step(cap)
    if m_seg.get(k, 1) == 0:
        # Hit in window -> increase recency protection
        window_target_bytes = min(int(cap * WINDOW_MAX), window_target_bytes + step)
    else:
        # Hit in main -> bias toward frequency
        window_target_bytes = max(int(cap * WINDOW_MIN), window_target_bytes - step)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key
      - Initialize resident metadata
      - Place into Window (probation)
      - Initialize H = L + benefit (TinyLFU-aware, size-aware)
    '''
    _maybe_reset(cache_snapshot)

    global bytes_in_window

    k = obj.key
    size = obj.size

    freq = _lfu_inc(cache_snapshot, k)

    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    m_seg[k] = 0  # into window
    bytes_in_window += size

    benefit = _benefit_value(cache_snapshot, size, freq, m_resident_hits[k])
    m_H[k] = L_age + benefit


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Maintain accurate window byte accounting
    '''
    _maybe_reset(cache_snapshot)

    global bytes_in_window

    ek = evicted_obj.key
    esize = evicted_obj.size

    # Window accounting
    if m_seg.get(ek, 1) == 0:
        bytes_in_window = max(0, bytes_in_window - esize)

    # Remove resident metadata (keep TinyLFU memory)
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_seg.pop(ek, None)
    m_H.pop(ek, None)
```
2025-11-27 20:37:31,140 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Policy: HALO-TFSv2 — Heap-Accelerated LFU with Recency, Freshness, and Gap Prediction
# Key improvements over previous version:
# - Stronger recency sensitivity with adaptive windowing
# - Do not credit LFU on cold insert (reduces one-timer pollution)
# - Per-key EWMA of inter-arrival gaps to predict time-to-next access
# - Fresh-insert "grace" multiplier to avoid immediate churn
# - Multi-hit protection is stronger and starts after the second hit
# - Bounded-rescan victim search for better choices without full scans

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_birth_ts = dict()         # key -> int access_count at insertion
m_resident_hits = dict()    # key -> int resident hit count (starts at 0 on insert)
m_gap_ewma = dict()         # key -> float ≈ EWMA of inter-arrival gap while resident

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 2048   # faster adaptation to workload shifts
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192
HEAP_GROWTH_FACTOR = 4

# Tunables for scoring
SIZE_ALPHA = 0.80               # size normalization exponent; favors small objects
REC_WIN_MIN = 64                # minimum recency window in accesses
REC_WIN_MULT = 6                # recency window ~ REC_WIN_MULT * resident_items
FREQ_WEIGHT = 1.00              # weight of frequency (TinyLFU)
REC_WEIGHT = 1.10               # weight of observed recency
PRED_WEIGHT = 0.90              # weight of predicted return risk (via gap EWMA)
MH_MULT = 1.50                  # multiplicative boost after >=2 resident hits
FRESH_GRACE = 128               # accesses; grace period after insert
FRESH_MULT = 1.30               # multiplicative boost during grace
GAP_BETA = 0.30                 # EWMA smoothing factor for inter-arrival gap

# Victim selection
RESCAN_LIMIT = 12               # bounded extra pops from heap to improve victim choice


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # decay is applied lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)


def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _predicted_risk(now, last, gap_ewma, window):
    # Predict time-to-next using EWMA gap. Convert to risk in (0,1].
    if last is None or last < 0 or gap_ewma is None or gap_ewma <= 0.0:
        return 0.0
    age = max(0, now - last)
    ttn = gap_ewma - age  # time until next (can be <= 0 if due/overdue)
    # Map to (0,1], ≈1 when due/overdue, smaller when far in future
    return 1.0 / (1.0 + (max(0.0, ttn) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency and predicted risk
    window = _recency_window(cache_snapshot)
    r_term = _recency_term(now, m_last_access.get(key), window)
    p_term = _predicted_risk(now, m_last_access.get(key), m_gap_ewma.get(key), window)

    # Freshness and multi-hit multipliers
    birth = m_birth_ts.get(key)
    fresh = (1.0 if birth is None else (FRESH_MULT if (now - birth) <= FRESH_GRACE else 1.0))
    mhits = m_resident_hits.get(key, 0)
    mh_mult = (MH_MULT if mhits >= 2 else 1.0)

    # Final score: combine, then size-normalize, then apply multiplicative boosts
    base = (FREQ_WEIGHT * f_term) + (REC_WEIGHT * r_term) + (PRED_WEIGHT * p_term)
    score = (base / size_norm) * fresh * mh_mult
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    - Seed heap on first use
    - Pop and validate entries lazily (versioning)
    - Recompute scores to reflect latest epochs and metadata
    - Bounded rescan: consider a small set of candidates and pick the weakest
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            # Initialize missing resident metadata best-effort
            m_last_access.setdefault(k, cache_snapshot.access_count)
            m_birth_ts.setdefault(k, cache_snapshot.access_count)
            m_resident_hits.setdefault(k, 0)
            m_gap_ewma.setdefault(k, float(_recency_window(cache_snapshot)))
            _heap_push(cache_snapshot, k)

    # Bounded rescan to find the weakest valid candidate
    best_key = None
    best_tuple = None  # (adjusted_score, score_tuple)
    considered = []

    attempts = 0
    while attempts < RESCAN_LIMIT and m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            attempts += 1
            continue
        # Skip if stale heap entry
        if m_ver.get(k, 0) != v:
            attempts += 1
            continue
        # Recompute current score (reflect decay/window/metadata changes)
        cur_sc = _score_key(cache_snapshot, k)
        # If score drifted upward, reinsert with new score
        if cur_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            attempts += 1
            continue

        # Track the weakest (lowest score) candidate
        adj_sc = cur_sc  # adjustment slots available if needed later
        if (best_tuple is None) or (adj_sc < best_tuple[0]):
            best_key = k
            best_tuple = (adj_sc, (sc, last, k, v))
        considered.append((sc, last, k, v))
        attempts += 1

    # Push back all considered entries except the chosen victim
    for tup in considered:
        if best_tuple is not None and tup[2] == best_key:
            continue
        heapq.heappush(m_heap, tup)

    # Fallbacks
    if best_key is not None:
        return best_key

    # If heap is exhausted or empty, choose the oldest resident
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Update EWMA of inter-arrival gap
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Update frequency only on hits (not on cold insert)
    _lfu_inc(cache_snapshot, k)

    # Update inter-arrival EWMA
    prev = m_last_access.get(k)
    if prev is not None:
        gap = max(1.0, float(now - prev))
        old = m_gap_ewma.get(k)
        if old is None or old <= 0.0:
            m_gap_ewma[k] = gap
        else:
            m_gap_ewma[k] = (1.0 - GAP_BETA) * old + GAP_BETA * gap
    else:
        # Initialize conservatively
        m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    # Hits: increment resident hits
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # Refresh timestamps
    m_last_access[k] = now

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch
      - Do NOT increment LFU on cold insert (reduces one-timer pollution)
      - Initialize resident metadata: last_access, birth_ts, resident_hits = 0
      - Initialize EWMA gap conservatively to recency window
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # No _lfu_inc here: cold items must earn credit by hitting

    m_last_access[k] = now
    m_birth_ts[k] = now
    m_resident_hits[k] = 0
    m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember popularity)
      - Invalidate its heap version (stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_birth_ts.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_gap_ewma.pop(ek, None)
    m_ver.pop(ek, None)

    _touch_and_maybe_rebuild(cache_snapshot)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 39
- Hit Rate: 0.0909

Example 2:
- Trace ID: 22
- Hit Rate: 0.06

Example 3:
- Trace ID: 16
- Hit Rate: 0.0198

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:37:31 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:37:31,142 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:40:20 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:40:20,185 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:40:20,187 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Policy: ARC-SLRU Hybrid (size-aware, ghost-adaptive)
# Summary:
# - Two resident segments:
#   - T1 (probationary, recency): new items and single-hit items live here
#   - T2 (protected, frequency): items promoted after multiple resident hits
# - Two ghost histories:
#   - B1: keys recently evicted from T1 (recency history)
#   - B2: keys recently evicted from T2 (frequency history)
# - Adaptive target split p_bytes between T1 and T2:
#   - If a reinsert hits B1 (recency-miss), increase p_bytes (give more room to T1)
#   - If a reinsert hits B2 (frequency-miss), decrease p_bytes (give more room to T2)
# - Promotion requires ≥2 resident hits (≥3 if item is much larger than average)
# - Evict from T1 if it exceeds p_bytes or if T2 is empty, else evict from T2
# - LRU ordering within each segment (OrderedDict); per-key last_access tracked for safe fallback

from collections import OrderedDict

# -------------------------------
# Global state (module scope)
# -------------------------------

# Resident segments (LRU: oldest at front, newest at end)
T1 = OrderedDict()  # probationary
T2 = OrderedDict()  # protected

# Ghost histories (LRU)
B1 = OrderedDict()  # recently evicted from T1
B2 = OrderedDict()  # recently evicted from T2

# Adaptive split in bytes for T1
p_bytes = None
last_capacity = None

# Accounting
T1_bytes = 0  # total bytes of resident keys in T1

# Per-key metadata
m_last_access = dict()   # key -> access_count timestamp
m_hits = dict()          # key -> integer resident-hit counter


# -------------------------------
# Helpers
# -------------------------------

def _ensure_init(cache_snapshot):
    """Initialize adaptive target when capacity changes or on first use."""
    global p_bytes, last_capacity
    cap = int(getattr(cache_snapshot, "capacity", 0) or 0)
    if p_bytes is None or last_capacity != cap:
        last_capacity = cap
        # Start with 1/3 of bytes as recency window (probationary)
        p_bytes = int(0.33 * cap) if cap > 0 else 0


def _avg_size_step(cache_snapshot, fallback_size):
    """Return a reasonable step size in bytes for adapting p_bytes."""
    n = len(cache_snapshot.cache)
    if n > 0:
        return max(1, int(cache_snapshot.size // n))
    return max(1, int(fallback_size))


def _clip_p(cache_snapshot):
    """Ensure p_bytes stays within [0, capacity]."""
    global p_bytes
    cap = int(getattr(cache_snapshot, "capacity", 0) or 0)
    if cap <= 0:
        p_bytes = 0
    else:
        if p_bytes < 0:
            p_bytes = 0
        elif p_bytes > cap:
            p_bytes = cap


def _ghost_prune(cache_snapshot):
    """Bound the total size of ghost histories by number of keys."""
    # Keep ghost size to ~4x resident key count (plus small slack).
    max_ghost = max(64, 4 * max(1, len(cache_snapshot.cache)))
    while (len(B1) + len(B2)) > max_ghost:
        # Evict from the larger ghost first
        if len(B1) >= len(B2):
            try:
                B1.popitem(last=False)
            except Exception:
                break
        else:
            try:
                B2.popitem(last=False)
            except Exception:
                break


def _pop_lru_valid(od, cache_snapshot):
    """Return the oldest valid resident key in the given OrderedDict.
       Drop stale entries (should be rare) and continue."""
    while od:
        k, _ = next(iter(od.items()))  # LRU key
        if k in cache_snapshot.cache:
            return k
        # stale entry (out of sync): drop it
        od.popitem(last=False)
    return None


def _promote_if_ready(cache_snapshot, obj, k):
    """Promote from T1->T2 when hit threshold is met (size-aware)."""
    global T1_bytes
    # Determine threshold: large objects require stronger evidence
    n = len(cache_snapshot.cache)
    avg_sz = (cache_snapshot.size // n) if n > 0 else obj.size
    threshold = 2 if obj.size <= 2 * max(1, avg_sz) else 3

    h = m_hits.get(k, 0)
    if h >= threshold and k in T1:
        # Move from T1 to T2
        if k in T1:
            T1.pop(k, None)
            T1_bytes = max(0, T1_bytes - obj.size)
        T2[k] = True  # insert as MRU
    elif k in T1:
        # Touch within T1 (move to MRU)
        try:
            T1.move_to_end(k, last=True)
        except KeyError:
            pass


# -------------------------------
# Policy entry points
# -------------------------------

def evict(cache_snapshot, obj):
    """
    Choose a victim using adaptive split between T1 and T2:
    - Prefer evicting from T1 (probationary) if it exceeds target p_bytes or T2 is empty
    - Otherwise evict from T2 (protected)
    Fallback to global LRU by last_access if segments are empty.
    """
    _ensure_init(cache_snapshot)
    _clip_p(cache_snapshot)

    # Select segment
    pick_T1 = False
    if T2:
        pick_T1 = (T1_bytes > p_bytes) or (not T1)
    else:
        # No protected items: must evict from T1 if possible
        pick_T1 = True

    victim = None
    if pick_T1 and T1:
        victim = _pop_lru_valid(T1, cache_snapshot)
    if victim is None and T2:
        victim = _pop_lru_valid(T2, cache_snapshot)
    if victim is None and T1:
        victim = _pop_lru_valid(T1, cache_snapshot)

    # Final fallback: global oldest by last_access
    if victim is None:
        min_k = None
        min_ts = None
        for k in cache_snapshot.cache.keys():
            ts = m_last_access.get(k, -1)
            if min_ts is None or ts < min_ts:
                min_ts = ts
                min_k = k
        victim = min_k

    return victim


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
    - Increment resident hit count
    - Update last_access timestamp
    - Promote from T1 to T2 after enough resident hits (size-aware threshold)
    - Maintain LRU position in its segment
    """
    _ensure_init(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Update metadata
    m_last_access[k] = now
    m_hits[k] = m_hits.get(k, 0) + 1

    if k in T2:
        # Touch protected: move to MRU
        try:
            T2.move_to_end(k, last=True)
        except KeyError:
            pass
        return

    if k in T1:
        _promote_if_ready(cache_snapshot, obj, k)
        return

    # If the key is resident but we didn't track it (rare), treat it as T1
    if k in cache_snapshot.cache and (k not in T1) and (k not in T2):
        T1[k] = True
        # Account its bytes into T1
        global T1_bytes
        T1_bytes += obj.size
        _promote_if_ready(cache_snapshot, obj, k)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
    - Adapt p_bytes based on ghost hits:
        * If key in B1: increase p_bytes by ~avg object size (more T1)
        * If key in B2: decrease p_bytes by ~avg object size (more T2)
      Then remove the key from the matching ghost.
    - Insert into T1 as MRU with hits=0
    - Initialize last_access
    - Prune ghost histories periodically
    """
    _ensure_init(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Adaptation via ghost hits
    step = _avg_size_step(cache_snapshot, obj.size)
    if k in B1:
        B1.pop(k, None)
        # Increase T1 target (favor recency)
        global p_bytes
        p_bytes += step
        _clip_p(cache_snapshot)
    elif k in B2:
        B2.pop(k, None)
        # Decrease T1 target (favor frequency)
        p_bytes -= step
        _clip_p(cache_snapshot)

    # Insert into T1 as MRU (probationary)
    if k in T2:
        # Extremely rare: if already tracked in T2 (inconsistency), normalize to T2
        try:
            T2.move_to_end(k, last=True)
        except KeyError:
            T2[k] = True
    else:
        T1[k] = True
        global T1_bytes
        T1_bytes += obj.size

    # Initialize resident metadata
    m_last_access[k] = now
    m_hits[k] = 0

    _ghost_prune(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After a victim is removed from the cache:
    - Remove it from its resident segment
    - Add its key to the corresponding ghost history (B1 if from T1, else B2)
    - Drop resident-only metadata
    - Prune ghost histories
    """
    _ensure_init(cache_snapshot)

    ek = evicted_obj.key
    now = cache_snapshot.access_count

    # Remove from resident segments and add to appropriate ghost
    if ek in T1:
        T1.pop(ek, None)
        global T1_bytes
        T1_bytes = max(0, T1_bytes - evicted_obj.size)
        B1[ek] = now
        # Ensure MRU at end
        try:
            B1.move_to_end(ek, last=True)
        except KeyError:
            pass
    elif ek in T2:
        T2.pop(ek, None)
        B2[ek] = now
        try:
            B2.move_to_end(ek, last=True)
        except KeyError:
            pass
    else:
        # If it's not in either (rare), attribute to T1 by default
        B1[ek] = now
        try:
            B1.move_to_end(ek, last=True)
        except KeyError:
            pass

    # Drop resident-only metadata
    m_last_access.pop(ek, None)
    m_hits.pop(ek, None)

    _ghost_prune(cache_snapshot)
```
2025-11-27 20:40:32,035 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved policy: Heap-Accelerated TinyLFU with Size and Recency (HALO-TFS)
# - Fast eviction via a lazy min-heap of retention scores (no full scans)
# - TinyLFU with lazy epoch decay (per-key small counters remembered across evictions)
# - Size-aware, recency-aware scoring with multi-hit boost
# - Robust to workload shifts; avoids timeouts via O(log n) victim selection and periodic heap rebuilds

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_resident_hits = dict()    # key -> int resident hit count (>=1 once inserted)

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096   # accesses per epoch (power of two recommended)
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192  # how often to check if heap needs rebuilding
HEAP_GROWTH_FACTOR = 4       # if heap > factor * resident_count, rebuild

# Tunables for scoring
SIZE_ALPHA = 0.75           # size normalization exponent; smaller favors small objects
REC_WIN_MIN = 64            # minimum recency window
REC_WIN_MULT = 8            # recency window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.75           # strength of recency term added to frequency
MULTI_HIT_BONUS = 0.50      # multiplicative boost for items with >=2 hits while resident


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # no sweeping; decay handled lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring
# -----------------------------

def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency component
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    r_term = _recency_term(now, m_last_access.get(key), window)

    # Multi-hit boost (stronger protection after the second hit)
    mh = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    mult = 1.0 + mh

    # Final score: combine frequency and recency, then size-normalize
    score = ((f_term + REC_WEIGHT * r_term) * mult) / size_norm
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    # Rebuild heap from current residents with fresh scores/versions
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    Lazy invalidation ensures correctness despite changing scores/epochs.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., unusual bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            if k not in m_ver:
                # Initialize resident metadata if missing (best effort)
                m_last_access.setdefault(k, cache_snapshot.access_count)
                m_resident_hits.setdefault(k, 1)
            _heap_push(cache_snapshot, k)

    # Candidate's "would-be" score (informal comparison; does not affect required eviction)
    # This is used only to help prefer weaker residents when ties occur.
    cand_freq = _lfu_peek(cache_snapshot, obj.key) + 1  # will be incremented on insert
    cand_f_term = math.log1p(float(cand_freq))
    cand_size_norm = max(1.0, float(obj.size)) ** SIZE_ALPHA
    cand_score = (cand_f_term + REC_WEIGHT * 1.0) / cand_size_norm  # recency ~1 on insert

    # Pop until we find a valid, up-to-date victim
    while m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            continue
        # Skip if stale entry
        if m_ver.get(k, 0) != v:
            continue
        # Recompute current score to account for epoch/window changes
        new_sc = _score_key(cache_snapshot, k)
        # If the score drifted upward (got better), reinsert with new score
        if new_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            continue
        # Optional tie-breaker with candidate: if resident clearly stronger than candidate,
        # try to find a weaker one by peeking more; but if none, return this one.
        if new_sc >= cand_score:
            # Keep searching a bit for something weaker; cap extra attempts to avoid overhead
            attempts = 0
            tmp = [(sc, last, k, v)]
            victim = None
            while attempts < 8 and m_heap:
                sc2, last2, k2, v2 = heapq.heappop(m_heap)
                if k2 not in cache_snapshot.cache or m_ver.get(k2, 0) != v2:
                    attempts += 1
                    continue
                cur_sc2 = _score_key(cache_snapshot, k2)
                if cur_sc2 > sc2 + 1e-12:
                    _heap_push(cache_snapshot, k2)
                    attempts += 1
                    continue
                if cur_sc2 < cand_score or cur_sc2 < new_sc:
                    victim = (cur_sc2, last2, k2, v2)
                    break
                tmp.append((sc2, last2, k2, v2))
                attempts += 1
            # Push back any entries we popped but didn't choose
            for ent in tmp:
                heapq.heappush(m_heap, ent)
            if victim is not None:
                return victim[2]
            # Fall back to the original k
        return k

    # Fallback: choose the oldest resident if heap is somehow empty
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch and increment counter for requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember its popularity)
      - Invalidate its heap version (lazy: stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_ver.pop(ek, None)
    _touch_and_maybe_rebuild(cache_snapshot)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 8
- Hit Rate: 0.5409

Example 2:
- Trace ID: 13
- Hit Rate: 0.0

Example 3:
- Trace ID: 44
- Hit Rate: 0.0917

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:40:32 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:40:32,037 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:43:35 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:43:35,199 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:43:35,200 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Policy: 2Q-SLRU with Tiny Frequency Memory (2Q-TFM)
# - Two resident segments:
#     A1in (probationary FIFO/LRU): newly admitted, 1-hit wonders live here
#     Am   (main LRU): promoted items (2nd reference or high tiny-frequency)
# - Ghost history B1 for A1in evictions to recognize recency on re-reference
# - Tiny frequency memory (lazy-decayed small counters) steers admission:
#     if freq(key) >= 2 or key in B1, admit directly to Am; else to A1in
# - Eviction victim: LRU of A1in if non-empty, else LRU of Am
# - O(1) operations via OrderedDict; robust on diverse traces

from collections import OrderedDict

# -----------------------------
# Global metadata
# -----------------------------

# Resident segments
m_A1in = OrderedDict()   # probationary: key -> None (LRU at beginning)
m_Am = OrderedDict()     # main/protected: key -> None (LRU at beginning)

# Membership: 0=non-resident, 1=A1in, 2=Am
m_seg = dict()

# Ghost history of recently evicted A1in keys (to recognize recency on re-reference)
m_B1 = OrderedDict()     # key -> last_seen_time (for trimming order)

# Tiny frequency memory with lazy epoch decay (small saturating counters)
m_freq = dict()          # key -> (count:int[0..15], epoch:int)
TFM_DECAY_INTERVAL = 4096
TFM_MAX = 15

# Capacity estimate in number of objects (learned online)
m_cap_est = 0
GHOST_MULT = 4  # B1 ghost capacity ~= GHOST_MULT * cap_est


# -----------------------------
# Helpers
# -----------------------------

def _epoch(snapshot):
    return snapshot.access_count // TFM_DECAY_INTERVAL


def _freq_peek(snapshot, key):
    entry = m_freq.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = _epoch(snapshot) - e
    if shift > 0:
        c >>= shift
    return c


def _freq_inc(snapshot, key):
    c = _freq_peek(snapshot, key)
    c = min(TFM_MAX, c + 1)
    m_freq[key] = (c, _epoch(snapshot))
    return c


def _ghost_add(snapshot, key):
    # Insert/update MRU in B1 and trim to capacity
    if key in m_B1:
        m_B1.pop(key, None)
    m_B1[key] = snapshot.access_count
    cap = max(1, GHOST_MULT * max(1, m_cap_est))
    while len(m_B1) > cap:
        m_B1.popitem(last=False)  # drop LRU in ghost


def _promote_to_Am(key):
    # Move key to Am MRU
    if key in m_A1in:
        m_A1in.pop(key, None)
    if key in m_Am:
        m_Am.pop(key, None)
    m_Am[key] = None
    m_seg[key] = 2


def _place_in_A1in(key):
    if key in m_Am:
        m_Am.pop(key, None)
    if key in m_A1in:
        m_A1in.pop(key, None)
    m_A1in[key] = None
    m_seg[key] = 1


def _sync_residents(snapshot):
    """
    Ensure our segment metadata matches actual residents.
    This is lightweight and only touches discrepancies.
    """
    # Remove any keys we still track that are no longer resident
    if m_seg and len(m_seg) != len(snapshot.cache):
        for k in list(m_A1in.keys()):
            if k not in snapshot.cache:
                m_A1in.pop(k, None)
                m_seg.pop(k, None)
        for k in list(m_Am.keys()):
            if k not in snapshot.cache:
                m_Am.pop(k, None)
                m_seg.pop(k, None)
    # Add any resident keys we didn't see before (treat as probationary)
    if len(m_seg) != len(snapshot.cache):
        for k in snapshot.cache.keys():
            if k not in m_seg:
                _place_in_A1in(k)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose eviction victim:
      - Prefer LRU from probationary (A1in)
      - If empty, evict LRU from main (Am)
    """
    global m_cap_est
    m_cap_est = max(m_cap_est, len(cache_snapshot.cache))

    _sync_residents(cache_snapshot)

    # If A1in has any entries, evict its LRU (1-hit likely)
    if m_A1in:
        victim_key = next(iter(m_A1in))  # LRU
        return victim_key
    # Otherwise evict LRU from Am
    if m_Am:
        victim_key = next(iter(m_Am))
        return victim_key
    # Fallback: any resident key
    for k in cache_snapshot.cache.keys():
        return k
    return None


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment tiny frequency
      - If in A1in, promote to Am (second touch)
      - If in Am, refresh MRU
      - If untracked (rare), place in Am (since it's a hit)
    """
    k = obj.key
    _freq_inc(cache_snapshot, k)

    if k in m_A1in:
        m_A1in.pop(k, None)
        _promote_to_Am(k)
    elif k in m_Am:
        # Refresh recency in Am
        m_Am.pop(k, None)
        m_Am[k] = None
        m_seg[k] = 2
    else:
        # Safety: a hit implies residency; ensure tracked and protected
        _promote_to_Am(k)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Increment tiny frequency
      - Admission:
          * If key in ghost B1 OR freq >= 2 -> admit to Am (protected)
          * Else -> admit to A1in (probationary)
      - Trim ghost B1 if needed
      - Update capacity estimate
    """
    global m_cap_est
    k = obj.key
    c = _freq_inc(cache_snapshot, k)

    if k in m_B1 or c >= 2:
        m_B1.pop(k, None)
        _promote_to_Am(k)
    else:
        _place_in_A1in(k)

    m_cap_est = max(m_cap_est, len(cache_snapshot.cache))

    # Keep ghost bounded
    cap = max(1, GHOST_MULT * max(1, m_cap_est))
    while len(m_B1) > cap:
        m_B1.popitem(last=False)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After victim is evicted:
      - Remove from its resident segment
      - If it was in A1in, add to B1 ghost (recency history)
      - If from Am, drop quietly
    """
    ek = evicted_obj.key
    seg = m_seg.pop(ek, 0)

    if seg == 1 or ek in m_A1in:
        m_A1in.pop(ek, None)
        _ghost_add(cache_snapshot, ek)
    else:
        m_Am.pop(ek, None)
```
2025-11-27 20:44:14,726 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 20
- Hit Rate: 0.4228

Example 2:
- Trace ID: 29
- Hit Rate: 0.0386

Example 3:
- Trace ID: 24
- Hit Rate: 0.286

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:44:14 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:44:14,727 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:47:06 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:47:06,366 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:47:06,367 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive Size-Aware TinyLFU with Two-Hit Promotion (A-SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style
# - Two-hit promotion: items must be hit twice as residents before entering protected
# - Stronger size-awareness: favors evicting large, low-value objects first
# - Belady-ish reuse modeling: EMA of inter-arrival time (IRT) to predict next reuse
# - Adaptive protected fraction based on recent per-segment hit mix
# - Protected segment is rebalanced fully (not just one demotion) when oversized
# - Victim selection considers value-per-byte density, not just raw score
#
# Policy summary:
#   value = freq_term(size-aware) + recency_term + predicted_reuse_term + burst_shield
#   density = value / (size_norm ** DENSITY_ALPHA)  # prefer evicting large, low-value objs
#   Evict the resident with the smallest density, preferring probation unless protected is oversized
#
# Notes:
# - TinyLFU counters are lazily decayed by epoch; they persist across evictions.
# - Metadata is maintained on hit/insert/evict; protected bytes are tracked by bytes.
# - The policy aims to reduce miss rate across diverse traces (scans, heavy skew, mixes).

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
g_protected_bytes = 0      # running total of bytes in protected
g_target_protected_frac = 0.72  # adaptive target starts moderate

# Recency/adaptation accounting per epoch
g_epoch_id = -1
g_epoch_prob_hits = 0
g_epoch_prot_hits = 0

# -----------------------------
# Tunables
# -----------------------------

# Size awareness
SIZE_ALPHA = 1.15          # penalize very large objects more (in freq term)
DENSITY_ALPHA = 0.55       # >0 biases victim choice toward evicting large, low-value objs

# Frequency shaping
FREQ_GAMMA = 1.00          # exponent for frequency -> value mapping
MULTI_HIT_BONUS = 0.60     # extra benefit for items with >=2 resident hits (frequency shaping)

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.90
W_REC_PROT = 0.25
W_PRED_PROB = 0.45
W_PRED_PROT = 0.20

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.45        # react reasonably fast to changing reuse

# Burst shield to avoid evicting items hit in a very short burst
BURST_SHIELD_AGE = 2       # accesses
BURST_SHIELD_BONUS = 0.40  # additional value if last access was very recent

# Adaptation of protected fraction by epoch
ADAPT_STEP = 0.02
PROT_FRAC_MIN = 0.50
PROT_FRAC_MAX = 0.90

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)
    _maybe_adapt_segments(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(g_target_protected_frac * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access_time) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _rebalance_protected_bytes(cache_snapshot):
    # If protected exceeds its target, demote oldest protected items until under target
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    while g_protected_bytes > target:
        key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
        if key is None:
            break
        obj = cache_snapshot.cache.get(key)
        if obj is None:
            # Already gone
            m_segment[key] = 0
            continue
        # Demote to probation
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
        m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _value_density(cache_snapshot, key):
    # Higher density -> stronger retention; select victim with smallest density
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return 0.0

    size_norm = _normalized_size(robj.size, cap)
    # Frequency component (decayed + resident-hit shaping), size-aware
    freq = float(_lfu_peek(cache_snapshot, key))
    rhits = m_resident_hits.get(key, 1)
    freq_shaped = max(0.0, freq) + (MULTI_HIT_BONUS if rhits >= 2 else 0.0)
    freq_term = (freq_shaped ** FREQ_GAMMA) / (size_norm ** SIZE_ALPHA)

    # Recency and predicted reuse components (bounded in [0,1] weights)
    window = _recency_window(cache_snapshot)
    last = m_last_access.get(key)
    if last is None:
        age = window
    else:
        age = max(0, now - last)

    # Smoothly decaying recency value: recent (small age) -> near w_rec; old -> ~0
    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_term = w_rec * (1.0 / (1.0 + float(age) / float(window)))

    # Predicted reuse via EMA of IRT: smaller IRT -> larger value
    irt = m_irt.get(key, float(window))
    predicted_term = w_pred * (1.0 / (1.0 + float(irt) / float(window)))

    # Burst shield for very recent reuses (avoid ejecting items in a small burst)
    burst_bonus = BURST_SHIELD_BONUS if age <= BURST_SHIELD_AGE else 0.0

    value = freq_term + recency_term + predicted_term + burst_bonus

    # Value-per-byte density: divide by size exponent to prefer dropping large, low-value items
    density = value / (size_norm ** DENSITY_ALPHA)
    return density

def _select_victim_in_segment(cache_snapshot, seg_id):
    # Returns (key, density, last_access) with minimal density in specified segment
    min_key = None
    min_density = None
    min_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != seg_id:
            continue
        density = _value_density(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if (min_key is None) or (density < min_density) or (density == min_density and last < min_time):
            min_key = k
            min_density = density
            min_time = last
    return min_key, min_density, min_time

# -----------------------------
# Adaptation
# -----------------------------

def _maybe_adapt_segments(cache_snapshot):
    # Adapt target protected fraction based on hit mix in the last epoch window
    global g_epoch_id, g_epoch_prob_hits, g_epoch_prot_hits, g_target_protected_frac
    cur_epoch = _current_epoch(cache_snapshot)
    if cur_epoch == g_epoch_id:
        return
    # On epoch boundary: adapt
    total_hits = g_epoch_prob_hits + g_epoch_prot_hits
    if total_hits >= 64:  # need some signal
        prob_ratio = float(g_epoch_prob_hits) / float(total_hits)
        # If many hits are in probation -> we want a bit more protected room (to retain once proven)
        if prob_ratio > 0.60:
            g_target_protected_frac = min(PROT_FRAC_MAX, g_target_protected_frac + ADAPT_STEP)
        elif prob_ratio < 0.35:
            # Protected likely too large / stale -> give more room to probation to explore
            g_target_protected_frac = max(PROT_FRAC_MIN, g_target_protected_frac - ADAPT_STEP)
    # Reset counters for the new epoch
    g_epoch_id = cur_epoch
    g_epoch_prob_hits = 0
    g_epoch_prot_hits = 0

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Fully rebalance protected by demoting oldest until at/below target
      - Prefer evicting from probation, but if protected is oversized, allow either segment
      - Choose the resident with the smallest value density
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Keep protected near its adaptive target
    _rebalance_protected_bytes(cache_snapshot)

    # Select victims
    prob_k, prob_d, prob_t = _select_victim_in_segment(cache_snapshot, seg_id=0)
    prot_k, prot_d, prot_t = _select_victim_in_segment(cache_snapshot, seg_id=1)

    if prob_k is None and prot_k is None:
        # Fallback: empty cache
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    target = _protected_target_bytes(cache_snapshot)
    # If protected is within target, prefer probation victim
    if g_protected_bytes <= target:
        if prob_k is not None:
            return prob_k
        else:
            return prot_k

    # Protected oversized: choose globally weakest (smallest density) across both segments
    if prob_k is None:
        return prot_k
    if prot_k is None:
        return prob_k

    # Compare densities; break ties by older last-access time
    if prot_d < prob_d:
        return prot_k
    if prob_d < prot_d:
        return prob_k
    # Tie: older loses
    return prob_k if prob_t <= prot_t else prot_k


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last access and IRT EMA
      - Increment resident hit count
      - Count hit per segment for adaptation BEFORE any promotion
      - Two-hit promotion: if in probation and resident_hits >= 2, promote to protected
      - Fully rebalance protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    last = m_last_access.get(k)
    if last is not None:
        delta = max(1, now - last)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize IRT conservatively
        m_irt[k] = float(_recency_window(cache_snapshot))

    # Segment counting for adaptation BEFORE promotion
    seg_before = _segment_of(k)
    global g_epoch_prob_hits, g_epoch_prot_hits
    if seg_before == 1:
        g_epoch_prot_hits += 1
    else:
        g_epoch_prob_hits += 1

    # Update resident metadata
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Two-hit promotion policy
    if seg_before == 0 and m_resident_hits[k] >= 2:
        m_segment[k] = 1
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (may demote multiple)
    _rebalance_protected_bytes(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default based on current working set
    m_irt[k] = float(_recency_window(cache_snapshot))
    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    if _segment_of(ek) == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU and IRT -> optional, but IRT is resident-based; reset)
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU preserves non-resident frequency
```
2025-11-27 20:48:07,839 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Dynamic WTinyLFU + GDS with Gated Promotion and Size-Sensitive Admission (DTinyLFU-GDS+)
# - Three components:
#   1) TinyLFU (Count-Min Sketch) for long-term frequency estimation (size-aware scoring)
#   2) Window segment W (recency-biased) that admits all new items (scan-resilient)
#   3) Main segment M (frequency- and size-aware) using GreedyDual-Size (GDS) with TinyLFU scores
#
# Key improvements over baseline:
#   - Size-sensitive scoring est / size^alpha (alpha ~ 0.85) to better balance large objects
#   - Admission decision uses consistent GDS terms: compare H_in = L + score_in vs min(H_M)
#   - Gated promotion: a hit in W promotes to M only if its H_in surpasses current M min(H)
#     (reduces pollution of M and improves scan resistance)
#   - Large-object streaming guard: very large, low-frequency newcomers favor evicting from W
#   - Ghost-biased admission: if newcomer present in M-ghost, bias to admit (evict from M);
#     if in W-ghost, bias to protect recency (evict from W)
#   - Safer window target clamping; consistent byte accounting; better tie-breaking
#
# Eviction:
#   - Evict from W if W exceeds its adaptive target, or large-object streaming guard triggers.
#   - Otherwise compute H_incoming and compare to main's minimum H:
#       * If H_incoming <= min(H_M) => evict from W (protect M)
#       * Else evict from M
#   - Within W: LRU. Within M: evict min H (GDS). Ties broken by LRU.
#
# Updates:
#   - On every access (hit or miss), increment TinyLFU.
#   - On hit in W: gated promotion to M if strong enough; otherwise remain in W.
#   - On hit in M: refresh its GDS priority H = L_M + score.
#   - On insert: admit to W; adapt W target using ARC-like ghosts.
#   - On evict: if M victim, set L_M to victim's H (GDS aging); record ghosts.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_priority = dict()      # key -> float priority H (only meaningful for M)
m_key_last_access = dict()   # key -> int access_count (for LRU tie-breaks)
m_key_segment = dict()       # key -> 'W' (window) or 'M' (main)

# Main segment GreedyDual age
m_age_M = 0.0

# Current resident bytes per segment
m_bytes_W = 0
m_bytes_M = 0

# Adaptive target for window bytes (W); M target = capacity - target_W
m_target_W_bytes = None

# Ghost lists for ARC-like adaptation of W/M split; store key -> (size, last_time)
m_ghost_W = dict()
m_ghost_M = dict()
m_ghost_W_bytes = 0
m_ghost_M_bytes = 0
m_ghost_limit_bytes = None

# -----------------------------
# TinyLFU (Count-Min Sketch)
# -----------------------------
m_cm_depth = None
m_cm_width = None
m_cm_mask = None
m_cm = None                 # 2D list: depth x width
m_cm_seeds = None
m_cm_inserts = 0
m_cm_sample = None          # when total increments exceed this, perform aging (halve)

# -----------------------------
# Tunables
# -----------------------------
SIZE_ALPHA = 0.85                  # exponent for size-aware score: est / size^alpha
MIN_SIZE_UNIT = 1                  # minimum divisor in bytes to avoid div-by-zero
LARGE_OBJ_FRAC = 0.25              # fraction of capacity considered "very large"
LARGE_OBJ_FREQ_CUTOFF = 2          # TinyLFU estimate threshold to consider "hot"
ADMIT_BIAS = 0.10                  # +/-10% bias based on ghosts when comparing H_in vs min(H_M)

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)

def _init_if_needed(cache_snapshot):
    # Initialize capacity-dependent variables lazily
    global m_target_W_bytes, m_ghost_limit_bytes
    global m_cm_depth, m_cm_width, m_cm_mask, m_cm, m_cm_seeds, m_cm_sample

    cap = cache_snapshot.capacity
    if m_target_W_bytes is None:
        # Start with a modest window (10% of capacity), typical for WTinyLFU
        m_target_W_bytes = cap * 0.10
    if m_ghost_limit_bytes is None:
        # Each ghost list limited to approximately the cache capacity in bytes
        m_ghost_limit_bytes = cap

    # Initialize TinyLFU CM sketch parameters once
    if m_cm is None:
        m_cm_depth = 4
        # Width tuned by capacity; enforce power-of-two for fast masking
        base = 4096
        try:
            # scale to ~2^k with k ~ [11..14] based on capacity bits
            scaled_pow = max(11, min(14, (cap.bit_length() - 6)))
            width = 1 << scaled_pow
        except Exception:
            width = base
        m_cm_width = _clamp(width, 2048, 16384)
        # round to power of two
        pw = 1
        while pw < m_cm_width:
            pw <<= 1
        m_cm_width = pw
        m_cm_mask = m_cm_width - 1
        m_cm = [[0] * m_cm_width for _ in range(m_cm_depth)]
        # Fixed seeds for hash mixing
        m_cm_seeds = [0x27d4eb2d, 0x85ebca6b, 0xc2b2ae35, 0x165667b1]
        # Sampling window before aging
        m_cm_sample = m_cm_width * 20  # e.g., 4096*20 = 81,920 increments between halvings

def _hash_idx(seed, key_str):
    # Simple mixed hash -> index [0..width-1]
    h = hash(str(seed) + '|' + key_str)
    return h & m_cm_mask

def _cm_increment(key, delta=1):
    # Increment TinyLFU counters for key; perform periodic aging
    global m_cm_inserts
    if m_cm is None:
        return
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key)
        # Saturate at a large value to avoid overflow
        if m_cm[d][idx] < 0x7fffffff:
            m_cm[d][idx] += delta
    m_cm_inserts += delta
    if m_cm_inserts >= (m_cm_sample or 1):
        # Halve all counters (right shift by 1) to age history
        for d in range(m_cm_depth):
            row = m_cm[d]
            for i in range(m_cm_width):
                row[i] >>= 1
        m_cm_inserts >>= 1  # approximate total after halving

def _cm_estimate(key):
    if m_cm is None:
        return 0
    est = None
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key)
        val = m_cm[d][idx]
        est = val if est is None else (val if val < est else est)
    return est or 0

def _score_freq_size(key, size):
    # Size-aware frequency score: est_freq / size^alpha
    if size <= 0:
        return 0.0
    denom = max(MIN_SIZE_UNIT, float(size)) ** float(SIZE_ALPHA)
    est = _cm_estimate(key)
    if est <= 0:
        return 0.0
    return float(est) / denom

def _pick_oldest_in_segment(cache_snapshot, seg_tag):
    # Returns (key, last_time) of the oldest (LRU) key in a segment
    oldest_key = None
    oldest_time = None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != seg_tag:
            continue
        last = m_key_last_access.get(key, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = key
    return (oldest_key, oldest_time)

def _pick_min_in_main(cache_snapshot):
    # Returns (key, prio, last_time) of the minimum-priority key in main (M)
    min_key = None
    min_prio = None
    min_time = None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != 'M':
            continue
        prio = m_key_priority.get(key)
        if prio is None:
            obj = cache_snapshot.cache.get(key)
            if obj is None:
                continue
            prio = m_age_M + _score_freq_size(key, obj.size)
            m_key_priority[key] = prio
        last = m_key_last_access.get(key, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_prio = prio
            min_time = last
            min_key = key
    return (min_key, min_prio, min_time)

def _ghost_add(ghost_dict, key, size, time_now, is_W):
    # Add key->(size, time) to chosen ghost, trimming if exceeds limit
    global m_ghost_W_bytes, m_ghost_M_bytes, m_ghost_limit_bytes

    if is_W:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_W_bytes += size
        else:
            old_size, _ = prev
            m_ghost_W_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_W_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_W_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_M_bytes += size
        else:
            old_size, _ = prev
            m_ghost_M_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_M_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_M_bytes -= sz

def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation of window target based on which ghost contains the new key
    global m_ghost_W, m_ghost_M, m_ghost_W_bytes, m_ghost_M_bytes, m_target_W_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Step sized by object size; clamp to [1%, 10%] of capacity to avoid huge jumps
    step = _clamp(obj.size, int(0.01 * cap), int(0.10 * cap))

    if obj.key in m_ghost_W:
        # Recency pressure ↑ => increase window size target
        m_target_W_bytes = _clamp(m_target_W_bytes + step, 0, cap)
        sz, _ = m_ghost_W.pop(obj.key)
        m_ghost_W_bytes -= sz
    elif obj.key in m_ghost_M:
        # Frequency pressure ↑ => decrease window, giving more to main
        m_target_W_bytes = _clamp(m_target_W_bytes - step, 0, cap)
        sz, _ = m_ghost_M.pop(obj.key)
        m_ghost_M_bytes -= sz

def _prefer_w_due_to_large_stream(cache_snapshot, obj):
    # For very large, low-frequency objects that are not hinted by M-ghost, prefer to evict from W
    cap = cache_snapshot.capacity or 1
    large = obj.size >= int(cap * LARGE_OBJ_FRAC)
    if not large:
        return False
    # If it's not frequent and not seen in M-ghost before, treat as likely stream
    if _cm_estimate(obj.key) < LARGE_OBJ_FREQ_CUTOFF and (obj.key not in m_ghost_M):
        return True
    return False

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using DTinyLFU-GDS+ policy:
      - Evict from W if W exceeds its adaptive target (recency window) or large-object stream guard triggers.
      - Else compute H_incoming and compare to M's weakest H:
          * If H_incoming <= weakest main H (after ghost bias) => evict from W (protect M)
          * Else evict from M
      - Within W: LRU. Within M: evict min H (GDS). Ties use LRU.
    '''
    global m_bytes_W, m_bytes_M, m_target_W_bytes

    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    # Clamp window target to [1% cap, 50% cap]
    min_w = int(max(1, cap * 0.01))
    max_w = int(cap * 0.50)
    target_W = int(_clamp(int(m_target_W_bytes), min_w, max_w))

    # Candidates
    w_key, _ = _pick_oldest_in_segment(cache_snapshot, 'W')
    m_key, m_prio, _ = _pick_min_in_main(cache_snapshot)

    # If nothing to evict, fallback to global LRU
    if w_key is None and m_key is None:
        min_key, min_time = None, None
        for key in cache_snapshot.cache.keys():
            t = m_key_last_access.get(key, -1)
            if min_time is None or t < min_time:
                min_key, min_time = key, t
        return min_key if min_key is not None else next(iter(cache_snapshot.cache))

    # Prefer evicting from W when it exceeds target or large streaming guard applies
    if (m_bytes_W > target_W and w_key is not None) or _prefer_w_due_to_large_stream(cache_snapshot, obj):
        return w_key if w_key is not None else m_key

    # If one segment is empty, evict from the other
    if w_key is None:
        return m_key
    if m_key is None:
        return w_key

    # Admission decision based on GDS-consistent comparison
    incoming_score = _score_freq_size(obj.key, obj.size)
    H_incoming = m_age_M + incoming_score

    # Ghost-based bias: if in M-ghost, bias towards admitting (evict M); if in W-ghost, bias to protect W
    bias = 0.0
    if obj.key in m_ghost_M:
        bias += ADMIT_BIAS
    if obj.key in m_ghost_W:
        bias -= ADMIT_BIAS
    # Apply bias by stretching/shrinking the threshold (min H)
    threshold = m_prio * (1.0 - bias)

    # If incoming not strong enough, protect main by evicting from window
    if H_incoming <= threshold:
        return w_key
    else:
        return m_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU
      - If in window (W), gated promotion to main (M) if H_incoming > min(H_M)
      - In main (M), refresh its GDS priority H = L_M + est_freq/size^alpha
      - Refresh last-access time
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_age_M, m_bytes_W, m_bytes_M

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Record access in TinyLFU
    _cm_increment(k, 1)

    # Update last access time
    m_key_last_access[k] = cache_snapshot.access_count

    seg = m_key_segment.get(k)
    if seg == 'W':
        # Gated promotion: move to M only if H_incoming surpasses current min in M
        H_incoming = m_age_M + _score_freq_size(k, sz)
        m_key, m_prio, _ = _pick_min_in_main(cache_snapshot)
        # If M empty or newcomer stronger than weakest M item, promote
        should_promote = (m_key is None) or (H_incoming > m_prio)
        if should_promote:
            m_key_segment[k] = 'M'
            # Adjust bytes
            m_bytes_W = max(0, m_bytes_W - sz)
            m_bytes_M += sz
            # Set main priority
            m_key_priority[k] = H_incoming
        else:
            # Stay in W; no priority in W
            m_key_priority.pop(k, None)
    else:
        # Already in main: refresh priority with current TinyLFU estimate
        m_key_priority[k] = m_age_M + _score_freq_size(k, sz)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU (record this access)
      - Adapt the W/M byte split using ARC-like ghosts
      - Admit the new object into window (W)
      - Record last access
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_bytes_W

    _init_if_needed(cache_snapshot)

    k = obj.key
    sz = obj.size

    # Record this access in TinyLFU
    _cm_increment(k, 1)

    # Adapt window target based on ghosts
    _adapt_targets_on_insert(cache_snapshot, obj)

    # Initialize metadata in window
    m_key_segment[k] = 'W'
    m_key_last_access[k] = cache_snapshot.access_count
    # No priority needed in W; clear any stale
    m_key_priority.pop(k, None)

    # Account bytes in window
    m_bytes_W += sz


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - If victim was in main (M), set L_M to victim's priority (GreedyDual aging)
      - Remove resident metadata
      - Update segment byte counters
      - Add the key to the corresponding ghost list to guide future adaptation
    '''
    global m_key_priority, m_key_last_access, m_key_segment
    global m_age_M, m_bytes_W, m_bytes_M
    global m_ghost_W, m_ghost_M

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'W')  # default to window if unknown
    # Use stored priority for main; if missing, approximate using current age + TinyLFU score
    if seg == 'M':
        evicted_prio = m_key_priority.get(ek)
        if evicted_prio is None:
            evicted_prio = m_age_M + _score_freq_size(ek, esz)
        # Age update for main
        m_age_M = evicted_prio

    # Cleanup resident metadata
    m_key_priority.pop(ek, None)
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust bytes and add to appropriate ghost
    if seg == 'M':
        m_bytes_M = max(0, m_bytes_M - esz)
        _ghost_add(m_ghost_M, ek, esz, cache_snapshot.access_count, is_W=False)
    else:
        m_bytes_W = max(0, m_bytes_W - esz)
        _ghost_add(m_ghost_W, ek, esz, cache_snapshot.access_count, is_W=True)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 43
- Hit Rate: 0.2333

Example 2:
- Trace ID: 15
- Hit Rate: 0.0187

Example 3:
- Trace ID: 47
- Hit Rate: 0.049

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:48:07 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:48:07,840 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:50:20 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:50:20,849 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:50:20,851 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Improved policy: W-TinyLFU with direct admission to Main (GDS-aged), gated promotion, and gentle ARC-style split adaptation.
# Key changes vs previous:
#   - Direct admission: On insert, if H_incoming > min(H_M), admit directly into Main (M) with priority (do not force it through Window).
#   - Stable, gentler window sizing: 5%..30% with 2% step using ghosts (prevents oscillations).
#   - Fix priority calculation: never inflate M priorities lazily; use stored m_key_priority or fall back to m_age_M (weak).
#   - Safer eviction choice: protect M unless incoming is strong; if M empty, prefer W unless W is empty.
#   - Better gated promotion: on W-hit, promote to M if strong (or if W above target).
#   - Size-aware TinyLFU score with stronger large-object penalty; streaming guard for huge cold items.

# -----------------------------
# Global metadata
# -----------------------------
m_key_priority = dict()      # key -> float H (only meaningful for M)
m_key_last_access = dict()   # key -> int (LRU timestamp)
m_key_segment = dict()       # key -> 'W' or 'M'

m_age_M = 0.0                # GreedyDual global age for M

m_bytes_W = 0
m_bytes_M = 0

m_target_W_bytes = None      # adaptive window target (bytes)

# Ghost lists: key -> (size, time)
m_ghost_W = dict()
m_ghost_M = dict()
m_ghost_W_bytes = 0
m_ghost_M_bytes = 0
m_ghost_limit_bytes = None

# -----------------------------
# TinyLFU (Count-Min Sketch)
# -----------------------------
m_cm_depth = None
m_cm_width = None
m_cm_mask = None
m_cm = None
m_cm_seeds = None
m_cm_inserts = 0
m_cm_sample = None

# -----------------------------
# Tunables
# -----------------------------
# Size-aware TinyLFU
SIZE_ALPHA = 0.92
MIN_SIZE_UNIT = 512          # normalize sizes ~KiB to avoid over-favoring tiny keys

# Window sizing
WIN_MIN_FRAC = 0.05
WIN_MAX_FRAC = 0.30
ADAPT_STEP_FRAC = 0.02       # per-ghost hit step (bytes)
ADMIT_BIAS = 0.05            # ghost bias on admission comparison

# Large-object streaming guard
LARGE_OBJ_FRAC = 0.20
LARGE_OBJ_FREQ_CUTOFF = 3

# -----------------------------
# Helpers
# -----------------------------
def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)

def _init_if_needed(cache_snapshot):
    global m_target_W_bytes, m_ghost_limit_bytes
    global m_cm_depth, m_cm_width, m_cm_mask, m_cm, m_cm_seeds, m_cm_sample

    cap = max(1, int(cache_snapshot.capacity))
    if m_target_W_bytes is None:
        m_target_W_bytes = int(cap * 0.20)  # start at 20%
    if m_ghost_limit_bytes is None:
        m_ghost_limit_bytes = cap

    if m_cm is None:
        m_cm_depth = 4
        # width: power-of-two scaled by capacity bits, clamped
        try:
            scaled_pow = max(11, min(14, (cap.bit_length() - 5)))
            width = 1 << scaled_pow
        except Exception:
            width = 4096
        width = _clamp(width, 2048, 16384)
        pw = 1
        while pw < width:
            pw <<= 1
        m_cm_width = pw
        m_cm_mask = m_cm_width - 1
        m_cm = [[0] * m_cm_width for _ in range(m_cm_depth)]
        m_cm_seeds = [0x27d4eb2d, 0x85ebca6b, 0xc2b2ae35, 0x165667b1]
        m_cm_sample = m_cm_width * 20

def _hash_idx(seed, key_str):
    # Use Python's hash mixed with seed; masked to width
    return hash(str(seed) + '|' + key_str) & m_cm_mask

def _cm_increment(key, delta=1):
    global m_cm_inserts
    if m_cm is None:
        return
    key_s = str(key)
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key_s)
        if m_cm[d][idx] < 0x7fffffff:
            m_cm[d][idx] += delta
    m_cm_inserts += delta
    if m_cm_inserts >= (m_cm_sample or 1):
        # age all counters by halving
        for d in range(m_cm_depth):
            row = m_cm[d]
            for i in range(m_cm_width):
                row[i] >>= 1
        m_cm_inserts >>= 1

def _cm_estimate(key):
    if m_cm is None:
        return 0
    key_s = str(key)
    est = None
    for d in range(m_cm_depth):
        idx = _hash_idx(m_cm_seeds[d], key_s)
        v = m_cm[d][idx]
        est = v if est is None else (v if v < est else est)
    return est or 0

def _score_freq_size(key, size):
    if size <= 0:
        return 0.0
    denom = max(float(MIN_SIZE_UNIT), float(size)) ** float(SIZE_ALPHA)
    est = _cm_estimate(key)
    if est <= 0:
        return 0.0
    return float(est) / denom

def _pick_oldest_in_segment(cache_snapshot, seg_tag):
    oldest_key, oldest_time = None, None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != seg_tag:
            continue
        t = m_key_last_access.get(key, -1)
        if oldest_time is None or t < oldest_time:
            oldest_time = t
            oldest_key = key
    return (oldest_key, oldest_time)

def _pick_min_in_main(cache_snapshot):
    # Return the minimum H in M using stored priority; missing priority => treat as weak m_age_M.
    min_key, min_prio, min_time = None, None, None
    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key) != 'M':
            continue
        prio = m_key_priority.get(key, m_age_M)  # do NOT inflate by recomputing score
        last = m_key_last_access.get(key, -1)
        if (min_prio is None) or (prio < min_prio) or (prio == min_prio and last < min_time):
            min_key, min_prio, min_time = key, prio, last
    return (min_key, min_prio, min_time)

def _ghost_add(ghost_dict, key, size, time_now, is_W):
    global m_ghost_W_bytes, m_ghost_M_bytes, m_ghost_limit_bytes

    if is_W:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_W_bytes += size
        else:
            old_size, _ = prev
            m_ghost_W_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_W_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_W_bytes -= sz
    else:
        prev = ghost_dict.get(key)
        if prev is None:
            ghost_dict[key] = (size, time_now)
            m_ghost_M_bytes += size
        else:
            old_size, _ = prev
            m_ghost_M_bytes += max(0, size - old_size)
            ghost_dict[key] = (size, time_now)
        # trim
        while m_ghost_M_bytes > (m_ghost_limit_bytes or 0):
            oldest_key, oldest_time = None, None
            for k, (_, t) in ghost_dict.items():
                if oldest_time is None or t < oldest_time:
                    oldest_key, oldest_time = k, t
            if oldest_key is None:
                break
            sz, _ = ghost_dict.pop(oldest_key)
            m_ghost_M_bytes -= sz

def _adapt_targets_on_insert(cache_snapshot, obj):
    global m_target_W_bytes, m_ghost_W, m_ghost_M, m_ghost_W_bytes, m_ghost_M_bytes

    _init_if_needed(cache_snapshot)
    cap = max(1, cache_snapshot.capacity)

    step = int(max(1, cap * ADAPT_STEP_FRAC))
    if obj.key in m_ghost_W:
        # Increase window (recency pressure)
        m_target_W_bytes = _clamp(int(m_target_W_bytes) + step, int(cap * WIN_MIN_FRAC), int(cap * WIN_MAX_FRAC))
        sz, _ = m_ghost_W.pop(obj.key)
        m_ghost_W_bytes -= sz
    elif obj.key in m_ghost_M:
        # Decrease window (frequency pressure)
        m_target_W_bytes = _clamp(int(m_target_W_bytes) - step, int(cap * WIN_MIN_FRAC), int(cap * WIN_MAX_FRAC))
        sz, _ = m_ghost_M.pop(obj.key)
        m_ghost_M_bytes -= sz

def _prefer_w_due_to_large_stream(cache_snapshot, obj):
    cap = max(1, cache_snapshot.capacity)
    large = obj.size >= int(cap * LARGE_OBJ_FRAC)
    if not large:
        return False
    # Not frequent and not historically frequent (not in M-ghost)
    if _cm_estimate(obj.key) < LARGE_OBJ_FREQ_CUTOFF and (obj.key not in m_ghost_M):
        return True
    return False

def _window_target_bytes(cache_snapshot):
    cap = max(1, cache_snapshot.capacity)
    lo = int(max(1, cap * WIN_MIN_FRAC))
    hi = int(max(lo, cap * WIN_MAX_FRAC))
    return int(_clamp(int(m_target_W_bytes or lo), lo, hi))

# -----------------------------
# Policy entry points
# -----------------------------
def evict(cache_snapshot, obj):
    """
    Choose an eviction victim:
      - If W exceeds its target or a large streaming guard triggers, evict from W (LRU).
      - Else compute H_incoming = age_M + score(key,size). Compare to min(H_M) with ghost bias:
          * If H_incoming <= threshold => evict from W (protect M)
          * Else evict from M (GDS: min H). If M empty, fallback to W.
    """
    global m_bytes_W, m_bytes_M

    _init_if_needed(cache_snapshot)

    target_W = _window_target_bytes(cache_snapshot)

    w_key, _ = _pick_oldest_in_segment(cache_snapshot, 'W')
    m_key, m_prio, _ = _pick_min_in_main(cache_snapshot)

    # Fallback if no metadata available
    if w_key is None and m_key is None:
        # Global LRU
        min_key, min_time = None, None
        for key in cache_snapshot.cache.keys():
            t = m_key_last_access.get(key, -1)
            if min_time is None or t < min_time:
                min_key, min_time = key, t
        return min_key if min_key is not None else next(iter(cache_snapshot.cache))

    # Enforce W target and streaming guard
    if (m_bytes_W > target_W and w_key is not None) or _prefer_w_due_to_large_stream(cache_snapshot, obj):
        return w_key if w_key is not None else (m_key if m_key is not None else w_key)

    # If one side empty, take the other
    if w_key is None:
        return m_key
    if m_key is None:
        return w_key

    # Admission compare
    H_incoming = m_age_M + _score_freq_size(obj.key, obj.size)

    # Ghost bias (slight)
    bias = 0.0
    if obj.key in m_ghost_M:
        bias += ADMIT_BIAS
    if obj.key in m_ghost_W:
        bias -= ADMIT_BIAS
    threshold = m_prio * (1.0 - bias)

    if H_incoming <= threshold:
        return w_key
    else:
        return m_key

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU
      - Update last access
      - If in W: promote to M if strong (H_incoming > min(H_M)) or W is over target
      - If in M: refresh its H = age_M + score
    """
    global m_key_priority, m_key_last_access, m_key_segment
    global m_age_M, m_bytes_W, m_bytes_M

    _init_if_needed(cache_snapshot)

    k, sz = obj.key, obj.size

    _cm_increment(k, 1)
    m_key_last_access[k] = cache_snapshot.access_count

    seg = m_key_segment.get(k)
    if seg == 'W':
        H_incoming = m_age_M + _score_freq_size(k, sz)
        m_key_min, m_prio_min, _ = _pick_min_in_main(cache_snapshot)
        target_W = _window_target_bytes(cache_snapshot)

        promote = False
        if m_key_min is None:
            # M empty: promote on hit to seed M
            promote = True
        else:
            promote = (H_incoming > m_prio_min) or (m_bytes_W > target_W)

        if promote:
            m_key_segment[k] = 'M'
            # bytes
            m_bytes_W = max(0, m_bytes_W - sz)
            m_bytes_M += sz
            # set priority
            m_key_priority[k] = H_incoming
        else:
            # remain in W
            m_key_priority.pop(k, None)
    else:
        # In main: refresh priority
        m_key_priority[k] = m_age_M + _score_freq_size(k, sz)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU
      - Adapt W/M split using ghosts
      - Direct admission:
          * Compute H_incoming and compare to min(H_M) with ghost bias
          * If stronger, admit directly to M with H; else to W
      - Update last access and byte counters
    """
    global m_key_priority, m_key_last_access, m_key_segment
    global m_bytes_W, m_bytes_M

    _init_if_needed(cache_snapshot)

    k, sz = obj.key, obj.size

    _cm_increment(k, 1)
    _adapt_targets_on_insert(cache_snapshot, obj)

    m_key_last_access[k] = cache_snapshot.access_count

    # Decide segment on admission
    H_incoming = m_age_M + _score_freq_size(k, sz)
    min_key, min_prio, _ = _pick_min_in_main(cache_snapshot)

    # Ghost bias
    bias = 0.0
    if k in m_ghost_M:
        bias += ADMIT_BIAS
    if k in m_ghost_W:
        bias -= ADMIT_BIAS
    threshold = (min_prio if min_prio is not None else float('-inf')) * (1.0 - bias)

    if (min_prio is not None) and (H_incoming > threshold):
        # Admit to M
        m_key_segment[k] = 'M'
        m_key_priority[k] = H_incoming
        m_bytes_M += sz
    else:
        # Admit to W
        m_key_segment[k] = 'W'
        m_key_priority.pop(k, None)
        m_bytes_W += sz

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting:
      - If victim was in M, set age_M to its H (GreedyDual aging)
      - Remove metadata; adjust bytes
      - Record into ghost lists
    """
    global m_key_priority, m_key_last_access, m_key_segment
    global m_age_M, m_bytes_W, m_bytes_M
    global m_ghost_W, m_ghost_M

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esz = evicted_obj.size

    seg = m_key_segment.get(ek, 'W')
    if seg == 'M':
        evicted_prio = m_key_priority.get(ek, m_age_M)
        m_age_M = evicted_prio

    # Cleanup
    m_key_priority.pop(ek, None)
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Bytes and ghosts
    if seg == 'M':
        m_bytes_M = max(0, m_bytes_M - esz)
        _ghost_add(m_ghost_M, ek, esz, cache_snapshot.access_count, is_W=False)
    else:
        m_bytes_W = max(0, m_bytes_W - esz)
        _ghost_add(m_ghost_W, ek, esz, cache_snapshot.access_count, is_W=True)
```
2025-11-27 20:53:40,422 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Policy: HALO-TFSv2 — Heap-Accelerated LFU with Recency, Freshness, and Gap Prediction
# Key improvements over previous version:
# - Stronger recency sensitivity with adaptive windowing
# - Do not credit LFU on cold insert (reduces one-timer pollution)
# - Per-key EWMA of inter-arrival gaps to predict time-to-next access
# - Fresh-insert "grace" multiplier to avoid immediate churn
# - Multi-hit protection is stronger and starts after the second hit
# - Bounded-rescan victim search for better choices without full scans

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_birth_ts = dict()         # key -> int access_count at insertion
m_resident_hits = dict()    # key -> int resident hit count (starts at 0 on insert)
m_gap_ewma = dict()         # key -> float ≈ EWMA of inter-arrival gap while resident

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 2048   # faster adaptation to workload shifts
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192
HEAP_GROWTH_FACTOR = 4

# Tunables for scoring
SIZE_ALPHA = 0.80               # size normalization exponent; favors small objects
REC_WIN_MIN = 64                # minimum recency window in accesses
REC_WIN_MULT = 6                # recency window ~ REC_WIN_MULT * resident_items
FREQ_WEIGHT = 1.00              # weight of frequency (TinyLFU)
REC_WEIGHT = 1.10               # weight of observed recency
PRED_WEIGHT = 0.90              # weight of predicted return risk (via gap EWMA)
MH_MULT = 1.50                  # multiplicative boost after >=2 resident hits
FRESH_GRACE = 128               # accesses; grace period after insert
FRESH_MULT = 1.30               # multiplicative boost during grace
GAP_BETA = 0.30                 # EWMA smoothing factor for inter-arrival gap

# Victim selection
RESCAN_LIMIT = 12               # bounded extra pops from heap to improve victim choice


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # decay is applied lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)


def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _predicted_risk(now, last, gap_ewma, window):
    # Predict time-to-next using EWMA gap. Convert to risk in (0,1].
    if last is None or last < 0 or gap_ewma is None or gap_ewma <= 0.0:
        return 0.0
    age = max(0, now - last)
    ttn = gap_ewma - age  # time until next (can be <= 0 if due/overdue)
    # Map to (0,1], ≈1 when due/overdue, smaller when far in future
    return 1.0 / (1.0 + (max(0.0, ttn) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency and predicted risk
    window = _recency_window(cache_snapshot)
    r_term = _recency_term(now, m_last_access.get(key), window)
    p_term = _predicted_risk(now, m_last_access.get(key), m_gap_ewma.get(key), window)

    # Freshness and multi-hit multipliers
    birth = m_birth_ts.get(key)
    fresh = (1.0 if birth is None else (FRESH_MULT if (now - birth) <= FRESH_GRACE else 1.0))
    mhits = m_resident_hits.get(key, 0)
    mh_mult = (MH_MULT if mhits >= 2 else 1.0)

    # Final score: combine, then size-normalize, then apply multiplicative boosts
    base = (FREQ_WEIGHT * f_term) + (REC_WEIGHT * r_term) + (PRED_WEIGHT * p_term)
    score = (base / size_norm) * fresh * mh_mult
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    - Seed heap on first use
    - Pop and validate entries lazily (versioning)
    - Recompute scores to reflect latest epochs and metadata
    - Bounded rescan: consider a small set of candidates and pick the weakest
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            # Initialize missing resident metadata best-effort
            m_last_access.setdefault(k, cache_snapshot.access_count)
            m_birth_ts.setdefault(k, cache_snapshot.access_count)
            m_resident_hits.setdefault(k, 0)
            m_gap_ewma.setdefault(k, float(_recency_window(cache_snapshot)))
            _heap_push(cache_snapshot, k)

    # Bounded rescan to find the weakest valid candidate
    best_key = None
    best_tuple = None  # (adjusted_score, score_tuple)
    considered = []

    attempts = 0
    while attempts < RESCAN_LIMIT and m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            attempts += 1
            continue
        # Skip if stale heap entry
        if m_ver.get(k, 0) != v:
            attempts += 1
            continue
        # Recompute current score (reflect decay/window/metadata changes)
        cur_sc = _score_key(cache_snapshot, k)
        # If score drifted upward, reinsert with new score
        if cur_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            attempts += 1
            continue

        # Track the weakest (lowest score) candidate
        adj_sc = cur_sc  # adjustment slots available if needed later
        if (best_tuple is None) or (adj_sc < best_tuple[0]):
            best_key = k
            best_tuple = (adj_sc, (sc, last, k, v))
        considered.append((sc, last, k, v))
        attempts += 1

    # Push back all considered entries except the chosen victim
    for tup in considered:
        if best_tuple is not None and tup[2] == best_key:
            continue
        heapq.heappush(m_heap, tup)

    # Fallbacks
    if best_key is not None:
        return best_key

    # If heap is exhausted or empty, choose the oldest resident
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Update EWMA of inter-arrival gap
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Update frequency only on hits (not on cold insert)
    _lfu_inc(cache_snapshot, k)

    # Update inter-arrival EWMA
    prev = m_last_access.get(k)
    if prev is not None:
        gap = max(1.0, float(now - prev))
        old = m_gap_ewma.get(k)
        if old is None or old <= 0.0:
            m_gap_ewma[k] = gap
        else:
            m_gap_ewma[k] = (1.0 - GAP_BETA) * old + GAP_BETA * gap
    else:
        # Initialize conservatively
        m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    # Hits: increment resident hits
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # Refresh timestamps
    m_last_access[k] = now

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch
      - Do NOT increment LFU on cold insert (reduces one-timer pollution)
      - Initialize resident metadata: last_access, birth_ts, resident_hits = 0
      - Initialize EWMA gap conservatively to recency window
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # No _lfu_inc here: cold items must earn credit by hitting

    m_last_access[k] = now
    m_birth_ts[k] = now
    m_resident_hits[k] = 0
    m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember popularity)
      - Invalidate its heap version (stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_birth_ts.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_gap_ewma.pop(ek, None)
    m_ver.pop(ek, None)

    _touch_and_maybe_rebuild(cache_snapshot)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 5
- Hit Rate: 0.4643

Example 2:
- Trace ID: 40
- Hit Rate: 0.0635

Example 3:
- Trace ID: 0
- Hit Rate: 0.4759

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:53:40 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:53:40,424 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:55:58 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:55:58,642 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:55:58,644 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Policy: SPLASH-WTinyARC — Size- and Prediction-aware LFU with Segmented Protection
# Goals:
# - Strong scan resistance: cold inserts get low priority until they prove reuse
# - Protect multi-hit objects in a separate segment (ARC-like probation/protected)
# - Size-aware retention to avoid large-object pollution
# - TinyLFU with lazy decay for popularity memory and fast adaptation
# - EWMA gap prediction to anticipate returns beyond simple recency
# - Heap-accelerated victim choice with bounded rescans

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_birth_ts = dict()         # key -> int access_count at insertion
m_resident_hits = dict()    # key -> int resident hit count (starts at 0 on insert)
m_gap_ewma = dict()         # key -> float ≈ EWMA of inter-arrival gap while resident
m_is_prot = dict()          # key -> bool (True if in protected segment)

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 1536   # a bit faster adaptation to workload shifts
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heaps for eviction: (score, last_access, key, version)
m_heap_prob = []            # probation segment (new/<=1 hit)
m_heap_prot = []            # protected segment (>=2 hits)
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192
HEAP_GROWTH_FACTOR = 4

# Tunables for scoring
SIZE_ALPHA = 0.85               # size normalization exponent; favors small objects
SIZE_FRAC_PEN = 2.5             # additional penalty scaled by size/capacity
REC_WIN_MIN = 64                # minimum recency window in accesses
REC_WIN_MULT = 8                # recency window ~ REC_WIN_MULT * resident_items

# Segment-specific weights
# Probation: bias toward proven popularity, light recency/prediction
P_F_WEIGHT = 1.20
P_R_WEIGHT = 0.60
P_P_WEIGHT = 0.80
# Protected: recency and prediction are more important
Q_F_WEIGHT = 0.80
Q_R_WEIGHT = 1.20
Q_P_WEIGHT = 1.25

# Freshness handling
FRESH_PENALTY0 = 0.55          # multiplicative penalty for 0-hit residents
FRESH_PENALTY1 = 0.90          # multiplicative penalty for exactly 1-hit residents
PROT_MULT = 1.20               # mild multiplicative boost for protected items
MH_PROMOTE_HITS = 2            # promotion threshold into protected

# EWMA of inter-arrival gap
GAP_BETA = 0.30                # smoothing factor for inter-arrival EWMA

# Victim selection
RESCAN_LIMIT = 16              # bounded extra pops from heap to improve victim choice
PROT_DEMOTE_IDLE_MULT = 2.5    # demote from protected if idle > this * predicted gap and weak


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # decay is applied lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)


def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _predicted_risk(now, last, gap_ewma, window):
    # Predict time-to-next using EWMA gap. Convert to risk in (0,1].
    if last is None or last < 0 or gap_ewma is None or gap_ewma <= 0.0:
        return 0.0
    age = max(0, now - last)
    ttn = gap_ewma - age  # time until next (can be <= 0 if due/overdue)
    # Map to (0,1], ≈1 when due/overdue, smaller when far in future
    return 1.0 / (1.0 + (max(0.0, ttn) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA
    cap = max(1.0, float(cache_snapshot.capacity))
    size_pen = 1.0 + SIZE_FRAC_PEN * (size / cap)

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency and predicted risk
    window = _recency_window(cache_snapshot)
    last = m_last_access.get(key)
    r_term = _recency_term(now, last, window)
    p_term = _predicted_risk(now, last, m_gap_ewma.get(key), window)

    # Segment-dependent weights and freshness/boosts
    prot = m_is_prot.get(key, False)
    hits = m_resident_hits.get(key, 0)
    if prot:
        base = (Q_F_WEIGHT * f_term) + (Q_R_WEIGHT * r_term) + (Q_P_WEIGHT * p_term)
        mult = PROT_MULT
    else:
        base = (P_F_WEIGHT * f_term) + (P_R_WEIGHT * r_term) + (P_P_WEIGHT * p_term)
        if hits <= 0:
            mult = FRESH_PENALTY0
        elif hits == 1:
            mult = FRESH_PENALTY1
        else:
            mult = 1.0

    score = (base * mult) / (size_norm * size_pen)
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the appropriate heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    if m_is_prot.get(key, False):
        heapq.heappush(m_heap_prot, (sc, last, key, v))
    else:
        heapq.heappush(m_heap_prob, (sc, last, key, v))


def _maybe_rebuild_heaps(cache_snapshot):
    """Rebuild heaps when they grow too large due to stale entries."""
    global m_heap_prob, m_heap_prot
    n = max(1, len(cache_snapshot.cache))
    if (len(m_heap_prob) + len(m_heap_prot)) <= HEAP_GROWTH_FACTOR * n:
        return

    new_prob = []
    new_prot = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if m_is_prot.get(k, False):
            new_prot.append((sc, last, k, v))
        else:
            new_prob.append((sc, last, k, v))
    heapq.heapify(new_prob)
    heapq.heapify(new_prot)
    m_heap_prob = new_prob
    m_heap_prot = new_prot


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heaps(cache_snapshot)


# -----------------------------
# Victim selection helpers
# -----------------------------

def _seed_metadata_if_needed(cache_snapshot):
    """Seed resident metadata and heaps if empty (bootstrap or after big churn)."""
    if (m_heap_prob or m_heap_prot) or not cache_snapshot.cache:
        return
    now = cache_snapshot.access_count
    window = _recency_window(cache_snapshot)
    default_gap = float(window * 2)  # conservative default
    for k in cache_snapshot.cache.keys():
        m_last_access.setdefault(k, now)
        m_birth_ts.setdefault(k, now)
        hits = m_resident_hits.get(k, 0)
        m_resident_hits[k] = hits
        m_gap_ewma.setdefault(k, default_gap)
        # Protect only if already has strong evidence
        is_prot = (hits >= MH_PROMOTE_HITS)
        m_is_prot[k] = is_prot
        _heap_push(cache_snapshot, k)


def _bounded_rescan_choose(cache_snapshot, heap, allow_demote=False):
    """
    Pop a few candidates from the given heap and choose the weakest valid one.
    If allow_demote and the candidate is protected but stale, demote it to probation and skip.
    Returns: (key or None, list_of_considered_entries_to_push_back)
    """
    considered = []
    best_key = None
    best_tuple = None  # (adjusted_score, score_tuple)

    attempts = 0
    now = cache_snapshot.access_count
    window = _recency_window(cache_snapshot)

    while attempts < RESCAN_LIMIT and heap:
        sc, last, k, v = heapq.heappop(heap)
        # Skip if not resident
        if k not in cache_snapshot.cache:
            attempts += 1
            continue
        # Skip if stale heap entry
        if m_ver.get(k, 0) != v:
            attempts += 1
            continue

        # Recompute current score (reflect decay/window/metadata changes)
        cur_sc = _score_key(cache_snapshot, k)

        # Optional demotion for protected items that look dead
        if allow_demote and m_is_prot.get(k, False):
            idle = now - m_last_access.get(k, now)
            gap = m_gap_ewma.get(k, float(window))
            freq = _lfu_peek(cache_snapshot, k)
            if idle > PROT_DEMOTE_IDLE_MULT * max(1.0, gap) and freq <= 1:
                # Demote to probation and reinsert with a new version
                m_is_prot[k] = False
                _heap_push(cache_snapshot, k)
                attempts += 1
                continue

        # If score drifted upward, reinsert with new score
        if cur_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            attempts += 1
            continue

        # Track the weakest (lowest score) candidate
        adj_sc = cur_sc
        if (best_tuple is None) or (adj_sc < best_tuple[0]):
            best_key = k
            best_tuple = (adj_sc, (sc, last, k, v))
        considered.append((sc, last, k, v))
        attempts += 1

    return best_key, considered


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using segmented heaps of retention scores.
    - Seed on first use
    - Prefer evicting from probation (scan resistance)
    - Pop and validate entries lazily (versioning) and recompute scores
    - Demote protected items that appear dead before evicting them
    - Bounded rescan to find the weakest valid candidate
    """
    _lfu_maybe_advance_epoch(cache_snapshot)
    _seed_metadata_if_needed(cache_snapshot)

    # 1) Try probation first
    victim, considered = _bounded_rescan_choose(cache_snapshot, m_heap_prob, allow_demote=False)
    # Push back all considered except the chosen victim
    for tup in considered:
        if victim is not None and tup[2] == victim:
            continue
        heapq.heappush(m_heap_prob, tup)

    if victim is not None:
        return victim

    # 2) Fall back to protected (with opportunistic demotion of stale entries)
    victim2, considered2 = _bounded_rescan_choose(cache_snapshot, m_heap_prot, allow_demote=True)
    for tup in considered2:
        if victim2 is not None and tup[2] == victim2:
            continue
        heapq.heappush(m_heap_prot, tup)

    if victim2 is not None:
        return victim2

    # 3) If heaps are exhausted or empty, choose the oldest resident
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Update EWMA of inter-arrival gap
      - Refresh last-access time
      - Promote to protected after MH_PROMOTE_HITS
      - Push updated score to the appropriate heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Update frequency only on hits (not on cold insert)
    _lfu_inc(cache_snapshot, k)

    # Update inter-arrival EWMA
    prev = m_last_access.get(k)
    if prev is not None:
        gap = max(1.0, float(now - prev))
        old = m_gap_ewma.get(k)
        if old is None or old <= 0.0:
            m_gap_ewma[k] = gap
        else:
            m_gap_ewma[k] = (1.0 - GAP_BETA) * old + GAP_BETA * gap
    else:
        # Initialize conservatively
        m_gap_ewma[k] = float(_recency_window(cache_snapshot) * 2)

    # Hits: increment resident hits
    hits = m_resident_hits.get(k, 0) + 1
    m_resident_hits[k] = hits

    # Promotion to protected after sufficient evidence
    if hits >= MH_PROMOTE_HITS:
        m_is_prot[k] = True

    # Refresh timestamps
    m_last_access[k] = now

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch
      - Do NOT increment LFU on cold insert (reduces one-timer pollution)
      - Initialize resident metadata: last_access, birth_ts, resident_hits = 0
      - Initialize EWMA gap conservatively to 2x recency window (very cautious)
      - Place into probation
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # No _lfu_inc here: cold items must earn credit by hitting

    m_last_access[k] = now
    m_birth_ts[k] = now
    m_resident_hits[k] = 0
    m_gap_ewma[k] = float(_recency_window(cache_snapshot) * 2)
    m_is_prot[k] = False

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember popularity)
      - Invalidate its heap version (stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_birth_ts.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_gap_ewma.pop(ek, None)
    m_is_prot.pop(ek, None)
    m_ver.pop(ek, None)

    _touch_and_maybe_rebuild(cache_snapshot)
```
2025-11-27 20:56:16,824 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 30
- Hit Rate: 0.0524

Example 2:
- Trace ID: 33
- Hit Rate: 0.6925

Example 3:
- Trace ID: 42
- Hit Rate: 0.0855

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:56:16 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:56:16,826 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m20:59:44 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 20:59:44,330 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 20:59:44,395 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive Segmented, Size-Aware TinyLFU with ARC-style target tuning (AST-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style
# - Dynamic target split between probation/protected using ARC-like ghost feedback
# - Size-aware, decayed TinyLFU, with recency and predicted reuse (IRT) components
# - Smarter promotion: require at least 2 resident hits and minimal frequency/size gating
# - Eviction chooses segment based on dynamic targets and new object's size
# - Ghost lists (by key) to adapt segment targets toward recency/frequency demand

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096  # shorter interval -> adapts faster

# Dynamic capacity targeting (by bytes)
g_probation_target_bytes = None  # initialized on first use to 0.20 * capacity
g_protected_bytes = 0            # running total of bytes in protected

# Ghost lists for ARC-style adaptation (store evicted keys and from-which segment)
# Each ghost is dict: key -> (size:int, ghost_time:int)
g_ghost_prob = dict()
g_ghost_prot = dict()
g_ghost_prob_bytes = 0
g_ghost_prot_bytes = 0

# Ghost budgets (bytes); set on first use based on capacity
g_ghost_budget_prob = None
g_ghost_budget_prot = None

# Scoring tunables
SIZE_ALPHA = 1.05          # ~1 -> balanced size penalty; slightly sublinear
MULTI_HIT_BONUS = 0.50     # bonus for >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 2           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.85
W_REC_PROT = 0.08
W_PRED_PROB = 0.15
W_PRED_PROT = 0.22

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.50        # respond faster to change

# Promotion gating
PROMOTE_MIN_HITS = 2       # need at least 2 resident hits to promote
PROMOTE_LFU_MIN = 2        # also require TinyLFU >= 2 for very large objects
PROMOTE_LARGE_FRAC = 0.10  # objects >10% of capacity need LFU>=PROMOTE_LFU_MIN

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    global g_probation_target_bytes, g_ghost_budget_prob, g_ghost_budget_prot
    _lfu_maybe_advance_epoch(cache_snapshot)
    if g_probation_target_bytes is None:
        # Start with 20% probation, 80% protected
        g_probation_target_bytes = int(0.20 * float(cache_snapshot.capacity))
    if g_ghost_budget_prob is None or g_ghost_budget_prot is None:
        # Ghost budgets (each up to capacity); conservative to cap memory
        cap = cache_snapshot.capacity
        g_ghost_budget_prob = cap
        g_ghost_budget_prot = cap

def _normalized_size(size, capacity):
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    # Protected target is the complement of probation target
    return max(0, cache_snapshot.capacity - int(g_probation_target_bytes))

def _probation_bytes(cache_snapshot):
    return max(0, cache_snapshot.size - g_protected_bytes)

def _find_oldest_in_segment(cache_snapshot, segment_id):
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_oldest_protected(cache_snapshot):
    # Demote the oldest protected item to probation
    global g_protected_bytes
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return False
    robj = cache_snapshot.cache.get(key)
    if robj is not None:
        g_protected_bytes = max(0, g_protected_bytes - robj.size)
    m_segment[key] = 0
    return True

def _rebalance_segments(cache_snapshot):
    # Demote from protected until protected_bytes <= target
    target_prot = _protected_target_bytes(cache_snapshot)
    # Avoid infinite loops; cap iterations by number of protected items
    guard = len(cache_snapshot.cache) + 2
    while g_protected_bytes > target_prot and guard > 0:
        if not _demote_oldest_protected(cache_snapshot):
            break
        guard -= 1

# -----------------------------
# Ghost helpers (ARC-like)
# -----------------------------

def _ghost_add(ghost_dict, key, size, now, is_prob):
    # Insert/update ghost entry; maintain budgets by evicting oldest
    global g_ghost_prob_bytes, g_ghost_prot_bytes
    if is_prob:
        prev = ghost_dict.get(key)
        if prev is not None:
            g_ghost_prob_bytes -= prev[0]
        ghost_dict[key] = (size, now)
        g_ghost_prob_bytes += size
        _ghost_prune(is_prob)
    else:
        prev = ghost_dict.get(key)
        if prev is not None:
            g_ghost_prot_bytes -= prev[0]
        ghost_dict[key] = (size, now)
        g_ghost_prot_bytes += size
        _ghost_prune(is_prob)

def _ghost_prune(is_prob):
    # Remove oldest ghosts to respect budget
    global g_ghost_prob_bytes, g_ghost_prot_bytes
    if is_prob:
        budget = g_ghost_budget_prob
        if budget is None:
            return
        if g_ghost_prob_bytes <= budget:
            return
        # Evict oldest entries until within budget
        while g_ghost_prob_bytes > budget and g_ghost_prob:
            # find oldest by time
            oldest_key, oldest_time = None, None
            for k, (_, t) in g_ghost_prob.items():
                if oldest_time is None or t < oldest_time:
                    oldest_time = t
                    oldest_key = k
            if oldest_key is None:
                break
            sz, _ = g_ghost_prob.pop(oldest_key)
            g_ghost_prob_bytes -= sz
    else:
        budget = g_ghost_budget_prot
        if budget is None:
            return
        if g_ghost_prot_bytes <= budget:
            return
        while g_ghost_prot_bytes > budget and g_ghost_prot:
            oldest_key, oldest_time = None, None
            for k, (_, t) in g_ghost_prot.items():
                if oldest_time is None or t < oldest_time:
                    oldest_time = t
                    oldest_key = k
            if oldest_key is None:
                break
            sz, _ = g_ghost_prot.pop(oldest_key)
            g_ghost_prot_bytes -= sz

def _adjust_targets_on_insert(cache_snapshot, obj):
    # ARC-style feedback: if miss hits probation ghost -> increase probation target (favor recency)
    # If miss hits protected ghost -> decrease probation target (favor frequency)
    global g_probation_target_bytes
    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    now = cache_snapshot.access_count
    k = obj.key

    # Adjust step: size of object or minimum step
    min_step = max(1, cap // 64)  # about 1.6% of capacity
    if k in g_ghost_prob:
        delta = max(min_step, g_ghost_prob[k][0])
        g_probation_target_bytes = min(cap, g_probation_target_bytes + delta)
        # touch and remove to avoid repeated boosts
        g_ghost_prob.pop(k, None)
        # Rebance since target changed
        _rebalance_segments(cache_snapshot)
    elif k in g_ghost_prot:
        delta = max(min_step, g_ghost_prot[k][0])
        g_probation_target_bytes = max(0, g_probation_target_bytes - delta)
        g_ghost_prot.pop(k, None)
        _rebalance_segments(cache_snapshot)

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Larger score -> stronger retention. Eviction chooses minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    multi_bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    freq_gain = (math.log2(1.0 + freq) + multi_bonus)

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)  # 0 recent .. 1 old
    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)            # 0 soon .. 1 far

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    # Gains: recent (low age_norm) and soon reuse (low irt_norm) get positive credit
    recency_gain = w_rec * (1.0 - age_norm)
    predicted_gain = w_pred * (1.0 - irt_norm)

    # Final retention strength per size penalty
    retention = (freq_gain + recency_gain + predicted_gain) / max(1e-12, size_penalty)
    return retention

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Adjust targets via ghost feedback (done on insert path)
      - Rebalance protected segment to stay under its target (demote oldest protected if needed)
      - Choose segment to evict from based on dynamic targets and the incoming object's size:
          * If probation_bytes + obj.size > probation_target -> evict from probation
          * Else -> evict from protected
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Keep protected under its dynamic target
    _rebalance_segments(cache_snapshot)

    # Decide which segment to evict from, considering the incoming object's size
    probation_bytes = _probation_bytes(cache_snapshot)
    probation_target = int(g_probation_target_bytes)
    prefer_probation = (probation_bytes + getattr(obj, 'size', 0)) > probation_target

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        min_key = None
        min_score = None
        min_time = None
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (min_key is None) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
        return min_key

    victim = None
    if prefer_probation:
        victim = select_from_segment(0)
        if victim is None:
            victim = select_from_segment(1)
    else:
        victim = select_from_segment(1)
        if victim is None:
            victim = select_from_segment(0)

    if victim is None:
        # Fallback: arbitrary
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    return victim


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - Promotion gating:
          * Promote from probation to protected only if:
              - resident_hits >= PROMOTE_MIN_HITS, and
              - if object is large (> PROMOTE_LARGE_FRAC*capacity), TinyLFU >= PROMOTE_LFU_MIN
      - Rebalance protected to its dynamic target after promotions
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive accesses
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = prev if prev is not None else now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion gating
    seg = _segment_of(k)
    if seg == 0:
        hits = m_resident_hits.get(k, 1)
        lfu = _lfu_peek(cache_snapshot, k)
        cap = cache_snapshot.capacity
        is_large = obj.size >= int(PROMOTE_LARGE_FRAC * float(cap))
        allow_promote = (hits >= PROMOTE_MIN_HITS) and (not is_large or lfu >= PROMOTE_LFU_MIN)
        if allow_promote:
            m_segment[k] = 1
            global g_protected_bytes
            g_protected_bytes += obj.size

    # Keep protected under its target
    _rebalance_segments(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - ARC-style target adaptation using ghost lists (if this key was seen recently)
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window adjusted slightly by TinyLFU
          segment = probation
      - Rebalance segments in case targets shifted
    '''
    _init_if_needed(cache_snapshot)

    # Ghost-driven target adaptation
    _adjust_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT: start from window; if LFU already high, expect sooner reuse
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    lfu = _lfu_peek(cache_snapshot, k)
    # Map lfu (0..15) to a factor in [0.5, 1.0]
    lfu_factor = 1.0 - 0.5 * min(1.0, float(lfu) / 15.0)
    m_irt[k] = float(window) * float(lfu_factor)

    # No change to protected bytes on insert (probation by default)

    # Rebalance to respect potential target changes
    _rebalance_segments(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Add key to appropriate ghost list (probation or protected) for ARC-style adaptation
      - Remove resident-only metadata (retain TinyLFU counters)
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    now = cache_snapshot.access_count

    # Determine segment before removing metadata
    seg = _segment_of(ek)

    # Adjust protected bytes if needed
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Add to ghost lists for adaptation
    if seg == 0:
        _ghost_add(g_ghost_prob, ek, evicted_obj.size, now, is_prob=True)
    else:
        _ghost_add(g_ghost_prot, ek, evicted_obj.size, now, is_prob=False)

    # Remove resident-only metadata (keep TinyLFU frequency)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)

    # No change to TinyLFU counters; they persist across evictions
```
2025-11-27 20:59:50,720 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# W-TinyLFU + Segmented protection + Size-aware retention
# - Two logical segments:
#     1) probation (new/resurrected items)
#     2) protected (promoted on hit; byte-quota limited)
# - TinyLFU frequency counters with lazy epoch decay (8-bit saturating)
# - Size-aware retention: benefit = log1p(freq) / normalized_size
# - Recency bonus added (not subtracted) to protect recent items
# - Protected segment gets an extra bonus; demoted by LRU when over target bytes
# - Eviction uses lazy min-heaps (probation first, then protected) to avoid full scans
#   with lazy invalidation via per-key stamps; periodic score refresh on pop.
#
# This design:
#   - Dramatically reduces per-eviction cost (avoids O(n) scans) -> fewer timeouts
#   - Corrects recency sign (recent items are now protected, not penalized)
#   - Uses size-aware TinyLFU benefit and a protected segment to cut miss rate

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Cache identity (to reset between runs if needed)
m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting
m_prot_bytes = 0
m_prot_target_bytes = 0

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_probation = []           # retention score (lower => more evictable) for probation
h_protected = []           # retention score for protected (used when probation empty)
h_prot_lru = []            # last_access (min-heap) for protected demotions

# TinyLFU counters (lazy decay with epochs; per-key to keep it simple)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Protected segment target (bytes)
PROT_FRAC = 0.80           # target fraction of capacity for protected bytes

# Recency window and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 3           # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.60     # recency weight in probation
REC_WEIGHT_PROT = 0.40     # recency weight in protected
PROT_BONUS = 0.60          # extra benefit for protected segment
MULTI_HIT_BONUS = 0.30     # extra benefit for items with >=2 resident hits

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16  # bound reheap/refresh work per eviction

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC * cache_snapshot.capacity)

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Return size as percentage of capacity to keep scales stable
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _retention_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # treat missing as extremely good (will be filtered by validity)
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)

    seg = m_segment.get(key, 0)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    # Size-aware frequency benefit
    benefit = math.log1p(float(freq)) / size_norm

    # Multi-hit bias
    if m_resident_hits.get(key, 0) >= 2:
        benefit += MULTI_HIT_BONUS

    # Recency bonus
    if seg == 1:
        benefit += PROT_BONUS + REC_WEIGHT_PROT * rec_bonus
    else:
        benefit += REC_WEIGHT_PROB * rec_bonus

    return benefit


# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    # Compute score at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    score = _retention_score(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (score, s, key))
    else:
        heapq.heappush(h_protected, (score, s, key))
        # Also maintain LRU heap for protected demotions
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot, heap_ref, expected_seg):
    # Return a valid key from the given heap, refreshing stale scores when needed.
    # Limit work per call to avoid long stalls.
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        # Skip invalid/stale entries
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Opportunistically refresh score if it drifted
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            # Reinsert with a new stamp
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key
    return None


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        # Push into probation heap with updated score/stamp
        _push_key(cache_snapshot, key)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim:
      1) Pop the weakest from probation heap (lowest retention)
      2) If probation empty, pop the weakest from protected heap
      3) Fallback: any resident key
    '''
    _init_if_needed(cache_snapshot)

    # Prefer evicting from probation
    victim = _pop_best_candidate(cache_snapshot, h_probation, expected_seg=0)
    if victim is None:
        victim = _pop_best_candidate(cache_snapshot, h_protected, expected_seg=1)

    if victim is not None:
        return victim

    # Fallback: arbitrary key (should be rare)
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote probation -> protected on first resident hit
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with new score/recency
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote to protected
        m_segment[k] = 1
        # Account protected bytes
        global m_prot_bytes
        m_prot_bytes += obj.size
        # Push into protected heaps
        _push_key(cache_snapshot, k)
        # Enforce protected target
        _maybe_demote_protected(cache_snapshot)
    else:
        # Already protected: refresh heaps
        _push_key(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place into probation segment and push to heap
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation
    _push_key(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Adjust protected bytes if it was protected
    seg = m_segment.pop(ek, None)
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 11
- Hit Rate: 0.4059

Example 2:
- Trace ID: 37
- Hit Rate: 0.6399

Example 3:
- Trace ID: 31
- Hit Rate: 0.0836

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m20:59:50 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 20:59:50,721 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:02:34 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:02:34,715 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:02:34,716 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Simpler, robust TinyLFU + size-aware GDSF-style priority with recency
# - Single priority heap (min-heap): evict the lowest "keep score"
# - Keep score combines:
#     * Frequency (TinyLFU with lazy epoch decay)
#     * Size-aware penalty (relative to current avg resident size) with exponent beta
#     * Recency bonus via a sliding window
#     * Extra bonus after multiple resident hits
# - Cold-start scan shield: recent bonus is smaller until the first resident hit
# - Stamped lazy heap to avoid O(n) scans and allow cheap updates
#
# Goals:
#   - Lower miss rates across diverse traces (including ones with larger objects)
#   - Keep operations O(log n) with bounded heap maintenance per eviction

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()    # key -> int (access_count at last hit/insert)
m_resident_hits = dict()  # key -> int (number of hits while resident)
m_stamp = dict()          # key -> int (monotonic; current valid stamp for heap entries)

# TinyLFU counters (lazy decay with epochs; per-key)
m_lfu_count = dict()      # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# Heap: tuples (keep_score:float, stamp:int, key:str)
h_main = []

# -----------------------------
# Tunables
# -----------------------------

# TinyLFU decay parameters
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step
LFU_COUNTER_MAX = 255

# Size-awareness and scoring
SIZE_PENALTY_BETA = 0.55   # 0 => size-agnostic; 1 => strong size penalty
FREQ_WEIGHT = 1.00         # weight for frequency term
REC_WEIGHT_COLD = 0.20     # recency weight before first hit (scan shield)
REC_WEIGHT_HOT = 0.60      # recency weight after first hit
MULTI_HIT_BONUS = 0.30     # extra bonus after >= 2 resident hits

# Recency window
REC_WIN_MIN = 256
REC_WIN_MULT = 2           # window ~= REC_WIN_MULT * resident_items

# Heap maintenance
SCORE_REFRESH_EPS = 0.05   # refresh only if score drift is meaningful
MAX_HEAP_FIX_PER_EVICT = 24

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_stamp
    global m_lfu_count, m_lfu_epoch, h_main

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_stamp.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0

    h_main.clear()


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; do not sweep


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _normalized_size(obj_size, cache_snapshot):
    # Normalize by current average resident object size to be robust
    n = max(1, len(cache_snapshot.cache))
    total_bytes = max(1, cache_snapshot.size)
    avg = float(total_bytes) / float(n)
    return max(1e-6, float(obj_size) / avg)


def _keep_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        # Shouldn't happen for valid entries; return large to avoid eviction
        return float('inf')

    size_norm = _normalized_size(obj.size, cache_snapshot)
    size_penalty = math.pow(size_norm, SIZE_PENALTY_BETA)

    freq = _lfu_peek(cache_snapshot, key)
    freq_term = math.log1p(float(freq)) / max(1e-9, size_penalty)

    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    hits = m_resident_hits.get(key, 0)
    rec_weight = REC_WEIGHT_HOT if hits >= 1 else REC_WEIGHT_COLD

    score = FREQ_WEIGHT * freq_term + rec_weight * rec_bonus
    if hits >= 2:
        score += MULTI_HIT_BONUS

    return score

# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    s = _next_stamp(key)
    score = _keep_score(cache_snapshot, key)
    heapq.heappush(h_main, (score, s, key))


def _is_valid(cache_snapshot, key, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot):
    # Pop a valid, reasonably fresh-scored eviction candidate.
    attempts = 0
    while h_main and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(h_main)
        if not _is_valid(cache_snapshot, key, stamp):
            attempts += 1
            continue
        new_score = _keep_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            # Reinsert freshly scored
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key
    return None

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim:
      - Pop the lowest keep score from the main heap (with lazy refresh)
      - Fallback to any resident key if heap is exhausted (rare)
    '''
    _init_if_needed(cache_snapshot)

    victim = _pop_best_candidate(cache_snapshot)
    if victim is not None:
        return victim

    # Fallback: arbitrary key
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last_access and resident_hits
      - Refresh heap entry with new keep score
      - Scan shield fades automatically after first resident hit
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    _push_key(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling proxy)
      - Initialize resident metadata: last_access, resident_hits = 0
      - Push into the main heap
      - Cold entries get a smaller recency weight until they earn a hit
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 0
    _push_key(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (retain TinyLFU counters across evictions)
      - Clear stamp so any stale heap entries are treated invalid
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
    # TinyLFU counters are retained to inform future admissions
```
2025-11-27 21:02:56,818 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 41
- Hit Rate: 0.178

Example 2:
- Trace ID: 18
- Error: Error - Timeout

Example 3:
- Trace ID: 26
- Hit Rate: 0.7944

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:02:56 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:02:56,819 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:05:08 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:05:08,942 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:05:08,943 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Windowed, Size-Aware SLRU with TinyLFU and k-sample victim selection (fast)
# - Two resident segments with explicit LRU lists:
#     * probation (window): newly admitted and single-hit items
#     * protected (main): promoted on hit; gets most of the capacity
# - Eviction selects among a small set of the oldest in each segment (k-sample),
#   using a size-aware TinyLFU-based retention score. This avoids O(n) scans.
# - Protected is kept near a target fraction by demoting its LRU to probation.
# - TinyLFU uses lazy, epoch-based decay (4-bit counters).
# - Metadata is updated on hit/insert/evict and lists are maintained consistently.

import math
from collections import OrderedDict
from itertools import islice

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Explicit LRU lists for both segments (oldest at beginning, MRU at end)
probation_lru = OrderedDict()   # key -> None
protected_lru = OrderedDict()   # key -> None

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.85  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Victim sampling (to avoid O(n) scans)
CANDIDATE_SAMPLES = 8      # number of oldest candidates to evaluate per segment

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights (used within small candidate sets)
REC_WIN_MIN = 2048
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.55
W_REC_PROT = 0.15
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _touch_probation(k):
    # Move key to MRU of probation (if resident in probation)
    if k in probation_lru:
        probation_lru.move_to_end(k, last=True)

def _touch_protected(k):
    # Move key to MRU of protected (if resident in protected)
    if k in protected_lru:
        protected_lru.move_to_end(k, last=True)

def _remove_from_lrus(k):
    probation_lru.pop(k, None)
    protected_lru.pop(k, None)

def _promote_to_protected(obj):
    # Remove from probation (if present) and add to protected MRU
    global g_protected_bytes
    k = obj.key
    if k in probation_lru:
        probation_lru.pop(k, None)
    if k not in protected_lru:
        protected_lru[k] = None
        g_protected_bytes += obj.size
    else:
        protected_lru.move_to_end(k, last=True)
    m_segment[k] = 1

def _add_to_probation_mru(k):
    # Put key at MRU of probation
    probation_lru.pop(k, None)
    probation_lru[k] = None
    m_segment[k] = 0

def _demote_one_from_protected(cache_snapshot):
    # Demote the oldest protected item into probation MRU
    global g_protected_bytes
    try:
        ek, _ = next(iter(protected_lru.items()))
    except StopIteration:
        return
    # Move ek to probation MRU
    protected_lru.pop(ek, None)
    m_segment[ek] = 0
    probation_lru[ek] = None  # MRU
    # Update bytes
    robj = cache_snapshot.cache.get(ek)
    if robj is not None:
        g_protected_bytes = max(0, g_protected_bytes - robj.size)

def _enforce_protected_target(cache_snapshot):
    target = _protected_target_bytes(cache_snapshot)
    # Demote until under target
    while g_protected_bytes > target and len(protected_lru) > 0:
        _demote_one_from_protected(cache_snapshot)

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

def _select_best_candidate(cache_snapshot, lru_dict, max_k):
    # Examine up to the oldest max_k keys in the LRU and return the weakest key by score
    best_key = None
    best_score = None
    best_time = None
    now = cache_snapshot.access_count

    for k in islice(lru_dict.keys(), 0, max_k):
        score = _retention_score(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if best_key is None or score < best_score or (score == best_score and last < best_time):
            best_key = k
            best_score = score
            best_time = last

    return best_key, best_score

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed (O(k))
      - Select from the k oldest of probation; if empty or protected has a far weaker
        candidate, consider protected's k oldest too and pick the weakest overall.
      - Ties are broken by older last-access time.
    '''
    _init_if_needed(cache_snapshot)

    # Maintain protected target (demotions don't change total cache size)
    _enforce_protected_target(cache_snapshot)

    # Collect candidates from probation
    p_key, p_score = _select_best_candidate(cache_snapshot, probation_lru, CANDIDATE_SAMPLES)

    # If probation empty, fall back to protected
    if p_key is None:
        g_key, _ = _select_best_candidate(cache_snapshot, protected_lru, CANDIDATE_SAMPLES)
        if g_key is not None:
            return g_key
        # Fallback: arbitrary
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Optionally consider protected if probation candidate is strong
    g_key = None
    g_score = None
    # Heuristic: only sample protected when probation candidate seems valuable,
    # otherwise don't waste protected capacity.
    if len(protected_lru) > 0:
        g_key, g_score = _select_best_candidate(cache_snapshot, protected_lru, min(4, CANDIDATE_SAMPLES // 2))

    # Decide victim
    if g_key is not None and g_score is not None and g_score < p_score:
        return g_key
    return p_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected; else refresh protected LRU
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive accesses
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize conservatively
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = _segment_of(k)
    if seg == 0:
        # Promote to protected
        _promote_to_protected(obj)
    else:
        # Refresh protected recency
        _touch_protected(k)

    # Ensure protected is within target
    _enforce_protected_target(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access = now
          resident_hits = 1
          irt = default window
          segment = probation; add to probation MRU
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # Ensure not present in protected LRU (stale)
    protected_lru.pop(k, None)
    # Add to probation MRU
    _add_to_probation_mru(k)
    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting and LRU structures
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed and remove from LRU structures
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)
        protected_lru.pop(ek, None)
    else:
        probation_lru.pop(ek, None)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)

    # Optionally keep protected within target (no-ops if already ok)
    _enforce_protected_target(cache_snapshot)
```
2025-11-27 21:08:06,756 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved: Count-based SLRU with TinyLFU, ARC-style adaptive split, and recency-aware scoring
# - Two resident segments by item count, not by bytes:
#     P (probation): admits all new objects; managed by LRU (via last_access timestamps)
#     S (protected): objects that hit at least once; also LRU-managed
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction score blends frequency and recency (recency matters beyond tie-break)
# - ARC-like ghost lists adapt the item split between P and S online (by counts)
#
# This design captures:
#   - Recency (via LRU timestamps and explicit recency in eviction score)
#   - Frequency (via TinyLFU)
#   - Adaptivity between recency-friendly and frequency-friendly behavior
#   - Correctness for caches limited by number of items (not bytes)

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU)
m_key_segment = dict()       # key -> 'P' or 'S'

# Current resident ITEM COUNTS per segment
m_cnt_P = 0
m_cnt_S = 0

# Adaptive target for protected items (S); probation target = capacity_items - target_S
m_target_S_items = None
m_cap_items_est = 0  # our estimate of capacity in number of items (learned at evict time)

# Ghost lists (non-resident metadata) to adapt split; store key -> last_time
m_ghost_P = dict()  # B1
m_ghost_S = dict()  # B2
m_ghost_limit_items = None

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)

# ---------------
# Scoring params
# ---------------
# Recency blend: score = est_freq + rec_weight * min(recency / half_life, rec_cap)
m_rec_half_life = 500.0  # accesses; tune to make recency effect comparable to est_freq
m_rec_cap = 10.0         # cap normalized recency contribution
m_rec_weight_P = 1.0     # probation recency weight
m_rec_weight_S = 0.6     # protected recency weight (S is more persistent)
m_protect_S_bias = 0.25  # additive bias to S candidates to modestly protect them
m_overweight_nudge = 0.2 # when a segment exceeds target, nudge its candidate to be more evictable

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_target_S_items, m_ghost_limit_items
    global m_sketch_tables, m_sketch_mask
    global m_cap_items_est

    # Learn capacity in items opportunistically; on evict() we'll update more accurately.
    if m_cap_items_est < len(cache_snapshot.cache):
        m_cap_items_est = len(cache_snapshot.cache)

    if m_target_S_items is None:
        # Start slightly frequency-friendly; adapt online
        base_items = max(1, len(cache_snapshot.cache))
        m_target_S_items = int(base_items * 0.6)

    if m_ghost_limit_items is None:
        # Each ghost list limited to approximately the cache capacity in items (we adjust later)
        m_ghost_limit_items = max(1, len(cache_snapshot.cache))

    if m_sketch_tables is None:
        # Width scales with estimated items; choose power of two near items*4 (empirical)
        # Minimum width to keep estimates reasonably stable.
        items = max(1, len(cache_snapshot.cache))
        width = 1
        target = max(1024, min(1 << 16, items * 4))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        # Halve all counters (right-shift by 1)
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _normalized_recency(now, last):
    if last is None or last < 0:
        return m_rec_cap
    age = max(0, now - last)
    norm = age / m_rec_half_life
    if norm > m_rec_cap:
        norm = m_rec_cap
    return norm


def _pick_min_score_in_segment(cache_snapshot, seg_tag, now):
    # Returns (key, score, last_time) that minimizes blended score within a segment
    # Score = est_freq + rec_weight * normalized_recency; tie-break by older first
    min_key = None
    min_score = None
    min_time = None

    rec_w = m_rec_weight_S if seg_tag == 'S' else m_rec_weight_P

    for key, obj in cache_snapshot.cache.items():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        est = float(_sketch_estimate(key))
        last = m_key_last_access.get(key, -1)
        rec = _normalized_recency(now, last)
        score = est + rec_w * rec
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = key
            min_score = score
            min_time = last

    return (min_key, min_score, min_time)


def _find_oldest_in_segment(cache_snapshot, seg_tag):
    oldest_key, oldest_time = None, None
    for k in cache_snapshot.cache.keys():
        if m_key_segment.get(k, 'P') != seg_tag:
            continue
        t = m_key_last_access.get(k, -1)
        if oldest_time is None or t < oldest_time:
            oldest_key, oldest_time = k, t
    return oldest_key


def _ghost_add(ghost_dict, key, time_now, which):
    # Add key->time to chosen ghost (which in {'P','S'}), trimming if exceeds limit
    global m_ghost_limit_items

    # Insert/update
    ghost_dict[key] = time_now

    # Trim to limit by evicting oldest
    limit = m_ghost_limit_items or 0
    if limit <= 0:
        return

    while len(ghost_dict) > limit:
        oldest_key, oldest_time = None, None
        for k, t in ghost_dict.items():
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        if oldest_key is None:
            break
        ghost_dict.pop(oldest_key, None)


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    # If key in P-ghost (B1): increase probation share (decrease S target)
    # If key in S-ghost (B2): increase protected share (increase S target)
    global m_target_S_items, m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Update our item-capacity estimate when cache is likely full (best signal: on evict call, but keep here too)
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)

    # Keep ghost size limits around capacity in items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est

    cap_items = max(1, m_cap_items_est)

    # Step size: 1 item per signal (conservative, stable)
    step = 1

    if obj.key in m_ghost_P:
        # Recent ghost hit: favor recency -> increase P share (decrease S)
        m_target_S_items = _clamp((m_target_S_items or 0) - step, 0, cap_items)
        m_ghost_P.pop(obj.key, None)
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: favor frequency -> increase S share
        m_target_S_items = _clamp((m_target_S_items or 0) + step, 0, cap_items)
        m_ghost_S.pop(obj.key, None)


def _maybe_demote_from_S_to_P(cache_snapshot):
    # If S exceeds its target, demote oldest S item to P
    global m_cnt_P, m_cnt_S, m_target_S_items
    if m_target_S_items is None:
        return
    if m_cnt_S > m_target_S_items:
        demote_key = _find_oldest_in_segment(cache_snapshot, 'S')
        if demote_key is not None:
            m_key_segment[demote_key] = 'P'
            m_cnt_S = max(0, m_cnt_S - 1)
            m_cnt_P += 1


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using count-based SLRU + TinyLFU with recency-aware scoring.
    - Compute candidate with minimal blended score in each segment:
        score = est_freq(key) + rec_weight * normalized_recency
    - Bias to evict from the segment exceeding its item-count target.
    - Protect S moderately by adding a small bias compared to P.
    '''
    global m_cnt_P, m_cnt_S, m_target_S_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Learn/refresh capacity in number of items at the moment of eviction (cache is full now)
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    cap_items = max(1, m_cap_items_est)
    if m_target_S_items is None:
        m_target_S_items = int(0.6 * cap_items)
    target_S = _clamp(m_target_S_items, 0, cap_items)
    target_P = cap_items - target_S

    now = cache_snapshot.access_count

    # Find min-score candidate in each segment
    p_key, p_score, p_lru = _pick_min_score_in_segment(cache_snapshot, 'P', now)
    s_key, s_score, s_lru = _pick_min_score_in_segment(cache_snapshot, 'S', now)

    # Prepare adjusted scores
    best_key = None
    best_adj = None

    if p_key is not None:
        adj_p = p_score
        # If P is overweight, make it slightly more likely to evict from P
        if m_cnt_P > target_P:
            adj_p -= m_overweight_nudge
        # No extra protection bias for P
        best_key = p_key
        best_adj = adj_p

    if s_key is not None:
        adj_s = s_score + m_protect_S_bias
        # If S is overweight, encourage eviction from S
        if m_cnt_S > target_S:
            adj_s -= m_overweight_nudge
        if (best_adj is None) or (adj_s < best_adj):
            best_adj = adj_s
            best_key = s_key

    # Fallback: if we somehow didn't find any key (shouldn't happen), pick oldest globally
    if best_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        best_key = oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - If in probation (P), promote to protected (S); if S exceeds target, demote oldest S to P
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    k = obj.key

    # Update TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    # Promote from P to S on hit
    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        m_key_segment[k] = 'S'
        m_cnt_P = max(0, m_cnt_P - 1)
        m_cnt_S += 1
        # If S above target, demote oldest S back to P
        _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S item split using ARC-like ghosts
      - Increment TinyLFU for the key (TinyLFU trains on both hits and misses)
      - Add the new object to probation (P)
      - Record last access time
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_cnt_P += 1

    # Keep S from drifting above target if previous operations changed target
    _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key
      - Update segment item counters
      - Add the key to the corresponding ghost list (count-limited) to guide future adaptation
      - Keep ghost sizes roughly equal to estimated cache capacity in items
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S
    global m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust item counts and add to appropriate ghost
    now = cache_snapshot.access_count
    if seg == 'S':
        m_cnt_S = max(0, m_cnt_S - 1)
        _ghost_add(m_ghost_S, ek, now, which='S')
    else:
        m_cnt_P = max(0, m_cnt_P - 1)
        _ghost_add(m_ghost_P, ek, now, which='P')

    # Update ghost limits to approximate current capacity in items
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 19
- Hit Rate: 0.2603

Example 2:
- Trace ID: 12
- Hit Rate: 0.0862

Example 3:
- Trace ID: 7
- Hit Rate: 0.3832

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:08:06 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:08:06,760 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:10:59 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:10:59,088 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:10:59,090 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Size-aware GreedyDual-Size-Frequency (GDSF) with TinyLFU
# - Byte-capacity aware: eviction prioritizes "value per byte"
# - Recency via GreedyDual's global age (L): on each hit/insert, item's priority H = value/size^alpha + L
#   and on eviction we set L := H(evicted). This causes older/colder items to decay relative to recent touches.
# - Frequency via TinyLFU (Count-Min Sketch) with periodic aging
# - No per-item-count assumptions; decisions use actual obj.size
#
# This policy is simple, fast, and robust across mixed workloads (recency + frequency + size skew).

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Last access time (for LRU tiebreaks only)
m_key_last_access = dict()  # key -> int access_count

# GreedyDual priority per resident key: H(key) = value(key)/size(key)^alpha + L_at_last_touch
m_key_H = dict()  # key -> float

# Global GreedyDual age (inflation)
m_age_L = 0.0

# Remember last chosen victim's H so update_after_evict can advance L precisely
m_last_chosen_evict_H = None

# Track whether we've initialized for the current run
m_inited = False

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)

# -----------------------------
# Tunables
# -----------------------------
# Value normalization: value = (TinyLFU_estimate + bias) / size^alpha
m_value_bias = 1.0      # ensures cold items get some initial value
m_size_alpha = 0.875    # 1.0 favors small items strongly; 0.0 ignores size
m_eps_tiebreak = 1e-12  # to avoid float edge-case instability

# -----------------------------
# Helpers
# -----------------------------

def _maybe_reset_for_new_run(cache_snapshot):
    # If a new trace/run starts in the same process, access_count will return to 0.
    # Reset all state in that case.
    global m_inited, m_key_last_access, m_key_H, m_age_L
    global m_sketch_tables, m_sketch_mask, m_sketch_ops
    global m_last_chosen_evict_H
    if cache_snapshot.access_count == 0 and not m_inited:
        m_key_last_access = dict()
        m_key_H = dict()
        m_age_L = 0.0
        m_last_chosen_evict_H = None
        m_sketch_tables = None
        m_sketch_mask = None
        m_sketch_ops = 0
        m_inited = True


def _init_if_needed(cache_snapshot):
    global m_sketch_tables, m_sketch_mask
    _maybe_reset_for_new_run(cache_snapshot)
    if m_sketch_tables is None:
        # Choose sketch width near capacity/4KB, clamped to [2^12, 2^18]
        # and rounded up to the next power of two.
        cap = max(1, cache_snapshot.capacity)
        target = cap // 4096
        if target < 4096:
            target = 4096
        if target > (1 << 18):
            target = (1 << 18)
        width = 1
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _value_per_size(freq_est, size_bytes):
    s = size_bytes if size_bytes > 0 else 1
    # value normalized by size^alpha
    return (float(freq_est) + m_value_bias) / (s ** m_size_alpha)


def _ensure_H_for_key(cache_snapshot, key):
    # If we haven't yet assigned H to a resident key (e.g., pre-existing before our init),
    # initialize it using current TinyLFU estimate and current age L. This treats it as
    # "recently touched", which is conservative; it will age naturally via L increases.
    if key not in m_key_H:
        obj = cache_snapshot.cache.get(key)
        if obj is None:
            return
        est = _sketch_estimate(key)
        base = _value_per_size(est, obj.size)
        m_key_H[key] = base + m_age_L


def _pick_min_H(cache_snapshot):
    # Returns (key, H, last_access_time) minimizing H; tie-break by older last_access
    min_key, min_H, min_time = None, None, None
    for k, obj in cache_snapshot.cache.items():
        # Ensure H exists
        if k not in m_key_H:
            est = _sketch_estimate(k)
            base = _value_per_size(est, obj.size)
            # initialize H lazily
            H = base + m_age_L
            m_key_H[k] = H
        else:
            H = m_key_H[k]
        t = m_key_last_access.get(k, -1)
        if (min_H is None) or (H < min_H - m_eps_tiebreak) or (abs(H - min_H) <= m_eps_tiebreak and t < min_time):
            min_key, min_H, min_time = k, H, t
    return (min_key, min_H, min_time)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim using size-aware GDSF:
      - H(k) = (TinyLFU_estimate(k) + bias)/size(k)^alpha + L_at_last_touch
      - Evict the key with minimal H
      - On hit/insert we refresh H to base + current L to capture recency
    """
    global m_last_chosen_evict_H

    _init_if_needed(cache_snapshot)

    # Pick key with minimal H (ties: older last_access first)
    victim_key, victim_H, _ = _pick_min_H(cache_snapshot)
    if victim_key is None:
        # Fallback to arbitrary key if something is off
        victim_key = next(iter(cache_snapshot.cache))
        victim_H = m_key_H.get(victim_key, 0.0)

    # Stash selected H so update_after_evict can advance L precisely
    m_last_chosen_evict_H = float(victim_H)
    return victim_key


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Train TinyLFU (+1)
      - Refresh last-access time
      - Refresh H = value/size^alpha + current L
    """
    global m_key_last_access, m_key_H

    _init_if_needed(cache_snapshot)

    k = obj.key
    _sketch_inc(k, 1)
    m_key_last_access[k] = cache_snapshot.access_count

    est = _sketch_estimate(k)
    base = _value_per_size(est, obj.size)
    m_key_H[k] = base + m_age_L


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss resulted in admission by the framework):
      - Train TinyLFU (+1)
      - Record last-access time
      - Initialize H = value/size^alpha + current L
    """
    global m_key_last_access, m_key_H

    _init_if_needed(cache_snapshot)

    k = obj.key
    _sketch_inc(k, 1)
    m_key_last_access[k] = cache_snapshot.access_count

    est = _sketch_estimate(k)
    base = _value_per_size(est, obj.size)
    m_key_H[k] = base + m_age_L


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After eviction:
      - Advance global age L to the H(evicted) (core GreedyDual aging step)
      - Remove resident metadata for that key
    """
    global m_key_last_access, m_key_H, m_age_L, m_last_chosen_evict_H

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Advance GreedyDual age using the exact H of the evicted victim (if available)
    if m_last_chosen_evict_H is not None:
        # Ensure monotonic non-decreasing L
        if m_last_chosen_evict_H > m_age_L:
            m_age_L = m_last_chosen_evict_H
        m_last_chosen_evict_H = None

    # Clean up metadata
    m_key_last_access.pop(ek, None)
    m_key_H.pop(ek, None)
```
2025-11-27 21:14:08,677 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 1
- Hit Rate: 0.4779

Example 2:
- Trace ID: 4
- Hit Rate: 0.5002

Example 3:
- Trace ID: 34
- Hit Rate: 0.0789

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:14:08 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:14:08,680 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:17:17 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:17:17,345 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:17:17,346 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# GreedyDual-TinyLFU with Segmented Promotion (GD-TLFU-SP)
# - Unifies strong size-awareness (GreedyDual) with decayed frequency (TinyLFU)
#   and light recency via GreedyDual's aging term.
# - Two logical segments:
#     • Probation (segment=0): newly admitted (or single-hit) items
#     • Protected (segment=1): items promoted on a hit (>=2 resident hits)
#   Probation items are slightly more evictable via a small discount.
# - Priority (stored per resident):
#     H(key) = GD_AGE + V(key), where
#       V(key) = (log2(1 + lfu_count) + bonus) / ( (size/capacity) ** ALPHA )
#     bonus = PROT_BONUS if in protected (or multi-hit), else 0
#   Eviction removes the smallest priority and then raises GD_AGE to that value.
# - Lazy-decayed TinyLFU sketch using 4-bit counters with epochs (no sweeping).
# - On hit/insert: increment TinyLFU, refresh last-access, update resident_hits,
#   adjust segment, and recompute priority.

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU-ish tie-break)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation) or 1 (protected)
m_priority = dict()        # key -> float (GreedyDual priority)

# GreedyDual global aging term
m_gd_age = 0.0

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # accesses per epoch (power of two recommended)

# Tunables
ALPHA = 1.08           # size penalty exponent (higher -> more size-sensitive)
PROT_BONUS = 0.85      # additive bonus for protected/multi-hit items
PROB_DISCOUNT = 0.10   # probation priority discount (makes them more evictable)

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    # Ensure TinyLFU epoch is advanced; GreedyDual age is maintained lazily.
    _lfu_maybe_advance_epoch(cache_snapshot)

def _size_norm(size, capacity):
    # Fraction of capacity occupied by this object
    return max(1e-12, float(size) / float(capacity))

def _value_component(cache_snapshot, key, size, seg, resident_hits):
    # V(key) = (log2(1 + freq) + bonus) / (size_norm ** ALPHA)
    freq = _lfu_peek(cache_snapshot, key)
    base = math.log2(1.0 + float(freq))
    bonus = PROT_BONUS if (seg >= 1 or resident_hits >= 2) else 0.0
    s_norm = _size_norm(size, cache_snapshot.capacity)
    return (base + bonus) / (s_norm ** ALPHA)

def _recompute_priority(cache_snapshot, key):
    # Compute and store GreedyDual priority for a resident key.
    # Falls back safely if object is unexpectedly missing.
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        # Object not resident; remove stale metadata.
        m_priority.pop(key, None)
        m_segment.pop(key, None)
        m_last_access.pop(key, None)
        m_resident_hits.pop(key, None)
        return None

    seg = m_segment.get(key, 0)
    hits = m_resident_hits.get(key, 1)
    v = _value_component(cache_snapshot, key, robj.size, seg, hits)
    prio = m_gd_age + v
    m_priority[key] = prio
    return prio

def _adjusted_priority_for_eviction(key, base_prio):
    # Probation items are slightly more evictable via a small discount.
    seg = m_segment.get(key, 0)
    if seg <= 0:
        return base_prio * (1.0 - PROB_DISCOUNT)
    return base_prio

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest adjusted GreedyDual priority.
    After selecting the victim, the GreedyDual age will be advanced in
    update_after_evict to the victim's base priority (monotonic non-decreasing).
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_adj_prio = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        base_prio = m_priority.get(k)
        if base_prio is None:
            base_prio = _recompute_priority(cache_snapshot, k)
            if base_prio is None:
                continue
        adj = _adjusted_priority_for_eviction(k, base_prio)
        last = m_last_access.get(k, -1)
        if (min_adj_prio is None) or (adj < min_adj_prio) or (adj == min_adj_prio and last < min_time):
            min_adj_prio = adj
            min_time = last
            min_key = k

    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key

def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Promote to protected segment on the first resident hit (>=2)
      - Refresh last-access time
      - Recompute GreedyDual priority with current GD_AGE
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count

    # Resident hit count and segment promotion
    prev_hits = m_resident_hits.get(k, 1)
    new_hits = prev_hits + 1
    m_resident_hits[k] = new_hits

    if new_hits >= 2:
        m_segment[k] = 1  # protected
    else:
        m_segment.setdefault(k, 0)  # probation by default

    _recompute_priority(cache_snapshot, k)

def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key (admission signal)
      - Set segment to probation
      - Initialize resident metadata: last_access, resident_hits = 1
      - Initialize GreedyDual priority using current GD_AGE
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    _recompute_priority(cache_snapshot, k)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Advance GreedyDual age to the victim's base priority (monotonic).
      - Remove resident-only metadata (TinyLFU counters are retained).
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    prio = m_priority.pop(ek, None)

    # Advance GreedyDual age to the victim's base priority
    global m_gd_age
    if prio is not None and prio > m_gd_age:
        m_gd_age = prio

    # Retain TinyLFU counters (important for future admissions)
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
```
2025-11-27 21:17:41,685 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved policy: Heap-Accelerated TinyLFU with Size and Recency (HALO-TFS)
# - Fast eviction via a lazy min-heap of retention scores (no full scans)
# - TinyLFU with lazy epoch decay (per-key small counters remembered across evictions)
# - Size-aware, recency-aware scoring with multi-hit boost
# - Robust to workload shifts; avoids timeouts via O(log n) victim selection and periodic heap rebuilds

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_resident_hits = dict()    # key -> int resident hit count (>=1 once inserted)

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096   # accesses per epoch (power of two recommended)
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192  # how often to check if heap needs rebuilding
HEAP_GROWTH_FACTOR = 4       # if heap > factor * resident_count, rebuild

# Tunables for scoring
SIZE_ALPHA = 0.75           # size normalization exponent; smaller favors small objects
REC_WIN_MIN = 64            # minimum recency window
REC_WIN_MULT = 8            # recency window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.75           # strength of recency term added to frequency
MULTI_HIT_BONUS = 0.50      # multiplicative boost for items with >=2 hits while resident


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # no sweeping; decay handled lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring
# -----------------------------

def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency component
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    r_term = _recency_term(now, m_last_access.get(key), window)

    # Multi-hit boost (stronger protection after the second hit)
    mh = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    mult = 1.0 + mh

    # Final score: combine frequency and recency, then size-normalize
    score = ((f_term + REC_WEIGHT * r_term) * mult) / size_norm
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    # Rebuild heap from current residents with fresh scores/versions
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    Lazy invalidation ensures correctness despite changing scores/epochs.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., unusual bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            if k not in m_ver:
                # Initialize resident metadata if missing (best effort)
                m_last_access.setdefault(k, cache_snapshot.access_count)
                m_resident_hits.setdefault(k, 1)
            _heap_push(cache_snapshot, k)

    # Candidate's "would-be" score (informal comparison; does not affect required eviction)
    # This is used only to help prefer weaker residents when ties occur.
    cand_freq = _lfu_peek(cache_snapshot, obj.key) + 1  # will be incremented on insert
    cand_f_term = math.log1p(float(cand_freq))
    cand_size_norm = max(1.0, float(obj.size)) ** SIZE_ALPHA
    cand_score = (cand_f_term + REC_WEIGHT * 1.0) / cand_size_norm  # recency ~1 on insert

    # Pop until we find a valid, up-to-date victim
    while m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            continue
        # Skip if stale entry
        if m_ver.get(k, 0) != v:
            continue
        # Recompute current score to account for epoch/window changes
        new_sc = _score_key(cache_snapshot, k)
        # If the score drifted upward (got better), reinsert with new score
        if new_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            continue
        # Optional tie-breaker with candidate: if resident clearly stronger than candidate,
        # try to find a weaker one by peeking more; but if none, return this one.
        if new_sc >= cand_score:
            # Keep searching a bit for something weaker; cap extra attempts to avoid overhead
            attempts = 0
            tmp = [(sc, last, k, v)]
            victim = None
            while attempts < 8 and m_heap:
                sc2, last2, k2, v2 = heapq.heappop(m_heap)
                if k2 not in cache_snapshot.cache or m_ver.get(k2, 0) != v2:
                    attempts += 1
                    continue
                cur_sc2 = _score_key(cache_snapshot, k2)
                if cur_sc2 > sc2 + 1e-12:
                    _heap_push(cache_snapshot, k2)
                    attempts += 1
                    continue
                if cur_sc2 < cand_score or cur_sc2 < new_sc:
                    victim = (cur_sc2, last2, k2, v2)
                    break
                tmp.append((sc2, last2, k2, v2))
                attempts += 1
            # Push back any entries we popped but didn't choose
            for ent in tmp:
                heapq.heappush(m_heap, ent)
            if victim is not None:
                return victim[2]
            # Fall back to the original k
        return k

    # Fallback: choose the oldest resident if heap is somehow empty
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch and increment counter for requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember its popularity)
      - Invalidate its heap version (lazy: stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_ver.pop(ek, None)
    _touch_and_maybe_rebuild(cache_snapshot)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 36
- Hit Rate: 0.1992

Example 2:
- Trace ID: 2
- Hit Rate: 0.4847

Example 3:
- Trace ID: 46
- Hit Rate: 0.4663

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:17:41 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:17:41,687 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:19:13 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:19:13,472 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:19:13,474 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Policy: GreedyDual-Size with TinyLFU (GD-TinyLFU)
# - Eviction via GreedyDual priority (p = L + cost/size^alpha)
# - TinyLFU with lazy epoch decay as a predictive "cost"
# - Size-aware, recency-aware via GreedyDual's inflation L
# - O(log n) eviction with lazy heap invalidation and periodic rebuild

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 2048   # accesses per epoch; smaller -> more reactive
LFU_MAX = 63                # saturating counter cap

# GreedyDual structures
m_L = 0.0                   # global inflation (recency anchor)
m_prio = dict()             # key -> current priority p
m_heap = []                 # min-heap of (p, key, version)
m_ver = dict()              # key -> current version for lazy invalidation

# Optional resident metadata
m_resident_hits = dict()    # key -> int count of hits while resident (>=1 once inserted)

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192
HEAP_GROWTH_FACTOR = 4

# Tunables
SIZE_ALPHA = 0.85           # size normalization exponent (0..1); higher penalizes large objs more
BETA_FREQ = 1.00            # weight for TinyLFU-based frequency cost
MULTI_HIT_BONUS = 0.35      # extra cost for multi-hit residents (stabilizes against churn)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # no sweeping; decay handled lazily per key


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Priority / scoring
# -----------------------------

def _cost_for_key(cache_snapshot, key):
    """
    Predictive cost using TinyLFU, with a small boost after the second resident hit.
    """
    freq = _lfu_peek(cache_snapshot, key)
    f_term = BETA_FREQ * math.log1p(float(freq))
    mh = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    # Base cost >= 1 to ensure some protection even with zero frequency
    return 1.0 + f_term + mh


def _priority_for_key(cache_snapshot, key):
    """
    GreedyDual priority: p = L + cost / size^alpha
    """
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA
    cost = _cost_for_key(cache_snapshot, key)
    return m_L + (cost / size_norm)


def _heap_push_with_priority(key, p):
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    m_prio[key] = p
    heapq.heappush(m_heap, (p, key, v))


def _heap_push(cache_snapshot, key):
    p = _priority_for_key(cache_snapshot, key)
    _heap_push_with_priority(key, p)


def _maybe_rebuild_heap(cache_snapshot):
    """
    Rebuild heap when many stale entries accumulate.
    """
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    new_heap = []
    for k in cache_snapshot.cache.keys():
        p = _priority_for_key(cache_snapshot, k)
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        m_prio[k] = p
        new_heap.append((p, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim using GreedyDual priority.
    The smallest p is evicted. Priority incorporates TinyLFU and size.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # Seed heap if empty
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            m_resident_hits.setdefault(k, 1)
            _heap_push(cache_snapshot, k)

    # Pop until we find a valid, up-to-date resident
    while m_heap:
        p, k, v = heapq.heappop(m_heap)
        if k not in cache_snapshot.cache:
            continue
        if m_ver.get(k, 0) != v:
            continue
        # Found a valid victim; return it. L will be updated in update_after_evict.
        return k

    # Fallback: if heap is unexpectedly empty, evict an arbitrary resident (oldest by priority recompute)
    victim = None
    min_p = None
    for k in cache_snapshot.cache.keys():
        cur_p = _priority_for_key(cache_snapshot, k)
        if (min_p is None) or (cur_p < min_p):
            min_p = cur_p
            victim = k
    return victim


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch and increment counter
      - Increment resident hit count
      - Refresh priority using current L and push new heap entry
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Update GreedyDual priority
    p = _priority_for_key(cache_snapshot, k)
    _heap_push_with_priority(k, p)

    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch and increment counter for the requested key
      - Initialize resident hit count to 1
      - Compute initial GreedyDual priority and push
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_resident_hits[k] = 1

    p = _priority_for_key(cache_snapshot, k)
    _heap_push_with_priority(k, p)

    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Set L to the victim's priority (GreedyDual inflation step)
      - Remove resident-only metadata (keep TinyLFU to remember popularity)
      - Invalidate heap entries via version removal (stale entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    # Update GreedyDual inflation
    evicted_p = m_prio.get(ek)
    if evicted_p is not None:
        # In GreedyDual, L becomes the priority of the evicted item
        # This increases the effective "age" and naturally decays stale items.
        global m_L
        m_L = max(m_L, float(evicted_p))

    # Cleanup resident metadata
    m_prio.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_ver.pop(ek, None)

    _touch_and_maybe_rebuild(cache_snapshot)
```
2025-11-27 21:19:31,484 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 9
- Hit Rate: 0.531

Example 2:
- Trace ID: 6
- Hit Rate: 0.2775

Example 3:
- Trace ID: 3
- Hit Rate: 0.4404

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:19:31 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:19:31,485 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:22:11 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:22:11,043 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:22:11,045 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# GreedyDual-TinyLFU with Probation/Protected (GDTL-P) eviction
# - Combines TinyLFU frequency sketch with GreedyDual-Size aging and a
#   simple two-tier SLRU (probation/protected) structure.
# - Size-aware benefit: benefit = log2(1+freq) / normalized_size
# - GreedyDual priority: priority = global_L + benefit [+ small bonuses/penalties]
# - Evict: choose resident with the smallest priority (prefer probation tier)
# - On hit: increment TinyLFU, promote probation->protected, refresh priority
# - On insert: place in probation and assign priority
# - On evict: bump global_L to victim's priority (GreedyDual aging)

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (for LRU tiebreaks, staleness)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_stage = dict()           # key -> 0: probation, 1: protected

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# GreedyDual priority per key and age
m_priority = dict()        # key -> float current priority
m_gd_L = 0.0               # global aging factor (L)
m_last_evict_priority = 0.0  # remember last victim's priority

# Tunables
MULTI_HIT_BONUS = 0.5      # extra benefit for items with >=2 resident hits
PROTECTED_BONUS = 0.25     # small bonus for protected items
STALE_WEIGHT = 0.15        # small penalty for being old relative to window
REC_WIN_MIN = 512          # minimum recency window for normalized age
REC_WIN_MULT = 3           # window ~ REC_WIN_MULT * resident_items

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Helper computations
# -----------------------------

def _normalized_size(size, capacity):
    # Size as percentage of capacity to keep benefit within a stable range.
    # Floor to avoid division blow-ups.
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _benefit(cache_snapshot, key, size):
    # TinyLFU frequency with a small multi-hit bonus, size-aware
    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cache_snapshot.capacity)
    return (math.log2(1.0 + float(freq)) + extra) / size_norm

def _priority_of(cache_snapshot, key):
    # Compute GreedyDual priority with small stage bonus and mild staleness penalty
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # not resident; should never be selected
    b = _benefit(cache_snapshot, key, obj.size)

    # Stage bonus: protect items that earned promotion
    if m_stage.get(key, 0) == 1:
        b += PROTECTED_BONUS

    # Mild staleness penalty to flush stale protected items eventually
    now = cache_snapshot.access_count
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    a_norm = _recency_normalized(now, m_last_access.get(key), window)
    b -= STALE_WEIGHT * a_norm

    return m_gd_L + b

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident with the smallest GreedyDual-TinyLFU priority.
    Prefer victims from the probation tier; if none exist, evict from protected.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    # Partition keys by stage
    probation_keys = []
    protected_keys = []
    for k in cache_snapshot.cache.keys():
        if m_stage.get(k, 0) == 1:
            protected_keys.append(k)
        else:
            probation_keys.append(k)

    # Prefer evicting from probation
    search_keys = probation_keys if probation_keys else protected_keys

    min_key = None
    min_pr = None
    min_time = None

    for k in search_keys:
        pr = _priority_of(cache_snapshot, k)
        # Store latest computed priority for reuse
        m_priority[k] = pr
        last = m_last_access.get(k, -1)
        if (min_pr is None) or (pr < min_pr) or (pr == min_pr and last < min_time):
            min_pr = pr
            min_time = last
            min_key = k

    # Fallback: if somehow empty, return any key
    if min_key is None:
        try:
            min_key = next(iter(cache_snapshot.cache))
            min_pr = _priority_of(cache_snapshot, min_key)
        except StopIteration:
            return None

    # Remember this eviction's priority for GreedyDual aging in update_after_evict
    global m_last_evict_priority
    m_last_evict_priority = min_pr

    return min_key

def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Promote probation -> protected
      - Increment resident hit count
      - Refresh last-access time
      - Refresh GreedyDual priority
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)

    # resident hits (start from 1 once inserted)
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Stage promotion on first successful reuse
    if m_stage.get(k, 0) == 0:
        m_stage[k] = 1  # promote to protected

    m_last_access[k] = cache_snapshot.access_count

    # Refresh priority with current global_L
    m_priority[k] = _priority_of(cache_snapshot, k)

def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1, stage = probation
      - Assign initial GreedyDual priority
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    m_stage[k] = 0  # probation upon insert

    # Assign initial priority
    m_priority[k] = _priority_of(cache_snapshot, k)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Advance GreedyDual global age L to the victim's priority
      - Remove resident-only metadata (TinyLFU counters are retained)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Update GreedyDual age (set to evicted priority)
    global m_gd_L, m_last_evict_priority
    # m_last_evict_priority was set in evict(); use it if available,
    # else fall back to current stored/computed priority
    ev_pr = m_last_evict_priority
    if not isinstance(ev_pr, (int, float)) or ev_pr == 0.0:
        ev_pr = m_priority.get(ek, _priority_of(cache_snapshot, ek))
    m_gd_L = float(ev_pr)

    # Clean resident-only metadata
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stage.pop(ek, None)
    m_priority.pop(ek, None)
```
2025-11-27 21:22:47,624 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 27
- Hit Rate: 0.8939

Example 2:
- Trace ID: 21
- Error: Error - Timeout

Example 3:
- Trace ID: 10
- Hit Rate: 0.1167

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:22:47 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:22:47,625 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:24:54 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:24:54,098 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:24:54,100 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Sampled TinyLFU-Recency-Size (sTFRS)
# - Same core signal as TFRS (TinyLFU + recency + size), but with O(1) metadata updates
#   and O(k) eviction via small random sampling (k << resident_items).
#   This removes full-cache scans and prevents timeouts on large traces.
# - TinyLFU with lazy-epoch 4-bit counters (counts both resident and non-resident accesses)
# - Recency bonus to protect very recent items
# - Size-aware benefit: small items get proportionally higher retention per byte
# - Multi-hit resident items get a small boost
#
# Key changes vs previous version:
#   1) Eviction scans only a small random sample of residents (default 32), not all keys.
#   2) Maintain an O(1) resident-key index (array + position map) for fast sampling/removal.
#   3) Keep the effective scoring model but improve performance to avoid timeouts.

import math
import random

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU-ish timestamp)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# Fast resident set for sampling (array + index map for O(1) add/remove)
m_resident_keys = []       # list of keys currently resident
m_resident_pos = dict()    # key -> index in m_resident_keys

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Sampling parameters for eviction
SAMPLE_SIZE_BASE = 32      # default random sample size
SAMPLE_SIZE_MIN = 8        # lower bound when cache small
SAMPLE_SIZE_MAX = 64       # upper bound; keep k small for speed

# Precompute log2(1+freq) for 4-bit frequency values (0..15)
_FREQ_GAIN = [math.log2(1 + i) for i in range(16)]


# -----------------------------
# Initialization helper
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)
    # Nothing else capacity-dependent to initialize


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Resident set helpers
# -----------------------------

def _resident_add(key):
    if key in m_resident_pos:
        return
    idx = len(m_resident_keys)
    m_resident_keys.append(key)
    m_resident_pos[key] = idx


def _resident_remove(key):
    idx = m_resident_pos.pop(key, None)
    if idx is None:
        return
    last_idx = len(m_resident_keys) - 1
    if idx != last_idx:
        last_key = m_resident_keys[last_idx]
        m_resident_keys[idx] = last_key
        m_resident_pos[last_key] = idx
    m_resident_keys.pop()


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit stable across caches
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key):
    # score = benefit - recency_gain
    #   benefit      = log2(1 + freq) (+bonus if multi-hit) divided by normalized size
    #   recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        # Should not occur; keep it very evictable
        return float('-inf')
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (_FREQ_GAIN[freq] + extra) / size_norm

    # Recency protection
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    return benefit - recency_gain


def _sample_keys(k):
    # Fast random sample without building an intermediate list
    # Uses our resident array for O(k) sampling.
    n = len(m_resident_keys)
    if n == 0:
        return []
    if k >= n:
        # Small cache: sample all
        return list(m_resident_keys)
    # Reservoir-like: random.sample over a range with indirection to keys
    # We avoid constructing a full list of keys.
    chosen = set()
    out = []
    while len(out) < k:
        idx = random.randrange(0, n)
        if idx not in chosen:
            chosen.add(idx)
            out.append(m_resident_keys[idx])
    return out


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score,
    but choose among a small random sample of residents to avoid full scans.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    n = len(m_resident_keys)
    if n == 0:
        # Fallback: rely on cache_snapshot.cache when our index is desynced (should not happen)
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Adaptive sample size: increase slightly with cache size but keep bounded
    if n <= SAMPLE_SIZE_MIN:
        sample_size = n
    else:
        # Grow very slowly with n to reduce variance a bit
        sample_size = min(SAMPLE_SIZE_MAX, max(SAMPLE_SIZE_MIN, SAMPLE_SIZE_BASE))

    candidates = _sample_keys(sample_size)

    min_key = None
    min_score = None
    min_time = None

    for k in candidates:
        score = _retention_score(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Safety fallback if sampling failed to pick one
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1
    # No change to resident set (already present)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key (so non-resident history matters)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Add key to resident sampling set
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    _resident_add(k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Remove key from resident sampling set
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Keep TinyLFU history to improve future admission/retention
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    _resident_remove(ek)
```
2025-11-27 21:27:34,659 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Sampled TinyLFU-Recency-Size (sTFRS)
# - Same core signal as TFRS (TinyLFU + recency + size), but with O(1) metadata updates
#   and O(k) eviction via small random sampling (k << resident_items).
#   This removes full-cache scans and prevents timeouts on large traces.
# - TinyLFU with lazy-epoch 4-bit counters (counts both resident and non-resident accesses)
# - Recency bonus to protect very recent items
# - Size-aware benefit: small items get proportionally higher retention per byte
# - Multi-hit resident items get a small boost
#
# Key changes vs previous version:
#   1) Eviction scans only a small random sample of residents (default 32), not all keys.
#   2) Maintain an O(1) resident-key index (array + position map) for fast sampling/removal.
#   3) Keep the effective scoring model but improve performance to avoid timeouts.

import math
import random

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU-ish timestamp)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# Fast resident set for sampling (array + index map for O(1) add/remove)
m_resident_keys = []       # list of keys currently resident
m_resident_pos = dict()    # key -> index in m_resident_keys

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Sampling parameters for eviction
SAMPLE_SIZE_BASE = 32      # default random sample size
SAMPLE_SIZE_MIN = 8        # lower bound when cache small
SAMPLE_SIZE_MAX = 64       # upper bound; keep k small for speed

# Precompute log2(1+freq) for 4-bit frequency values (0..15)
_FREQ_GAIN = [math.log2(1 + i) for i in range(16)]


# -----------------------------
# Initialization helper
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)
    # Nothing else capacity-dependent to initialize


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Resident set helpers
# -----------------------------

def _resident_add(key):
    if key in m_resident_pos:
        return
    idx = len(m_resident_keys)
    m_resident_keys.append(key)
    m_resident_pos[key] = idx


def _resident_remove(key):
    idx = m_resident_pos.pop(key, None)
    if idx is None:
        return
    last_idx = len(m_resident_keys) - 1
    if idx != last_idx:
        last_key = m_resident_keys[last_idx]
        m_resident_keys[idx] = last_key
        m_resident_pos[last_key] = idx
    m_resident_keys.pop()


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit stable across caches
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key):
    # score = benefit - recency_gain
    #   benefit      = log2(1 + freq) (+bonus if multi-hit) divided by normalized size
    #   recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        # Should not occur; keep it very evictable
        return float('-inf')
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (_FREQ_GAIN[freq] + extra) / size_norm

    # Recency protection
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    return benefit - recency_gain


def _sample_keys(k):
    # Fast random sample without building an intermediate list
    # Uses our resident array for O(k) sampling.
    n = len(m_resident_keys)
    if n == 0:
        return []
    if k >= n:
        # Small cache: sample all
        return list(m_resident_keys)
    # Reservoir-like: random.sample over a range with indirection to keys
    # We avoid constructing a full list of keys.
    chosen = set()
    out = []
    while len(out) < k:
        idx = random.randrange(0, n)
        if idx not in chosen:
            chosen.add(idx)
            out.append(m_resident_keys[idx])
    return out


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score,
    but choose among a small random sample of residents to avoid full scans.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    n = len(m_resident_keys)
    if n == 0:
        # Fallback: rely on cache_snapshot.cache when our index is desynced (should not happen)
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Adaptive sample size: increase slightly with cache size but keep bounded
    if n <= SAMPLE_SIZE_MIN:
        sample_size = n
    else:
        # Grow very slowly with n to reduce variance a bit
        sample_size = min(SAMPLE_SIZE_MAX, max(SAMPLE_SIZE_MIN, SAMPLE_SIZE_BASE))

    candidates = _sample_keys(sample_size)

    min_key = None
    min_score = None
    min_time = None

    for k in candidates:
        score = _retention_score(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Safety fallback if sampling failed to pick one
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1
    # No change to resident set (already present)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key (so non-resident history matters)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Add key to resident sampling set
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    _resident_add(k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Remove key from resident sampling set
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Keep TinyLFU history to improve future admission/retention
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    _resident_remove(ek)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 23
- Hit Rate: 0.0606

Example 2:
- Trace ID: 14
- Hit Rate: 0.0228

Example 3:
- Trace ID: 45
- Hit Rate: 0.1719

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:27:34 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:27:34,660 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:30:33 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:30:33,257 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:30:33,258 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# W-sTFRS: Windowed Sampled TinyLFU with Recency and Size
# - Two segments:
#     W (window): byte-capped LRU to absorb bursts/scan and protect very new items
#     M (main):   frequency/size/recency-based retention, evicted via small random sampling
# - Adaptive window size via ARC-like ghost feedback (recently evicted from W vs M)
# - TinyLFU (4-bit, lazy-decayed) counts all requests (resident and non-resident)
# - O(1) updates on hits/inserts/evictions; O(k) sampling on eviction (k << residents)
#
# Rationale:
#   The window prevents scan pollution and boosts recency; the main segment keeps
#   frequency- and size-aware items. Ghost feedback adjusts the window size to match
#   workload mix. This typically lowers miss rates across diverse traces.

import math
import random
from collections import deque

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU-ish timestamp)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_seg = dict()             # key -> 'W' or 'M'

# Main-segment resident set for sampling (array + index map for O(1) add/remove)
m_resident_keys = []       # M-segment keys
m_resident_pos = dict()    # key -> index in m_resident_keys

# Window (W) LRU: doubly linked list via dicts for O(1) add/move/remove
m_w_prev = dict()
m_w_next = dict()
m_w_head = None
m_w_tail = None
m_w_bytes = 0              # current bytes in W

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Ghost lists (recently evicted non-residents) for window-size adaptation
G_W = set()
G_M = set()
G_W_q = deque()
G_M_q = deque()
GHOST_MAX = 65536          # cap ghost remembering to keep overhead bounded

# Window target (bytes), self-tuned
m_last_capacity = None
m_w_target_bytes = None
W_FRAC_INIT = 0.12         # initial window ~12% of capacity bytes
W_FRAC_MIN = 0.02          # lower bound ~2%
W_FRAC_MAX = 0.50          # upper bound ~50%
W_TUNE_STEP_FRAC = 0.02    # +/-2% capacity per adjustment event
W_HYSTERESIS_FRAC = 0.05   # 5% hysteresis to avoid flap

# Scoring tunables
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.35          # strength of recency bonus in retention score (higher -> more recency)
MULTI_HIT_BONUS = 0.25     # extra benefit for items with >=2 resident hits

# Sampling parameters for main-segment eviction
SAMPLE_SIZE_MIN = 16
SAMPLE_SIZE_MAX = 96

# Precompute log2(1+freq) for 4-bit frequency values (0..15)
_FREQ_GAIN = [math.log2(1 + i) for i in range(16)]


# -----------------------------
# Initialization helper
# -----------------------------

def _init_if_needed(cache_snapshot):
    global m_lfu_epoch, m_last_capacity, m_w_target_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = cache_snapshot.capacity
    if m_last_capacity != cap or m_w_target_bytes is None:
        m_last_capacity = cap
        # Initialize window target to a fraction of capacity bytes
        m_w_target_bytes = max(1, int(W_FRAC_INIT * cap))


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Window (W) LRU helpers
# -----------------------------

def _w_add_front(cache_snapshot, key, size):
    global m_w_head, m_w_tail, m_w_bytes
    if key in m_w_prev or key in m_w_next or m_seg.get(key) == 'W':
        # Already present; first remove to avoid duplicates
        _w_remove(cache_snapshot, key, size)
    m_w_prev[key] = None
    m_w_next[key] = m_w_head
    if m_w_head is not None:
        m_w_prev[m_w_head] = key
    m_w_head = key
    if m_w_tail is None:
        m_w_tail = key
    m_w_bytes += size


def _w_remove(cache_snapshot, key, size=None):
    global m_w_head, m_w_tail, m_w_bytes
    if key not in m_w_prev and key not in m_w_next and m_w_head != key and m_w_tail != key:
        return
    # Determine size if not provided
    if size is None:
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            size = obj.size
        else:
            # best effort; if unknown, skip bytes accounting
            size = 0
    prev_k = m_w_prev.pop(key, None)
    next_k = m_w_next.pop(key, None)
    if prev_k is None:
        # head
        if m_w_head == key:
            m_w_head = next_k
    else:
        m_w_next[prev_k] = next_k
    if next_k is None:
        # tail
        if m_w_tail == key:
            m_w_tail = prev_k
    else:
        m_w_prev[next_k] = prev_k
    m_w_bytes = max(0, m_w_bytes - size)


def _w_oldest_key():
    return m_w_tail


# -----------------------------
# Main-segment resident sampling helpers
# -----------------------------

def _m_add(key):
    if key in m_resident_pos:
        return
    idx = len(m_resident_keys)
    m_resident_keys.append(key)
    m_resident_pos[key] = idx


def _m_remove(key):
    idx = m_resident_pos.pop(key, None)
    if idx is None:
        return
    last_idx = len(m_resident_keys) - 1
    if idx != last_idx:
        last_key = m_resident_keys[last_idx]
        m_resident_keys[idx] = last_key
        m_resident_pos[last_key] = idx
    m_resident_keys.pop()


def _m_sample_keys(k):
    n = len(m_resident_keys)
    if n == 0:
        return []
    if k >= n:
        return list(m_resident_keys)
    chosen = set()
    out = []
    while len(out) < k:
        idx = random.randrange(0, n)
        if idx not in chosen:
            chosen.add(idx)
            out.append(m_resident_keys[idx])
    return out


# -----------------------------
# Ghost helpers
# -----------------------------

def _ghost_add(gset, gq, key):
    if key in gset:
        return
    gset.add(key)
    gq.append(key)
    # Trim if too large
    while len(gq) > GHOST_MAX:
        old = gq.popleft()
        gset.discard(old)


def _tune_window_on_insert(cache_snapshot, key):
    global m_w_target_bytes
    cap = cache_snapshot.capacity
    step = max(1, int(W_TUNE_STEP_FRAC * cap))
    inGw = key in G_W
    inGm = key in G_M
    if inGw and not inGm:
        # Recent miss for a W-evicted key -> need more recency
        m_w_target_bytes = min(int(W_FRAC_MAX * cap), m_w_target_bytes + step)
    elif inGm and not inGw:
        # Recent miss for a M-evicted key -> too much recency, reduce window
        m_w_target_bytes = max(int(W_FRAC_MIN * cap), m_w_target_bytes - step)
    # Clear ghosts for this key to avoid repeated adjustments
    if inGw:
        G_W.discard(key)
    if inGm:
        G_M.discard(key)


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit stable across caches
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key):
    # score = benefit - recency_gain
    #   benefit      = log2(1 + freq) (+bonus if multi-hit) divided by normalized size
    #   recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (_FREQ_GAIN[freq] + extra) / size_norm

    # Recency protection
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Eviction strategy:
      1) If window W bytes exceed its target (with hysteresis), evict the oldest in W (pure LRU).
      2) Otherwise, evict from M using TinyLFU-Recency-Size retention score among a random sample.
         Ties broken by oldest last-access.
    '''
    _init_if_needed(cache_snapshot)

    # Prefer evicting from the window if it exceeds target (with hysteresis)
    w_cap = m_w_target_bytes
    if m_w_bytes > int(w_cap * (1.0 + W_HYSTERESIS_FRAC)):
        wk = _w_oldest_key()
        if wk is not None:
            return wk
        # Fall through if window tracking is inconsistent

    # Evict from main (M) via sampled selection
    nM = len(m_resident_keys)
    if nM == 0:
        # Nothing in M; evict oldest in W if any
        wk = _w_oldest_key()
        if wk is not None:
            return wk
        # Fallback: if both empty, rely on cache_snapshot
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Adaptive sample size ~ 2*sqrt(n), bounded
    sample_size = max(SAMPLE_SIZE_MIN, min(SAMPLE_SIZE_MAX, int(2.0 * math.sqrt(nM))))
    candidates = _m_sample_keys(sample_size)

    min_key = None
    min_score = None
    min_time = None

    for k in candidates:
        score = _retention_score(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    if min_key is not None:
        return min_key

    # Safety fallback
    wk = _w_oldest_key()
    if wk is not None:
        return wk
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - If in window W, promote to main M (SLRU-like), preserving TinyLFU history
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_seg.get(k)
    if seg == 'W':
        # Promote to M on first hit; remove from W-LRU, add to M sampling set
        _w_remove(cache_snapshot, k, obj.size)
        m_seg[k] = 'M'
        _m_add(k)
    # If already in M, nothing else needed


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - TinyLFU++ for the requested key (history)
      - Adjust window target via ARC-like ghost feedback
      - Place into window W (LRU); initialize resident metadata and segment
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)

    # Adaptive window tuning based on where this key was evicted from previously
    _tune_window_on_insert(cache_snapshot, k)

    # Initialize resident metadata
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # If somehow resident in M/W, clear previous tracking first
    if m_seg.get(k) == 'M':
        _m_remove(k)
    elif m_seg.get(k) == 'W':
        _w_remove(cache_snapshot, k, obj.size)

    # Insert into window W (LRU)
    _w_add_front(cache_snapshot, k, obj.size)
    m_seg[k] = 'W'


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata and segment tracking
      - Add key to appropriate ghost list (W or M) for window adaptation
      - For M, remove from the M sampling set; for W, remove from W-LRU
      - Keep TinyLFU history to improve future admissions/retention
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    seg = m_seg.pop(ek, None)

    # Remove metadata
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    if seg == 'M':
        _m_remove(ek)
        _ghost_add(G_M, G_M_q, ek)
    elif seg == 'W':
        # Ensure W structures drop it and bytes are updated
        _w_remove(cache_snapshot, ek, evicted_obj.size)
        _ghost_add(G_W, G_W_q, ek)
    else:
        # Unknown segment (inconsistent); assign to M ghost as conservative default
        _ghost_add(G_M, G_M_q, ek)
```
2025-11-27 21:31:00,627 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved: Count-based SLRU with TinyLFU, ARC-style adaptive split, and recency-aware scoring
# - Two resident segments by item count, not by bytes:
#     P (probation): admits all new objects; managed by LRU (via last_access timestamps)
#     S (protected): objects that hit at least once; also LRU-managed
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction score blends frequency and recency (recency matters beyond tie-break)
# - ARC-like ghost lists adapt the item split between P and S online (by counts)
#
# This design captures:
#   - Recency (via LRU timestamps and explicit recency in eviction score)
#   - Frequency (via TinyLFU)
#   - Adaptivity between recency-friendly and frequency-friendly behavior
#   - Correctness for caches limited by number of items (not bytes)

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU)
m_key_segment = dict()       # key -> 'P' or 'S'

# Current resident ITEM COUNTS per segment
m_cnt_P = 0
m_cnt_S = 0

# Adaptive target for protected items (S); probation target = capacity_items - target_S
m_target_S_items = None
m_cap_items_est = 0  # our estimate of capacity in number of items (learned at evict time)

# Ghost lists (non-resident metadata) to adapt split; store key -> last_time
m_ghost_P = dict()  # B1
m_ghost_S = dict()  # B2
m_ghost_limit_items = None

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)

# ---------------
# Scoring params
# ---------------
# Recency blend: score = est_freq + rec_weight * min(recency / half_life, rec_cap)
m_rec_half_life = 500.0  # accesses; tune to make recency effect comparable to est_freq
m_rec_cap = 10.0         # cap normalized recency contribution
m_rec_weight_P = 1.0     # probation recency weight
m_rec_weight_S = 0.6     # protected recency weight (S is more persistent)
m_protect_S_bias = 0.25  # additive bias to S candidates to modestly protect them
m_overweight_nudge = 0.2 # when a segment exceeds target, nudge its candidate to be more evictable

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_target_S_items, m_ghost_limit_items
    global m_sketch_tables, m_sketch_mask
    global m_cap_items_est

    # Learn capacity in items opportunistically; on evict() we'll update more accurately.
    if m_cap_items_est < len(cache_snapshot.cache):
        m_cap_items_est = len(cache_snapshot.cache)

    if m_target_S_items is None:
        # Start slightly frequency-friendly; adapt online
        base_items = max(1, len(cache_snapshot.cache))
        m_target_S_items = int(base_items * 0.6)

    if m_ghost_limit_items is None:
        # Each ghost list limited to approximately the cache capacity in items (we adjust later)
        m_ghost_limit_items = max(1, len(cache_snapshot.cache))

    if m_sketch_tables is None:
        # Width scales with estimated items; choose power of two near items*4 (empirical)
        # Minimum width to keep estimates reasonably stable.
        items = max(1, len(cache_snapshot.cache))
        width = 1
        target = max(1024, min(1 << 16, items * 4))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        # Halve all counters (right-shift by 1)
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _normalized_recency(now, last):
    if last is None or last < 0:
        return m_rec_cap
    age = max(0, now - last)
    norm = age / m_rec_half_life
    if norm > m_rec_cap:
        norm = m_rec_cap
    return norm


def _pick_min_score_in_segment(cache_snapshot, seg_tag, now):
    # Returns (key, score, last_time) that minimizes blended score within a segment
    # Score = est_freq + rec_weight * normalized_recency; tie-break by older first
    min_key = None
    min_score = None
    min_time = None

    rec_w = m_rec_weight_S if seg_tag == 'S' else m_rec_weight_P

    for key, obj in cache_snapshot.cache.items():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        est = float(_sketch_estimate(key))
        last = m_key_last_access.get(key, -1)
        rec = _normalized_recency(now, last)
        score = est + rec_w * rec
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = key
            min_score = score
            min_time = last

    return (min_key, min_score, min_time)


def _find_oldest_in_segment(cache_snapshot, seg_tag):
    oldest_key, oldest_time = None, None
    for k in cache_snapshot.cache.keys():
        if m_key_segment.get(k, 'P') != seg_tag:
            continue
        t = m_key_last_access.get(k, -1)
        if oldest_time is None or t < oldest_time:
            oldest_key, oldest_time = k, t
    return oldest_key


def _ghost_add(ghost_dict, key, time_now, which):
    # Add key->time to chosen ghost (which in {'P','S'}), trimming if exceeds limit
    global m_ghost_limit_items

    # Insert/update
    ghost_dict[key] = time_now

    # Trim to limit by evicting oldest
    limit = m_ghost_limit_items or 0
    if limit <= 0:
        return

    while len(ghost_dict) > limit:
        oldest_key, oldest_time = None, None
        for k, t in ghost_dict.items():
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        if oldest_key is None:
            break
        ghost_dict.pop(oldest_key, None)


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    # If key in P-ghost (B1): increase probation share (decrease S target)
    # If key in S-ghost (B2): increase protected share (increase S target)
    global m_target_S_items, m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Update our item-capacity estimate when cache is likely full (best signal: on evict call, but keep here too)
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)

    # Keep ghost size limits around capacity in items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est

    cap_items = max(1, m_cap_items_est)

    # Step size: 1 item per signal (conservative, stable)
    step = 1

    if obj.key in m_ghost_P:
        # Recent ghost hit: favor recency -> increase P share (decrease S)
        m_target_S_items = _clamp((m_target_S_items or 0) - step, 0, cap_items)
        m_ghost_P.pop(obj.key, None)
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: favor frequency -> increase S share
        m_target_S_items = _clamp((m_target_S_items or 0) + step, 0, cap_items)
        m_ghost_S.pop(obj.key, None)


def _maybe_demote_from_S_to_P(cache_snapshot):
    # If S exceeds its target, demote oldest S item to P
    global m_cnt_P, m_cnt_S, m_target_S_items
    if m_target_S_items is None:
        return
    if m_cnt_S > m_target_S_items:
        demote_key = _find_oldest_in_segment(cache_snapshot, 'S')
        if demote_key is not None:
            m_key_segment[demote_key] = 'P'
            m_cnt_S = max(0, m_cnt_S - 1)
            m_cnt_P += 1


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using count-based SLRU + TinyLFU with recency-aware scoring.
    - Compute candidate with minimal blended score in each segment:
        score = est_freq(key) + rec_weight * normalized_recency
    - Bias to evict from the segment exceeding its item-count target.
    - Protect S moderately by adding a small bias compared to P.
    '''
    global m_cnt_P, m_cnt_S, m_target_S_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Learn/refresh capacity in number of items at the moment of eviction (cache is full now)
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    cap_items = max(1, m_cap_items_est)
    if m_target_S_items is None:
        m_target_S_items = int(0.6 * cap_items)
    target_S = _clamp(m_target_S_items, 0, cap_items)
    target_P = cap_items - target_S

    now = cache_snapshot.access_count

    # Find min-score candidate in each segment
    p_key, p_score, p_lru = _pick_min_score_in_segment(cache_snapshot, 'P', now)
    s_key, s_score, s_lru = _pick_min_score_in_segment(cache_snapshot, 'S', now)

    # Prepare adjusted scores
    best_key = None
    best_adj = None

    if p_key is not None:
        adj_p = p_score
        # If P is overweight, make it slightly more likely to evict from P
        if m_cnt_P > target_P:
            adj_p -= m_overweight_nudge
        # No extra protection bias for P
        best_key = p_key
        best_adj = adj_p

    if s_key is not None:
        adj_s = s_score + m_protect_S_bias
        # If S is overweight, encourage eviction from S
        if m_cnt_S > target_S:
            adj_s -= m_overweight_nudge
        if (best_adj is None) or (adj_s < best_adj):
            best_adj = adj_s
            best_key = s_key

    # Fallback: if we somehow didn't find any key (shouldn't happen), pick oldest globally
    if best_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        best_key = oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - If in probation (P), promote to protected (S); if S exceeds target, demote oldest S to P
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    k = obj.key

    # Update TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    # Promote from P to S on hit
    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        m_key_segment[k] = 'S'
        m_cnt_P = max(0, m_cnt_P - 1)
        m_cnt_S += 1
        # If S above target, demote oldest S back to P
        _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S item split using ARC-like ghosts
      - Increment TinyLFU for the key (TinyLFU trains on both hits and misses)
      - Add the new object to probation (P)
      - Record last access time
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_cnt_P += 1

    # Keep S from drifting above target if previous operations changed target
    _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key
      - Update segment item counters
      - Add the key to the corresponding ghost list (count-limited) to guide future adaptation
      - Keep ghost sizes roughly equal to estimated cache capacity in items
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S
    global m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust item counts and add to appropriate ghost
    now = cache_snapshot.access_count
    if seg == 'S':
        m_cnt_S = max(0, m_cnt_S - 1)
        _ghost_add(m_ghost_S, ek, now, which='S')
    else:
        m_cnt_P = max(0, m_cnt_P - 1)
        _ghost_add(m_ghost_P, ek, now, which='P')

    # Update ghost limits to approximate current capacity in items
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 1
- Error: Error - Timeout

Example 2:
- Trace ID: 22
- Hit Rate: 0.0567

Example 3:
- Trace ID: 29
- Hit Rate: 0.0591

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:31:00 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:31:00,628 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:33:49 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:33:49,515 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:33:49,517 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Size-aware W-TinyLFU SLRU with byte-based targets and O(log N) operations
# - Three resident segments by BYTES:
#     W  (window): all new objects; managed by LRU
#     MP (main probation): promoted from W on first hit; LRU
#     MS (main protected): promoted from MP on second hit; LRU
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction chooses oldest within the most-overweight segment (by bytes);
#   otherwise evicts the lowest value-density candidate among W/MP (and MS only as last resort),
#   where value-density ~ est_freq / size^alpha (alpha in (0,1)), giving size-aware bias.
# - Adaptive targets:
#     * Window fraction (W) grows if many hits happen in W; shrinks otherwise
#     * Protected fraction (MS share of Main) grows if most hits are in MS; shrinks otherwise
# - Efficient metadata:
#     * Per-segment heaps keyed by last_access for O(log N) LRU operations, using lazy pruning
#     * No full scans on evictions, avoiding timeouts on large caches
#
# Assumptions:
#   - Cache capacity is in BYTES (cache_snapshot.capacity)
#   - The environment may call evict repeatedly until enough space is freed for a new object

from heapq import heappush, heappop

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU validation)
m_key_segment = dict()       # key -> 'W' | 'MP' | 'MS'
m_key_size = dict()          # key -> size in bytes (for quick segment bytes accounting)

# Segment byte counters
m_seg_bytes = {'W': 0, 'MP': 0, 'MS': 0}

# LRU heaps per segment: list of (last_access, key)
m_heap_W = []
m_heap_MP = []
m_heap_MS = []

# Adaptive byte targets (fractions)
m_frac_W = 0.15          # window fraction of total capacity
m_frac_MS_main = 0.7     # fraction of MAIN bytes (capacity * (1 - frac_W)) reserved for MS

m_frac_W_min = 0.05
m_frac_W_max = 0.30
m_frac_MS_min = 0.50
m_frac_MS_max = 0.95

# Adaptation bookkeeping
m_recent_hits = {'W': 0, 'MP': 0, 'MS': 0}
m_recent_ops = 0
m_adapt_interval = 20000  # adjust every N operations (hits+inserts)

# -------------------
# TinyLFU (CMSketch)
# -------------------
m_sketch_tables = None
m_sketch_mask = None
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0
m_sketch_age_interval = 100000  # aging interval
m_sketch_counter_cap = 255

# -----------------------------
# Scoring params (size-aware)
# -----------------------------
# value_density ~ est_freq / size_bytes^alpha
m_size_alpha = 0.7
m_ms_protect_bias = 1.25  # multiply MS candidate score to protect it in tie situations

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_sketch_tables, m_sketch_mask
    if m_sketch_tables is None:
        # Width: power of two near max(4k, capacity/64) to balance accuracy and space
        cap = max(1, int(cache_snapshot.capacity))
        target = max(4096, min(1 << 16, cap // 64))
        width = 1
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        v = m_sketch_tables[t][i]
        nv = v + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    if m_sketch_ops >= m_sketch_age_interval:
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _push_heap(seg, key, ts):
    entry = (ts, key)
    if seg == 'W':
        heappush(m_heap_W, entry)
    elif seg == 'MP':
        heappush(m_heap_MP, entry)
    else:
        heappush(m_heap_MS, entry)


def _heap_pop_valid(heap, seg):
    # Pop until entry is valid (still in same segment and ts matches last_access)
    while heap:
        ts, key = heappop(heap)
        if m_key_segment.get(key) != seg:
            continue
        if m_key_last_access.get(key) != ts:
            continue
        return (ts, key)
    return (None, None)


def _heap_peek_valid(heap, seg):
    # Peek oldest valid element without removing; does lazy pops from a copy buffer
    # Implement via pop-valid + re-push to keep complexity manageable.
    ts, key = _heap_pop_valid(heap, seg)
    if key is None:
        return (None, None)
    # Reinsert to keep item in heap
    heappush(heap, (ts, key))
    return (ts, key)


def _get_oldest_key_in_seg(seg):
    if seg == 'W':
        _, k = _heap_peek_valid(m_heap_W, 'W')
        return k
    elif seg == 'MP':
        _, k = _heap_peek_valid(m_heap_MP, 'MP')
        return k
    else:
        _, k = _heap_peek_valid(m_heap_MS, 'MS')
        return k


def _seg_targets_bytes(cache_snapshot):
    cap = max(1, int(cache_snapshot.capacity))
    w = int(cap * m_frac_W)
    main = cap - w
    ms = int(main * m_frac_MS_main)
    mp = main - ms
    return {'W': w, 'MP': mp, 'MS': ms}


def _size_value_density(size_bytes, est_freq):
    # Avoid extremely strong bias toward minuscule objects: use size^alpha
    denom = max(1.0, float(size_bytes) ** m_size_alpha)
    return float(est_freq) / denom


def _demote_ms_if_needed(cache_snapshot):
    # Demote oldest MS to MP until MS bytes <= target
    targets = _seg_targets_bytes(cache_snapshot)
    while m_seg_bytes['MS'] > targets['MS']:
        ts, key = _heap_pop_valid(m_heap_MS, 'MS')
        if key is None:
            break
        # Move key to MP (keep its last_access = ts)
        m_key_segment[key] = 'MP'
        m_seg_bytes['MS'] -= m_key_size.get(key, 0)
        m_seg_bytes['MP'] += m_key_size.get(key, 0)
        _push_heap('MP', key, ts)


def _promote_on_hit(cache_snapshot, key, from_seg):
    # W -> MP on first hit; MP -> MS on second hit; MS stays
    ts = cache_snapshot.access_count
    if from_seg == 'W':
        # Promote to MP
        m_key_segment[key] = 'MP'
        size = m_key_size.get(key, 0)
        m_seg_bytes['W'] -= size
        m_seg_bytes['MP'] += size
        _push_heap('MP', key, ts)
    elif from_seg == 'MP':
        # Promote to MS
        m_key_segment[key] = 'MS'
        size = m_key_size.get(key, 0)
        m_seg_bytes['MP'] -= size
        m_seg_bytes['MS'] += size
        _push_heap('MS', key, ts)
        _demote_ms_if_needed(cache_snapshot)
    # If MS, nothing to change besides refreshing timestamp


def _adapt_targets_on_activity():
    # Adjust fractions based on recent hit distribution
    global m_frac_W, m_frac_MS_main, m_recent_hits, m_recent_ops
    total_hits = sum(m_recent_hits.values())
    if total_hits <= 0:
        m_recent_ops = 0
        return

    frac_hits_W = m_recent_hits['W'] / total_hits
    frac_hits_MS = m_recent_hits['MS'] / total_hits

    # Window grows if many hits occur in W (bursty recency)
    if frac_hits_W > 0.50:
        m_frac_W = _clamp(m_frac_W + 0.02, m_frac_W_min, m_frac_W_max)
    else:
        m_frac_W = _clamp(m_frac_W - 0.01, m_frac_W_min, m_frac_W_max)

    # Protected grows if most hits are in MS (strong frequency locality)
    if frac_hits_MS > 0.60:
        m_frac_MS_main = _clamp(m_frac_MS_main + 0.05, m_frac_MS_min, m_frac_MS_max)
    else:
        m_frac_MS_main = _clamp(m_frac_MS_main - 0.03, m_frac_MS_min, m_frac_MS_max)

    # Reset counters
    m_recent_hits = {'W': 0, 'MP': 0, 'MS': 0}
    m_recent_ops = 0


def _record_op_and_maybe_adapt():
    # Called on hit and insert to control adaptation cadence
    global m_recent_ops
    m_recent_ops += 1
    if m_recent_ops >= m_adapt_interval:
        _adapt_targets_on_activity()


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim:
      1) Evict oldest from the segment whose BYTES exceed target by the largest margin
      2) If no segment overweight, choose the lowest value-density candidate among W and MP
         (and MS only if W and MP are empty), where value-density ~ est_freq / size^alpha.
    '''
    _init_if_needed(cache_snapshot)

    targets = _seg_targets_bytes(cache_snapshot)

    # Determine overweight by bytes
    over_W = m_seg_bytes['W'] - targets['W']
    over_MP = m_seg_bytes['MP'] - targets['MP']
    over_MS = m_seg_bytes['MS'] - targets['MS']

    # Helper: fetch candidate key for a segment
    cand_W = _get_oldest_key_in_seg('W')
    cand_MP = _get_oldest_key_in_seg('MP')
    cand_MS = _get_oldest_key_in_seg('MS')

    # 1) Evict from most overweight segment
    overweight = [('W', over_W, cand_W), ('MP', over_MP, cand_MP), ('MS', over_MS, cand_MS)]
    overweight.sort(key=lambda x: x[1], reverse=True)  # largest positive first
    if overweight[0][1] > 0:
        seg_choice, _, key_choice = overweight[0]
        if key_choice is not None:
            return key_choice

    # 2) No overweight: prefer evicting from W or MP based on value-density; MS last resort
    best_key = None
    best_score = None

    # Candidate evaluation function
    def consider(seg, key):
        nonlocal best_key, best_score
        if key is None:
            return
        est = _sketch_estimate(key)
        size = max(1, m_key_size.get(key, 1))
        val = _size_value_density(size, est)
        # Lower value-density => less beneficial to keep => higher eviction priority
        # We invert it to a "cost" by taking negative value-density
        # For comparison, we simply use (-val) and apply segment bias for MS
        score = -val
        if seg == 'MS':
            score *= m_ms_protect_bias  # protect MS a bit
        if (best_score is None) or (score < best_score):
            best_score = score
            best_key = key

    consider('W', cand_W)
    consider('MP', cand_MP)

    if best_key is not None:
        return best_key

    # If W and MP are empty or lacked valid candidates, fall back to MS oldest
    if cand_MS is not None:
        return cand_MS

    # As a final fallback, evict the globally oldest (rare)
    # Scan minimal by peeking each heap
    ow = _get_oldest_key_in_seg('W')
    omp = _get_oldest_key_in_seg('MP')
    oms = _get_oldest_key_in_seg('MS')
    for k in (ow, omp, oms):
        if k is not None:
            return k

    # If cache appears empty (shouldn't happen), return any key from snapshot
    return next(iter(cache_snapshot.cache)) if cache_snapshot.cache else None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Train TinyLFU
      - Refresh last-access time (push to segment heap)
      - Promote W->MP, MP->MS; enforce MS target by demoting oldest MS to MP if needed
      - Track hit distribution for adaptive target tuning
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    seg = m_key_segment.get(k)
    if seg is None:
        # Unknown key; treat as a fresh observation
        return

    # Train TinyLFU
    _sketch_inc(k, 1)

    # Refresh last access
    ts = cache_snapshot.access_count
    m_key_last_access[k] = ts
    _push_heap(seg, k, ts)

    # Record hit segment for adaptation
    if seg in m_recent_hits:
        m_recent_hits[seg] += 1
    _record_op_and_maybe_adapt()

    # Promote on hit
    if seg == 'W' or seg == 'MP':
        _promote_on_hit(cache_snapshot, k, seg)
    elif seg == 'MS':
        # MS stays; already pushed updated ts
        pass


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss and successful admission by the cache):
      - Train TinyLFU on the key
      - Add to Window (W)
      - Initialize last-access and segment bytes
      - Periodically adapt segment targets
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    size = max(1, int(obj.size))

    # Train TinyLFU on miss as well
    _sketch_inc(k, 1)

    # Admit into Window
    ts = cache_snapshot.access_count
    m_key_last_access[k] = ts
    m_key_segment[k] = 'W'
    m_key_size[k] = size
    m_seg_bytes['W'] += size
    _push_heap('W', k, ts)

    _record_op_and_maybe_adapt()


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting:
      - Remove resident metadata
      - Update segment byte counters
      - No need to touch heaps due to lazy pruning
    '''
    ek = evicted_obj.key
    seg = m_key_segment.pop(ek, None)

    size = m_key_size.pop(ek, 0)
    m_key_last_access.pop(ek, None)

    if seg in m_seg_bytes:
        m_seg_bytes[seg] = max(0, m_seg_bytes[seg] - size)

    # No adaptation here; it's handled on hits/inserts
```
2025-11-27 21:36:08,521 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# W-TinyLFU + Segmented protection + Size-aware retention
# - Two logical segments:
#     1) probation (new/resurrected items)
#     2) protected (promoted on hit; byte-quota limited)
# - TinyLFU frequency counters with lazy epoch decay (8-bit saturating)
# - Size-aware retention: benefit = log1p(freq) / normalized_size
# - Recency bonus added (not subtracted) to protect recent items
# - Protected segment gets an extra bonus; demoted by LRU when over target bytes
# - Eviction uses lazy min-heaps (probation first, then protected) to avoid full scans
#   with lazy invalidation via per-key stamps; periodic score refresh on pop.
#
# This design:
#   - Dramatically reduces per-eviction cost (avoids O(n) scans) -> fewer timeouts
#   - Corrects recency sign (recent items are now protected, not penalized)
#   - Uses size-aware TinyLFU benefit and a protected segment to cut miss rate

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Cache identity (to reset between runs if needed)
m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting
m_prot_bytes = 0
m_prot_target_bytes = 0

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_probation = []           # retention score (lower => more evictable) for probation
h_protected = []           # retention score for protected (used when probation empty)
h_prot_lru = []            # last_access (min-heap) for protected demotions

# TinyLFU counters (lazy decay with epochs; per-key to keep it simple)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Protected segment target (bytes)
PROT_FRAC = 0.80           # target fraction of capacity for protected bytes

# Recency window and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 3           # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.60     # recency weight in probation
REC_WEIGHT_PROT = 0.40     # recency weight in protected
PROT_BONUS = 0.60          # extra benefit for protected segment
MULTI_HIT_BONUS = 0.30     # extra benefit for items with >=2 resident hits

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16  # bound reheap/refresh work per eviction

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC * cache_snapshot.capacity)

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Return size as percentage of capacity to keep scales stable
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _retention_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # treat missing as extremely good (will be filtered by validity)
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)

    seg = m_segment.get(key, 0)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    # Size-aware frequency benefit
    benefit = math.log1p(float(freq)) / size_norm

    # Multi-hit bias
    if m_resident_hits.get(key, 0) >= 2:
        benefit += MULTI_HIT_BONUS

    # Recency bonus
    if seg == 1:
        benefit += PROT_BONUS + REC_WEIGHT_PROT * rec_bonus
    else:
        benefit += REC_WEIGHT_PROB * rec_bonus

    return benefit


# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    # Compute score at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    score = _retention_score(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (score, s, key))
    else:
        heapq.heappush(h_protected, (score, s, key))
        # Also maintain LRU heap for protected demotions
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot, heap_ref, expected_seg):
    # Return a valid key from the given heap, refreshing stale scores when needed.
    # Limit work per call to avoid long stalls.
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        # Skip invalid/stale entries
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Opportunistically refresh score if it drifted
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            # Reinsert with a new stamp
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key
    return None


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        # Push into probation heap with updated score/stamp
        _push_key(cache_snapshot, key)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim:
      1) Pop the weakest from probation heap (lowest retention)
      2) If probation empty, pop the weakest from protected heap
      3) Fallback: any resident key
    '''
    _init_if_needed(cache_snapshot)

    # Prefer evicting from probation
    victim = _pop_best_candidate(cache_snapshot, h_probation, expected_seg=0)
    if victim is None:
        victim = _pop_best_candidate(cache_snapshot, h_protected, expected_seg=1)

    if victim is not None:
        return victim

    # Fallback: arbitrary key (should be rare)
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote probation -> protected on first resident hit
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with new score/recency
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote to protected
        m_segment[k] = 1
        # Account protected bytes
        global m_prot_bytes
        m_prot_bytes += obj.size
        # Push into protected heaps
        _push_key(cache_snapshot, k)
        # Enforce protected target
        _maybe_demote_protected(cache_snapshot)
    else:
        # Already protected: refresh heaps
        _push_key(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place into probation segment and push to heap
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation
    _push_key(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Adjust protected bytes if it was protected
    seg = m_segment.pop(ek, None)
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 26
- Hit Rate: 0.7905

Example 2:
- Trace ID: 6
- Hit Rate: 0.2727

Example 3:
- Trace ID: 39
- Hit Rate: 0.1076

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:36:08 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:36:08,522 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:38:57 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:38:57,526 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:38:57,527 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptively-sized protected segment + TinyLFU + size-aware scoring + ARC-style ghost feedback
# - Two resident segments:
#     0) probation (new/resurrected items)
#     1) protected (promoted on resident hit; byte-quota limited and demoted by LRU)
# - TinyLFU (8-bit, lazy epoch decay) counts requests for all keys
# - Size-aware benefit: log1p(freq) / normalized_size
# - Recency bonus (windowed by resident set size), lower in protected
# - Multi-hit bias for items with multiple resident hits
# - Eviction chooses the global weakest item across both segments (lazy heaps)
# - Adaptive protected-byte target tuned online using ARC-style ghost hits
# - Lazy heaps with per-key stamps avoid O(n) scans

import math
import heapq
from collections import deque

# -----------------------------
# Global metadata (module scope)
# -----------------------------

m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int(access_count) for recency
m_resident_hits = dict()   # key -> int resident hit count
m_segment = dict()         # key -> 0 probation, 1 protected
m_stamp = dict()           # key -> int, increases whenever key is re-pushed to heap

# Protected bytes accounting and adaptive target
m_prot_bytes = 0
m_prot_target_bytes = 0

# Heaps (lazy, stamped)
# Tuples: (priority, stamp, key)
h_probation = []
h_protected = []
h_prot_lru = []            # (last_access, stamp, key), to demote LRU from protected

# TinyLFU counters (lazy decay by epochs)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# Ghost histories for ARC-style feedback (evicted keys)
g_probation = dict()       # key -> ticket
g_protected = dict()       # key -> ticket
q_probation = deque()      # deque of (key, ticket) to age out old ghosts
q_protected = deque()
m_ghost_ticket = 0         # monotonic ticket id for ghost insertions

# -----------------------------
# Tunables
# -----------------------------

# TinyLFU
LFU_DECAY_INTERVAL = 2048  # quicker decay for adaptivity
LFU_COUNTER_MAX = 255

# Protected target fractions and adaptation
PROT_FRAC_INIT = 0.65
PROT_FRAC_MIN = 0.05
PROT_FRAC_MAX = 0.95
ADAPT_BASE_FRAC = 1.0 / 64.0  # base step ~1.56% of capacity per adaptation

# Recency window and weights
REC_WIN_MIN = 256
REC_WIN_MULT = 2
REC_WEIGHT_PROB = 0.50
REC_WEIGHT_PROT = 0.20
PROT_BONUS = 0.30
MULTI_HIT_BONUS = 0.40

# Eviction choice
PROT_EVICT_MARGIN = 0.02   # require protected candidate to be this much worse to evict it over probation

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16

# Ghost sizes (by count, not bytes; auto scales with resident size)
GHOST_BASE = 512
GHOST_MULT = 2             # each ghost up to GHOST_MULT * resident_items + GHOST_BASE

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch
    global g_probation, g_protected, q_probation, q_protected, m_ghost_ticket

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC_INIT * cache_snapshot.capacity)

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0

    g_probation.clear()
    g_protected.clear()
    q_probation.clear()
    q_protected.clear()
    m_ghost_ticket = 0


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # size as percentage of capacity to stabilize scales
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_bonus(now, last, window):
    if last is None or window <= 0:
        return 0.0
    age = max(0, now - last)
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _retention_score(cache_snapshot, key):
    # Higher score => more worth keeping. Evict the minimum score.
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')

    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity
    size = obj.size

    freq = float(_lfu_peek(cache_snapshot, key))
    size_norm = _normalized_size(size, cap)

    seg = m_segment.get(key, 0)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    benefit = math.log1p(freq) / size_norm

    # Multi-hit bias
    if m_resident_hits.get(key, 0) >= 2:
        benefit += MULTI_HIT_BONUS

    # Recency and protection
    if seg == 1:
        benefit += PROT_BONUS + REC_WEIGHT_PROT * rec_bonus
    else:
        benefit += REC_WEIGHT_PROB * rec_bonus

    return benefit


# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    score = _retention_score(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (score, s, key))
    else:
        heapq.heappush(h_protected, (score, s, key))
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot, heap_ref, expected_seg):
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # refresh score if drifted
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key
    return None


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items until protected within target bytes
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote to probation
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        _push_key(cache_snapshot, key)


# -----------------------------
# Ghost helpers (ARC-style feedback)
# -----------------------------

def _ghost_limits(cache_snapshot):
    # Limit by count; scales with resident items
    n = max(1, len(cache_snapshot.cache))
    lim = GHOST_MULT * n + GHOST_BASE
    return lim, lim  # same limit for both ghosts


def _ghost_add(cache_snapshot, seg, key):
    # seg: 0 probation, 1 protected
    global m_ghost_ticket
    m_ghost_ticket += 1
    ticket = m_ghost_ticket
    if seg == 1:
        g_protected[key] = ticket
        q_protected.append((key, ticket))
    else:
        g_probation[key] = ticket
        q_probation.append((key, ticket))
    _ghost_trim(cache_snapshot)


def _ghost_trim(cache_snapshot):
    lim_prob, lim_prot = _ghost_limits(cache_snapshot)
    while len(g_probation) > lim_prob and q_probation:
        k, t = q_probation.popleft()
        if g_probation.get(k) == t:
            g_probation.pop(k, None)
    while len(g_protected) > lim_prot and q_protected:
        k, t = q_protected.popleft()
        if g_protected.get(k) == t:
            g_protected.pop(k, None)


def _ghost_on_insert_feedback(cache_snapshot, key, obj_size):
    # Adjust protected target using ghost hits (ARC-like)
    global m_prot_target_bytes
    cap = cache_snapshot.capacity
    lim_prob, lim_prot = _ghost_limits(cache_snapshot)

    in_prob = key in g_probation
    in_prot = key in g_protected

    if not in_prob and not in_prot:
        return  # no adaptation

    # Determine which ghost was more recent if in both
    if in_prob and in_prot:
        t_prob = g_probation.get(key, -1)
        t_prot = g_protected.get(key, -1)
        in_prob = t_prob >= t_prot
        in_prot = not in_prob

    base_step = int(max(1, ADAPT_BASE_FRAC * cap))
    # ARC-inspired relative step amplification
    b1 = max(1, len(g_probation))
    b2 = max(1, len(g_protected))
    if in_prob:
        # Need more recency: shrink protected target
        factor = max(1.0, float(b2) / float(b1))
        delta = int(min(cap * 0.25, max(obj_size, base_step) * factor))
        m_prot_target_bytes = max(int(PROT_FRAC_MIN * cap), m_prot_target_bytes - delta)
        # Remove from ghost
        g_probation.pop(key, None)
    elif in_prot:
        # Need more frequency: grow protected target
        factor = max(1.0, float(b1) / float(b2))
        delta = int(min(cap * 0.25, max(obj_size, base_step) * factor))
        m_prot_target_bytes = min(int(PROT_FRAC_MAX * cap), m_prot_target_bytes + delta)
        g_protected.pop(key, None)
    # No need to trim here; ghosts will be trimmed on add


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim by comparing the weakest from probation and protected:
      - Maintain protected demotions if over target
      - Pop one valid candidate from each heap (if available)
      - Evict the global minimum retention score, with a small bias preferring
        probation unless protected is clearly worse
      - Reinsert the non-chosen candidate back into its heap
    '''
    _init_if_needed(cache_snapshot)

    # Enforce protected target before choosing
    _maybe_demote_protected(cache_snapshot)

    kp = _pop_best_candidate(cache_snapshot, h_probation, expected_seg=0)
    ks = _pop_best_candidate(cache_snapshot, h_protected, expected_seg=1)

    if kp is None and ks is None:
        # Fallback: any key
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    if kp is not None and ks is None:
        return kp
    if ks is not None and kp is None:
        return ks

    # Both candidates available
    sp = _retention_score(cache_snapshot, kp)
    ss = _retention_score(cache_snapshot, ks)

    # Bias: prefer evicting probation unless protected is sufficiently worse
    if ss + PROT_EVICT_MARGIN < sp:
        # put back probation candidate
        _push_key(cache_snapshot, kp)
        return ks
    else:
        _push_key(cache_snapshot, ks)
        return kp


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU for the key
      - Increment resident hit count
      - Refresh last-access
      - Promote probation -> protected on first resident hit
      - Maintain protected-byte target via LRU demotion
      - Refresh heaps
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote to protected
        m_segment[k] = 1
        global m_prot_bytes
        m_prot_bytes += obj.size
        _push_key(cache_snapshot, k)
        _maybe_demote_protected(cache_snapshot)
    else:
        # Protected: refresh rank and LRU
        _push_key(cache_snapshot, k)
        # If target was reduced recently (via ghost feedback), demote if needed
        _maybe_demote_protected(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after miss):
      - Increment TinyLFU for the key (admission signal)
      - ARC-style ghost feedback to tune protected target
      - Initialize resident metadata: last_access, resident_hits = 0
      - Place into probation and push to heap
      - Enforce protected target (if adapted downwards previously)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)

    # Adaptive protected target adjustment using ghost hits
    _ghost_on_insert_feedback(cache_snapshot, k, obj.size)

    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 0   # starts at zero; first hit will be 1
    m_segment[k] = 0         # probation
    _push_key(cache_snapshot, k)

    # If protected target shrank, ensure it's respected
    _maybe_demote_protected(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After a victim is evicted:
      - Add to corresponding ghost history (for adaptation)
      - Adjust protected bytes if needed
      - Drop resident-only metadata; keep TinyLFU counters
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    seg = m_segment.pop(ek, None)

    # Add to ghost history for feedback
    if seg is not None:
        _ghost_add(cache_snapshot, seg, ek)

    # Adjust protected bytes if it was protected
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```
2025-11-27 21:39:00,365 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Policy: HALO-TFSv2 — Heap-Accelerated LFU with Recency, Freshness, and Gap Prediction
# Key improvements over previous version:
# - Stronger recency sensitivity with adaptive windowing
# - Do not credit LFU on cold insert (reduces one-timer pollution)
# - Per-key EWMA of inter-arrival gaps to predict time-to-next access
# - Fresh-insert "grace" multiplier to avoid immediate churn
# - Multi-hit protection is stronger and starts after the second hit
# - Bounded-rescan victim search for better choices without full scans

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_birth_ts = dict()         # key -> int access_count at insertion
m_resident_hits = dict()    # key -> int resident hit count (starts at 0 on insert)
m_gap_ewma = dict()         # key -> float ≈ EWMA of inter-arrival gap while resident

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 2048   # faster adaptation to workload shifts
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192
HEAP_GROWTH_FACTOR = 4

# Tunables for scoring
SIZE_ALPHA = 0.80               # size normalization exponent; favors small objects
REC_WIN_MIN = 64                # minimum recency window in accesses
REC_WIN_MULT = 6                # recency window ~ REC_WIN_MULT * resident_items
FREQ_WEIGHT = 1.00              # weight of frequency (TinyLFU)
REC_WEIGHT = 1.10               # weight of observed recency
PRED_WEIGHT = 0.90              # weight of predicted return risk (via gap EWMA)
MH_MULT = 1.50                  # multiplicative boost after >=2 resident hits
FRESH_GRACE = 128               # accesses; grace period after insert
FRESH_MULT = 1.30               # multiplicative boost during grace
GAP_BETA = 0.30                 # EWMA smoothing factor for inter-arrival gap

# Victim selection
RESCAN_LIMIT = 12               # bounded extra pops from heap to improve victim choice


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # decay is applied lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)


def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _predicted_risk(now, last, gap_ewma, window):
    # Predict time-to-next using EWMA gap. Convert to risk in (0,1].
    if last is None or last < 0 or gap_ewma is None or gap_ewma <= 0.0:
        return 0.0
    age = max(0, now - last)
    ttn = gap_ewma - age  # time until next (can be <= 0 if due/overdue)
    # Map to (0,1], ≈1 when due/overdue, smaller when far in future
    return 1.0 / (1.0 + (max(0.0, ttn) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency and predicted risk
    window = _recency_window(cache_snapshot)
    r_term = _recency_term(now, m_last_access.get(key), window)
    p_term = _predicted_risk(now, m_last_access.get(key), m_gap_ewma.get(key), window)

    # Freshness and multi-hit multipliers
    birth = m_birth_ts.get(key)
    fresh = (1.0 if birth is None else (FRESH_MULT if (now - birth) <= FRESH_GRACE else 1.0))
    mhits = m_resident_hits.get(key, 0)
    mh_mult = (MH_MULT if mhits >= 2 else 1.0)

    # Final score: combine, then size-normalize, then apply multiplicative boosts
    base = (FREQ_WEIGHT * f_term) + (REC_WEIGHT * r_term) + (PRED_WEIGHT * p_term)
    score = (base / size_norm) * fresh * mh_mult
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    - Seed heap on first use
    - Pop and validate entries lazily (versioning)
    - Recompute scores to reflect latest epochs and metadata
    - Bounded rescan: consider a small set of candidates and pick the weakest
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            # Initialize missing resident metadata best-effort
            m_last_access.setdefault(k, cache_snapshot.access_count)
            m_birth_ts.setdefault(k, cache_snapshot.access_count)
            m_resident_hits.setdefault(k, 0)
            m_gap_ewma.setdefault(k, float(_recency_window(cache_snapshot)))
            _heap_push(cache_snapshot, k)

    # Bounded rescan to find the weakest valid candidate
    best_key = None
    best_tuple = None  # (adjusted_score, score_tuple)
    considered = []

    attempts = 0
    while attempts < RESCAN_LIMIT and m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            attempts += 1
            continue
        # Skip if stale heap entry
        if m_ver.get(k, 0) != v:
            attempts += 1
            continue
        # Recompute current score (reflect decay/window/metadata changes)
        cur_sc = _score_key(cache_snapshot, k)
        # If score drifted upward, reinsert with new score
        if cur_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            attempts += 1
            continue

        # Track the weakest (lowest score) candidate
        adj_sc = cur_sc  # adjustment slots available if needed later
        if (best_tuple is None) or (adj_sc < best_tuple[0]):
            best_key = k
            best_tuple = (adj_sc, (sc, last, k, v))
        considered.append((sc, last, k, v))
        attempts += 1

    # Push back all considered entries except the chosen victim
    for tup in considered:
        if best_tuple is not None and tup[2] == best_key:
            continue
        heapq.heappush(m_heap, tup)

    # Fallbacks
    if best_key is not None:
        return best_key

    # If heap is exhausted or empty, choose the oldest resident
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Update EWMA of inter-arrival gap
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Update frequency only on hits (not on cold insert)
    _lfu_inc(cache_snapshot, k)

    # Update inter-arrival EWMA
    prev = m_last_access.get(k)
    if prev is not None:
        gap = max(1.0, float(now - prev))
        old = m_gap_ewma.get(k)
        if old is None or old <= 0.0:
            m_gap_ewma[k] = gap
        else:
            m_gap_ewma[k] = (1.0 - GAP_BETA) * old + GAP_BETA * gap
    else:
        # Initialize conservatively
        m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    # Hits: increment resident hits
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # Refresh timestamps
    m_last_access[k] = now

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch
      - Do NOT increment LFU on cold insert (reduces one-timer pollution)
      - Initialize resident metadata: last_access, birth_ts, resident_hits = 0
      - Initialize EWMA gap conservatively to recency window
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # No _lfu_inc here: cold items must earn credit by hitting

    m_last_access[k] = now
    m_birth_ts[k] = now
    m_resident_hits[k] = 0
    m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember popularity)
      - Invalidate its heap version (stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_birth_ts.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_gap_ewma.pop(ek, None)
    m_ver.pop(ek, None)

    _touch_and_maybe_rebuild(cache_snapshot)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 25
- Hit Rate: 0.2581

Example 2:
- Trace ID: 35
- Hit Rate: 0.1395

Example 3:
- Trace ID: 41
- Hit Rate: 0.0725

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:39:00 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:39:00,367 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:42:10 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:42:10,118 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:42:10,120 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Policy: SLRU-TinyARC — Segmented LRU with TinyLFU, Size-Aware scoring, and ARC-style adaptation
#
# Goals:
# - Stronger recency discrimination through Segmented LRU (probation/protected)
# - TinyLFU for robust long-term popularity tracking (lazy decayed counters)
# - Size-aware retention to reduce byte-inefficient pollution
# - ARC-style adaptive target for protected space (using ghost lists on misses)
# - Lightweight heaps per segment to pick good victims quickly with bounded rescans
#
# Notes:
# - Insertions go to Probation (P). First hit promotes to Protected (Q).
# - Evictions prefer P unless Q exceeds its adaptive byte target; otherwise from Q.
# - Ghost lists (B1/B2) adapt the protected target at insert time based on where
#   the key was last evicted from (recency vs frequency pressure).
# - We avoid giving LFU credit on cold insert to reduce one-timer pollution.

import math
import heapq
from collections import OrderedDict

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count timestamp (last touched)
m_birth_ts = dict()        # key -> int access_count at insertion
m_resident_hits = dict()   # key -> int resident hit count (0 on insert)
m_gap_ewma = dict()        # key -> float EWMA of inter-arrival gap (accesses)

# Segment membership: 'P' (probation) or 'Q' (protected)
m_seg = dict()             # key -> 'P' or 'Q'
m_P_bytes = 0              # current bytes in Probation
m_Q_bytes = 0              # current bytes in Protected

# TinyLFU counters with lazy epoch decay
m_lfu_count = dict()       # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096  # slower decay for stability across mid-term phases
LFU_MAX = 31               # 5-bit saturating counter

# Heaps per segment: (score, last_access, key, version)
m_heapP = []
m_heapQ = []
m_ver = dict()             # key -> current version tag to invalidate stale heap entries

# ARC-style ghosts for recency/frequency adaptation
ghost_B1 = OrderedDict()   # recently evicted from P: key -> (size:int, ts:int)
ghost_B2 = OrderedDict()   # recently evicted from Q: key -> (size:int, ts:int)
m_B1_bytes = 0
m_B2_bytes = 0

# Adaptive protected target in bytes (ARC-like)
m_Q_target_bytes = None

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192
HEAP_GROWTH_FACTOR = 4

# -----------------------------
# Tunables and scoring weights
# -----------------------------

SIZE_ALPHA = 0.75          # size normalization exponent, favors smaller objects

REC_WIN_MIN = 64
REC_WIN_MULT = 8           # window ≈ REC_WIN_MULT * resident_items

# Probation scores (favor recency strongly, light frequency)
P_W_REC = 1.35
P_W_FREQ = 0.35
P_W_PRED = 0.50

# Protected scores (favor frequency, moderate recency, prediction)
Q_W_REC = 0.55
Q_W_FREQ = 1.25
Q_W_PRED = 0.90

MH_MULT = 1.35             # multiplicative boost inside Q for multi-hit items

# Freshness grace disabled (reduces one-timer pollution)
FRESH_GRACE = 0
FRESH_MULT = 1.0

# Gap EWMA
GAP_BETA = 0.30

# Victim selection
RESCAN_LIMIT = 16

# -----------------------------
# Helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # decay is applied lazily on read/write per key

def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count; do not write back epoch for missing key."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)

def _recency_term(now, last, window):
    # In (0,1]; 1 for very recent, decays smoothly
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))

def _predicted_risk(now, last, gap_ewma, window):
    # EWMA time-to-next -> risk in (0,1]; ≈1 when due/overdue, small when far away
    if last is None or last < 0 or gap_ewma is None or gap_ewma <= 0.0:
        return 0.0
    age = max(0, now - last)
    ttn = gap_ewma - age
    return 1.0 / (1.0 + (max(0.0, ttn) / float(window)))

def _size_norm(obj):
    return (max(1.0, float(obj.size))) ** SIZE_ALPHA

def _score_P(cache_snapshot, key):
    """Retention score for Probation (higher => more protected)."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')
    size_n = _size_norm(obj)
    window = _recency_window(cache_snapshot)
    r = _recency_term(now, m_last_access.get(key), window)
    f = math.log1p(float(_lfu_peek(cache_snapshot, key)))
    p = _predicted_risk(now, m_last_access.get(key), m_gap_ewma.get(key), window)
    base = (P_W_REC * r) + (P_W_FREQ * f) + (P_W_PRED * p)
    fresh = 1.0  # no fresh grace
    return (base / size_n) * fresh

def _score_Q(cache_snapshot, key):
    """Retention score for Protected (higher => more protected)."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')
    size_n = _size_norm(obj)
    window = _recency_window(cache_snapshot)
    r = _recency_term(now, m_last_access.get(key), window)
    f = math.log1p(float(_lfu_peek(cache_snapshot, key)))
    p = _predicted_risk(now, m_last_access.get(key), m_gap_ewma.get(key), window)
    mh = MH_MULT if m_resident_hits.get(key, 0) >= 2 else 1.0
    base = (Q_W_REC * r) + (Q_W_FREQ * f) + (Q_W_PRED * p)
    fresh = 1.0
    return (base / size_n) * fresh * mh

def _heap_push(cache_snapshot, key):
    """Push key into the appropriate segment heap with freshly computed score."""
    seg = m_seg.get(key)
    if seg is None:
        return
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    last = m_last_access.get(key, -1)
    if seg == 'P':
        sc = _score_P(cache_snapshot, key)
        heapq.heappush(m_heapP, (sc, last, key, v))
    else:
        sc = _score_Q(cache_snapshot, key)
        heapq.heappush(m_heapQ, (sc, last, key, v))

def _maybe_rebuild_heaps(cache_snapshot):
    """Rebuild both heaps when they grow too large due to stale entries."""
    global m_heapP, m_heapQ
    n = max(1, len(cache_snapshot.cache))
    if len(m_heapP) <= HEAP_GROWTH_FACTOR * n and len(m_heapQ) <= HEAP_GROWTH_FACTOR * n:
        return
    newP, newQ = [], []
    for k in cache_snapshot.cache.keys():
        seg = m_seg.get(k)
        if seg is None:
            continue
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        last = m_last_access.get(k, -1)
        if seg == 'P':
            sc = _score_P(cache_snapshot, k)
            newP.append((sc, last, k, v))
        else:
            sc = _score_Q(cache_snapshot, k)
            newQ.append((sc, last, k, v))
    heapq.heapify(newP)
    heapq.heapify(newQ)
    m_heapP = newP
    m_heapQ = newQ

def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heaps(cache_snapshot)

def _ensure_seed(cache_snapshot):
    """If heaps/segments are empty but there are residents, seed as probation."""
    global m_P_bytes, m_Q_bytes, m_Q_target_bytes
    if not cache_snapshot.cache:
        return
    if not m_seg:
        m_P_bytes = 0
        m_Q_bytes = 0
        for k, obj in cache_snapshot.cache.items():
            m_seg[k] = 'P'
            m_last_access.setdefault(k, cache_snapshot.access_count)
            m_birth_ts.setdefault(k, cache_snapshot.access_count)
            m_resident_hits.setdefault(k, 0)
            m_gap_ewma.setdefault(k, float(_recency_window(cache_snapshot)))
            m_P_bytes += obj.size
            _heap_push(cache_snapshot, k)
    if m_Q_target_bytes is None:
        # Start with balanced split
        m_Q_target_bytes = 0.5 * float(cache_snapshot.capacity)

# -----------------------------
# ARC-style target + ghosts
# -----------------------------

def _ghost_enforce_limits(cache_snapshot):
    """Ensure ghost lists respect their dynamic byte budgets."""
    global ghost_B1, ghost_B2, m_B1_bytes, m_B2_bytes
    cap = float(cache_snapshot.capacity)
    targetQ = max(0.0, min(cap, m_Q_target_bytes if m_Q_target_bytes is not None else 0.5 * cap))
    limit_B2 = targetQ
    limit_B1 = max(0.0, cap - targetQ)

    # Trim B1
    while m_B1_bytes > limit_B1 and ghost_B1:
        k, (sz, _) = ghost_B1.popitem(last=False)
        m_B1_bytes -= sz
    # Trim B2
    while m_B2_bytes > limit_B2 and ghost_B2:
        k, (sz, _) = ghost_B2.popitem(last=False)
        m_B2_bytes -= sz

def _ghost_note_evict(cache_snapshot, key, size, from_seg):
    """Record eviction of key into appropriate ghost list."""
    global m_B1_bytes, m_B2_bytes
    now = cache_snapshot.access_count
    if from_seg == 'P':
        # Insert/update in B1
        if key in ghost_B1:
            old_sz, _ = ghost_B1.pop(key)
            m_B1_bytes -= old_sz
        ghost_B1[key] = (size, now)
        m_B1_bytes += size
        ghost_B1.move_to_end(key, last=True)
    else:
        # Insert/update in B2
        if key in ghost_B2:
            old_sz, _ = ghost_B2.pop(key)
            m_B2_bytes -= old_sz
        ghost_B2[key] = (size, now)
        m_B2_bytes += size
        ghost_B2.move_to_end(key, last=True)
    _ghost_enforce_limits(cache_snapshot)

def _maybe_adjust_target_on_insert(cache_snapshot, key, size):
    """Adjust protected target based on ghost hits at insert time (ARC logic)."""
    global m_Q_target_bytes, m_B1_bytes, m_B2_bytes
    if m_Q_target_bytes is None:
        m_Q_target_bytes = 0.5 * float(cache_snapshot.capacity)
    cap = float(cache_snapshot.capacity)
    step = float(max(1, size))
    if key in ghost_B1:
        # Favor recency: shrink Q target
        m_Q_target_bytes = max(0.0, m_Q_target_bytes - step)
        # Move-to-end to record reuse recency
        sz, ts = ghost_B1.pop(key)
        m_B1_bytes -= sz
    elif key in ghost_B2:
        # Favor frequency: grow Q target
        m_Q_target_bytes = min(cap, m_Q_target_bytes + step)
        sz, ts = ghost_B2.pop(key)
        m_B2_bytes -= sz
    # Enforce new limits
    _ghost_enforce_limits(cache_snapshot)

# -----------------------------
# Victim selection
# -----------------------------

def _pick_from_heap(cache_snapshot, seg):
    """Pop a victim from the given segment heap, with bounded rescan and validation."""
    heap = m_heapP if seg == 'P' else m_heapQ
    best_key = None
    best_tuple = None
    considered = []
    attempts = 0
    while attempts < RESCAN_LIMIT and heap:
        sc, last, k, v = heapq.heappop(heap)
        # Validate residency and segment
        if k not in cache_snapshot.cache:
            attempts += 1
            continue
        if m_seg.get(k) != seg:
            attempts += 1
            continue
        if m_ver.get(k, 0) != v:
            attempts += 1
            continue
        # Recompute score to reflect latest metadata/decay
        cur_sc = _score_P(cache_snapshot, k) if seg == 'P' else _score_Q(cache_snapshot, k)
        if cur_sc > sc + 1e-12:
            # Improved score; push back with updated
            _heap_push(cache_snapshot, k)
            attempts += 1
            continue
        # Lower score => weaker retention => better victim
        if (best_tuple is None) or (cur_sc < best_tuple[0]):
            best_key = k
            best_tuple = (cur_sc, (sc, last, k, v))
        considered.append((sc, last, k, v))
        attempts += 1

    # Push back non-chosen considered items
    for tup in considered:
        if best_tuple is not None and tup[2] == best_key:
            continue
        heapq.heappush(heap, tup)

    return best_key

def _fallback_oldest(cache_snapshot):
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        la = m_last_access.get(k, -1)
        if min_last is None or la < min_last:
            min_last = la
            min_k = k
    return min_k

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim:
      - Ensure heaps/segments are seeded if needed
      - Decide which segment to evict from using adaptive protected target
      - Pop a victim from that segment heap with bounded rescan
      - Fallback robustly if heaps are exhausted
    """
    _lfu_maybe_advance_epoch(cache_snapshot)
    _ensure_seed(cache_snapshot)

    # Decide segment to evict from
    cap = float(cache_snapshot.capacity)
    if m_Q_target_bytes is None:
        m_Q_target_bytes = 0.5 * cap

    # If one segment empty, evict from the other
    seg_choice = None
    if m_P_bytes <= 0 and m_Q_bytes > 0:
        seg_choice = 'Q'
    elif m_Q_bytes <= 0 and m_P_bytes > 0:
        seg_choice = 'P'
    else:
        # Prefer P unless Q exceeds target
        if m_Q_bytes > m_Q_target_bytes:
            seg_choice = 'Q'
        else:
            seg_choice = 'P'

    victim = _pick_from_heap(cache_snapshot, seg_choice)
    if victim is not None:
        return victim

    # Try the other segment
    other = 'P' if seg_choice == 'Q' else 'Q'
    victim = _pick_from_heap(cache_snapshot, other)
    if victim is not None:
        return victim

    # Fallback: oldest resident
    return _fallback_oldest(cache_snapshot)

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch and increment frequency
      - Update inter-arrival EWMA and last-access time
      - If in Probation, promote to Protected (SLRU)
      - Update resident hit count
      - Push updated score to the corresponding heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Frequency credit only on hits
    _lfu_inc(cache_snapshot, k)

    # Inter-arrival EWMA
    prev = m_last_access.get(k)
    if prev is not None:
        gap = max(1.0, float(now - prev))
        old = m_gap_ewma.get(k)
        if old is None or old <= 0.0:
            m_gap_ewma[k] = gap
        else:
            m_gap_ewma[k] = (1.0 - GAP_BETA) * old + GAP_BETA * gap
    else:
        m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    # Update last-access and resident hits
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # SLRU promotion on first hit in Probation
    seg = m_seg.get(k)
    if seg == 'P':
        # Promote to Protected
        m_seg[k] = 'Q'
        # Move bytes accounting
        global m_P_bytes, m_Q_bytes
        m_P_bytes -= obj.size
        m_Q_bytes += obj.size
        # Push to Q heap
        _heap_push(cache_snapshot, k)
    else:
        # Still in Protected: refresh heap entry
        _heap_push(cache_snapshot, k)

    _touch_and_maybe_rebuild(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Advance TinyLFU epoch (no LFU increment; cold items must earn credit)
      - Adjust protected target if key is in ghosts (ARC adaptation)
      - Insert into Probation with initialized metadata
      - Push into Probation heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)
    _ensure_seed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # ARC-style target adjustment on ghost hits
    _maybe_adjust_target_on_insert(cache_snapshot, k, obj.size)

    # Initialize resident metadata
    m_last_access[k] = now
    m_birth_ts[k] = now
    m_resident_hits[k] = 0
    m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    # Place into Probation
    if m_seg.get(k) != 'Q':
        m_seg[k] = 'P'
    global m_P_bytes
    m_P_bytes += obj.size

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Update bytes accounting and remove resident-only metadata
      - Record into appropriate ghost list for ARC-style adaptation
      - Invalidate heap version; stale heap entries are skipped lazily
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    seg = m_seg.pop(ek, None)

    # Update segment bytes
    global m_P_bytes, m_Q_bytes
    if seg == 'P':
        m_P_bytes = max(0, m_P_bytes - evicted_obj.size)
    elif seg == 'Q':
        m_Q_bytes = max(0, m_Q_bytes - evicted_obj.size)

    # Remove resident-only metadata
    m_last_access.pop(ek, None)
    m_birth_ts.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_gap_ewma.pop(ek, None)
    m_ver.pop(ek, None)

    # Ghost note for adaptation (keep TinyLFU so popularity memory persists)
    if seg in ('P', 'Q'):
        _ghost_note_evict(cache_snapshot, ek, evicted_obj.size, seg)

    _touch_and_maybe_rebuild(cache_snapshot)
```
2025-11-27 21:42:51,752 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Sampled TinyLFU-Recency-Size (sTFRS)
# - Same core signal as TFRS (TinyLFU + recency + size), but with O(1) metadata updates
#   and O(k) eviction via small random sampling (k << resident_items).
#   This removes full-cache scans and prevents timeouts on large traces.
# - TinyLFU with lazy-epoch 4-bit counters (counts both resident and non-resident accesses)
# - Recency bonus to protect very recent items
# - Size-aware benefit: small items get proportionally higher retention per byte
# - Multi-hit resident items get a small boost
#
# Key changes vs previous version:
#   1) Eviction scans only a small random sample of residents (default 32), not all keys.
#   2) Maintain an O(1) resident-key index (array + position map) for fast sampling/removal.
#   3) Keep the effective scoring model but improve performance to avoid timeouts.

import math
import random

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU-ish timestamp)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# Fast resident set for sampling (array + index map for O(1) add/remove)
m_resident_keys = []       # list of keys currently resident
m_resident_pos = dict()    # key -> index in m_resident_keys

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Sampling parameters for eviction
SAMPLE_SIZE_BASE = 32      # default random sample size
SAMPLE_SIZE_MIN = 8        # lower bound when cache small
SAMPLE_SIZE_MAX = 64       # upper bound; keep k small for speed

# Precompute log2(1+freq) for 4-bit frequency values (0..15)
_FREQ_GAIN = [math.log2(1 + i) for i in range(16)]


# -----------------------------
# Initialization helper
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)
    # Nothing else capacity-dependent to initialize


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Resident set helpers
# -----------------------------

def _resident_add(key):
    if key in m_resident_pos:
        return
    idx = len(m_resident_keys)
    m_resident_keys.append(key)
    m_resident_pos[key] = idx


def _resident_remove(key):
    idx = m_resident_pos.pop(key, None)
    if idx is None:
        return
    last_idx = len(m_resident_keys) - 1
    if idx != last_idx:
        last_key = m_resident_keys[last_idx]
        m_resident_keys[idx] = last_key
        m_resident_pos[last_key] = idx
    m_resident_keys.pop()


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit stable across caches
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key):
    # score = benefit - recency_gain
    #   benefit      = log2(1 + freq) (+bonus if multi-hit) divided by normalized size
    #   recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        # Should not occur; keep it very evictable
        return float('-inf')
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (_FREQ_GAIN[freq] + extra) / size_norm

    # Recency protection
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    return benefit - recency_gain


def _sample_keys(k):
    # Fast random sample without building an intermediate list
    # Uses our resident array for O(k) sampling.
    n = len(m_resident_keys)
    if n == 0:
        return []
    if k >= n:
        # Small cache: sample all
        return list(m_resident_keys)
    # Reservoir-like: random.sample over a range with indirection to keys
    # We avoid constructing a full list of keys.
    chosen = set()
    out = []
    while len(out) < k:
        idx = random.randrange(0, n)
        if idx not in chosen:
            chosen.add(idx)
            out.append(m_resident_keys[idx])
    return out


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score,
    but choose among a small random sample of residents to avoid full scans.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    n = len(m_resident_keys)
    if n == 0:
        # Fallback: rely on cache_snapshot.cache when our index is desynced (should not happen)
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Adaptive sample size: increase slightly with cache size but keep bounded
    if n <= SAMPLE_SIZE_MIN:
        sample_size = n
    else:
        # Grow very slowly with n to reduce variance a bit
        sample_size = min(SAMPLE_SIZE_MAX, max(SAMPLE_SIZE_MIN, SAMPLE_SIZE_BASE))

    candidates = _sample_keys(sample_size)

    min_key = None
    min_score = None
    min_time = None

    for k in candidates:
        score = _retention_score(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Safety fallback if sampling failed to pick one
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1
    # No change to resident set (already present)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key (so non-resident history matters)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Add key to resident sampling set
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    _resident_add(k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Remove key from resident sampling set
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Keep TinyLFU history to improve future admission/retention
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    _resident_remove(ek)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 15
- Hit Rate: 0.0228

Example 2:
- Trace ID: 19
- Hit Rate: 0.275

Example 3:
- Trace ID: 24
- Hit Rate: 0.3318

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:42:51 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:42:51,755 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:46:44 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:46:44,745 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:46:44,747 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Segmented Sampled TinyLFU with Size-aware scoring (sSTLFU-SS)
# - Two resident segments: probation (single-hit/new) and protected (multi-hit)
# - TinyLFU with lazy-epoch 4-bit counters over all requests
# - Size-aware, frequency-first scoring; recency is a per-byte bonus
# - Random sampling on eviction; biased by segment balance and incoming size
# - O(1) metadata updates; O(k) eviction where k << resident_items

import math
import random

# ---------------------------------
# Global metadata (module scope)
# ---------------------------------

# Per-key resident metadata
m_last_access = dict()        # key -> int access_count (timestamp)
m_resident_hits = dict()      # key -> # of resident hits since insertion (starts at 0)

# Segmented resident sets for fast sampling (arrays + index maps)
m_prob_keys = []              # probation: new/single-hit items
m_prob_pos = dict()           # key -> index in m_prob_keys

m_prot_keys = []              # protected: multi-hit items (>= 2 resident hits)
m_prot_pos = dict()           # key -> index in m_prot_keys

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0

# Segment balance (adaptive target for protected share; 0..1)
m_prot_target = 0.55          # start slightly frequency-biased
PROT_ADAPT_STEP = 0.02
PROT_TARGET_MIN = 0.10
PROT_TARGET_MAX = 0.90
BALANCE_EPS = 0.05

# Tunables
LFU_DECAY_INTERVAL = 4096     # accesses per decay epoch (power-of-two preferred)
REC_WIN_MIN = 400             # minimum recency normalization window (in accesses)
REC_WIN_MULT = 3              # window ~= REC_WIN_MULT * resident_items
REC_W_PROB = 0.18             # recency weight (probation), per-byte
REC_W_PROT = 0.28             # recency weight (protected), per-byte
PROTECTED_BONUS = 1.4         # extra frequency-equivalent gain for protected items

# Sampling parameters for eviction
SAMPLE_SIZE_MIN = 12
SAMPLE_SIZE_MAX = 128

# Precompute log2(1+freq) for 4-bit frequency values (0..15)
_FREQ_GAIN = [math.log2(1 + i) for i in range(16)]


# ---------------------------------
# Initialization helper
# ---------------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)


# ---------------------------------
# TinyLFU helpers (lazy decay)
# ---------------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy: counters decay upon next touch


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# ---------------------------------
# Resident set helpers (segmented)
# ---------------------------------

def _seg_of(key):
    if key in m_prot_pos:
        return 'prot'
    if key in m_prob_pos:
        return 'prob'
    return None


def _prob_add(key):
    if key in m_prob_pos or key in m_prot_pos:
        return
    idx = len(m_prob_keys)
    m_prob_keys.append(key)
    m_prob_pos[key] = idx


def _prot_add(key):
    if key in m_prot_pos or key in m_prob_pos:
        return
    idx = len(m_prot_keys)
    m_prot_keys.append(key)
    m_prot_pos[key] = idx


def _prob_remove(key):
    idx = m_prob_pos.pop(key, None)
    if idx is None:
        return
    last_idx = len(m_prob_keys) - 1
    if idx != last_idx:
        last_key = m_prob_keys[last_idx]
        m_prob_keys[idx] = last_key
        m_prob_pos[last_key] = idx
    m_prob_keys.pop()


def _prot_remove(key):
    idx = m_prot_pos.pop(key, None)
    if idx is None:
        return
    last_idx = len(m_prot_keys) - 1
    if idx != last_idx:
        last_key = m_prot_keys[last_idx]
        m_prot_keys[idx] = last_key
        m_prot_pos[last_key] = idx
    m_prot_keys.pop()


def _promote_to_protected(key):
    if key in m_prot_pos:
        return
    if key in m_prob_pos:
        _prob_remove(key)
    _prot_add(key)


def _demote_to_probation(key):
    if key in m_prob_pos:
        return
    if key in m_prot_pos:
        _prot_remove(key)
    _prob_add(key)


# ---------------------------------
# Scoring helpers
# ---------------------------------

def _normalized_size(size, capacity):
    # Scale to percent of capacity to keep numeric ranges stable
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, seg_hint=None):
    # Higher score => better to keep
    # score = [ (log2(1+freq) + segment_bonus) / size_norm ] + [ recency_bonus_per_byte ]
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)

    # Segment-aware bonus for multi-hit items
    seg = seg_hint or _seg_of(key)
    bonus = PROTECTED_BONUS if seg == 'prot' else 0.0
    benefit = (_FREQ_GAIN[freq] + bonus) / size_norm

    # Recency bonus per byte (so very large objects don't get over-protected)
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    rec_w = REC_W_PROT if seg == 'prot' else REC_W_PROB
    recency_bonus = rec_w * (1.0 - a_norm) / size_norm

    return benefit + recency_bonus


def _sample_from(segment_keys, k):
    n = len(segment_keys)
    if n == 0:
        return []
    if k >= n:
        return list(segment_keys)
    chosen = set()
    out = []
    while len(out) < k:
        idx = random.randrange(0, n)
        if idx not in chosen:
            chosen.add(idx)
            out.append(segment_keys[idx])
    return out


def _dynamic_sample_size(n):
    # Grow ~sqrt(n) but stay within bounds
    base = int(2 * math.sqrt(max(1, n))) + 8
    return min(SAMPLE_SIZE_MAX, max(SAMPLE_SIZE_MIN, base))


# ---------------------------------
# Policy entry points
# ---------------------------------

def evict(cache_snapshot, obj):
    '''
    Evict a low-retention resident using segmented, size-aware sampled scoring.
    Prefer evicting from the segment that is oversized relative to the adaptive target.
    Within candidates, bias toward victims whose size roughly matches the incoming object
    when the incoming object is larger than the average resident.
    '''
    _init_if_needed(cache_snapshot)

    n_prob = len(m_prob_keys)
    n_prot = len(m_prot_keys)
    n_total = n_prob + n_prot

    if n_total == 0:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Choose segment to evict from
    protected_share = float(n_prot) / float(n_total)
    evict_from_prot = False
    if n_prob == 0:
        evict_from_prot = True
    elif n_prot == 0:
        evict_from_prot = False
    else:
        # If protected is oversized relative to target, evict there; otherwise probation
        if protected_share > m_prot_target + BALANCE_EPS:
            evict_from_prot = True
        else:
            evict_from_prot = False

    seg_keys = m_prot_keys if evict_from_prot else m_prob_keys
    seg_name = 'prot' if evict_from_prot else 'prob'

    k = _dynamic_sample_size(len(seg_keys))
    candidates = _sample_from(seg_keys, k)

    if not candidates:
        # Fallback across all residents
        seg_keys = m_prot_keys + m_prob_keys
        seg_name = None
        k = _dynamic_sample_size(len(seg_keys))
        candidates = _sample_from(seg_keys, k)
        if not candidates:
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    # Size-aware tie-breaking: if incoming is larger than avg, prefer evicting a larger victim
    avg_size = 1.0
    try:
        avg_size = max(1.0, float(cache_snapshot.size) / max(1, len(cache_snapshot.cache)))
    except Exception:
        avg_size = 1.0

    incoming_size = getattr(obj, 'size', 0) or 0
    prefer_big = incoming_size > 1.2 * avg_size
    big_target = 0.75 * incoming_size

    min_key = None
    min_score = None
    min_time = None

    big_min_key = None
    big_min_score = None
    big_min_time = None

    for kkey in candidates:
        score = _retention_score(cache_snapshot, kkey, seg_name)
        last = m_last_access.get(kkey, -1)

        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = kkey

        if prefer_big:
            robj = cache_snapshot.cache.get(kkey)
            if robj is not None and robj.size >= big_target:
                if (big_min_score is None) or (score < big_min_score) or (score == big_min_score and last < big_min_time):
                    big_min_score = score
                    big_min_time = last
                    big_min_key = kkey

    victim = big_min_key if (prefer_big and big_min_key is not None) else min_key

    if victim is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    return victim


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Refresh last-access time
      - Increase resident hit count; upon second hit promote to protected
      - Adapt segment target: hits in protected -> favor protected; hits in probation -> favor probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count

    # If we somehow missed this key in segments (desync), place it in probation
    seg = _seg_of(k)
    if seg is None:
        _prob_add(k)
        m_resident_hits[k] = 0
        seg = 'prob'

    # Increment resident hit count
    hits = m_resident_hits.get(k, 0) + 1
    m_resident_hits[k] = hits

    # Adaptive target based on where hits occur
    global m_prot_target
    if seg == 'prot':
        m_prot_target = min(PROT_TARGET_MAX, m_prot_target + PROT_ADAPT_STEP)
    else:
        m_prot_target = max(PROT_TARGET_MIN, m_prot_target - PROT_ADAPT_STEP)

    # Promote to protected on second resident hit
    if hits >= 2 and seg != 'prot':
        _promote_to_protected(k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (counts non-resident history)
      - Initialize resident metadata: last_access, resident_hits = 0 (probation)
      - Place key into probation segment
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 0
    _prob_add(k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to inform future decisions)
      - Remove key from its segment
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    if ek in m_prob_pos:
        _prob_remove(ek)
    elif ek in m_prot_pos:
        _prot_remove(ek)
```
2025-11-27 21:47:48,221 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 27
- Hit Rate: 0.8939

Example 2:
- Trace ID: 23
- Hit Rate: 0.06

Example 3:
- Trace ID: 5
- Hit Rate: 0.4892

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:47:48 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:47:48,223 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:49:56 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:49:56,880 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:49:56,885 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive Segmented Size-Aware TinyLFU (A-SS-TinyLFU)
# Key improvements over previous version:
# 1) FIXED sign bug: recent and soon-to-be-reused items now gain retention (were penalized).
# 2) Adaptive protected/probation balance (ARC-inspired hill-climbing) to fit diverse traces.
# 3) Ghost history: reinserted keys seen very recently are "warm-started" (early promote).
# 4) Safer protected resizing (loop demotions; by-bytes).
# 5) Tuned weights and cleaner metadata handling.

import math
from collections import OrderedDict

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
# This is now adaptive via hill-climbing around a target fraction.
g_protected_fraction = 0.75    # start slightly lower for more recency headroom
PROTECTED_FRACTION_MIN = 0.10
PROTECTED_FRACTION_MAX = 0.95
PROTECTED_FRACTION_STEP = 0.02
g_protected_bytes = 0          # running total of bytes in protected (resident only)

# Scoring tunables
SIZE_ALPHA = 1.05              # modest size penalty, less aggressive than before
MULTI_HIT_BONUS = 0.45         # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1024             # min recency window
REC_WIN_MULT = 4               # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
# Note: these are "bonuses" added to retention (larger -> keep longer).
W_REC_PROB = 0.50
W_REC_PROT = 0.18
W_PRED_PROB = 0.28
W_PRED_PROT = 0.14

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.50            # react faster to changing reuse intervals

# Ghost history (recently evicted) for warm-start on reinsertion
m_ghost = OrderedDict()        # key -> (last_access:int, size:int, lfu_count:int)
GHOST_SOFT_LIMIT = 50000       # max entries (bounded for memory)
GHOST_RECENT_MULT = 2          # consider "recently evicted" if within 2x recency window

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(g_protected_fraction * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_from_protected_until_within_target(cache_snapshot):
    # If protected exceeds its target, demote oldest protected items to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    while g_protected_bytes > target:
        key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
        if key is None:
            break
        obj = cache_snapshot.cache.get(key)
        if obj is None:
            break
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
        m_segment[key] = 0  # probation

def _ghost_remember(cache_snapshot, evicted_obj):
    # Remember evicted key with its last access and approximate frequency
    k = evicted_obj.key
    la = m_last_access.get(k, cache_snapshot.access_count)
    lfu = _lfu_peek(cache_snapshot, k)
    # Update/invalidate existing entry order
    if k in m_ghost:
        try:
            del m_ghost[k]
        except KeyError:
            pass
    m_ghost[k] = (la, evicted_obj.size, lfu)
    # Enforce bound (LRU eviction from ghost)
    while len(m_ghost) > GHOST_SOFT_LIMIT:
        m_ghost.popitem(last=False)

def _ghost_lookup(key):
    return m_ghost.get(key, None)

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Larger score -> stronger retention.
    # We evict the key with the smallest retention score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    freq_benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    # Bonuses: more recent (smaller age_norm) -> higher bonus
    recency_bonus = w_rec * (1.0 - age_norm)
    # More imminent reuse (smaller irt_norm) -> higher bonus
    predicted_bonus = w_pred * (1.0 - irt_norm)

    return freq_benefit + recency_bonus + predicted_bonus

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed (loop).
      - Prefer evicting from probation; fall back to protected if probation empty.
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time).
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized (demote oldest protected until within target)
    _demote_from_protected_until_within_target(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last access and IRT EMA
      - Increment resident hit count
      - ARC-style adaptation:
          * hit in probation -> shift balance toward probation (decrease protected fraction)
          * hit in protected -> shift balance toward protected (increase protected fraction)
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive accesses
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize conservatively
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # ARC-style hill climbing on split
    global g_protected_fraction, g_protected_bytes
    seg = _segment_of(k)
    if seg == 0:
        # Hit in probation -> recency working set is larger; give more room to probation
        g_protected_fraction = max(PROTECTED_FRACTION_MIN, g_protected_fraction - PROTECTED_FRACTION_STEP)
        # Promote to protected
        m_segment[k] = 1
        g_protected_bytes += obj.size
    else:
        # Hit in protected -> frequency-biased; more protected is beneficial
        g_protected_fraction = min(PROTECTED_FRACTION_MAX, g_protected_fraction + PROTECTED_FRACTION_STEP)
        # Already protected, no change in bytes accounting

    # Enforce protected target (demote oldest protected if oversized)
    _demote_from_protected_until_within_target(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access = now
          resident_hits = 1 (unless warm-start)
          irt = default window (or smaller if warm-start)
          segment = probation (or protected if warm-start)
      - Warm-start: if this key was evicted recently (ghost entry within a
        recent window), treat as multi-hit and place directly into protected.
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    n_items = max(1, len(cache_snapshot.cache))
    base_window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    # Warm-start using ghost history
    ghost = _ghost_lookup(k)
    warm = False
    if ghost is not None:
        last_evicted_at, _, _ = ghost
        if now - last_evicted_at <= GHOST_RECENT_MULT * base_window:
            warm = True
            # Remove from ghost on re-admission (optional)
            try:
                del m_ghost[k]
            except KeyError:
                pass

    m_last_access[k] = now
    if warm:
        # Early promote frequently revisited items
        m_resident_hits[k] = 2
        m_irt[k] = float(base_window) * 0.5
        m_segment[k] = 1  # protected
        global g_protected_bytes
        g_protected_bytes += obj.size
        # Keep protected within target
        _demote_from_protected_until_within_target(cache_snapshot)
    else:
        m_resident_hits[k] = 1
        m_irt[k] = float(base_window)
        m_segment[k] = 0  # probation


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remember ghost info to warm-start on future reinsertions
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed (use current segment before delete)
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Ghost remember (after reading metadata)
    _ghost_remember(cache_snapshot, evicted_obj)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```
2025-11-27 21:50:52,550 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 2
- Hit Rate: 0.4826

Example 2:
- Trace ID: 14
- Error: Error - Timeout

Example 3:
- Trace ID: 32
- Hit Rate: 0.0878

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:50:52 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:50:52,552 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:53:32 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:53:32,627 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:53:32,630 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Fast Segmented-LRU with TinyLFU (FSR-TinyLFU)
# Goals:
#   - Avoid full scans on eviction (prevents timeouts) using O(1) LRU lists per segment
#   - Maintain two SLRU segments (probation/protected) with size-aware TinyLFU-aware promotion
#   - Prefer evicting probation; protected is shielded and bounded by a byte target
#   - Use small tail sampling within a segment to pick the weakest victim (size-aware, TinyLFU-aware)
#   - Maintain predicted reuse (IRT EMA) and decayed TinyLFU counters
#
# Summary:
#   - update_after_insert: place into probation MRU, init metadata, TinyLFU++
#   - update_after_hit: TinyLFU++, touch MRU; promote to protected on 2nd hit or freq>=2,
#                       unless object is huge; demote protected tail if segment exceeds target
#   - evict: demote protected until within byte target; pick victim by sampling the tail
#            (probation first; fallback to protected). No full scans.
#   - update_after_evict: remove from lists and resident metadata; keep TinyLFU counters
#
# Complexity: O(1) on hits/inserts; O(sample) on eviction (sample size ~32).
# This improves both speed and hit rate vs the previous all-key scanning policy.

import math

# ---------------------------------
# Global metadata (module scope)
# ---------------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> hits since admission (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation) or 1 (protected)

# Exponential moving average of inter-arrival time
m_irt = dict()             # key -> float EMA

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # accesses per epoch (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80
g_protected_bytes = 0

# Doubly-linked lists for segment-local LRU (per segment)
m_head = {0: None, 1: None}  # segment -> head key (MRU)
m_tail = {0: None, 1: None}  # segment -> tail key (LRU)
m_prev = dict()              # key -> prev key (within its segment)
m_next = dict()              # key -> next key (within its segment)

# Scoring tunables
SIZE_ALPHA = 1.05            # mild size penalty
MULTI_HIT_BONUS = 0.35       # extra retention if >=2 resident hits

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.55
W_REC_PROT = 0.15
W_PRED_PROB = 0.20
W_PRED_PROT = 0.10

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40

# Recency windows
REC_WIN_MIN = 1000
REC_WIN_MULT = 4

# Tail sampling for victim selection
SAMPLE_LIMIT = 32           # max keys to consider from a segment tail on each eviction

# ---------------------------------
# TinyLFU helpers (lazy decay)
# ---------------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter
    m_lfu_count[key] = (c, cur_epoch)
    return c

# ---------------------------------
# Helpers
# ---------------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

# ---- Doubly-linked list ops (per segment) ----

def _dll_remove(seg_id, key):
    # Remove key from its segment's linked list (if present)
    if key is None:
        return
    # Ensure only remove if this key is currently in that segment list
    if m_segment.get(key) != seg_id:
        # If pointers linger incorrectly, still try to detach from whichever links exist
        prev_k = m_prev.pop(key, None)
        next_k = m_next.pop(key, None)
        if prev_k is not None:
            m_next[prev_k] = next_k
        if next_k is not None:
            m_prev[next_k] = prev_k
        # Fix heads/tails if needed
        if m_head.get(seg_id) == key:
            m_head[seg_id] = next_k if m_segment.get(next_k) == seg_id else None
        if m_tail.get(seg_id) == key:
            m_tail[seg_id] = prev_k if m_segment.get(prev_k) == seg_id else None
        return

    prev_k = m_prev.pop(key, None)
    next_k = m_next.pop(key, None)

    if prev_k is not None:
        m_next[prev_k] = next_k
    else:
        # key was head
        m_head[seg_id] = next_k
    if next_k is not None:
        m_prev[next_k] = prev_k
    else:
        # key was tail
        m_tail[seg_id] = prev_k

def _dll_append_front(seg_id, key):
    # Insert key at MRU position (front) of segment seg_id
    # Remove from any existing location first
    if m_prev.get(key) is not None or m_next.get(key) is not None or m_head.get(seg_id) == key or m_tail.get(seg_id) == key:
        _dll_remove(m_segment.get(key, seg_id), key)

    old_head = m_head.get(seg_id)
    m_prev[key] = None
    m_next[key] = old_head
    if old_head is not None:
        m_prev[old_head] = key
    else:
        m_tail[seg_id] = key
    m_head[seg_id] = key

def _dll_append_tail(seg_id, key):
    # Insert key at LRU position (tail) of segment seg_id
    if m_prev.get(key) is not None or m_next.get(key) is not None or m_head.get(seg_id) == key or m_tail.get(seg_id) == key:
        _dll_remove(m_segment.get(key, seg_id), key)

    old_tail = m_tail.get(seg_id)
    m_next[key] = None
    m_prev[key] = old_tail
    if old_tail is not None:
        m_next[old_tail] = key
    else:
        m_head[seg_id] = key
    m_tail[seg_id] = key

def _iter_segment_from_tail(seg_id, limit):
    # Yields up to 'limit' resident keys from the LRU end of the segment
    k = m_tail.get(seg_id)
    count = 0
    while k is not None and count < limit:
        # If key vanished from cache (stale pointer), unlink and continue
        yield_k = k
        k = m_prev.get(k)
        count += 1
        yield yield_k

def _demote_until_within_target(cache_snapshot, max_steps=8):
    # Demote oldest protected items to probation until protected bytes <= target
    # Bounds work per-call to constant time
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    steps = 0
    while g_protected_bytes > target and steps < max_steps:
        victim = m_tail.get(1)
        if victim is None:
            break
        # Only demote if still resident
        if victim not in cache_snapshot.cache:
            # stale pointer cleanup
            _dll_remove(1, victim)
            m_segment.pop(victim, None)
            continue
        # Move from protected tail to probation tail (preserve coldness)
        _dll_remove(1, victim)
        m_segment[victim] = 0
        _dll_append_tail(0, victim)
        obj = cache_snapshot.cache.get(victim)
        if obj is not None:
            g_protected_bytes = max(0, g_protected_bytes - obj.size)
        steps += 1

# ---------------------------------
# Scoring (eviction priority)
# ---------------------------------

def _retention_score(cache_snapshot, key):
    # Lower score -> weaker -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

def _pick_victim_from_segment(cache_snapshot, seg_id):
    # Sample from the LRU end to find the weakest score
    min_key = None
    min_score = None
    min_time = None

    # Limit sampling to keep eviction O(1) amortized
    limit = SAMPLE_LIMIT

    for k in _iter_segment_from_tail(seg_id, limit):
        # Skip if not resident due to stale pointers (self-heal)
        if k not in cache_snapshot.cache:
            _dll_remove(seg_id, k)
            m_segment.pop(k, None)
            continue
        # Safety: ensure segment marker matches list
        if _segment_of(k) != seg_id:
            continue
        score = _retention_score(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if (min_key is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = k
            min_score = score
            min_time = last

    return min_key, min_score

# ---------------------------------
# Policy entry points
# ---------------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed (O(1) per call)
      - Prefer evicting from probation; fallback to protected if probation empty or clearly stronger
      - Within a segment, choose the weakest score among a small sample from the LRU end
    '''
    _init_if_needed(cache_snapshot)

    # First, adjust protected segment if oversized (bounded work)
    _demote_until_within_target(cache_snapshot, max_steps=8)

    # Candidate from probation
    k0, s0 = _pick_victim_from_segment(cache_snapshot, 0)

    if k0 is None:
        # No probation -> pick from protected
        k1, s1 = _pick_victim_from_segment(cache_snapshot, 1)
        if k1 is not None:
            return k1
        # Fallback: arbitrary
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Also peek a protected candidate and compare (rarely chosen)
    k1, s1 = _pick_victim_from_segment(cache_snapshot, 1)

    if k1 is None:
        return k0

    # Prefer probation unless protected candidate is clearly weaker
    # Small bias toward evicting probation
    if s1 + 0.05 < s0:
        return k1
    return k0


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - TinyLFU++, update last/prev access and IRT EMA
      - Increment resident hit count
      - Touch to MRU in its segment
      - If in probation and has 2nd hit or TinyLFU>=2 and not huge, promote to protected
      - Enforce protected byte target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = _segment_of(k)

    # Promotion rule: on 2nd hit OR TinyLFU>=2, but avoid promoting very large objects
    promote = False
    if seg == 0:
        freq = _lfu_peek(cache_snapshot, k)
        if m_resident_hits[k] >= 2 or freq >= 2:
            # size guard: don't let huge objects dominate protected
            if obj.size <= (cache_snapshot.capacity * 0.50):
                promote = True

    global g_protected_bytes

    if promote:
        # Move from probation to protected MRU
        _dll_remove(0, k)
        m_segment[k] = 1
        _dll_append_front(1, k)
        g_protected_bytes += obj.size
    else:
        # Simple touch to MRU within current segment
        _dll_remove(seg, k)
        _dll_append_front(seg, k)

    # Enforce protected target
    _demote_until_within_target(cache_snapshot, max_steps=8)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - TinyLFU++ for key (counts the request)
      - Initialize resident metadata
      - Insert into probation MRU
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # Link into probation MRU
    _dll_remove(0, k)  # ensure clean
    _dll_append_front(0, k)
    # No change to protected bytes (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove from its segment list and resident-only metadata
      - Maintain protected-bytes accounting
      - Keep TinyLFU counters
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    seg = _segment_of(ek)

    # Adjust protected bytes if needed
    global g_protected_bytes
    if seg == 1:
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove from LRU structure
    _dll_remove(seg, ek)

    # Remove resident-only metadata
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Keep m_lfu_count[ek] to preserve frequency history
```
2025-11-27 21:54:32,282 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 17
- Error: Error - Timeout

Example 2:
- Trace ID: 4
- Hit Rate: 0.5002

Example 3:
- Trace ID: 8
- Hit Rate: 0.5223

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:54:32 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:54:32,284 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m21:56:21 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 21:56:21,646 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 21:56:21,654 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# SLRU + TinyLFU + Size-aware sampled eviction (fast and high hit-rate)
# - Two resident segments with byte quotas:
#     Probation (new/once-hit) and Protected (multi-hit)
# - O(1) updates on hit/insert via OrderedDict LRU queues
# - Eviction chooses from Probation first (SLRU), falls back to Protected
# - Within the chosen segment, select victim by sampling a few oldest keys
#   and picking the smallest TinyLFU-Recency-Size score (no full scan)
# - TinyLFU sketch with lazy epoch decay (4-bit counters) tracks popularity
# - Metadata survives evictions where useful (TinyLFU); resident-only info removed

import math
from collections import OrderedDict

# -----------------------------
# Global metadata
# -----------------------------

# Segmented LRU structures (byte-aware)
PROTECTED_RATIO = 0.80        # fraction of capacity reserved for Protected
SAMPLE_K_PROB = 6             # candidates sampled from Probation on eviction
SAMPLE_K_PROT = 4             # candidates sampled from Protected on eviction

prob_lru = OrderedDict()      # key -> None (LRU on left, MRU on right)
prot_lru = OrderedDict()      # key -> None
seg_bytes_prob = 0            # total bytes in Probation
seg_bytes_prot = 0            # total bytes in Protected
m_segment = dict()            # key -> 0 (probation) or 1 (protected)

# Per-key resident metadata
m_last_access = dict()        # key -> int time (for recency scoring)
m_resident_hits = dict()      # key -> int (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Scoring tunables (robust defaults)
REC_WIN_MIN = 1000
REC_WIN_MULT = 4
REC_WEIGHT = 0.25
MULTI_HIT_BONUS = 0.35

# -----------------------------
# Init / TinyLFU helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Segment helpers
# -----------------------------

def _prot_target_bytes(cache_snapshot):
    try:
        return max(0, int(cache_snapshot.capacity * PROTECTED_RATIO))
    except Exception:
        return 0

def _seg_insert_prob(key, size):
    global seg_bytes_prob
    if m_segment.get(key) == 0:
        # refresh MRU
        prob_lru.pop(key, None)
        prob_lru[key] = None
        return
    if m_segment.get(key) == 1:
        # remove from protected first (shouldn't happen on insert)
        prot_lru.pop(key, None)
        global seg_bytes_prot
        seg_bytes_prot -= size
    m_segment[key] = 0
    prob_lru[key] = None
    seg_bytes_prob += size

def _seg_move_to_prot(cache_snapshot, key, size):
    # Move key to Protected MRU
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 1:
        # already in protected: refresh MRU
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    # remove from probation if present
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    # insert into protected
    m_segment[key] = 1
    prot_lru[key] = None
    seg_bytes_prot += size

    # Demote from protected to probation if protected exceeds target
    target = _prot_target_bytes(cache_snapshot)
    while seg_bytes_prot > target and prot_lru:
        # Demote LRU of protected into probation MRU (not evict)
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        seg_bytes_prot -= dsize

        # place into probation MRU if still resident
        if robj is not None:
            prob_lru[dem_key] = None
            seg_bytes_prob += dsize
            m_segment[dem_key] = 0
        else:
            m_segment.pop(dem_key, None)  # no longer resident; clean

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _seg_remove(cache_snapshot, key, size):
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 1:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        # unknown; ensure not lingering
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _retention_score(cache_snapshot, key):
    # Lower score -> weaker retention -> better eviction candidate
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    return benefit - recency_gain

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    # Iterate the oldest k_sample keys in 'order' and return the min-score key
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    # Fallback in case of issues
    if chosen_key is None:
        try:
            return next(iter(order))
        except StopIteration:
            return None
    return chosen_key

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Evict using SLRU: choose from Probation first; if empty, from Protected.
    Within the chosen segment, sample a few LRU-ordered keys and evict the
    one with the smallest TinyLFU-Recency-Size score.
    """
    _init_if_needed(cache_snapshot)

    # Prefer evicting from Probation (new/weak items)
    if prob_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
        return victim

    # Fall back to Protected if Probation empty
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)
        return victim

    # As a last resort, evict any key
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access time and resident hit count
      - Promote from Probation to Protected (SLRU) on first hit
      - Refresh LRU position within its segment
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked (shouldn't happen on a hit); insert into Probation
        _seg_insert_prob(k, obj.size)
        return

    if seg == 0:
        # Promote on first hit (classic SLRU)
        _seg_move_to_prot(cache_snapshot, k, obj.size)
    else:
        # Touch protected
        _seg_touch_on_hit(cache_snapshot, k)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU counter
      - Initialize resident metadata
      - Place into Probation MRU
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # New resident goes to Probation MRU
    _seg_insert_prob(k, obj.size)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata and from segment structures
      - Keep TinyLFU counters to remember popularity of non-residents
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    _seg_remove(cache_snapshot, ek, evicted_obj.size)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Keep m_lfu_count[ek] for future admission/eviction decisions
```
2025-11-27 21:58:54,834 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Policy: HALO-TFSv2 — Heap-Accelerated LFU with Recency, Freshness, and Gap Prediction
# Key improvements over previous version:
# - Stronger recency sensitivity with adaptive windowing
# - Do not credit LFU on cold insert (reduces one-timer pollution)
# - Per-key EWMA of inter-arrival gaps to predict time-to-next access
# - Fresh-insert "grace" multiplier to avoid immediate churn
# - Multi-hit protection is stronger and starts after the second hit
# - Bounded-rescan victim search for better choices without full scans

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_birth_ts = dict()         # key -> int access_count at insertion
m_resident_hits = dict()    # key -> int resident hit count (starts at 0 on insert)
m_gap_ewma = dict()         # key -> float ≈ EWMA of inter-arrival gap while resident

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 2048   # faster adaptation to workload shifts
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192
HEAP_GROWTH_FACTOR = 4

# Tunables for scoring
SIZE_ALPHA = 0.80               # size normalization exponent; favors small objects
REC_WIN_MIN = 64                # minimum recency window in accesses
REC_WIN_MULT = 6                # recency window ~ REC_WIN_MULT * resident_items
FREQ_WEIGHT = 1.00              # weight of frequency (TinyLFU)
REC_WEIGHT = 1.10               # weight of observed recency
PRED_WEIGHT = 0.90              # weight of predicted return risk (via gap EWMA)
MH_MULT = 1.50                  # multiplicative boost after >=2 resident hits
FRESH_GRACE = 128               # accesses; grace period after insert
FRESH_MULT = 1.30               # multiplicative boost during grace
GAP_BETA = 0.30                 # EWMA smoothing factor for inter-arrival gap

# Victim selection
RESCAN_LIMIT = 12               # bounded extra pops from heap to improve victim choice


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # decay is applied lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)


def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _predicted_risk(now, last, gap_ewma, window):
    # Predict time-to-next using EWMA gap. Convert to risk in (0,1].
    if last is None or last < 0 or gap_ewma is None or gap_ewma <= 0.0:
        return 0.0
    age = max(0, now - last)
    ttn = gap_ewma - age  # time until next (can be <= 0 if due/overdue)
    # Map to (0,1], ≈1 when due/overdue, smaller when far in future
    return 1.0 / (1.0 + (max(0.0, ttn) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency and predicted risk
    window = _recency_window(cache_snapshot)
    r_term = _recency_term(now, m_last_access.get(key), window)
    p_term = _predicted_risk(now, m_last_access.get(key), m_gap_ewma.get(key), window)

    # Freshness and multi-hit multipliers
    birth = m_birth_ts.get(key)
    fresh = (1.0 if birth is None else (FRESH_MULT if (now - birth) <= FRESH_GRACE else 1.0))
    mhits = m_resident_hits.get(key, 0)
    mh_mult = (MH_MULT if mhits >= 2 else 1.0)

    # Final score: combine, then size-normalize, then apply multiplicative boosts
    base = (FREQ_WEIGHT * f_term) + (REC_WEIGHT * r_term) + (PRED_WEIGHT * p_term)
    score = (base / size_norm) * fresh * mh_mult
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    - Seed heap on first use
    - Pop and validate entries lazily (versioning)
    - Recompute scores to reflect latest epochs and metadata
    - Bounded rescan: consider a small set of candidates and pick the weakest
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            # Initialize missing resident metadata best-effort
            m_last_access.setdefault(k, cache_snapshot.access_count)
            m_birth_ts.setdefault(k, cache_snapshot.access_count)
            m_resident_hits.setdefault(k, 0)
            m_gap_ewma.setdefault(k, float(_recency_window(cache_snapshot)))
            _heap_push(cache_snapshot, k)

    # Bounded rescan to find the weakest valid candidate
    best_key = None
    best_tuple = None  # (adjusted_score, score_tuple)
    considered = []

    attempts = 0
    while attempts < RESCAN_LIMIT and m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            attempts += 1
            continue
        # Skip if stale heap entry
        if m_ver.get(k, 0) != v:
            attempts += 1
            continue
        # Recompute current score (reflect decay/window/metadata changes)
        cur_sc = _score_key(cache_snapshot, k)
        # If score drifted upward, reinsert with new score
        if cur_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            attempts += 1
            continue

        # Track the weakest (lowest score) candidate
        adj_sc = cur_sc  # adjustment slots available if needed later
        if (best_tuple is None) or (adj_sc < best_tuple[0]):
            best_key = k
            best_tuple = (adj_sc, (sc, last, k, v))
        considered.append((sc, last, k, v))
        attempts += 1

    # Push back all considered entries except the chosen victim
    for tup in considered:
        if best_tuple is not None and tup[2] == best_key:
            continue
        heapq.heappush(m_heap, tup)

    # Fallbacks
    if best_key is not None:
        return best_key

    # If heap is exhausted or empty, choose the oldest resident
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Update EWMA of inter-arrival gap
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Update frequency only on hits (not on cold insert)
    _lfu_inc(cache_snapshot, k)

    # Update inter-arrival EWMA
    prev = m_last_access.get(k)
    if prev is not None:
        gap = max(1.0, float(now - prev))
        old = m_gap_ewma.get(k)
        if old is None or old <= 0.0:
            m_gap_ewma[k] = gap
        else:
            m_gap_ewma[k] = (1.0 - GAP_BETA) * old + GAP_BETA * gap
    else:
        # Initialize conservatively
        m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    # Hits: increment resident hits
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # Refresh timestamps
    m_last_access[k] = now

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch
      - Do NOT increment LFU on cold insert (reduces one-timer pollution)
      - Initialize resident metadata: last_access, birth_ts, resident_hits = 0
      - Initialize EWMA gap conservatively to recency window
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # No _lfu_inc here: cold items must earn credit by hitting

    m_last_access[k] = now
    m_birth_ts[k] = now
    m_resident_hits[k] = 0
    m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember popularity)
      - Invalidate its heap version (stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_birth_ts.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_gap_ewma.pop(ek, None)
    m_ver.pop(ek, None)

    _touch_and_maybe_rebuild(cache_snapshot)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 31
- Hit Rate: 0.007

Example 2:
- Trace ID: 12
- Hit Rate: 0.04

Example 3:
- Trace ID: 37
- Hit Rate: 0.628

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m21:58:54 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 21:58:54,837 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:00:27 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:00:27,859 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:00:27,865 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Policy: GD-LFUα — Size-aware GreedyDual with TinyLFU credits
# Rationale:
# - Core eviction priority uses GreedyDual-Size-Frequency (GDSF) idea:
#     H(key) = L + cost(key) / size(key)^alpha
#   where L is the global aging level set to the priority of the last eviction.
# - TinyLFU provides a stable, decayed popularity estimate (across residents and non-residents).
# - Multi-hit protection and a short freshness grace boost stabilize early recencies.
# - The global aging L naturally ages cold objects without explicit rescoring scans.
# - Eviction is a simple min-heap on H-values; updates push new H lazily via versioning.

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_birth_ts = dict()         # key -> int access_count at insertion
m_resident_hits = dict()    # key -> int resident hit count (starts at 0 on insert)

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 2048
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# GreedyDual state
m_hval = dict()             # key -> float current H value
m_L = 0.0                   # global aging value (increases to evicted H)

# Min-heap for eviction: (H, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192
HEAP_GROWTH_FACTOR = 4

# Tunables
SIZE_ALPHA = 0.87           # size normalization exponent; closer to 1 favors small objects
FREQ_WEIGHT = 1.20          # weight of TinyLFU on cost via log1p
MH_MULT = 1.40              # multiplicative boost after >=2 resident hits
FRESH_GRACE = 96            # accesses; grace period after insert
FRESH_MULT = 1.20           # multiplicative boost during grace


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # decay applied lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers (GreedyDual)
# -----------------------------

def _size_norm(obj):
    return max(1.0, float(obj.size)) ** SIZE_ALPHA


def _base_cost(cache_snapshot, key, freq_override=None):
    """
    Compute the "cost" term (popularity credit) for key.
    Uses TinyLFU (decayed count), resident hit boosts, and freshness grace.
    """
    freq = _lfu_peek(cache_snapshot, key) if freq_override is None else freq_override
    base = 1.0 + FREQ_WEIGHT * math.log1p(float(freq))

    # Multi-hit protection (kicks in after second resident hit)
    rhits = m_resident_hits.get(key, 0)
    if rhits >= 2:
        base *= MH_MULT

    # Freshness grace for very recent inserts
    birth = m_birth_ts.get(key)
    now = cache_snapshot.access_count
    if birth is not None and (now - birth) <= FRESH_GRACE:
        base *= FRESH_MULT

    return base


def _compute_H(cache_snapshot, key, freq_override=None):
    """Compute H = L + cost/size_norm for a resident key."""
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')
    cost = _base_cost(cache_snapshot, key, freq_override=freq_override)
    return m_L + (cost / _size_norm(obj))


def _heap_push(cache_snapshot, key, precomputed_H=None):
    """Push a fresh entry for key into the heap with current H."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    H = _compute_H(cache_snapshot, key) if precomputed_H is None else precomputed_H
    m_hval[key] = H
    last = m_last_access.get(key, cache_snapshot.access_count)
    heapq.heappush(m_heap, (H, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        H = _compute_H(cache_snapshot, k)
        m_hval[k] = H
        last = m_last_access.get(k, cache_snapshot.access_count)
        new_heap.append((H, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim using GreedyDual priority:
      - Seed heap on first use
      - Pop min-H with lazy invalidation (versioning)
      - Set global aging level L to victim's H
    """
    # Seed heap if empty (bootstrap)
    if not m_heap and cache_snapshot.cache:
        now = cache_snapshot.access_count
        for k in cache_snapshot.cache.keys():
            # Initialize resident metadata best-effort if missing
            m_last_access.setdefault(k, now)
            m_birth_ts.setdefault(k, now)
            m_resident_hits.setdefault(k, 0)
            _heap_push(cache_snapshot, k)

    # Pop until a valid resident with up-to-date version is found
    while m_heap:
        H, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            continue
        # Skip if stale entry due to newer pushes
        if m_ver.get(k, 0) != v:
            continue
        # Ensure the popped H matches current stored H for the key
        curH = m_hval.get(k)
        if curH is None or abs(curH - H) > 1e-12:
            # Out-of-date; push current and continue
            _heap_push(cache_snapshot, k, precomputed_H=curH if curH is not None else _compute_H(cache_snapshot, k))
            continue

        # Victim found — advance aging level to victim's H
        global m_L
        m_L = H
        return k

    # Fallback: no heap entries — choose the oldest resident
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    # Advance aging based on chosen victim's current H
    if min_k is not None:
        Hv = _compute_H(cache_snapshot, min_k)
        m_hval[min_k] = Hv
        m_L = Hv
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Refresh last-access time
      - Recompute H and push to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # TinyLFU: update on hit
    new_freq = _lfu_inc(cache_snapshot, k)

    # Hits: increment resident hits
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # Refresh timestamp
    m_last_access[k] = now

    # Recompute H using fresh freq and push
    H = _compute_H(cache_snapshot, k, freq_override=new_freq)
    _heap_push(cache_snapshot, k, precomputed_H=H)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch
      - Do NOT increment LFU on cold insert (one-timer control)
      - Initialize resident metadata: last_access, birth_ts, resident_hits = 0
      - Compute H = L + cost/size^alpha using current TinyLFU (peek)
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Initialize resident metadata
    m_last_access[k] = now
    m_birth_ts[k] = now
    m_resident_hits[k] = 0

    # H based on current TinyLFU without increment
    freq = _lfu_peek(cache_snapshot, k)
    H = _compute_H(cache_snapshot, k, freq_override=freq)

    _heap_push(cache_snapshot, k, precomputed_H=H)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember popularity)
      - Invalidate its heap version (stale heap entries will be skipped)
    Note: The global aging value m_L is already advanced in evict().
    """
    # No need to advance epoch here; counts are retained for future admissions
    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_birth_ts.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_hval.pop(ek, None)
    m_ver.pop(ek, None)

    _touch_and_maybe_rebuild(cache_snapshot)
```
2025-11-27 22:00:35,704 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 20
- Hit Rate: 0.4267

Example 2:
- Trace ID: 9
- Hit Rate: 0.531

Example 3:
- Trace ID: 46
- Hit Rate: 0.4663

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:00:35 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:00:35,705 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:03:33 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:03:33,350 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:03:33,351 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Segmented, Size-aware TinyLFU with Recency Shield (S3-LFU)
# - Two resident segments: probation (cold) and protected (hot)
#   * New inserts start in probation; first hit promotes to protected
#   * Protected items get a shield bonus; evictions prefer probation
#   * If protected grows too large (by bytes), demote the weakest protected item
# - Keep-score = size-aware TinyLFU benefit + recency bonus + segment shield
#   Eviction picks the resident key with the smallest keep-score.
# - TinyLFU: lazy-epoch, 4-bit counters retained across evictions
# - Ghost set: remembers recently evicted keys; on reinsert they start in protected
# - Size-awareness: benefit is divided by normalized size (percent of capacity)

import math

# ---------------------------------
# Global metadata (module scope)
# ---------------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident-only hit count (>=1 when inserted)
m_segment = dict()         # key -> 0 (probation) or 1 (protected)

# Segment byte tracking (resident only)
SEG_PROB = 0
SEG_PROT = 1
seg_bytes = {SEG_PROB: 0, SEG_PROT: 0}

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()        # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192   # accesses between epochs (power of two recommended)

# Ghost set for recently evicted keys (helps hot reentry)
g_ghost = dict()            # key -> last_evicted_access_count (insertion-ordered)
GHOST_MAX_BASE = 8192       # lower bound
GHOST_MULT = 2              # max ghost entries ~= GHOST_MULT * resident_items

# Tunables
# Recency window for normalization
REC_WIN_MIN = 1000
REC_WIN_MULT = 4

# Segment behavior and shields
PROT_TARGET_FRAC = 0.70     # target fraction (by bytes) for protected
PROB_MIN_FRAC = 0.15        # if probation fraction (by bytes) below this, allow protected evictions more easily
PROTECTED_SHIELD = 0.90     # additive keep-score bonus for protected items (makes them harder to evict)

# Recency weights per segment (probation protects very recent items more)
REC_W_PROB = 0.45
REC_W_PROT = 0.20

# Benefit tweaks
MULTI_HIT_BONUS = 0.40      # extra benefit if resident has >=2 hits
MIN_SIZE_NORM = 1e-9

# ---------------------------------
# TinyLFU helpers (lazy decay)
# ---------------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; per-key decay happens on touch

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# ---------------------------------
# Ghost set helpers
# ---------------------------------

def _ghost_limit(cache_snapshot):
    # Keep the ghost set bounded relative to resident size
    return max(GHOST_MAX_BASE, GHOST_MULT * max(1, len(cache_snapshot.cache)))

def _ghost_record(cache_snapshot, key):
    # Insert/move-to-end for Python 3.7+ dict (insertion order preserved)
    if key in g_ghost:
        g_ghost.pop(key, None)
    g_ghost[key] = cache_snapshot.access_count
    # Trim oldest entries if above limit
    limit = _ghost_limit(cache_snapshot)
    excess = len(g_ghost) - limit
    if excess > 0:
        # Pop 'excess' oldest entries
        for k in list(g_ghost.keys())[:excess]:
            g_ghost.pop(k, None)

def _ghost_touch_remove(key):
    # When a key comes back and is resident, no need to keep it in ghost
    g_ghost.pop(key, None)

def _ghost_contains(key):
    return key in g_ghost

# ---------------------------------
# Scoring helpers
# ---------------------------------

def _normalized_size(size, capacity):
    # percentage of capacity; stable across traces
    return max(MIN_SIZE_NORM, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _recency_bonus(cache_snapshot, key, seg_id, rec_win_items):
    now = cache_snapshot.access_count
    last = m_last_access.get(key)
    window = max(REC_WIN_MIN, REC_WIN_MULT * rec_win_items)
    age_norm = _recency_normalized(now, last, window)
    # More recent -> larger bonus (age_norm small)
    w = REC_W_PROB if seg_id == SEG_PROB else REC_W_PROT
    return w * (1.0 - age_norm)

def _segment_shield(seg_id, probation_frac_bytes, incoming_size_norm):
    # Base shield for protected; reduced if probation share is too small
    if seg_id == SEG_PROT:
        scale = 1.0
        if probation_frac_bytes < PROB_MIN_FRAC:
            # If probation too small, reduce shield to allow some protected eviction
            scale = max(0.0, probation_frac_bytes / PROB_MIN_FRAC)
        # If incoming object is very large, further reduce shield (we may need big space)
        if incoming_size_norm >= 10.0:  # >=10% of capacity
            scale *= 0.5
        return PROTECTED_SHIELD * scale
    return 0.0

def _keep_score(cache_snapshot, key, incoming_obj):
    # Keep-score: higher = stronger retention, lower = more evictable
    cap = cache_snapshot.capacity
    cache = cache_snapshot.cache

    robj = cache.get(key)
    if robj is None:
        return float('inf')  # shouldn't happen; make it non-evictable by default

    size_norm = _normalized_size(robj.size, cap)
    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    seg_id = m_segment.get(key, SEG_PROB)
    # recency over an adaptive window based on resident items
    n_items = max(1, len(cache))
    rbonus = _recency_bonus(cache_snapshot, key, seg_id, n_items)

    # segment shield to prefer probation evictions; adaptive to probation share and incoming size
    total_bytes = max(1, cache_snapshot.size)
    prob_bytes = max(0, seg_bytes.get(SEG_PROB, 0))
    probation_frac_bytes = float(prob_bytes) / float(total_bytes)
    inc_size_norm = _normalized_size(incoming_obj.size, cap)
    shield = _segment_shield(seg_id, probation_frac_bytes, inc_size_norm)

    return benefit + rbonus + shield

# ---------------------------------
# Segment maintenance
# ---------------------------------

def _seg_bytes_add(seg_id, sz):
    seg_bytes[seg_id] = seg_bytes.get(seg_id, 0) + sz

def _seg_bytes_sub(seg_id, sz):
    seg_bytes[seg_id] = max(0, seg_bytes.get(seg_id, 0) - sz)

def _promote_to_protected(cache_snapshot, key):
    # Move key from probation -> protected if resident
    if m_segment.get(key, SEG_PROB) == SEG_PROT:
        return
    # size from resident object
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return
    m_segment[key] = SEG_PROT
    _seg_bytes_sub(SEG_PROB, obj.size)
    _seg_bytes_add(SEG_PROT, obj.size)

def _demote_to_probation(cache_snapshot, key):
    if m_segment.get(key, SEG_PROB) == SEG_PROB:
        return
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return
    m_segment[key] = SEG_PROB
    _seg_bytes_sub(SEG_PROT, obj.size)
    _seg_bytes_add(SEG_PROB, obj.size)

def _maybe_rebalance_segments(cache_snapshot):
    # Keep protected bytes under target fraction by demoting weakest protected item
    total_bytes = max(1, cache_snapshot.size)
    prot_bytes = seg_bytes.get(SEG_PROT, 0)
    target = PROT_TARGET_FRAC * total_bytes
    if prot_bytes <= target or prot_bytes == 0:
        return

    # Find weakest protected key by keep-score (smallest = most demotable)
    min_k = None
    min_score = None
    for k in cache_snapshot.cache.keys():
        if m_segment.get(k, SEG_PROB) != SEG_PROT:
            continue
        s = _keep_score(cache_snapshot, k, incoming_obj=_DummyIncoming(cache_snapshot))
        if (min_score is None) or (s < min_score) or (s == min_score and m_last_access.get(k, -1) < m_last_access.get(min_k, -1)):
            min_score = s
            min_k = k

    if min_k is not None:
        _demote_to_probation(cache_snapshot, min_k)

class _DummyIncoming:
    # Used only for rebalancing where incoming size influence is negligible; treat as tiny
    def __init__(self, cache_snapshot):
        self.size = max(1, cache_snapshot.capacity // 10000)  # ~0.01% cap

# ---------------------------------
# Policy entry points
# ---------------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest keep-score (benefit + recency + segment shield).
    Ties are broken by oldest last-access time.
    Probation is preferred for eviction via segment shield.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    # Pre-compute adaptive shield scale via probation bytes share
    for k in cache_snapshot.cache.keys():
        s = _keep_score(cache_snapshot, k, incoming_obj=obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (s < min_score) or (s == min_score and last < min_time):
            min_score = s
            min_time = last
            min_key = k

    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key

def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Increment resident hit count
      - Refresh last-access time
      - On first resident hit (count becomes >=2), promote to protected
      - If protected exceeds target bytes, demote weakest protected key
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    # Initialize to at least 1 if missing
    cur_hits = m_resident_hits.get(k, 1) + 1
    m_resident_hits[k] = cur_hits

    # Promote to protected on first additional hit
    if m_segment.get(k, SEG_PROB) == SEG_PROB and cur_hits >= 2:
        _promote_to_protected(cache_snapshot, k)
        _maybe_rebalance_segments(cache_snapshot)
    else:
        # If already protected, we may still rebalance if protected is oversized
        _maybe_rebalance_segments(cache_snapshot)

    # Remove from ghost on hit (no longer a non-resident)
    _ghost_touch_remove(k)

def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits
      - Segment placement:
          * If the key was recently evicted (in ghost), start in protected (hot reentry)
          * Otherwise start in probation
      - If protected exceeds target bytes, demote weakest protected key
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count

    # If in ghost, consider it hot reentry: start in protected with hits=2
    if _ghost_contains(k):
        m_resident_hits[k] = 2
        m_segment[k] = SEG_PROT
        _seg_bytes_add(SEG_PROT, obj.size)
        _ghost_touch_remove(k)
        _maybe_rebalance_segments(cache_snapshot)
    else:
        m_resident_hits[k] = 1
        m_segment[k] = SEG_PROB
        _seg_bytes_add(SEG_PROB, obj.size)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata for the evicted key
      - Retain TinyLFU counts across evictions
      - Record the key in the ghost set to capture recency working set churn
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Update segment bytes based on its last known segment
    seg_id = m_segment.pop(ek, SEG_PROB)
    _seg_bytes_sub(seg_id, evicted_obj.size)

    # Resident-only metadata removal
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # TinyLFU counts are intentionally retained
    # Track in ghost for hot reentry heuristics
    _ghost_record(cache_snapshot, ek)
```
2025-11-27 22:03:51,916 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 18
- Error: Error - Timeout

Example 2:
- Trace ID: 34
- Hit Rate: 0.0789

Example 3:
- Trace ID: 42
- Hit Rate: 0.0855

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:03:51 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:03:51,917 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:05:59 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:05:59,307 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:05:59,308 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Fast SLRU + TinyLFU (byte-aware) with O(1) segment operations and O(k) victim choice
# - Two resident segments with true LRU lists:
#     * probation: newly admitted and single-hit items (LRU managed)
#     * protected: promoted upon hit; capped by bytes via demotion of oldest
# - Eviction prefers the probation tail; falls back to protected tail
# - Victim selection samples a small number (k) of LRU-tail candidates and picks
#   the one with the smallest retention score (TinyLFU benefit vs size, with recency/predicted reuse)
# - TinyLFU uses lazy-decayed 4-bit counters and persists across eviction
# - All segment operations are O(1), fixing prior timeouts and improving robustness

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU timestamp)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# SLRU doubly-linked lists per-segment (0: probation, 1: protected)
_lru_prev = {0: dict(), 1: dict()}  # seg -> {key: prev_key or None}
_lru_next = {0: dict(), 1: dict()}  # seg -> {key: next_key or None}
_lru_head = {0: None, 1: None}      # seg -> MRU key
_lru_tail = {0: None, 1: None}      # seg -> LRU key

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.40     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.55
W_REC_PROT = 0.15
W_PRED_PROB = 0.22
W_PRED_PROT = 0.10

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# Tail sample size for candidate victims
BASE_TAIL_SAMPLE = 5
LARGE_OBJ_SAMPLE = 10      # for very large incoming objects (>10% capacity)

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

# -----------------------------
# SLRU list helpers (O(1))
# -----------------------------

def _lru_unlink(seg, key):
    if key is None:
        return
    prev_k = _lru_prev[seg].pop(key, None)
    next_k = _lru_next[seg].pop(key, None)

    if prev_k is not None:
        _lru_next[seg][prev_k] = next_k
    else:
        # was head
        if _lru_head[seg] == key:
            _lru_head[seg] = next_k

    if next_k is not None:
        _lru_prev[seg][next_k] = prev_k
    else:
        # was tail
        if _lru_tail[seg] == key:
            _lru_tail[seg] = prev_k

def _lru_link_head(seg, key):
    # Insert at MRU (head)
    prev_head = _lru_head[seg]
    _lru_prev[seg][key] = None
    _lru_next[seg][key] = prev_head
    _lru_head[seg] = key
    if prev_head is not None:
        _lru_prev[seg][prev_head] = key
    if _lru_tail[seg] is None:
        _lru_tail[seg] = key

def _lru_move_to_head(seg, key):
    # Move an existing node to MRU
    if _lru_head[seg] == key:
        return
    # If the key is unknown to the list (shouldn't happen), treat as new link
    if key not in _lru_prev[seg] and key not in _lru_next[seg] and _lru_head[seg] != key:
        _lru_link_head(seg, key)
        return
    _lru_unlink(seg, key)
    _lru_link_head(seg, key)

def _lru_peek_tail(seg):
    return _lru_tail[seg]

def _lru_iter_tail_k(seg, k):
    # Iterate up to k keys from LRU toward MRU
    res = []
    cur = _lru_tail[seg]
    while cur is not None and len(res) < k:
        res.append(cur)
        cur = _lru_prev[seg].get(cur)
    return res

def _seg_add(cache_snapshot, seg, key, size_bytes):
    # Add to segment seg and LRU head
    m_segment[key] = seg
    _lru_link_head(seg, key)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes += size_bytes

def _seg_remove(cache_snapshot, seg, key, size_bytes):
    # Remove from segment seg and LRU
    _lru_unlink(seg, key)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - size_bytes)
    m_segment.pop(key, None)

def _promote_to_protected(cache_snapshot, key):
    # Move key from probation to protected; caller ensures key is resident
    if _segment_of(key) == 1:
        # already protected: just move to MRU
        _lru_move_to_head(1, key)
        return
    # unlink from probation and add to protected
    _lru_unlink(0, key)
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        # Shouldn't happen: if missing, just mark protected to keep consistency
        m_segment[key] = 1
        return
    _seg_add(cache_snapshot, 1, key, robj.size)

def _demote_one_protected_tail(cache_snapshot):
    # Demote oldest protected item (LRU tail) to probation MRU
    key = _lru_peek_tail(1)
    if key is None:
        return False
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        # Clean up inconsistent entry
        _lru_unlink(1, key)
        m_segment.pop(key, None)
        return False
    # Remove from protected and add to probation
    _seg_remove(cache_snapshot, 1, key, robj.size)
    _seg_add(cache_snapshot, 0, key, 0)  # size counted only for protected bytes
    return True

def _rebalance_protected_bytes(cache_snapshot):
    target = _protected_target_bytes(cache_snapshot)
    # Demote oldest protected until within target
    while g_protected_bytes > target:
        if not _demote_one_protected_tail(cache_snapshot):
            break

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed (O(1) per demotion)
      - Prefer evicting from probation; fall back to protected if probation empty
      - Sample up to k keys from the LRU tail of the chosen segment and evict the smallest retention score
      - k is larger for very large incoming objects to better find a bulky/weak victim
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized (demote at most necessary)
    _rebalance_protected_bytes(cache_snapshot)

    # Choose segment to evict from
    seg_to_evict = 0 if _lru_peek_tail(0) is not None else 1
    if _lru_peek_tail(seg_to_evict) is None:
        # Fallback: no candidates in either segment
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Decide sample size based on incoming object size
    cap = cache_snapshot.capacity
    sample_k = LARGE_OBJ_SAMPLE if obj and obj.size >= 0.10 * cap else BASE_TAIL_SAMPLE

    # Gather candidates from chosen segment tail
    candidates = _lru_iter_tail_k(seg_to_evict, sample_k)
    # If that segment has fewer than k and the other segment has items, optionally extend
    if len(candidates) < sample_k:
        other = 1 - seg_to_evict
        candidates += _lru_iter_tail_k(other, max(0, sample_k - len(candidates)))

    # Select by smallest retention score; break ties by oldest last access, then by largest size
    best_key = None
    best_score = None
    best_last = None
    best_size = None

    for k in candidates:
        score = _retention_score(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        size = cache_snapshot.cache.get(k).size if k in cache_snapshot.cache else 0
        if (best_key is None or
            score < best_score or
            (score == best_score and last < best_last) or
            (score == best_score and last == best_last and size > best_size)):
            best_key = k
            best_score = score
            best_last = last
            best_size = size

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected; else move to MRU in its segment
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = _segment_of(k)
    if seg == 0:
        # Promote probation -> protected
        _promote_to_protected(cache_snapshot, k)
    else:
        # Move to MRU within protected
        _lru_move_to_head(1, k)

    # Enforce protected target (demote oldest protected if oversized)
    _rebalance_protected_bytes(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation, appended at MRU of probation LRU
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # Insert into probation MRU
    # If somehow already in a list (shouldn't happen), unlink first
    if _segment_of(k) == 1:
        _lru_unlink(1, k)
    else:
        _lru_unlink(0, k)
    _seg_add(cache_snapshot, 0, k, 0)  # probation, no protected byte accounting


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata and unlink from its segment LRU
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    seg = _segment_of(ek)
    # Unlink from the appropriate segment and adjust protected bytes if needed
    if seg == 1:
        _seg_remove(cache_snapshot, 1, ek, evicted_obj.size)
    else:
        _lru_unlink(0, ek)
        m_segment.pop(ek, None)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_irt.pop(ek, None)

    # Ensure protected bytes accounting non-negative
    global g_protected_bytes
    if g_protected_bytes < 0:
        g_protected_bytes = 0
```
2025-11-27 22:06:26,120 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 38
- Hit Rate: 0.1255

Example 2:
- Trace ID: 47
- Hit Rate: 0.1732

Example 3:
- Trace ID: 0
- Hit Rate: 0.503

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:06:26 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:06:26,121 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:07:58 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:07:58,749 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:07:58,751 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# GreedyDual-TinyLFU (GDTLFU)
# - Core policy: GreedyDual with size-awareness and LFU-informed "cost"
#     * Each resident item maintains a priority H[k].
#     * On eviction, evict the key with the smallest H; update the global inflation L to that H.
#     * On insert: H[k] = L + benefit(key, size)
#     * On hit:    H[k] += benefit(key, size)
# - Benefit is frequency- and size-aware:
#     benefit = (1 + FREQ_WEIGHT * log2(1+lfu_count) + multi_hit_bonus) / max(size/capacity, SIZE_SATURATE)
#   This favors small and frequently accessed items but caps the tiny-object advantage via SIZE_SATURATE.
# - Frequency is tracked using a TinyLFU-like lazy-decayed 4-bit counter retained across evictions.
# - Recency is implicitly handled by GreedyDual's inflation L: old priorities age as L increases.
#
# Rationale:
#   GDSF/GD-Size-type strategies are strong baselines on variable-sized caches; augmenting the "cost"
#   with a decayed TinyLFU signal substantially improves admission/retention decisions without needing
#   a separate admission filter. The global inflation L yields natural aging, while LFU and size awareness
#   reduce misses across diverse workloads.

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (for tie-breaking)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters), retained across evictions
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # accesses per epoch (power-of-two recommended)

# GreedyDual priorities
m_H = dict()               # key -> float priority
g_L = 0.0                  # global inflation

# Tunables
FREQ_WEIGHT = 1.2          # strength of LFU in benefit
MULTI_HIT_BONUS = 0.3      # extra benefit once an item has >=2 resident hits
SIZE_SATURATE = 0.01       # floor on size/capacity in benefit denominator (caps tiny-object advantage)

# Lazily ensure TinyLFU epoch is current
def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Benefit / priority helpers
# -----------------------------

def _size_norm(size, capacity):
    # Normalize size to fraction of capacity, with a floor to cap tiny-object advantage
    frac = float(size) / float(capacity) if capacity > 0 else 1.0
    return max(frac, SIZE_SATURATE)

def _benefit(cache_snapshot, key, size):
    # Size- and LFU-aware benefit. Larger -> stronger retention.
    cap = cache_snapshot.capacity
    freq = _lfu_peek(cache_snapshot, key)
    base = 1.0 + FREQ_WEIGHT * math.log2(1.0 + float(freq))
    if m_resident_hits.get(key, 0) >= 2:
        base += MULTI_HIT_BONUS
    denom = _size_norm(size, cap)
    return base / denom

def _ensure_priority(cache_snapshot, key, obj):
    # Ensure an H[k] exists for resident key; lazily initialize if missing.
    if key not in m_H:
        # Initialize to current L + one benefit unit
        m_H[key] = g_L + _benefit(cache_snapshot, key, obj.size)
    return m_H[key]


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest GreedyDual-TinyLFU priority H.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_H_val = None
    min_time = None

    for k, robj in cache_snapshot.cache.items():
        Hk = _ensure_priority(cache_snapshot, k, robj)
        last = m_last_access.get(k, -1)
        if (min_H_val is None) or (Hk < min_H_val) or (Hk == min_H_val and last < min_time):
            min_H_val = Hk
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Increase GreedyDual priority by one benefit unit
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Increase H by benefit; ensure it exists
    size = obj.size
    if k not in m_H:
        m_H[k] = g_L
    m_H[k] += _benefit(cache_snapshot, k, size)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - Initialize GreedyDual priority: H = L + benefit
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    m_H[k] = g_L + _benefit(cache_snapshot, k, obj.size)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Update global inflation L to victim's H
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Update L using the evicted key's priority (default to current L if missing)
    evicted_H = m_H.get(ek, g_L)
    # Set global inflation to the evicted priority as per GreedyDual
    global g_L
    g_L = evicted_H

    # Remove resident-only metadata. Keep LFU history for better future decisions.
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_H.pop(ek, None)
```
2025-11-27 22:08:01,583 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved policy: Heap-Accelerated TinyLFU with Size and Recency (HALO-TFS)
# - Fast eviction via a lazy min-heap of retention scores (no full scans)
# - TinyLFU with lazy epoch decay (per-key small counters remembered across evictions)
# - Size-aware, recency-aware scoring with multi-hit boost
# - Robust to workload shifts; avoids timeouts via O(log n) victim selection and periodic heap rebuilds

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_resident_hits = dict()    # key -> int resident hit count (>=1 once inserted)

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096   # accesses per epoch (power of two recommended)
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192  # how often to check if heap needs rebuilding
HEAP_GROWTH_FACTOR = 4       # if heap > factor * resident_count, rebuild

# Tunables for scoring
SIZE_ALPHA = 0.75           # size normalization exponent; smaller favors small objects
REC_WIN_MIN = 64            # minimum recency window
REC_WIN_MULT = 8            # recency window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.75           # strength of recency term added to frequency
MULTI_HIT_BONUS = 0.50      # multiplicative boost for items with >=2 hits while resident


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # no sweeping; decay handled lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring
# -----------------------------

def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency component
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    r_term = _recency_term(now, m_last_access.get(key), window)

    # Multi-hit boost (stronger protection after the second hit)
    mh = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    mult = 1.0 + mh

    # Final score: combine frequency and recency, then size-normalize
    score = ((f_term + REC_WEIGHT * r_term) * mult) / size_norm
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    # Rebuild heap from current residents with fresh scores/versions
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    Lazy invalidation ensures correctness despite changing scores/epochs.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., unusual bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            if k not in m_ver:
                # Initialize resident metadata if missing (best effort)
                m_last_access.setdefault(k, cache_snapshot.access_count)
                m_resident_hits.setdefault(k, 1)
            _heap_push(cache_snapshot, k)

    # Candidate's "would-be" score (informal comparison; does not affect required eviction)
    # This is used only to help prefer weaker residents when ties occur.
    cand_freq = _lfu_peek(cache_snapshot, obj.key) + 1  # will be incremented on insert
    cand_f_term = math.log1p(float(cand_freq))
    cand_size_norm = max(1.0, float(obj.size)) ** SIZE_ALPHA
    cand_score = (cand_f_term + REC_WEIGHT * 1.0) / cand_size_norm  # recency ~1 on insert

    # Pop until we find a valid, up-to-date victim
    while m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            continue
        # Skip if stale entry
        if m_ver.get(k, 0) != v:
            continue
        # Recompute current score to account for epoch/window changes
        new_sc = _score_key(cache_snapshot, k)
        # If the score drifted upward (got better), reinsert with new score
        if new_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            continue
        # Optional tie-breaker with candidate: if resident clearly stronger than candidate,
        # try to find a weaker one by peeking more; but if none, return this one.
        if new_sc >= cand_score:
            # Keep searching a bit for something weaker; cap extra attempts to avoid overhead
            attempts = 0
            tmp = [(sc, last, k, v)]
            victim = None
            while attempts < 8 and m_heap:
                sc2, last2, k2, v2 = heapq.heappop(m_heap)
                if k2 not in cache_snapshot.cache or m_ver.get(k2, 0) != v2:
                    attempts += 1
                    continue
                cur_sc2 = _score_key(cache_snapshot, k2)
                if cur_sc2 > sc2 + 1e-12:
                    _heap_push(cache_snapshot, k2)
                    attempts += 1
                    continue
                if cur_sc2 < cand_score or cur_sc2 < new_sc:
                    victim = (cur_sc2, last2, k2, v2)
                    break
                tmp.append((sc2, last2, k2, v2))
                attempts += 1
            # Push back any entries we popped but didn't choose
            for ent in tmp:
                heapq.heappush(m_heap, ent)
            if victim is not None:
                return victim[2]
            # Fall back to the original k
        return k

    # Fallback: choose the oldest resident if heap is somehow empty
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch and increment counter for requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember its popularity)
      - Invalidate its heap version (lazy: stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_ver.pop(ek, None)
    _touch_and_maybe_rebuild(cache_snapshot)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 11
- Hit Rate: 0.3601

Example 2:
- Trace ID: 28
- Hit Rate: 0.0398

Example 3:
- Trace ID: 7
- Hit Rate: 0.4713

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:08:01 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:08:01,584 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:10:03 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:10:03,669 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:10:03,670 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive Replacement Cache (ARC) with ghost history
# - Two resident lists (T1: recent, T2: frequent), both LRU-ordered
# - Two non-resident ghost lists (B1: keys evicted from T1, B2: keys evicted from T2)
# - Dynamically adapts the balance between recency and frequency via target p
# - Eviction chooses from T1 or T2 according to ARC's REPLACE policy
# - O(1) updates using OrderedDict for LRU maintenance

from collections import OrderedDict

# -----------------------------
# Global ARC state (module scope)
# -----------------------------

# Resident lists (keys only)
m_T1 = OrderedDict()  # Recent items (seen once)
m_T2 = OrderedDict()  # Frequent items (seen >= 2 times while resident)

# Ghost lists (keys only, record history of evicted items)
m_B1 = OrderedDict()  # Recently evicted from T1
m_B2 = OrderedDict()  # Recently evicted from T2

# Target size of T1 (0..capacity); T2 implicitly uses the remainder
m_p = 0

# Tracks from which list the last eviction occurred, so we can update ghost lists accurately
m_last_evicted_from = dict()  # key -> 'T1' or 'T2'

# Cache capacity snapshot (number of objects). Initialized lazily.
m_cap_n = None


# -----------------------------
# Helpers
# -----------------------------

def _cap_n(cache_snapshot):
    global m_cap_n
    # We assume capacity is the number of objects, per problem statement.
    # Initialize once and treat as constant during a run.
    if m_cap_n is None:
        m_cap_n = max(1, int(cache_snapshot.capacity))
    return m_cap_n


def _move_to_mru(od, key):
    od[key] = None
    od.move_to_end(key, last=True)


def _remove_if_present(od, key):
    if key in od:
        try:
            del od[key]
        except KeyError:
            pass
        return True
    return False


def _prune_non_residents(cache_snapshot):
    # Ensure resident lists contain only actual residents (defensive)
    resident = cache_snapshot.cache
    for od in (m_T1, m_T2):
        to_del = [k for k in od.keys() if k not in resident]
        for k in to_del:
            _remove_if_present(od, k)


def _ensure_seed_from_residents(cache_snapshot):
    # If all lists empty but cache has residents (e.g., warm-start), seed T1 in LRU-ish order.
    if (not m_T1) and (not m_T2) and cache_snapshot.cache:
        # Insert in arbitrary order; hits will sculpt correct order over time.
        for k in cache_snapshot.cache.keys():
            _move_to_mru(m_T1, k)


def _adapt_p_on_miss(key, cap_n):
    # If the incoming (missed) key is in ghost lists, adapt p accordingly (ARC)
    global m_p
    if key in m_B1:
        # Favor recency: increase p, stronger when B2 >> B1
        delta = max(1, len(m_B2) // max(1, len(m_B1)))
        m_p = min(cap_n, m_p + delta)
    elif key in m_B2:
        # Favor frequency: decrease p, stronger when B1 >> B2
        delta = max(1, len(m_B1) // max(1, len(m_B2)))
        m_p = max(0, m_p - delta)
    # Clamp p just in case
    if m_p < 0:
        m_p = 0
    elif m_p > cap_n:
        m_p = cap_n


def _choose_victim_for(key_new):
    # ARC REPLACE routine: decide whether to evict from T1 or T2.
    # Evict LRU of T1 if:
    #  - size(T1) > p, or
    #  - key_new in B2 and size(T1) == p
    # Else evict LRU of T2.
    size_T1 = len(m_T1)
    if size_T1 > 0 and ((key_new in m_B2 and size_T1 == m_p) or (size_T1 > m_p)):
        # Evict from T1
        k_evict, _ = m_T1.popitem(last=False)  # LRU
        m_last_evicted_from[k_evict] = 'T1'
        return k_evict
    # Otherwise, evict from T2 (fallback if T1 empty)
    if m_T2:
        k_evict, _ = m_T2.popitem(last=False)  # LRU
        m_last_evicted_from[k_evict] = 'T2'
        return k_evict
    # Fallback: if both empty, we cannot decide based on ARC; return None
    return None


def _ensure_ghost_budget(cap_n):
    # Keep ghost lists size bounded by cap_n (total ghosts <= capacity)
    # We evict from B1 or B2 to maintain the invariant.
    while (len(m_B1) + len(m_B2)) > cap_n:
        if len(m_B1) > m_p:
            # Prefer trimming recency ghosts if T1 target is large
            m_B1.popitem(last=False)
        elif m_B2:
            m_B2.popitem(last=False)
        elif m_B1:
            m_B1.popitem(last=False)
        else:
            break


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose a victim using ARC REPLACE policy:
      - Adapt target p using ghost history membership of the requested key
      - Evict from T1 if T1 is too large or requested key is likely frequent (in B2), else from T2
    """
    cap_n = _cap_n(cache_snapshot)
    _ensure_seed_from_residents(cache_snapshot)
    _prune_non_residents(cache_snapshot)

    k_new = obj.key

    # Adapt balance parameter based on ghost lists
    _adapt_p_on_miss(k_new, cap_n)

    # Decide victim
    victim = _choose_victim_for(k_new)
    if victim is not None:
        return victim

    # Fallback: pick any resident key if lists are out of sync
    for k in cache_snapshot.cache.keys():
        return k
    return None


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - If in T1: promote to T2 MRU
      - If in T2: refresh to T2 MRU
      - If somehow not in our lists but resident: add to T2 MRU (treat as frequent)
    """
    k = obj.key
    _ensure_seed_from_residents(cache_snapshot)
    _prune_non_residents(cache_snapshot)

    if _remove_if_present(m_T1, k):
        _move_to_mru(m_T2, k)
        return

    if k in m_T2:
        m_T2.move_to_end(k, last=True)  # refresh MRU
        return

    if k in cache_snapshot.cache:
        # Not tracked (e.g., initialization mismatch); treat as frequent due to hit
        _remove_if_present(m_B1, k)
        _remove_if_present(m_B2, k)
        _move_to_mru(m_T2, k)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - If key was in B1: increase p and place it into T2 (MRU)
      - If key was in B2: decrease p and place it into T2 (MRU)
      - Otherwise: place into T1 (MRU)
    """
    cap_n = _cap_n(cache_snapshot)
    k = obj.key

    # Adapt p if key present in ghosts (matching standard ARC behavior)
    if k in m_B1:
        delta = max(1, len(m_B2) // max(1, len(m_B1)))
        # Increase p (favor recency)
        global m_p
        m_p = min(cap_n, m_p + delta)
        _remove_if_present(m_B1, k)
        _move_to_mru(m_T2, k)  # promote on re-reference
    elif k in m_B2:
        delta = max(1, len(m_B1) // max(1, len(m_B2)))
        # Decrease p (favor frequency)
        global m_p
        m_p = max(0, m_p - delta)
        _remove_if_present(m_B2, k)
        _move_to_mru(m_T2, k)  # promote on re-reference
    else:
        # New item: insert into T1 (recency)
        _remove_if_present(m_T1, k)
        _remove_if_present(m_T2, k)
        _move_to_mru(m_T1, k)

    # Keep ghosts within budget
    _ensure_ghost_budget(cap_n)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After a victim is evicted:
      - Add its key to the appropriate ghost list (B1 if from T1; B2 if from T2)
      - Enforce ghost size budget
    """
    cap_n = _cap_n(cache_snapshot)
    ek = evicted_obj.key

    # Determine from which list we evicted
    origin = m_last_evicted_from.pop(ek, None)

    # Remove from resident lists defensively
    _remove_if_present(m_T1, ek)
    _remove_if_present(m_T2, ek)

    # Add to appropriate ghost list as MRU
    if origin == 'T1':
        _remove_if_present(m_B1, ek)
        _move_to_mru(m_B1, ek)
    else:
        # Treat unknown origin as T2 for safety
        _remove_if_present(m_B2, ek)
        _move_to_mru(m_B2, ek)

    # Enforce ghost capacity
    _ensure_ghost_budget(cap_n)
```
2025-11-27 22:10:51,432 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved: Count-based SLRU with TinyLFU, ARC-style adaptive split, and recency-aware scoring
# - Two resident segments by item count, not by bytes:
#     P (probation): admits all new objects; managed by LRU (via last_access timestamps)
#     S (protected): objects that hit at least once; also LRU-managed
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction score blends frequency and recency (recency matters beyond tie-break)
# - ARC-like ghost lists adapt the item split between P and S online (by counts)
#
# This design captures:
#   - Recency (via LRU timestamps and explicit recency in eviction score)
#   - Frequency (via TinyLFU)
#   - Adaptivity between recency-friendly and frequency-friendly behavior
#   - Correctness for caches limited by number of items (not bytes)

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU)
m_key_segment = dict()       # key -> 'P' or 'S'

# Current resident ITEM COUNTS per segment
m_cnt_P = 0
m_cnt_S = 0

# Adaptive target for protected items (S); probation target = capacity_items - target_S
m_target_S_items = None
m_cap_items_est = 0  # our estimate of capacity in number of items (learned at evict time)

# Ghost lists (non-resident metadata) to adapt split; store key -> last_time
m_ghost_P = dict()  # B1
m_ghost_S = dict()  # B2
m_ghost_limit_items = None

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)

# ---------------
# Scoring params
# ---------------
# Recency blend: score = est_freq + rec_weight * min(recency / half_life, rec_cap)
m_rec_half_life = 500.0  # accesses; tune to make recency effect comparable to est_freq
m_rec_cap = 10.0         # cap normalized recency contribution
m_rec_weight_P = 1.0     # probation recency weight
m_rec_weight_S = 0.6     # protected recency weight (S is more persistent)
m_protect_S_bias = 0.25  # additive bias to S candidates to modestly protect them
m_overweight_nudge = 0.2 # when a segment exceeds target, nudge its candidate to be more evictable

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_target_S_items, m_ghost_limit_items
    global m_sketch_tables, m_sketch_mask
    global m_cap_items_est

    # Learn capacity in items opportunistically; on evict() we'll update more accurately.
    if m_cap_items_est < len(cache_snapshot.cache):
        m_cap_items_est = len(cache_snapshot.cache)

    if m_target_S_items is None:
        # Start slightly frequency-friendly; adapt online
        base_items = max(1, len(cache_snapshot.cache))
        m_target_S_items = int(base_items * 0.6)

    if m_ghost_limit_items is None:
        # Each ghost list limited to approximately the cache capacity in items (we adjust later)
        m_ghost_limit_items = max(1, len(cache_snapshot.cache))

    if m_sketch_tables is None:
        # Width scales with estimated items; choose power of two near items*4 (empirical)
        # Minimum width to keep estimates reasonably stable.
        items = max(1, len(cache_snapshot.cache))
        width = 1
        target = max(1024, min(1 << 16, items * 4))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        # Halve all counters (right-shift by 1)
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _normalized_recency(now, last):
    if last is None or last < 0:
        return m_rec_cap
    age = max(0, now - last)
    norm = age / m_rec_half_life
    if norm > m_rec_cap:
        norm = m_rec_cap
    return norm


def _pick_min_score_in_segment(cache_snapshot, seg_tag, now):
    # Returns (key, score, last_time) that minimizes blended score within a segment
    # Score = est_freq + rec_weight * normalized_recency; tie-break by older first
    min_key = None
    min_score = None
    min_time = None

    rec_w = m_rec_weight_S if seg_tag == 'S' else m_rec_weight_P

    for key, obj in cache_snapshot.cache.items():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        est = float(_sketch_estimate(key))
        last = m_key_last_access.get(key, -1)
        rec = _normalized_recency(now, last)
        score = est + rec_w * rec
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = key
            min_score = score
            min_time = last

    return (min_key, min_score, min_time)


def _find_oldest_in_segment(cache_snapshot, seg_tag):
    oldest_key, oldest_time = None, None
    for k in cache_snapshot.cache.keys():
        if m_key_segment.get(k, 'P') != seg_tag:
            continue
        t = m_key_last_access.get(k, -1)
        if oldest_time is None or t < oldest_time:
            oldest_key, oldest_time = k, t
    return oldest_key


def _ghost_add(ghost_dict, key, time_now, which):
    # Add key->time to chosen ghost (which in {'P','S'}), trimming if exceeds limit
    global m_ghost_limit_items

    # Insert/update
    ghost_dict[key] = time_now

    # Trim to limit by evicting oldest
    limit = m_ghost_limit_items or 0
    if limit <= 0:
        return

    while len(ghost_dict) > limit:
        oldest_key, oldest_time = None, None
        for k, t in ghost_dict.items():
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        if oldest_key is None:
            break
        ghost_dict.pop(oldest_key, None)


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    # If key in P-ghost (B1): increase probation share (decrease S target)
    # If key in S-ghost (B2): increase protected share (increase S target)
    global m_target_S_items, m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Update our item-capacity estimate when cache is likely full (best signal: on evict call, but keep here too)
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)

    # Keep ghost size limits around capacity in items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est

    cap_items = max(1, m_cap_items_est)

    # Step size: 1 item per signal (conservative, stable)
    step = 1

    if obj.key in m_ghost_P:
        # Recent ghost hit: favor recency -> increase P share (decrease S)
        m_target_S_items = _clamp((m_target_S_items or 0) - step, 0, cap_items)
        m_ghost_P.pop(obj.key, None)
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: favor frequency -> increase S share
        m_target_S_items = _clamp((m_target_S_items or 0) + step, 0, cap_items)
        m_ghost_S.pop(obj.key, None)


def _maybe_demote_from_S_to_P(cache_snapshot):
    # If S exceeds its target, demote oldest S item to P
    global m_cnt_P, m_cnt_S, m_target_S_items
    if m_target_S_items is None:
        return
    if m_cnt_S > m_target_S_items:
        demote_key = _find_oldest_in_segment(cache_snapshot, 'S')
        if demote_key is not None:
            m_key_segment[demote_key] = 'P'
            m_cnt_S = max(0, m_cnt_S - 1)
            m_cnt_P += 1


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using count-based SLRU + TinyLFU with recency-aware scoring.
    - Compute candidate with minimal blended score in each segment:
        score = est_freq(key) + rec_weight * normalized_recency
    - Bias to evict from the segment exceeding its item-count target.
    - Protect S moderately by adding a small bias compared to P.
    '''
    global m_cnt_P, m_cnt_S, m_target_S_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Learn/refresh capacity in number of items at the moment of eviction (cache is full now)
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    cap_items = max(1, m_cap_items_est)
    if m_target_S_items is None:
        m_target_S_items = int(0.6 * cap_items)
    target_S = _clamp(m_target_S_items, 0, cap_items)
    target_P = cap_items - target_S

    now = cache_snapshot.access_count

    # Find min-score candidate in each segment
    p_key, p_score, p_lru = _pick_min_score_in_segment(cache_snapshot, 'P', now)
    s_key, s_score, s_lru = _pick_min_score_in_segment(cache_snapshot, 'S', now)

    # Prepare adjusted scores
    best_key = None
    best_adj = None

    if p_key is not None:
        adj_p = p_score
        # If P is overweight, make it slightly more likely to evict from P
        if m_cnt_P > target_P:
            adj_p -= m_overweight_nudge
        # No extra protection bias for P
        best_key = p_key
        best_adj = adj_p

    if s_key is not None:
        adj_s = s_score + m_protect_S_bias
        # If S is overweight, encourage eviction from S
        if m_cnt_S > target_S:
            adj_s -= m_overweight_nudge
        if (best_adj is None) or (adj_s < best_adj):
            best_adj = adj_s
            best_key = s_key

    # Fallback: if we somehow didn't find any key (shouldn't happen), pick oldest globally
    if best_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        best_key = oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - If in probation (P), promote to protected (S); if S exceeds target, demote oldest S to P
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    k = obj.key

    # Update TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    # Promote from P to S on hit
    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        m_key_segment[k] = 'S'
        m_cnt_P = max(0, m_cnt_P - 1)
        m_cnt_S += 1
        # If S above target, demote oldest S back to P
        _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S item split using ARC-like ghosts
      - Increment TinyLFU for the key (TinyLFU trains on both hits and misses)
      - Add the new object to probation (P)
      - Record last access time
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_cnt_P += 1

    # Keep S from drifting above target if previous operations changed target
    _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key
      - Update segment item counters
      - Add the key to the corresponding ghost list (count-limited) to guide future adaptation
      - Keep ghost sizes roughly equal to estimated cache capacity in items
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S
    global m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust item counts and add to appropriate ghost
    now = cache_snapshot.access_count
    if seg == 'S':
        m_cnt_S = max(0, m_cnt_S - 1)
        _ghost_add(m_ghost_S, ek, now, which='S')
    else:
        m_cnt_P = max(0, m_cnt_P - 1)
        _ghost_add(m_ghost_P, ek, now, which='P')

    # Update ghost limits to approximate current capacity in items
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 16
- Hit Rate: 0.0203

Example 2:
- Trace ID: 33
- Hit Rate: 0.6879

Example 3:
- Trace ID: 21
- Error: Error - Timeout

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:10:51 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:10:51,433 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:14:02 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:14:02,880 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:14:02,882 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Size-aware SLRU with TinyLFU and sampled eviction (fast and robust)
# - Two resident segments by bytes:
#     P (probation): admits all new objects; managed by LRU (OrderedDict)
#     S (protected): objects that hit at least once; also LRU-managed
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction uses small-sample selection from the LRU tail, scoring each candidate by:
#       benefit_density = (freq_estimate + recency_weight * freshness(now-last_access)) / size_norm
#   and evicts the item with the smallest benefit per byte (protects small/hot items)
# - Adaptive S target: nudged slightly on hits to learn whether the workload is more recency- or frequency-biased
#
# This design aims to:
#   - Be time-efficient (O(sample_k) per eviction; O(1) per hit/insert)
#   - Be size-aware (bytes, not item count)
#   - Capture frequency (TinyLFU) and recency (LRU + freshness in the score)
#   - Avoid full-cache scans (prevents timeouts on large traces)

from collections import OrderedDict

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key metadata
m_key_last_access = dict()    # key -> int access_count (for recency/freshness)
m_key_segment = dict()        # key -> 'P' or 'S'

# LRU lists (keys only); order: LRU (front) -> MRU (end)
m_lru_P = OrderedDict()
m_lru_S = OrderedDict()

# Segment byte usage
m_bytes_P = 0
m_bytes_S = 0

# Adaptive target for protected bytes (fraction of total capacity bytes)
m_target_S_frac = None
m_capacity_bytes = 0

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0
m_sketch_age_interval = 50000   # age after this many ops
m_sketch_counter_cap = 255      # cap per counter (8-bit style)
m_sketch_width_min = 16384      # per row width lower bound (power of two)

# ---------------
# Scoring params
# ---------------
# Freshness-based benefit: benefit = est_freq + rec_weight * freshness
# freshness = 1 / (1 + age / half_life)
m_rec_half_life = 500.0
m_rec_weight_P = 6.0
m_rec_weight_S = 8.0

# Size normalization (promote small objects by dividing benefit by size_norm)
m_size_norm_bytes = 4096.0  # 4KB typical

# Eviction sampling
m_sample_k = 6  # how many LRU-tail candidates to evaluate from a segment

# Adaptive nudges for S fraction (on hits)
m_adapt_up = 0.01   # when P hits (promotions), increase S fraction
m_adapt_down = 0.002  # when S hits, decrease S fraction
m_target_S_frac_min = 0.50
m_target_S_frac_max = 0.90

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_target_S_frac, m_capacity_bytes, m_sketch_tables, m_sketch_mask
    global m_bytes_P, m_bytes_S

    # Initialize capacity and target split
    cap = int(getattr(cache_snapshot, 'capacity', 0) or 0)
    if cap > 0:
        m_capacity_bytes = cap
    if m_target_S_frac is None:
        # Start frequency-friendly but not extreme; adapt online
        m_target_S_frac = 0.7

    # Initialize TinyLFU sketch if needed
    if m_sketch_tables is None:
        # Width is power-of-two; choose near max(m_sketch_width_min, capacity/avg_size)
        width = 1
        target = max(m_sketch_width_min, 1 << 14)  # default to 16384 or larger
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1

    # Ensure segment bytes are non-negative
    if m_bytes_P < 0: m_bytes_P = 0
    if m_bytes_S < 0: m_bytes_S = 0


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    if m_sketch_tables is None:
        return
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    if m_sketch_tables is None:
        return 0
    idxs = _hash_indices(key)
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _freshness(now, last):
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    # 1 / (1 + age / half_life)
    return 1.0 / (1.0 + (age / m_rec_half_life))


def _benefit_density(cache_snapshot, key, seg_tag, now):
    # Compute benefit per normalized byte for a resident key
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')
    size = float(getattr(obj, 'size', 1) or 1)
    denom = max(1.0, size / m_size_norm_bytes)

    est = float(_sketch_estimate(key))
    last = m_key_last_access.get(key, None)
    fresh = _freshness(now, last)
    rec_w = m_rec_weight_S if seg_tag == 'S' else m_rec_weight_P
    benefit = est + rec_w * fresh
    return benefit / denom


def _target_S_bytes():
    if m_capacity_bytes <= 0:
        return 0
    frac = _clamp(m_target_S_frac, m_target_S_frac_min, m_target_S_frac_max)
    return int(frac * m_capacity_bytes)


def _move_to_S(cache_snapshot, key):
    # Promote key from P to S (assumes it currently resides in P)
    global m_bytes_P, m_bytes_S
    if key in m_lru_P:
        m_lru_P.pop(key, None)
    m_key_segment[key] = 'S'
    m_lru_S[key] = None
    obj = cache_snapshot.cache.get(key)
    sz = int(getattr(obj, 'size', 0) or 0)
    m_bytes_P = max(0, m_bytes_P - sz)
    m_bytes_S += sz


def _move_to_P(cache_snapshot, key):
    # Demote key from S to P (assumes it currently resides in S)
    global m_bytes_P, m_bytes_S
    if key in m_lru_S:
        m_lru_S.pop(key, None)
    m_key_segment[key] = 'P'
    m_lru_P[key] = None
    obj = cache_snapshot.cache.get(key)
    sz = int(getattr(obj, 'size', 0) or 0)
    m_bytes_S = max(0, m_bytes_S - sz)
    m_bytes_P += sz


def _ensure_S_within_target(cache_snapshot):
    # If S exceeds its target bytes, demote oldest S items to P
    tgt = _target_S_bytes()
    while m_bytes_S > tgt and m_lru_S:
        old_key, _ = m_lru_S.popitem(last=False)  # LRU from S
        # Demote to P
        m_key_segment[old_key] = 'P'
        m_lru_P[old_key] = None
        obj = cache_snapshot.cache.get(old_key)
        sz = int(getattr(obj, 'size', 0) or 0)
        m_bytes_S = max(0, m_bytes_S - sz)
        m_bytes_P += sz


def _pick_from_lru_sample(cache_snapshot, seg_tag, now):
    # Sample up to m_sample_k keys from the segment's LRU tail and pick the lowest benefit density
    if seg_tag == 'P':
        od = m_lru_P
    else:
        od = m_lru_S

    if not od:
        return None

    # Iterate from LRU side: OrderedDict preserves order; keys() returns from LRU->MRU
    # We sample the first m_sample_k keys (the stalest subset)
    best_key = None
    best_score = None
    count = 0
    for k in od.keys():
        score = _benefit_density(cache_snapshot, k, seg_tag, now)
        if (best_score is None) or (score < best_score):
            best_score = score
            best_key = k
        count += 1
        if count >= m_sample_k:
            break
    return best_key


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using size-aware SLRU + TinyLFU with sampled selection.
    - Prefer evicting from probation (P). If P is empty, evict from S.
    - Within a segment, consider up to m_sample_k LRU-tail candidates and evict the one with
      smallest (frequency + recency_freshness) per byte.
    '''
    _init_if_needed(cache_snapshot)

    # Update capacity (in case it changes)
    cap = int(getattr(cache_snapshot, 'capacity', 0) or 0)
    if cap > 0:
        global m_capacity_bytes
        m_capacity_bytes = cap

    now = cache_snapshot.access_count

    # If both LRU lists are empty (rare, e.g., cold start), fallback to any key in snapshot
    if not m_lru_P and not m_lru_S:
        # Try to pick a low-benefit key by sampling a few from cache_snapshot.cache
        best_key = None
        best_score = None
        count = 0
        for k, v in cache_snapshot.cache.items():
            seg = m_key_segment.get(k, 'P')
            score = _benefit_density(cache_snapshot, k, seg, now)
            if best_score is None or score < best_score:
                best_score = score
                best_key = k
            count += 1
            if count >= m_sample_k:
                break
        if best_key is not None:
            return best_key
        # Absolute fallback
        return next(iter(cache_snapshot.cache))

    # Prefer evicting from P; if empty, from S
    victim = _pick_from_lru_sample(cache_snapshot, 'P', now)
    if victim is not None:
        return victim

    victim = _pick_from_lru_sample(cache_snapshot, 'S', now)
    if victim is not None:
        return victim

    # Fallback in unexpected case: pick any
    return next(iter(cache_snapshot.cache))


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time and move to MRU in its segment
      - If in probation (P), promote to protected (S)
      - Adapt S target fraction slightly: P hits -> increase S; S hits -> decrease S
      - Enforce S target by demoting oldest S items if necessary
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Train TinyLFU on hit
    _sketch_inc(k, 1)

    # Refresh last-access
    m_key_last_access[k] = now

    seg = m_key_segment.get(k)
    if seg == 'S':
        # Move to MRU in S
        if k in m_lru_S:
            m_lru_S.move_to_end(k, last=True)
        else:
            # If metadata missing, add to S
            m_lru_S[k] = None
        # Slightly reduce S fraction (workload leaning toward recency)
        global m_target_S_frac
        m_target_S_frac = _clamp((m_target_S_frac or 0.7) - m_adapt_down,
                                 m_target_S_frac_min, m_target_S_frac_max)
    else:
        # Treat as in P by default: promote to S
        # Ensure it's not duplicated in P
        if k in m_lru_P:
            m_lru_P.pop(k, None)
        else:
            # If not tracked, account its size to P first so bytes stay consistent on promotion
            global m_bytes_P
            m_bytes_P += int(getattr(obj, 'size', 0) or 0)
        _move_to_S(cache_snapshot, k)
        # Move to MRU in S
        m_lru_S.move_to_end(k, last=True)
        # Slightly increase S fraction (more P hits -> want more protection)
        m_target_S_frac = _clamp((m_target_S_frac or 0.7) + m_adapt_up,
                                 m_target_S_frac_min, m_target_S_frac_max)

    # Enforce S target
    _ensure_S_within_target(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Train TinyLFU on the accessed key (misses inform future admissions)
      - Add the new object to probation (P) MRU
      - Record last-access time
      - Nudge S fraction slightly down (admitting new items favors recency a bit)
      - Keep S within its target (demote if necessary)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Train TinyLFU on miss
    _sketch_inc(k, 1)

    # Admit into P at MRU
    if k in m_lru_P:
        m_lru_P.pop(k, None)
    if k in m_lru_S:
        # If somehow present in S, normalize to P for fresh insert
        m_lru_S.pop(k, None)

    m_key_segment[k] = 'P'
    m_lru_P[k] = None
    m_lru_P.move_to_end(k, last=True)
    m_key_last_access[k] = now

    # Account bytes
    global m_bytes_P
    m_bytes_P += int(getattr(obj, 'size', 0) or 0)

    # Slightly bias toward recency on continuous inserts
    global m_target_S_frac
    m_target_S_frac = _clamp((m_target_S_frac or 0.7) - 0.001,
                             m_target_S_frac_min, m_target_S_frac_max)

    # Enforce S target
    _ensure_S_within_target(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove all resident metadata for that key
      - Update segment byte counters and LRU structures
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    sz = int(getattr(evicted_obj, 'size', 0) or 0)

    seg = m_key_segment.pop(ek, None)

    # Remove from LRUs and adjust bytes
    global m_bytes_P, m_bytes_S
    if seg == 'S':
        if ek in m_lru_S:
            m_lru_S.pop(ek, None)
        m_bytes_S = max(0, m_bytes_S - sz)
    else:
        if ek in m_lru_P:
            m_lru_P.pop(ek, None)
        m_bytes_P = max(0, m_bytes_P - sz)

    m_key_last_access.pop(ek, None)

    # No ghost lists used (keep policy fast). Target S enforced elsewhere.
```
2025-11-27 22:14:08,260 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# SLRU + TinyLFU + Size-aware sampled eviction (fast and high hit-rate)
# - Two resident segments with byte quotas:
#     Probation (new/once-hit) and Protected (multi-hit)
# - O(1) updates on hit/insert via OrderedDict LRU queues
# - Eviction chooses from Probation first (SLRU), falls back to Protected
# - Within the chosen segment, select victim by sampling a few oldest keys
#   and picking the smallest TinyLFU-Recency-Size score (no full scan)
# - TinyLFU sketch with lazy epoch decay (4-bit counters) tracks popularity
# - Metadata survives evictions where useful (TinyLFU); resident-only info removed

import math
from collections import OrderedDict

# -----------------------------
# Global metadata
# -----------------------------

# Segmented LRU structures (byte-aware)
PROTECTED_RATIO = 0.80        # fraction of capacity reserved for Protected
SAMPLE_K_PROB = 6             # candidates sampled from Probation on eviction
SAMPLE_K_PROT = 4             # candidates sampled from Protected on eviction

prob_lru = OrderedDict()      # key -> None (LRU on left, MRU on right)
prot_lru = OrderedDict()      # key -> None
seg_bytes_prob = 0            # total bytes in Probation
seg_bytes_prot = 0            # total bytes in Protected
m_segment = dict()            # key -> 0 (probation) or 1 (protected)

# Per-key resident metadata
m_last_access = dict()        # key -> int time (for recency scoring)
m_resident_hits = dict()      # key -> int (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Scoring tunables (robust defaults)
REC_WIN_MIN = 1000
REC_WIN_MULT = 4
REC_WEIGHT = 0.25
MULTI_HIT_BONUS = 0.35

# -----------------------------
# Init / TinyLFU helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Segment helpers
# -----------------------------

def _prot_target_bytes(cache_snapshot):
    try:
        return max(0, int(cache_snapshot.capacity * PROTECTED_RATIO))
    except Exception:
        return 0

def _seg_insert_prob(key, size):
    global seg_bytes_prob
    if m_segment.get(key) == 0:
        # refresh MRU
        prob_lru.pop(key, None)
        prob_lru[key] = None
        return
    if m_segment.get(key) == 1:
        # remove from protected first (shouldn't happen on insert)
        prot_lru.pop(key, None)
        global seg_bytes_prot
        seg_bytes_prot -= size
    m_segment[key] = 0
    prob_lru[key] = None
    seg_bytes_prob += size

def _seg_move_to_prot(cache_snapshot, key, size):
    # Move key to Protected MRU
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 1:
        # already in protected: refresh MRU
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    # remove from probation if present
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    # insert into protected
    m_segment[key] = 1
    prot_lru[key] = None
    seg_bytes_prot += size

    # Demote from protected to probation if protected exceeds target
    target = _prot_target_bytes(cache_snapshot)
    while seg_bytes_prot > target and prot_lru:
        # Demote LRU of protected into probation MRU (not evict)
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        seg_bytes_prot -= dsize

        # place into probation MRU if still resident
        if robj is not None:
            prob_lru[dem_key] = None
            seg_bytes_prob += dsize
            m_segment[dem_key] = 0
        else:
            m_segment.pop(dem_key, None)  # no longer resident; clean

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _seg_remove(cache_snapshot, key, size):
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 1:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        # unknown; ensure not lingering
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _retention_score(cache_snapshot, key):
    # Lower score -> weaker retention -> better eviction candidate
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    return benefit - recency_gain

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    # Iterate the oldest k_sample keys in 'order' and return the min-score key
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    # Fallback in case of issues
    if chosen_key is None:
        try:
            return next(iter(order))
        except StopIteration:
            return None
    return chosen_key

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Evict using SLRU: choose from Probation first; if empty, from Protected.
    Within the chosen segment, sample a few LRU-ordered keys and evict the
    one with the smallest TinyLFU-Recency-Size score.
    """
    _init_if_needed(cache_snapshot)

    # Prefer evicting from Probation (new/weak items)
    if prob_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
        return victim

    # Fall back to Protected if Probation empty
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)
        return victim

    # As a last resort, evict any key
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access time and resident hit count
      - Promote from Probation to Protected (SLRU) on first hit
      - Refresh LRU position within its segment
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked (shouldn't happen on a hit); insert into Probation
        _seg_insert_prob(k, obj.size)
        return

    if seg == 0:
        # Promote on first hit (classic SLRU)
        _seg_move_to_prot(cache_snapshot, k, obj.size)
    else:
        # Touch protected
        _seg_touch_on_hit(cache_snapshot, k)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU counter
      - Initialize resident metadata
      - Place into Probation MRU
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # New resident goes to Probation MRU
    _seg_insert_prob(k, obj.size)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata and from segment structures
      - Keep TinyLFU counters to remember popularity of non-residents
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    _seg_remove(cache_snapshot, ek, evicted_obj.size)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Keep m_lfu_count[ek] for future admission/eviction decisions
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 40
- Hit Rate: 0.1429

Example 2:
- Trace ID: 45
- Hit Rate: 0.1714

Example 3:
- Trace ID: 3
- Hit Rate: 0.4083

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:14:08 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:14:08,260 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:16:22 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:16:22,010 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:16:22,012 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive SLRU + TinyLFU + ARC-style ghost feedback + size-aware promotion
# - Two resident segments with byte quotas:
#     Probation (new/once-hit) and Protected (multi-hit)
# - O(1) updates via OrderedDict LRU queues
# - Eviction samples both segments and evicts the weaker-scored candidate
#   (bias to Probation to protect hot Protected items, but adaptive)
# - TinyLFU sketch with lazy epoch decay (4-bit counters) tracks popularity
# - ARC-style ghost histories adapt Protected/Probation split online
# - Size-aware promotion thresholds avoid polluting Protected with large items
# - Optional direct promotion on insert for tiny, very popular keys
#
# Metadata survives evictions where useful (TinyLFU, ghosts); resident-only info is removed.

import math
from collections import OrderedDict

# -----------------------------
# Global metadata
# -----------------------------

# Segmented LRU structures (byte-aware)
PROTECTED_RATIO = 0.75        # dynamically adapted at runtime
SAMPLE_K_PROB = 8             # candidates sampled from Probation on eviction
SAMPLE_K_PROT = 5             # candidates sampled from Protected on eviction

prob_lru = OrderedDict()      # key -> None (LRU on left, MRU on right)
prot_lru = OrderedDict()      # key -> None
seg_bytes_prob = 0            # total bytes in Probation
seg_bytes_prot = 0            # total bytes in Protected
m_segment = dict()            # key -> 0 (probation) or 1 (protected)

# Per-key resident metadata
m_last_access = dict()        # key -> int time (for recency scoring)
m_resident_hits = dict()      # key -> int (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# ARC-style ghosts (remember recently evicted keys and from which segment)
ghost_prob = OrderedDict()    # key -> size
ghost_prot = OrderedDict()    # key -> size
ghost_bytes_prob = 0
ghost_bytes_prot = 0
GHOST_MAX_BYTES_FACTOR = 1.0  # each ghost list trimmed to <= capacity bytes

# Scoring tunables (robust defaults, frequency-forward)
REC_WIN_MIN = 500
REC_WIN_MULT = 4
REC_WEIGHT = 0.15
MULTI_HIT_BONUS = 0.55

# Adaptation tunables
ADAPT_BASE_STEP = 0.05
ADAPT_SIZE_MULT = 0.40
PROT_RATIO_MIN = 0.05
PROT_RATIO_MAX = 0.95

# Misc
_last_seen_capacity = 0

# -----------------------------
# Init / TinyLFU helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    global _last_seen_capacity
    _lfu_maybe_advance_epoch(cache_snapshot)
    _last_seen_capacity = cache_snapshot.capacity

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Ghost helpers (ARC-style)
# -----------------------------

def _ghost_trim():
    global ghost_bytes_prob, ghost_bytes_prot
    cap = max(1, _last_seen_capacity)
    limit = int(cap * GHOST_MAX_BYTES_FACTOR)

    # Trim B1 (probation ghost)
    while ghost_bytes_prob > limit and ghost_prob:
        k, sz = ghost_prob.popitem(last=False)
        ghost_bytes_prob -= sz

    # Trim B2 (protected ghost)
    while ghost_bytes_prot > limit and ghost_prot:
        k, sz = ghost_prot.popitem(last=False)
        ghost_bytes_prot -= sz

def _ghost_add(seg, key, size):
    # seg: 0 probation, 1 protected
    global ghost_bytes_prob, ghost_bytes_prot
    if seg == 0:
        if key in ghost_prob:
            ghost_bytes_prob -= ghost_prob.pop(key)
        ghost_prob[key] = size
        ghost_bytes_prob += size
    elif seg == 1:
        if key in ghost_prot:
            ghost_bytes_prot -= ghost_prot.pop(key)
        ghost_prot[key] = size
        ghost_bytes_prot += size
    _ghost_trim()

def _protected_ratio_adjust(delta):
    global PROTECTED_RATIO
    PROTECTED_RATIO = max(PROT_RATIO_MIN, min(PROT_RATIO_MAX, PROTECTED_RATIO + delta))

def _size_norm_fraction(size, cap):
    cap = max(1, cap)
    return min(1.0, max(0.0, float(size) / float(cap)))

# -----------------------------
# Segment helpers
# -----------------------------

def _prot_target_bytes(cache_snapshot):
    try:
        return max(0, int(cache_snapshot.capacity * PROTECTED_RATIO))
    except Exception:
        return 0

def _seg_insert_prob(key, size):
    global seg_bytes_prob
    if m_segment.get(key) == 0:
        # refresh MRU
        prob_lru.pop(key, None)
        prob_lru[key] = None
        return
    if m_segment.get(key) == 1:
        # remove from protected first (shouldn't happen on insert)
        prot_lru.pop(key, None)
        global seg_bytes_prot
        seg_bytes_prot -= size
    m_segment[key] = 0
    prob_lru[key] = None
    seg_bytes_prob += size

def _seg_move_to_prot(cache_snapshot, key, size):
    # Move key to Protected MRU
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 1:
        # already in protected: refresh MRU
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    # remove from probation if present
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    # insert into protected
    m_segment[key] = 1
    prot_lru[key] = None
    seg_bytes_prot += size

    # Demote from protected to probation if protected exceeds target
    target = _prot_target_bytes(cache_snapshot)
    while seg_bytes_prot > target and prot_lru:
        # Demote LRU of protected into probation MRU (not evict)
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        seg_bytes_prot -= dsize

        # place into probation MRU if still resident
        if robj is not None:
            prob_lru[dem_key] = None
            seg_bytes_prob += dsize
            m_segment[dem_key] = 0
        else:
            m_segment.pop(dem_key, None)  # no longer resident; clean

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _seg_remove(cache_snapshot, key, size):
    # Returns previous segment (0 probation, 1 protected, None unknown)
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 1:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        # unknown; ensure not lingering
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)
    return seg

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _retention_score(cache_snapshot, key):
    # Lower score -> weaker retention -> better eviction candidate
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    freq = _lfu_peek(cache_snapshot, key)
    rhits = m_resident_hits.get(key, 1)
    # Multi-hit bonus scales (log) with resident hits
    extra = MULTI_HIT_BONUS * math.log1p(max(0, rhits - 1))
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_penalty = REC_WEIGHT * a_norm  # older (a_norm close to 1) -> higher penalty

    return benefit - recency_penalty

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    # Iterate the oldest k_sample keys in 'order' and return the key with min-score
    if not order:
        return None, None
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    # Fallback in case of issues
    if chosen_key is None:
        try:
            k = next(iter(order))
            return k, _retention_score(cache_snapshot, k)
        except StopIteration:
            return None, None
    return chosen_key, chosen_score

def _promotion_hit_threshold(size, cap):
    # Size-aware promotion thresholds: larger objects need more confirmations
    frac = _size_norm_fraction(size, cap)
    if frac <= 0.01:
        return 2  # promote on first re-reference
    if frac <= 0.05:
        return 3
    if frac <= 0.10:
        return 4
    return 5

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Evict using size-aware, TinyLFU-informed SLRU:
      - Sample candidates from both Probation and Protected (LRU order)
      - Score by TinyLFU+recency+size
      - Choose the smallest score; add a bias to prefer evicting Probation
      - Bias is reduced/removed for very hot incoming objects (by TinyLFU)
        and increased for very large incoming objects (to better protect hot set)
    """
    _init_if_needed(cache_snapshot)

    # Compute bias based on incoming object popularity and size
    f_new = _lfu_peek(cache_snapshot, obj.key)
    cap = max(1, cache_snapshot.capacity)
    size_frac = _size_norm_fraction(obj.size, cap)

    # Default bias protects Protected (higher bias -> less likely to evict Protected)
    bias_prot = 0.15
    if f_new >= 7:
        bias_prot = -0.05  # very hot incoming -> willing to evict weak Protected items
    elif f_new >= 3:
        bias_prot = 0.0    # moderate popularity -> neutral

    # Large inserts: further protect Protected (likely scans)
    if size_frac >= 0.20:
        bias_prot = max(bias_prot, 0.35)

    # Gather candidates
    k_prob, s_prob = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
    k_prot, s_prot = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)

    # If only one segment has candidates, choose from it
    if k_prob is None and k_prot is None:
        # Last resort: any key
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    if k_prob is None:
        return k_prot
    if k_prot is None:
        return k_prob

    # Apply bias to Protected score and choose
    s_prot_biased = s_prot + bias_prot
    if s_prob <= s_prot_biased:
        return k_prob
    else:
        return k_prot

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access time and resident hit count
      - Size-aware promote from Probation to Protected after sufficient hits
      - Refresh LRU position within its segment
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked (shouldn't happen on a hit); place into Probation
        _seg_insert_prob(k, obj.size)
        return

    if seg == 0:
        # Size-aware promotion threshold
        need = _promotion_hit_threshold(obj.size, cache_snapshot.capacity)
        if m_resident_hits.get(k, 1) >= need:
            _seg_move_to_prot(cache_snapshot, k, obj.size)
        else:
            _seg_touch_on_hit(cache_snapshot, k)
    else:
        # Touch protected
        _seg_touch_on_hit(cache_snapshot, k)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU counter
      - Initialize resident metadata
      - Place into Probation MRU
      - ARC-style adaptation:
          * If key found in Probation-ghost, shift capacity towards Probation
          * If key found in Protected-ghost, shift capacity towards Protected
      - Optional fast-track: direct promote tiny, very popular keys
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    f = _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # New resident goes to Probation MRU
    _seg_insert_prob(k, obj.size)

    # ARC-style adaptation via ghosts
    cap = max(1, cache_snapshot.capacity)
    if k in ghost_prob:
        sz = ghost_prob.pop(k)
        global ghost_bytes_prob
        ghost_bytes_prob -= sz
        # Increase recent (Probation) share -> decrease Protected ratio
        step = ADAPT_BASE_STEP + ADAPT_SIZE_MULT * (float(sz) / float(cap))
        _protected_ratio_adjust(-step)
    elif k in ghost_prot:
        sz = ghost_prot.pop(k)
        global ghost_bytes_prot
        ghost_bytes_prot -= sz
        # Increase frequent (Protected) share -> increase Protected ratio
        step = ADAPT_BASE_STEP + ADAPT_SIZE_MULT * (float(sz) / float(cap))
        _protected_ratio_adjust(+step)

    # Optional fast-track: if key is tiny and very popular, move to Protected now
    if f >= 7 and obj.size <= int(0.02 * cap):
        _seg_move_to_prot(cache_snapshot, k, obj.size)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata and from segment structures
      - Remember the victim in appropriate ghost list to adapt segment sizing
      - Keep TinyLFU counters to remember popularity of non-residents
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    seg = _seg_remove(cache_snapshot, ek, evicted_obj.size)

    # Ghost remember from which segment it was evicted
    if seg in (0, 1):
        _ghost_add(seg, ek, evicted_obj.size)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Keep m_lfu_count[ek] for future admission/eviction decisions
```
2025-11-27 22:16:40,435 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 13
- Hit Rate: 0.0

Example 2:
- Trace ID: 43
- Hit Rate: 0.3667

Example 3:
- Trace ID: 44
- Hit Rate: 0.1881

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:16:40 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:16:40,437 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:18:10 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:18:10,209 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:18:10,211 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# GreedyDual-TinyLFU (GDTLFU)
# - Eviction uses GreedyDual's age-based priority: priority = base_value + L
#   where L is a global "aging" watermark set to the priority of the last evicted item.
# - base_value is size-aware and frequency-aware using a decayed TinyLFU sketch.
# - On hit/insert we refresh the resident's priority to base_value + L
#   which naturally promotes frequently/recently used items.
# - TinyLFU counters persist across evictions (for better re-admission decisions),
#   while resident-only metadata is removed on eviction.
#
# Design goals:
# - Strong size-awareness (large items need more evidence to stay)
# - Frequency-awareness with lazy decay (adapts to phase changes)
# - Robust aging without global sweeps (GreedyDual's L)
# - Minimal per-object metadata and O(n) scan for eviction victim

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (for tiebreaking and optional insights)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_priority = dict()        # key -> float GD priority = base_value + m_L (resident only)

# Global GreedyDual watermark (monotonically non-decreasing)
m_L = 0.0

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs

# Tunables (conservative, robust across traces)
SIZE_EXP = 0.82            # strength of size division (0: off, 1: full 1/size)
FREQ_WEIGHT = 1.25         # importance of frequency in base_value
MULTI_HIT_BONUS = 0.35     # bonus when item has >=2 resident hits
BIG_OBJ_FRAC = 0.20        # items > 20% of capacity are penalized unless they show use
BIG_HIT_THRESH = 2         # minimum hits to lift big-object penalty
BIG_PENALTY = 0.5          # multiplicative penalty for big, low-evidence objects
EPS = 1e-12                # numerical stability

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Base value and priority
# -----------------------------

def _size_fraction(size, capacity):
    # Fraction of cache capacity the object occupies
    return float(size) / float(max(1, capacity))

def _base_value(cache_snapshot, key, size, resident_hits_hint):
    # Frequency-aware, size-aware value used by GreedyDual.
    # Larger base_value = higher priority to keep.
    cap = cache_snapshot.capacity
    s_frac = _size_fraction(size, cap)

    # Frequency from TinyLFU (already incremented by caller when appropriate)
    freq = _lfu_peek(cache_snapshot, key)

    # Smooth frequency to avoid overreacting; add small bonus for multi-hit residents
    fscore = math.log2(1.0 + float(freq))
    if resident_hits_hint >= 2:
        fscore += MULTI_HIT_BONUS

    # Size-aware denominator with softened exponent
    denom = (s_frac ** SIZE_EXP) + EPS

    base = (1.0 + FREQ_WEIGHT * fscore) / denom

    # Penalize very large objects unless they show sufficient evidence
    if s_frac >= BIG_OBJ_FRAC and resident_hits_hint < BIG_HIT_THRESH and freq < BIG_HIT_THRESH:
        base *= BIG_PENALTY

    return base

def _set_priority(cache_snapshot, key, size, resident_hits_hint):
    # Recompute base and set GD priority = base + L
    global m_priority
    base = _base_value(cache_snapshot, key, size, resident_hits_hint)
    m_priority[key] = base + m_L
    return m_priority[key]

def _ensure_priority(cache_snapshot, key, obj):
    # Ensure a reasonable priority exists for a resident key.
    # If missing (e.g., after restart or migration), rebuild it.
    if key not in m_priority:
        hits = m_resident_hits.get(key, 1)
        _set_priority(cache_snapshot, key, obj.size if obj is not None else 1, hits)
    return m_priority[key]

# -----------------------------
# Policy entry points
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def evict(cache_snapshot, obj):
    '''
    GreedyDual victim selection:
      - Evict the resident with the smallest GD priority (priority = base + L).
      - Ties broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_pri = None
    min_time = None

    for k, robj in cache_snapshot.cache.items():
        pri = m_priority.get(k)
        if pri is None:
            # Lazily reconstruct a priority if missing
            pri = _ensure_priority(cache_snapshot, k, robj)
        last = m_last_access.get(k, -1)
        if (min_pri is None) or (pri < min_pri) or (pri == min_pri and last < min_time):
            min_pri = pri
            min_time = last
            min_key = k

    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key

def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Increment resident hit count
      - Refresh last-access time
      - Refresh GD priority = base_value + L
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    _set_priority(cache_snapshot, k, obj.size, m_resident_hits[k])

def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key (counts every request)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Initialize GD priority = base_value + L
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    _set_priority(cache_snapshot, k, obj.size, m_resident_hits[k])

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Advance GreedyDual watermark L to the victim's priority (monotonic)
      - Remove resident-only metadata (TinyLFU counters are retained)
    '''
    _init_if_needed(cache_snapshot)

    global m_L

    ek = evicted_obj.key
    ev_pri = m_priority.get(ek, m_L)
    # GreedyDual aging step: L becomes the priority of the evicted item
    if ev_pri > m_L:
        m_L = ev_pri

    # Remove resident-only metadata
    m_priority.pop(ek, None)
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Keep m_lfu_count[ek] to remember non-resident frequency
```
2025-11-27 22:18:20,986 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Policy: HALO-TFSv2 — Heap-Accelerated LFU with Recency, Freshness, and Gap Prediction
# Key improvements over previous version:
# - Stronger recency sensitivity with adaptive windowing
# - Do not credit LFU on cold insert (reduces one-timer pollution)
# - Per-key EWMA of inter-arrival gaps to predict time-to-next access
# - Fresh-insert "grace" multiplier to avoid immediate churn
# - Multi-hit protection is stronger and starts after the second hit
# - Bounded-rescan victim search for better choices without full scans

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_birth_ts = dict()         # key -> int access_count at insertion
m_resident_hits = dict()    # key -> int resident hit count (starts at 0 on insert)
m_gap_ewma = dict()         # key -> float ≈ EWMA of inter-arrival gap while resident

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 2048   # faster adaptation to workload shifts
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192
HEAP_GROWTH_FACTOR = 4

# Tunables for scoring
SIZE_ALPHA = 0.80               # size normalization exponent; favors small objects
REC_WIN_MIN = 64                # minimum recency window in accesses
REC_WIN_MULT = 6                # recency window ~ REC_WIN_MULT * resident_items
FREQ_WEIGHT = 1.00              # weight of frequency (TinyLFU)
REC_WEIGHT = 1.10               # weight of observed recency
PRED_WEIGHT = 0.90              # weight of predicted return risk (via gap EWMA)
MH_MULT = 1.50                  # multiplicative boost after >=2 resident hits
FRESH_GRACE = 128               # accesses; grace period after insert
FRESH_MULT = 1.30               # multiplicative boost during grace
GAP_BETA = 0.30                 # EWMA smoothing factor for inter-arrival gap

# Victim selection
RESCAN_LIMIT = 12               # bounded extra pops from heap to improve victim choice


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # decay is applied lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)


def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _predicted_risk(now, last, gap_ewma, window):
    # Predict time-to-next using EWMA gap. Convert to risk in (0,1].
    if last is None or last < 0 or gap_ewma is None or gap_ewma <= 0.0:
        return 0.0
    age = max(0, now - last)
    ttn = gap_ewma - age  # time until next (can be <= 0 if due/overdue)
    # Map to (0,1], ≈1 when due/overdue, smaller when far in future
    return 1.0 / (1.0 + (max(0.0, ttn) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency and predicted risk
    window = _recency_window(cache_snapshot)
    r_term = _recency_term(now, m_last_access.get(key), window)
    p_term = _predicted_risk(now, m_last_access.get(key), m_gap_ewma.get(key), window)

    # Freshness and multi-hit multipliers
    birth = m_birth_ts.get(key)
    fresh = (1.0 if birth is None else (FRESH_MULT if (now - birth) <= FRESH_GRACE else 1.0))
    mhits = m_resident_hits.get(key, 0)
    mh_mult = (MH_MULT if mhits >= 2 else 1.0)

    # Final score: combine, then size-normalize, then apply multiplicative boosts
    base = (FREQ_WEIGHT * f_term) + (REC_WEIGHT * r_term) + (PRED_WEIGHT * p_term)
    score = (base / size_norm) * fresh * mh_mult
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    - Seed heap on first use
    - Pop and validate entries lazily (versioning)
    - Recompute scores to reflect latest epochs and metadata
    - Bounded rescan: consider a small set of candidates and pick the weakest
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            # Initialize missing resident metadata best-effort
            m_last_access.setdefault(k, cache_snapshot.access_count)
            m_birth_ts.setdefault(k, cache_snapshot.access_count)
            m_resident_hits.setdefault(k, 0)
            m_gap_ewma.setdefault(k, float(_recency_window(cache_snapshot)))
            _heap_push(cache_snapshot, k)

    # Bounded rescan to find the weakest valid candidate
    best_key = None
    best_tuple = None  # (adjusted_score, score_tuple)
    considered = []

    attempts = 0
    while attempts < RESCAN_LIMIT and m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            attempts += 1
            continue
        # Skip if stale heap entry
        if m_ver.get(k, 0) != v:
            attempts += 1
            continue
        # Recompute current score (reflect decay/window/metadata changes)
        cur_sc = _score_key(cache_snapshot, k)
        # If score drifted upward, reinsert with new score
        if cur_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            attempts += 1
            continue

        # Track the weakest (lowest score) candidate
        adj_sc = cur_sc  # adjustment slots available if needed later
        if (best_tuple is None) or (adj_sc < best_tuple[0]):
            best_key = k
            best_tuple = (adj_sc, (sc, last, k, v))
        considered.append((sc, last, k, v))
        attempts += 1

    # Push back all considered entries except the chosen victim
    for tup in considered:
        if best_tuple is not None and tup[2] == best_key:
            continue
        heapq.heappush(m_heap, tup)

    # Fallbacks
    if best_key is not None:
        return best_key

    # If heap is exhausted or empty, choose the oldest resident
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Update EWMA of inter-arrival gap
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Update frequency only on hits (not on cold insert)
    _lfu_inc(cache_snapshot, k)

    # Update inter-arrival EWMA
    prev = m_last_access.get(k)
    if prev is not None:
        gap = max(1.0, float(now - prev))
        old = m_gap_ewma.get(k)
        if old is None or old <= 0.0:
            m_gap_ewma[k] = gap
        else:
            m_gap_ewma[k] = (1.0 - GAP_BETA) * old + GAP_BETA * gap
    else:
        # Initialize conservatively
        m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    # Hits: increment resident hits
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # Refresh timestamps
    m_last_access[k] = now

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch
      - Do NOT increment LFU on cold insert (reduces one-timer pollution)
      - Initialize resident metadata: last_access, birth_ts, resident_hits = 0
      - Initialize EWMA gap conservatively to recency window
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # No _lfu_inc here: cold items must earn credit by hitting

    m_last_access[k] = now
    m_birth_ts[k] = now
    m_resident_hits[k] = 0
    m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember popularity)
      - Invalidate its heap version (stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_birth_ts.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_gap_ewma.pop(ek, None)
    m_ver.pop(ek, None)

    _touch_and_maybe_rebuild(cache_snapshot)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 10
- Hit Rate: 0.075

Example 2:
- Trace ID: 36
- Hit Rate: 0.1261

Example 3:
- Trace ID: 30
- Hit Rate: 0.0478

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:18:20 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:18:20,987 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:21:13 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:21:13,525 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:21:13,527 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Policy: SLRU-TinyLFU (size-aware) — Segmented LRU with TinyLFU and decayed admission guard
# Overview:
# - Two resident segments by recency and hits:
#     - Probation: all cold (0-hit) items, true LRU
#     - Protected: items that hit at least once, true LRU
# - Eviction prefers probation's LRU, with a bounded scan to avoid evicting stronger items.
# - TinyLFU with lazy epoch decay provides a lightweight popularity estimate.
# - Size-aware retention scoring to avoid hoarding large low-value objects.
# - On hit, promote from probation to protected and keep protected within a size target by demoting its LRU.
# - Minimal metadata, no heap; robust on diverse traces.

import math
from collections import OrderedDict

# ------------------------------------------------------
# Global metadata (module scope)
# ------------------------------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_birth_ts = dict()         # key -> int access_count at insertion
m_resident_hits = dict()    # key -> int resident hit count (starts at 0 on insert)
m_size = dict()             # key -> last known size (int)

# Segmented LRU: probation (cold) and protected (warm/hot)
prob_od = OrderedDict()     # key -> None (oldest at beginning)
prot_od = OrderedDict()     # key -> None (oldest at beginning)
prob_bytes = 0
prot_bytes = 0

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096   # accesses per global decay epoch (lazy)
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Tunables
PROTECTED_FRAC = 0.80       # target share of capacity for protected segment (by bytes)
EVICT_SCAN_PROB = 12        # number of LRU-side candidates to examine in probation
EVICT_SCAN_PROT = 6         # number of LRU-side candidates to examine in protected
ADMIT_MARGIN = 1            # prefer not to evict items with freq > incoming + margin
SIZE_ALPHA = 0.80           # size normalization exponent (favor small objects)
FREQ_WEIGHT = 1.10          # weight of TinyLFU popularity
REC_WEIGHT = 0.45           # weight of recency (kept modest; LRU order already strong)
PROT_RETENTION_MULT = 1.35  # extra retention for protected items
REC_WIN_MIN = 64            # minimum recency window (in accesses)
REC_WIN_MULT = 4            # recency window ~ REC_WIN_MULT * resident_items

# ------------------------------------------------------
# TinyLFU helpers (lazy decay)
# ------------------------------------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # decay is applied lazily per key

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# ------------------------------------------------------
# Segmented LRU helpers
# ------------------------------------------------------

def _protected_target_bytes(cache_snapshot):
    cap = max(1, cache_snapshot.capacity)
    return int(PROTECTED_FRAC * cap)

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)

def _age_term(cache_snapshot, key):
    now = cache_snapshot.access_count
    last = m_last_access.get(key)
    if last is None:
        return 0.0
    age = max(0, now - last)
    win = _recency_window(cache_snapshot)
    return 1.0 / (1.0 + (float(age) / float(win)))

def _retention_score(cache_snapshot, key, in_protected):
    # Higher score => more protected; eviction chooses lowest score
    size = max(1.0, float(m_size.get(key, 1)))
    size_norm = size ** SIZE_ALPHA
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))
    r_term = _age_term(cache_snapshot, key)
    base = (FREQ_WEIGHT * f_term) + (REC_WEIGHT * r_term)
    if in_protected:
        base *= PROT_RETENTION_MULT
    return base / size_norm

def _prob_add_mru(k, size):
    global prob_bytes
    if k in prob_od:
        prob_od.move_to_end(k, last=True)
    else:
        prob_od[k] = None
        prob_bytes += size

def _prob_remove(k):
    global prob_bytes
    if k in prob_od:
        prob_bytes -= m_size.get(k, 0)
        prob_od.pop(k, None)

def _prot_add_mru(k, size):
    global prot_bytes
    if k in prot_od:
        prot_od.move_to_end(k, last=True)
    else:
        prot_od[k] = None
        prot_bytes += size

def _prot_remove(k):
    global prot_bytes
    if k in prot_od:
        prot_bytes -= m_size.get(k, 0)
        prot_od.pop(k, None)

def _promote_to_protected(cache_snapshot, k):
    # Move from probation to protected MRU
    if k in prob_od:
        _prob_remove(k)
    _prot_add_mru(k, m_size.get(k, 0))
    # If protected exceeds its byte target, demote its LRU back to probation's LRU side
    target = _protected_target_bytes(cache_snapshot)
    while prot_bytes > target and prot_od:
        # Demote LRU of protected
        demote_k, _ = prot_od.popitem(last=False)
        prot_bytes -= m_size.get(demote_k, 0)
        # Re-add to probation at LRU side (demotions are "old")
        _prob_add_lru(demote_k, m_size.get(demote_k, 0))

def _prob_add_lru(k, size):
    # Insert at LRU side (left)
    global prob_bytes
    if k in prob_od:
        # Move to LRU side
        prob_od.move_to_end(k, last=False)
    else:
        prob_od[k] = None
        prob_od.move_to_end(k, last=False)
        prob_bytes += size

def _sync_membership(cache_snapshot):
    # Ensure all resident keys exist in one of the segments (bootstrap/laziness)
    # Missing entries are treated as probation with default last_access = now
    if (len(prob_od) + len(prot_od)) == len(cache_snapshot.cache):
        return
    now = cache_snapshot.access_count
    for k, obj in cache_snapshot.cache.items():
        if (k not in prob_od) and (k not in prot_od):
            m_size[k] = obj.size
            m_last_access.setdefault(k, now)
            m_birth_ts.setdefault(k, now)
            m_resident_hits.setdefault(k, 0)
            _prob_add_mru(k, obj.size)
    # Optional: prune stale entries from lists if they are no longer resident
    for k in list(prob_od.keys()):
        if k not in cache_snapshot.cache:
            _prob_remove(k)
    for k in list(prot_od.keys()):
        if k not in cache_snapshot.cache:
            _prot_remove(k)

def _collect_candidates(od, limit):
    # Return up to 'limit' oldest keys from the LRU side of an OrderedDict
    out = []
    if not od:
        return out
    i = 0
    for k in od.keys():  # iterates from LRU(oldest) to MRU(newest)
        out.append(k)
        i += 1
        if i >= limit:
            break
    return out

# ------------------------------------------------------
# Policy entry points
# ------------------------------------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim using Segmented LRU with TinyLFU guard:
      - Prefer LRU from probation (cold) with a bounded scan to skip strong items.
      - Fall back to protected's LRU when probation is empty or all scanned items are strong.
      - Size-aware retention scoring; TinyLFU peeks guide choices relative to the incoming item.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)
    _sync_membership(cache_snapshot)

    incoming_key = getattr(obj, 'key', None)
    incoming_freq = _lfu_peek(cache_snapshot, incoming_key) if incoming_key is not None else 0

    # Gather candidates: more from probation, fewer from protected
    prob_cands = _collect_candidates(prob_od, EVICT_SCAN_PROB)
    prot_cands = _collect_candidates(prot_od, EVICT_SCAN_PROT)

    best_key = None
    best_score = None

    def consider(keys, in_protected, prefer_weaker_than_incoming):
        nonlocal best_key, best_score
        for k in keys:
            # Skip if somehow non-resident (defensive)
            if k not in cache_snapshot.cache:
                continue
            kfreq = _lfu_peek(cache_snapshot, k)
            if prefer_weaker_than_incoming and (kfreq > incoming_freq + ADMIT_MARGIN):
                # Guard: try not to evict items with clearly higher popularity than incoming
                continue
            sc = _retention_score(cache_snapshot, k, in_protected)
            if (best_score is None) or (sc < best_score):
                best_score = sc
                best_key = k

    # First pass: try to evict only items that are no stronger than the incoming
    prefer_weaker = True
    consider(prob_cands, in_protected=False, prefer_weaker_than_incoming=prefer_weaker)
    if best_key is None:
        consider(prot_cands, in_protected=True, prefer_weaker_than_incoming=prefer_weaker)

    # Second pass: if none fit the guard, pick the globally weakest among scanned candidates
    if best_key is None:
        prefer_weaker = False
        consider(prob_cands, in_protected=False, prefer_weaker_than_incoming=prefer_weaker)
        if best_key is None:
            consider(prot_cands, in_protected=True, prefer_weaker_than_incoming=prefer_weaker)

    # Fallback: if still none (shouldn't happen), evict absolute LRU across both segments
    if best_key is None:
        if prob_od:
            best_key = next(iter(prob_od.keys()))
        elif prot_od:
            best_key = next(iter(prot_od.keys()))
        else:
            # As last resort, pick oldest resident by last_access
            min_k = None
            min_last = None
            for k in cache_snapshot.cache.keys():
                last = m_last_access.get(k, -1)
                if min_last is None or last < min_last:
                    min_last = last
                    min_k = k
            best_key = min_k
    return best_key

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch and increment popularity.
      - Update last-access time and size.
      - Promote from probation to protected, or refresh position in protected.
      - Keep protected within its target by demoting its LRU to probation's LRU.
      - Track resident hit count.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count
    m_size[k] = obj.size

    # Every access (hit) contributes to TinyLFU popularity
    _lfu_inc(cache_snapshot, k)

    # Update timestamps and hits
    m_last_access[k] = now
    m_birth_ts.setdefault(k, now)
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # Ensure membership for residents
    _sync_membership(cache_snapshot)

    if k in prob_od:
        # Promote to protected on first resident hit
        _promote_to_protected(cache_snapshot, k)
    else:
        # Refresh recency in protected (or add defensively if metadata desynced)
        if k in prot_od:
            prot_od.move_to_end(k, last=True)
        else:
            # Defensive: if missing from both segments but resident, treat as protected
            _prot_add_mru(k, obj.size)
            # Ensure protected does not exceed target
            _promote_to_protected(cache_snapshot, k)  # will rebalance if needed

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch and increment popularity for the requested key (miss counted).
      - Initialize resident metadata.
      - Place in probation MRU.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count
    m_size[k] = obj.size

    # Count the access in TinyLFU (misses should be counted for future admission decisions)
    _lfu_inc(cache_snapshot, k)

    # Initialize metadata
    m_last_access[k] = now
    m_birth_ts[k] = now
    m_resident_hits[k] = 0

    # Add to probation MRU
    _prob_add_mru(k, obj.size)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove it from the resident segments and resident-only metadata.
      - Keep TinyLFU counters to remember global popularity under lazy decay.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key

    # Remove from segments
    if ek in prob_od:
        _prob_remove(ek)
    if ek in prot_od:
        _prot_remove(ek)

    # Remove resident-only metadata
    m_last_access.pop(ek, None)
    m_birth_ts.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_size.pop(ek, None)
```
2025-11-27 22:21:17,587 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Sampled TinyLFU-Recency-Size (sTFRS)
# - Same core signal as TFRS (TinyLFU + recency + size), but with O(1) metadata updates
#   and O(k) eviction via small random sampling (k << resident_items).
#   This removes full-cache scans and prevents timeouts on large traces.
# - TinyLFU with lazy-epoch 4-bit counters (counts both resident and non-resident accesses)
# - Recency bonus to protect very recent items
# - Size-aware benefit: small items get proportionally higher retention per byte
# - Multi-hit resident items get a small boost
#
# Key changes vs previous version:
#   1) Eviction scans only a small random sample of residents (default 32), not all keys.
#   2) Maintain an O(1) resident-key index (array + position map) for fast sampling/removal.
#   3) Keep the effective scoring model but improve performance to avoid timeouts.

import math
import random

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU-ish timestamp)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# Fast resident set for sampling (array + index map for O(1) add/remove)
m_resident_keys = []       # list of keys currently resident
m_resident_pos = dict()    # key -> index in m_resident_keys

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Sampling parameters for eviction
SAMPLE_SIZE_BASE = 32      # default random sample size
SAMPLE_SIZE_MIN = 8        # lower bound when cache small
SAMPLE_SIZE_MAX = 64       # upper bound; keep k small for speed

# Precompute log2(1+freq) for 4-bit frequency values (0..15)
_FREQ_GAIN = [math.log2(1 + i) for i in range(16)]


# -----------------------------
# Initialization helper
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)
    # Nothing else capacity-dependent to initialize


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Resident set helpers
# -----------------------------

def _resident_add(key):
    if key in m_resident_pos:
        return
    idx = len(m_resident_keys)
    m_resident_keys.append(key)
    m_resident_pos[key] = idx


def _resident_remove(key):
    idx = m_resident_pos.pop(key, None)
    if idx is None:
        return
    last_idx = len(m_resident_keys) - 1
    if idx != last_idx:
        last_key = m_resident_keys[last_idx]
        m_resident_keys[idx] = last_key
        m_resident_pos[last_key] = idx
    m_resident_keys.pop()


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit stable across caches
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key):
    # score = benefit - recency_gain
    #   benefit      = log2(1 + freq) (+bonus if multi-hit) divided by normalized size
    #   recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        # Should not occur; keep it very evictable
        return float('-inf')
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (_FREQ_GAIN[freq] + extra) / size_norm

    # Recency protection
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    return benefit - recency_gain


def _sample_keys(k):
    # Fast random sample without building an intermediate list
    # Uses our resident array for O(k) sampling.
    n = len(m_resident_keys)
    if n == 0:
        return []
    if k >= n:
        # Small cache: sample all
        return list(m_resident_keys)
    # Reservoir-like: random.sample over a range with indirection to keys
    # We avoid constructing a full list of keys.
    chosen = set()
    out = []
    while len(out) < k:
        idx = random.randrange(0, n)
        if idx not in chosen:
            chosen.add(idx)
            out.append(m_resident_keys[idx])
    return out


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score,
    but choose among a small random sample of residents to avoid full scans.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    n = len(m_resident_keys)
    if n == 0:
        # Fallback: rely on cache_snapshot.cache when our index is desynced (should not happen)
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Adaptive sample size: increase slightly with cache size but keep bounded
    if n <= SAMPLE_SIZE_MIN:
        sample_size = n
    else:
        # Grow very slowly with n to reduce variance a bit
        sample_size = min(SAMPLE_SIZE_MAX, max(SAMPLE_SIZE_MIN, SAMPLE_SIZE_BASE))

    candidates = _sample_keys(sample_size)

    min_key = None
    min_score = None
    min_time = None

    for k in candidates:
        score = _retention_score(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Safety fallback if sampling failed to pick one
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1
    # No change to resident set (already present)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key (so non-resident history matters)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Add key to resident sampling set
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    _resident_add(k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Remove key from resident sampling set
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Keep TinyLFU history to improve future admission/retention
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    _resident_remove(ek)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 7
- Hit Rate: 0.4849

Example 2:
- Trace ID: 22
- Hit Rate: 0.0606

Example 3:
- Trace ID: 47
- Hit Rate: 0.1732

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:21:17 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:21:17,588 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:24:18 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:24:18,883 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:24:18,884 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Improved policy: Sampled W-TinyLFU + Segmented Recency + Size-aware (sWTinyLFU-SLRU)
# - Two resident segments (probation and protected) with O(1) updates and O(k) sampling
# - TinyLFU with lazy-epoch saturating 8-bit counters, shared across resident/non-resident
# - Recency protects very recent items (correct sign), stronger in probation than protected
# - Size-aware retention: benefit per "size^alpha" to favor small objects, penalize large ones
# - Eviction prefers probation; if empty, demote oldest protected (via sampling) then evict
# - Adaptive sampling: larger incoming objects use larger samples to avoid costly mistakes

import math
import random

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()        # key -> int access_count (timestamp)
m_resident_hits = dict()      # key -> int resident hits since admitted
m_partition = dict()          # key -> 0 for probation, 1 for protected

# Resident sets for sampling (array + index map for O(1) add/remove)
_prob_keys = []
_prob_pos = dict()

_prot_keys = []
_prot_pos = dict()

# Remember last known size (helps when cache_snapshot.cache lookup is unavailable)
m_obj_size = dict()           # key -> int size

# TinyLFU sketch (lazy-decayed 8-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192     # accesses between epochs (power of two recommended)

# -----------------------------
# Tunables
# -----------------------------

# Recency windows and weights
REC_WIN_MIN = 256
REC_WIN_MULT_PROB = 2         # probation recency window ~ 2 * resident_items
REC_WIN_MULT_PROT = 8         # protected recency window ~ 8 * resident_items
REC_WEIGHT_PROB = 0.50        # stronger recent protection in probation
REC_WEIGHT_PROT = 0.20        # lighter in protected

# Size sensitivity (benefit / size_norm^alpha)
SIZE_ALPHA = 1.15

# Multi-hit bonus
MULTI_HIT_BONUS_PROB = 0.25   # probation items with >=1 hit
MULTI_HIT_BONUS_PROT = 0.45   # protected items (inherently multi-hit)

# Segments target split (by item count)
PROTECTED_TARGET_RATIO = 0.80

# Sampling parameters
SAMPLE_SIZE_BASE = 32
SAMPLE_SIZE_MIN = 8
SAMPLE_SIZE_MAX = 96
PROT_TRIM_SAMPLE = 16         # sample size to pick oldest protected to demote

# Precompute log2(1+freq) for 8-bit frequency values (0..255)
_FREQ_GAIN = [math.log2(1 + i) for i in range(256)]


# -----------------------------
# Initialization helper
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)
    # nothing else to init per capacity


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift if shift < 8 else 7
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c, e = 0, cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift if shift < 8 else 7
    c = min(255, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Resident set helpers
# -----------------------------

def _prob_add(key):
    if key in _prob_pos or key in _prot_pos:
        return
    idx = len(_prob_keys)
    _prob_keys.append(key)
    _prob_pos[key] = idx
    m_partition[key] = 0


def _prot_add(key):
    if key in _prot_pos or key in _prob_pos:
        return
    idx = len(_prot_keys)
    _prot_keys.append(key)
    _prot_pos[key] = idx
    m_partition[key] = 1


def _prob_remove(key):
    idx = _prob_pos.pop(key, None)
    if idx is None:
        return
    last_idx = len(_prob_keys) - 1
    if idx != last_idx:
        last_key = _prob_keys[last_idx]
        _prob_keys[idx] = last_key
        _prob_pos[last_key] = idx
    _prob_keys.pop()
    if m_partition.get(key) == 0:
        m_partition.pop(key, None)


def _prot_remove(key):
    idx = _prot_pos.pop(key, None)
    if idx is None:
        return
    last_idx = len(_prot_keys) - 1
    if idx != last_idx:
        last_key = _prot_keys[last_idx]
        _prot_keys[idx] = last_key
        _prot_pos[last_key] = idx
    _prot_keys.pop()
    if m_partition.get(key) == 1:
        m_partition.pop(key, None)


def _resident_remove(key):
    if key in _prob_pos:
        _prob_remove(key)
    if key in _prot_pos:
        _prot_remove(key)
    m_partition.pop(key, None)


def _resident_move_prob_to_prot(key):
    if key in _prob_pos:
        _prob_remove(key)
    _prot_add(key)
    m_partition[key] = 1


def _resident_move_prot_to_prob(key):
    if key in _prot_pos:
        _prot_remove(key)
    _prob_add(key)
    m_partition[key] = 0


def _sample_from(keys_arr, k):
    n = len(keys_arr)
    if n == 0:
        return []
    if k >= n:
        return list(keys_arr)
    chosen = set()
    out = []
    # random.sample would need to materialize full list; we already have it
    while len(out) < k:
        idx = random.randrange(0, n)
        if idx not in chosen:
            chosen.add(idx)
            out.append(keys_arr[idx])
    return out


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # percentage of capacity; keep scale stable across caches
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_bonus(now, last, window, weight):
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    a_norm = min(1.0, float(age) / float(window))
    # bonus highest when very recent (a_norm near 0)
    return weight * (1.0 - a_norm)


def _keep_score(cache_snapshot, key, in_protected):
    # Larger score => better to keep; eviction picks the smallest
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    size = robj.size if robj is not None else m_obj_size.get(key, 1)
    size_norm = _normalized_size(size, cap)
    denom = pow(size_norm, SIZE_ALPHA)

    # frequency + bonuses
    freq = _lfu_peek(cache_snapshot, key)
    base = _FREQ_GAIN[freq]
    if in_protected:
        bonus = MULTI_HIT_BONUS_PROT
    else:
        bonus = MULTI_HIT_BONUS_PROB if m_resident_hits.get(key, 0) >= 1 else 0.0
    benefit = (base + bonus) / max(1e-9, denom)

    # recency protection (correct sign: add bonus when recent)
    n_items = max(1, len(cache_snapshot.cache))
    if in_protected:
        window = max(REC_WIN_MIN, REC_WIN_MULT_PROT * n_items)
        weight = REC_WEIGHT_PROT
    else:
        window = max(REC_WIN_MIN, REC_WIN_MULT_PROB * n_items)
        weight = REC_WEIGHT_PROB
    last = m_last_access.get(key)
    r_bonus = _recency_bonus(now, last, window, weight)

    return benefit + r_bonus


def _protected_target_size():
    total = len(_prob_keys) + len(_prot_keys)
    if total <= 0:
        return 0
    return max(1, int(PROTECTED_TARGET_RATIO * total))


def _demote_oldest_protected_if_needed():
    # Try to keep protected size near target by demoting oldest via sampling
    target = _protected_target_size()
    cur = len(_prot_keys)
    if cur <= target or cur == 0:
        return
    # pick the oldest among a small sample
    k = min(PROT_TRIM_SAMPLE, cur)
    candidates = _sample_from(_prot_keys, k)
    oldest_key = None
    oldest_time = None
    for key in candidates:
        t = m_last_access.get(key, -1)
        if oldest_time is None or t < oldest_time:
            oldest_time = t
            oldest_key = key
    if oldest_key is not None:
        _resident_move_prot_to_prob(oldest_key)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict using Segmented-LRU preference:
      - Prefer evicting from probation using TinyLFU+Recency+Size keep-score (min is victim)
      - If probation empty, demote an old protected item to probation (via sampling), then evict
      - Adaptive sampling: increase sample size for large incoming objects
    '''
    _init_if_needed(cache_snapshot)

    total_res = len(_prob_keys) + len(_prot_keys)
    if total_res == 0:
        # Fallback to cache_snapshot.cache if our metadata isn't warmed up yet
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Adaptive sample size; larger incoming objects (relative to capacity) -> larger sample
    base = SAMPLE_SIZE_BASE if total_res > SAMPLE_SIZE_MIN else total_res
    if total_res <= SAMPLE_SIZE_MIN:
        sample_size = total_res
    else:
        ratio = 0.0
        try:
            ratio = float(obj.size) / float(cache_snapshot.capacity)
        except Exception:
            ratio = 0.0
        amp = min(1.0, 4.0 * max(0.0, ratio))  # emphasize very large objects
        sample_size = int(base + (SAMPLE_SIZE_MAX - base) * amp)
        sample_size = max(SAMPLE_SIZE_MIN, min(SAMPLE_SIZE_MAX, sample_size))

    # Ensure protected isn't bloated before picking a victim
    _demote_oldest_protected_if_needed()

    # Choose candidates: probation first
    victim_key = None
    victim_score = None
    victim_time = None

    def consider_keys(keys_arr, in_protected, k):
        nonlocal victim_key, victim_score, victim_time
        if len(keys_arr) == 0:
            return
        candidates = _sample_from(keys_arr, min(k, len(keys_arr)))
        for key in candidates:
            score = _keep_score(cache_snapshot, key, in_protected)
            last = m_last_access.get(key, -1)
            if (victim_score is None) or (score < victim_score) or (score == victim_score and last < victim_time):
                victim_score = score
                victim_time = last
                victim_key = key

    # Try probation
    consider_keys(_prob_keys, False, sample_size)

    # If no probation candidate (could be empty), demote some protected then retry probation
    if victim_key is None:
        if len(_prot_keys) > 0:
            _resident_move_prot_to_prob(_pick_oldest_protected_for_demote())
            consider_keys(_prob_keys, False, sample_size)

    # As a last resort, pick from protected
    if victim_key is None and len(_prot_keys) > 0:
        consider_keys(_prot_keys, True, sample_size)

    # Safety fallback to any resident key or any cache key
    if victim_key is None:
        if len(_prob_keys) > 0:
            victim_key = _prob_keys[0]
        elif len(_prot_keys) > 0:
            victim_key = _prot_keys[0]
        else:
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return victim_key


def _pick_oldest_protected_for_demote():
    # Helper: sample protected and return oldest key
    cur = len(_prot_keys)
    if cur == 0:
        return None
    k = min(PROT_TRIM_SAMPLE, cur)
    candidates = _sample_from(_prot_keys, k)
    oldest_key = None
    oldest_time = None
    for key in candidates:
        t = m_last_access.get(key, -1)
        if oldest_time is None or t < oldest_time:
            oldest_time = t
            oldest_key = key
    return oldest_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Refresh last-access
      - Increment resident hit count
      - Promote from probation to protected on first hit
      - Keep protected size near target by demoting an old one if over target
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_obj_size[k] = obj.size
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    part = m_partition.get(k)
    if part == 0:
        # Promote on first hit
        _resident_move_prob_to_prot(k)
    elif part is None:
        # If our index missed it, conservatively place it into protected
        _prot_add(k)

    # Keep protected near target
    _demote_oldest_protected_if_needed()


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter (counts this request)
      - Initialize resident metadata
      - Place item into probation segment
      - Keep protected near its target (no change needed unless it drifted)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_obj_size[k] = obj.size
    m_resident_hits[k] = 0
    _prob_add(k)

    # If protected was over target due to prior promotions, trim it
    _demote_oldest_protected_if_needed()


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU history to improve future decisions
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    _resident_remove(ek)
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_obj_size.pop(ek, None)
    # Keep TinyLFU counts (m_lfu_count) for re-reference benefit
```
2025-11-27 22:24:39,424 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 19
- Hit Rate: 0.2722

Example 2:
- Trace ID: 41
- Hit Rate: 0.178

Example 3:
- Trace ID: 18
- Error: Error - Timeout

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:24:39 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:24:39,425 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:27:28 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:27:28,353 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:27:28,354 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Hybrid SS-TinyLFU with ARC-style dynamic sizing, heap-based O(log n) recency,
# lazy-decayed TinyLFU, global reuse prediction, and size-aware fit pressure.
#
# Key improvements:
# - Fast eviction: heaps per segment to fetch oldest K candidates (no full scans)
# - Better reuse prediction: global EMA of inter-request-time persists across evictions
# - ARC-like ghost feedback dynamically tunes protected fraction
# - Size-aware fit pressure biases toward evicting fewer, larger items when necessary
# - TinyLFU retained across evictions; resident metadata pruned only when needed
#
# Eviction flow:
#   1) Demote oldest protected until protected-bytes <= target (dynamic)
#   2) Pick victim from probation if non-empty, else protected
#   3) Consider top-K oldest in that segment (by heap), score by TinyLFU/size/recency/reuse
#   4) Adjust score with "fit pressure" so large incoming objects prefer large victims
#   5) Return the victim key
#
# Metadata updates:
#   - On hit: increment TinyLFU, update global IRT EMA, LRU timestamp; promote probation->protected
#   - On insert: increment TinyLFU, initialize resident meta, adjust protected target via ghosts
#   - On evict: remove resident meta; add key to ARC-style ghost set; TinyLFU + global IRT retained

import math
import random
import heapq
from collections import deque

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (resident-only LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Global per-key request stream stats (persist across evictions)
m_req_last = dict()        # key -> last request time (hit or miss that led to insert)
m_req_irt = dict()         # key -> EMA of inter-request time (IRT), persists

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes), dynamically tuned (ARC ghost feedback)
g_dyn_protected_fraction = 0.80
g_protected_bytes = 0      # running total of bytes in protected
g_probation_bytes = 0
g_prot_count = 0
g_prob_count = 0

# Heaps for fast "oldest" lookup per segment (lazy invalidation)
# entries: (last_access, uid, key)
heap_prob = []
heap_prot = []
m_heap_uid = 0

# ARC-style ghost history (keys only, recent evictions from probation/protected)
ghost_prob_set = set()
ghost_prot_set = set()
ghost_prob_q = deque()
ghost_prot_q = deque()

# Scoring tunables
SIZE_ALPHA = 1.18          # slightly stronger size penalty
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.58
W_REC_PROT = 0.12
W_PRED_PROB = 0.28
W_PRED_PROT = 0.14

# EMA weight for inter-arrival time (IRT) on the global request stream
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# Eviction selection
K_OLDEST_CANDIDATES = 8    # how many oldest candidates to consider per eviction
FIT_PRESSURE_COEF = 0.15   # penalty strength for candidates too small to satisfy needed bytes

# ARC dynamic protected tuning
ARC_STEP = 0.02            # fraction step per ghost hit
PROTECTED_MIN = 0.20
PROTECTED_MAX = 0.95

# Ghost sizes (bounds); adaptive to active set size
GHOST_BASE_MAX = 1024
GHOST_SQRT_MULT = 4

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(g_dyn_protected_fraction * float(cache_snapshot.capacity))

def _heap_push(seg_id, key, last_access):
    global m_heap_uid
    m_heap_uid += 1
    entry = (last_access, m_heap_uid, key)
    if seg_id == 1:
        heapq.heappush(heap_prot, entry)
    else:
        heapq.heappush(heap_prob, entry)

def _heap_pop_valid(seg_id, cache_snapshot):
    # Pop until a valid (segment matches, resident, last_access current) entry is found
    heap = heap_prot if seg_id == 1 else heap_prob
    while heap:
        last, uid, key = heap[0]
        # Peek; check validity
        if key not in cache_snapshot.cache:
            heapq.heappop(heap)
            continue
        if _segment_of(key) != seg_id:
            heapq.heappop(heap)
            continue
        cur_last = m_last_access.get(key)
        if cur_last is None or cur_last != last:
            heapq.heappop(heap)
            continue
        return heap[0]  # valid peek
    return None

def _get_k_oldest_keys(seg_id, k, cache_snapshot):
    # Retrieve up to k valid oldest keys (non-destructive)
    heap = heap_prot if seg_id == 1 else heap_prob
    results = []
    temp = []
    taken = 0
    while heap and taken < k:
        entry = heapq.heappop(heap)
        last, uid, key = entry
        # validate
        if key in cache_snapshot.cache and _segment_of(key) == seg_id and m_last_access.get(key) == last:
            results.append(key)
            taken += 1
            temp.append(entry)  # push back later
        else:
            # stale; drop
            continue
    # push back
    for e in temp:
        heapq.heappush(heap, e)
    return results

def _demote_one_oldest_protected(cache_snapshot):
    # Demote the oldest protected entry (by last access) into probation
    global g_protected_bytes, g_probation_bytes, g_prot_count, g_prob_count
    entry = _heap_pop_valid(seg_id=1, cache_snapshot=cache_snapshot)
    if entry is None:
        return
    last, uid, key = entry
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return
    # Demote
    m_segment[key] = 0
    g_protected_bytes = max(0, g_protected_bytes - obj.size)
    g_probation_bytes += obj.size
    g_prot_count = max(0, g_prot_count - 1)
    g_prob_count += 1
    # Push to probation heap with same last access
    _heap_push(0, key, last)

def _demote_until_target(cache_snapshot):
    target = _protected_target_bytes(cache_snapshot)
    # Demote oldest protected until within target
    # Ensures we don't scan linearly; each demotion is O(log n)
    while g_protected_bytes > target:
        before = g_protected_bytes
        _demote_one_oldest_protected(cache_snapshot)
        if g_protected_bytes >= before:
            # Safety break to avoid infinite loop
            break

def _ghost_trim():
    # Bound the size of the ghost sets using an adaptive limit
    n = max(1, len(m_segment))  # number of resident entries (approx)
    max_ghost = GHOST_BASE_MAX + GHOST_SQRT_MULT * int(math.sqrt(n))
    # probation ghosts
    while len(ghost_prob_q) > max_ghost:
        old = ghost_prob_q.popleft()
        ghost_prob_set.discard(old)
    # protected ghosts
    while len(ghost_prot_q) > max_ghost:
        old = ghost_prot_q.popleft()
        ghost_prot_set.discard(old)

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    # Use global IRT estimate (persists across evictions)
    irt = m_req_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

def _fit_pressure_adjusted(score, cand_size, needed_bytes):
    if needed_bytes <= 0:
        return score
    if cand_size >= needed_bytes:
        return score
    # Penalize candidates that free too little space
    ratio = float(needed_bytes) / float(max(1, cand_size))
    return score + FIT_PRESSURE_COEF * math.log1p(ratio)

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Consider top-K oldest candidates (heap) and choose the lowest adjusted retention score
      - Adjust score by "fit pressure" to free enough space for incoming object
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_until_target(cache_snapshot)

    # Determine segment to evict from
    from_probation = (g_prob_count > 0) or (g_prot_count == 0)

    seg_id = 0 if from_probation else 1
    candidates = _get_k_oldest_keys(seg_id, K_OLDEST_CANDIDATES, cache_snapshot)

    if not candidates:
        # Fallback: try the other segment
        other_seg = 1 - seg_id
        candidates = _get_k_oldest_keys(other_seg, K_OLDEST_CANDIDATES, cache_snapshot)

    if not candidates:
        # Ultimate fallback: arbitrary resident key
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Compute how many bytes we need to free
    needed = cache_snapshot.size + obj.size - cache_snapshot.capacity

    # Select the best victim among candidates
    best_key = None
    best_adj_score = None
    best_time = None

    for k in candidates:
        base = _retention_score(cache_snapshot, k)
        cand_size = cache_snapshot.cache[k].size
        adj = _fit_pressure_adjusted(base, cand_size, needed)
        last = m_last_access.get(k, -1)
        if (best_key is None) or (adj < best_adj_score) or (adj == best_adj_score and last < best_time):
            best_key = k
            best_adj_score = adj
            best_time = last

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update global request IRT EMA
      - Update resident last_access and resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update global IRT EMA using delta between consecutive requests (resident or not)
    prev_req = m_req_last.get(k)
    if prev_req is not None:
        delta = max(1, now - prev_req)
        old_irt = m_req_irt.get(k, float(delta))
        m_req_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize conservatively using recency window
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_req_irt[k] = float(window)
    m_req_last[k] = now

    # Update resident metadata
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = _segment_of(k)
    if seg == 0:
        # Promotion to protected on first resident hit
        m_segment[k] = 1
        global g_protected_bytes, g_probation_bytes, g_prot_count, g_prob_count
        g_protected_bytes += obj.size
        g_probation_bytes = max(0, g_probation_bytes - obj.size)
        g_prot_count += 1
        g_prob_count = max(0, g_prob_count - 1)
        # Push into protected heap
        _heap_push(1, k, now)
    else:
        # Refresh protected heap position
        _heap_push(1, k, now)

    # Also refresh probation heap if it exists there (no-op if promoted above)
    if seg == 0:
        _heap_push(0, k, now)

    # Enforce protected target (demote oldest protected if oversized)
    _demote_until_target(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Update global request stream stats (m_req_last/m_req_irt)
      - Initialize resident metadata:
          last_access = now
          resident_hits = 1
          segment = probation
      - ARC-like dynamic protected tuning using ghost hits
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count
    _lfu_inc(cache_snapshot, k)

    # Global request stream update
    prev_req = m_req_last.get(k)
    if prev_req is not None:
        delta = max(1, now - prev_req)
        old_irt = m_req_irt.get(k, float(delta))
        m_req_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_req_irt[k] = float(window)
    m_req_last[k] = now

    # Resident metadata
    m_last_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Update segment accounting and heaps
    global g_probation_bytes, g_prob_count
    g_probation_bytes += obj.size
    g_prob_count += 1
    _heap_push(0, k, now)

    # ARC-style dynamic protected fraction adjustment via ghosts
    global g_dyn_protected_fraction
    if k in ghost_prot_set and k not in ghost_prob_set:
        g_dyn_protected_fraction = min(PROTECTED_MAX, g_dyn_protected_fraction + ARC_STEP)
        ghost_prot_set.discard(k)
        # remove from deque as well (lazy removal acceptable; we trim by size anyway)
    elif k in ghost_prob_set and k not in ghost_prot_set:
        g_dyn_protected_fraction = max(PROTECTED_MIN, g_dyn_protected_fraction - ARC_STEP)
        ghost_prob_set.discard(k)
    # Trim ghost histories
    _ghost_trim()

    # No change to protected bytes on insert (probation by default)
    # Demotion not needed here; promotion happens on hit


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters and global request IRT across evictions
      - Maintain segment bytes/count accounting
      - Record in ARC-style ghost history (probation vs protected)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    seg = _segment_of(ek)

    # Adjust bytes/counts
    global g_protected_bytes, g_probation_bytes, g_prot_count, g_prob_count
    if seg == 1:
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)
        g_prot_count = max(0, g_prot_count - 1)
        # Add to protected ghost
        if ek not in ghost_prot_set:
            ghost_prot_set.add(ek)
            ghost_prot_q.append(ek)
    else:
        g_probation_bytes = max(0, g_probation_bytes - evicted_obj.size)
        g_prob_count = max(0, g_prob_count - 1)
        # Add to probation ghost
        if ek not in ghost_prob_set:
            ghost_prob_set.add(ek)
            ghost_prob_q.append(ek)

    # Trim ghost histories
    _ghost_trim()

    # Remove resident-only metadata (keep TinyLFU and global request stats)
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    # Do NOT delete m_lfu_count[ek] or m_req_irt[ek] / m_req_last[ek]; they persist across evictions
```
2025-11-27 22:28:02,225 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# SLRU + TinyLFU + Size-aware sampled eviction (fast and high hit-rate)
# - Two resident segments with byte quotas:
#     Probation (new/once-hit) and Protected (multi-hit)
# - O(1) updates on hit/insert via OrderedDict LRU queues
# - Eviction chooses from Probation first (SLRU), falls back to Protected
# - Within the chosen segment, select victim by sampling a few oldest keys
#   and picking the smallest TinyLFU-Recency-Size score (no full scan)
# - TinyLFU sketch with lazy epoch decay (4-bit counters) tracks popularity
# - Metadata survives evictions where useful (TinyLFU); resident-only info removed

import math
from collections import OrderedDict

# -----------------------------
# Global metadata
# -----------------------------

# Segmented LRU structures (byte-aware)
PROTECTED_RATIO = 0.80        # fraction of capacity reserved for Protected
SAMPLE_K_PROB = 6             # candidates sampled from Probation on eviction
SAMPLE_K_PROT = 4             # candidates sampled from Protected on eviction

prob_lru = OrderedDict()      # key -> None (LRU on left, MRU on right)
prot_lru = OrderedDict()      # key -> None
seg_bytes_prob = 0            # total bytes in Probation
seg_bytes_prot = 0            # total bytes in Protected
m_segment = dict()            # key -> 0 (probation) or 1 (protected)

# Per-key resident metadata
m_last_access = dict()        # key -> int time (for recency scoring)
m_resident_hits = dict()      # key -> int (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Scoring tunables (robust defaults)
REC_WIN_MIN = 1000
REC_WIN_MULT = 4
REC_WEIGHT = 0.25
MULTI_HIT_BONUS = 0.35

# -----------------------------
# Init / TinyLFU helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Segment helpers
# -----------------------------

def _prot_target_bytes(cache_snapshot):
    try:
        return max(0, int(cache_snapshot.capacity * PROTECTED_RATIO))
    except Exception:
        return 0

def _seg_insert_prob(key, size):
    global seg_bytes_prob
    if m_segment.get(key) == 0:
        # refresh MRU
        prob_lru.pop(key, None)
        prob_lru[key] = None
        return
    if m_segment.get(key) == 1:
        # remove from protected first (shouldn't happen on insert)
        prot_lru.pop(key, None)
        global seg_bytes_prot
        seg_bytes_prot -= size
    m_segment[key] = 0
    prob_lru[key] = None
    seg_bytes_prob += size

def _seg_move_to_prot(cache_snapshot, key, size):
    # Move key to Protected MRU
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 1:
        # already in protected: refresh MRU
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    # remove from probation if present
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    # insert into protected
    m_segment[key] = 1
    prot_lru[key] = None
    seg_bytes_prot += size

    # Demote from protected to probation if protected exceeds target
    target = _prot_target_bytes(cache_snapshot)
    while seg_bytes_prot > target and prot_lru:
        # Demote LRU of protected into probation MRU (not evict)
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        seg_bytes_prot -= dsize

        # place into probation MRU if still resident
        if robj is not None:
            prob_lru[dem_key] = None
            seg_bytes_prob += dsize
            m_segment[dem_key] = 0
        else:
            m_segment.pop(dem_key, None)  # no longer resident; clean

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _seg_remove(cache_snapshot, key, size):
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 1:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        # unknown; ensure not lingering
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _retention_score(cache_snapshot, key):
    # Lower score -> weaker retention -> better eviction candidate
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    return benefit - recency_gain

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    # Iterate the oldest k_sample keys in 'order' and return the min-score key
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    # Fallback in case of issues
    if chosen_key is None:
        try:
            return next(iter(order))
        except StopIteration:
            return None
    return chosen_key

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Evict using SLRU: choose from Probation first; if empty, from Protected.
    Within the chosen segment, sample a few LRU-ordered keys and evict the
    one with the smallest TinyLFU-Recency-Size score.
    """
    _init_if_needed(cache_snapshot)

    # Prefer evicting from Probation (new/weak items)
    if prob_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
        return victim

    # Fall back to Protected if Probation empty
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)
        return victim

    # As a last resort, evict any key
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access time and resident hit count
      - Promote from Probation to Protected (SLRU) on first hit
      - Refresh LRU position within its segment
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked (shouldn't happen on a hit); insert into Probation
        _seg_insert_prob(k, obj.size)
        return

    if seg == 0:
        # Promote on first hit (classic SLRU)
        _seg_move_to_prot(cache_snapshot, k, obj.size)
    else:
        # Touch protected
        _seg_touch_on_hit(cache_snapshot, k)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU counter
      - Initialize resident metadata
      - Place into Probation MRU
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # New resident goes to Probation MRU
    _seg_insert_prob(k, obj.size)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata and from segment structures
      - Keep TinyLFU counters to remember popularity of non-residents
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    _seg_remove(cache_snapshot, ek, evicted_obj.size)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Keep m_lfu_count[ek] for future admission/eviction decisions
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 27
- Hit Rate: 0.8922

Example 2:
- Trace ID: 42
- Hit Rate: 0.0576

Example 3:
- Trace ID: 24
- Hit Rate: 0.2862

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:28:02 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:28:02,227 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:30:41 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:30:41,189 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:30:41,191 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive SLRU + TinyLFU with ARC-style ghost tuning and size-aware promotion
# - Two resident segments tracked in bytes: Probation (new/once-hit) and Protected (multi-hit)
# - ARC-inspired ghost lists to adapt the Protected/Probation split online
# - TinyLFU with lazy epoch decay; Doorkeeper prevents singletons from inflating LFU
# - Eviction selects lowest retention-score from sampled old items across segments
# - Size-aware promotion threshold: large objects require more hits to enter Protected
# - All operations are O(1) amortized; sampling keeps eviction fast

import math
from collections import OrderedDict

# -----------------------------
# Global metadata
# -----------------------------

# Dynamic Protected ratio (ARC-style tuning via ghost hits)
g_prot_ratio = 0.80
PROT_MIN = 0.05
PROT_MAX = 0.95

# Sampling parameters (eviction)
SAMPLE_K_PROB = 8
SAMPLE_K_PROT = 6
PROB_BIAS_MARGIN = 0.08  # small bias to prefer evicting from Probation if similar score

# Segmented resident LRU (byte-aware)
prob_lru = OrderedDict()      # key -> None (LRU on left, MRU on right)
prot_lru = OrderedDict()      # key -> None
seg_bytes_prob = 0            # total bytes in Probation
seg_bytes_prot = 0            # total bytes in Protected
m_segment = dict()            # key -> 0 (probation) or 1 (protected)

# Per-key resident metadata
m_last_access = dict()        # key -> int time
m_resident_hits = dict()      # key -> int (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Doorkeeper (per-epoch set to dampen one-hit wonders)
door_epoch = -1
door_set = set()

# ARC-style ghosts (LRU lists of recently evicted keys; metadata-only)
ghost_recent = OrderedDict()   # evicted from Probation
ghost_frequent = OrderedDict() # evicted from Protected

# Scoring tunables
REC_WIN_MIN = 1000
REC_WIN_MULT = 4
REC_WEIGHT = 0.35
MULTI_HIT_BONUS = 0.45

# -----------------------------
# Epoch / TinyLFU / Doorkeeper helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch, door_epoch, door_set
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur
    if cur != door_epoch:
        door_epoch = cur
        # Reset doorkeeper each LFU epoch to avoid unbounded growth
        door_set.clear()

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key, amount=1):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + amount)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _doorkeeper_seen(key):
    # Returns True if key has been seen in the current doorkeeper epoch
    return key in door_set

def _doorkeeper_touch(key):
    # Mark key in doorkeeper; return True if it was already present
    if key in door_set:
        return True
    door_set.add(key)
    return False

# -----------------------------
# Segment helpers
# -----------------------------

def _prot_target_bytes(cache_snapshot):
    try:
        cap = int(cache_snapshot.capacity)
        ratio = float(g_prot_ratio)
        return max(0, min(cap, int(cap * ratio)))
    except Exception:
        return 0

def _seg_insert_prob(key, size):
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 0:
        # refresh MRU
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 1:
        # remove from protected first (safety)
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    m_segment[key] = 0
    prob_lru[key] = None
    seg_bytes_prob += size

def _seg_move_to_prot(cache_snapshot, key, size):
    # Move key to Protected MRU; demote overflow back to Probation
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    m_segment[key] = 1
    prot_lru[key] = None
    seg_bytes_prot += size

    # Demote LRU from Protected into Probation until within target
    target = _prot_target_bytes(cache_snapshot)
    while seg_bytes_prot > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        seg_bytes_prot -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            seg_bytes_prob += dsize
            m_segment[dem_key] = 0
        else:
            m_segment.pop(dem_key, None)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _seg_remove(cache_snapshot, key, size):
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 1:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)

# -----------------------------
# Ghost helpers and adaptive split
# -----------------------------

def _ghost_limit(cache_snapshot):
    # Bound ghost metadata: proportional to resident cardinality
    n = max(256, 8 * max(1, len(cache_snapshot.cache)))
    return n

def _ghost_add(ghost_od, key, limit):
    ghost_od[key] = None
    # Maintain MRU at right
    ghost_od.move_to_end(key, last=True)
    # Trim if beyond limit
    while len(ghost_od) > limit:
        ghost_od.popitem(last=False)

def _adapt_protected_ratio(cache_snapshot, direction, size_hint=0):
    # direction: +1 -> increase Protected, -1 -> decrease Protected
    global g_prot_ratio
    cap = max(1, int(cache_snapshot.capacity))
    # Step grows slightly with object size
    step = 0.02 + min(0.10, 0.30 * (float(size_hint) / float(cap)))
    if direction > 0:
        g_prot_ratio = min(PROT_MAX, g_prot_ratio + step)
    else:
        g_prot_ratio = max(PROT_MIN, g_prot_ratio - step)

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _retention_score(cache_snapshot, key):
    # Lower score -> weaker retention -> better eviction candidate
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    freq = _lfu_peek(cache_snapshot, key)
    multi_bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + multi_bonus) / size_norm

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_penalty = REC_WEIGHT * (1.0 - a_norm)  # higher for very recent -> reduces eviction

    return benefit - recency_penalty

def _pick_candidate_with_score(cache_snapshot, order, k_sample):
    if not order:
        return (None, None)
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            key = next(iter(order))
            return (key, _retention_score(cache_snapshot, key))
        except StopIteration:
            return (None, None)
    return (chosen_key, chosen_score)

def _promotion_threshold(size, capacity):
    # Size-aware promotion threshold (resident_hits must reach this value):
    # - Large objects need more confirmations before entering Protected
    frac = float(size) / float(capacity) if capacity > 0 else 0.0
    if frac >= 0.10:
        return 3  # two re-references (insert -> hit -> hit)
    elif frac >= 0.03:
        return 2  # one re-reference
    else:
        return 2  # small objects promote on first hit

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Evict using adaptive SLRU with TinyLFU scoring:
      - Sample candidates from both segments (older side) and compute retention scores
      - Prefer Probation, but allow evicting Protected if clearly lower score
      - Score blends frequency (TinyLFU, with multi-hit bonus), size, and recency
    """
    _init_if_needed(cache_snapshot)

    # Sample from both segments
    p_key, p_score = _pick_candidate_with_score(cache_snapshot, prob_lru, SAMPLE_K_PROB)
    f_key, f_score = _pick_candidate_with_score(cache_snapshot, prot_lru, SAMPLE_K_PROT)

    if p_key is None and f_key is None:
        # Fallback: any key
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    if p_key is None:
        return f_key
    if f_key is None:
        return p_key

    # Prefer evicting from Probation unless it is substantially more valuable to retain
    if (p_score + PROB_BIAS_MARGIN) <= f_score:
        return p_key
    else:
        return f_key

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access time and resident hit count
      - Promote to Protected when resident_hits reaches size-aware threshold
      - Refresh LRU position
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k, amount=1)
    m_last_access[k] = cache_snapshot.access_count
    prev = m_resident_hits.get(k, 1)
    cur_hits = prev + 1
    m_resident_hits[k] = cur_hits

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked (should be rare); treat as fresh insert into Probation
        _seg_insert_prob(k, obj.size)
        return

    # Size-aware promotion
    th = _promotion_threshold(obj.size, cache_snapshot.capacity)
    if seg == 0:
        if cur_hits >= th:
            _seg_move_to_prot(cache_snapshot, k, obj.size)
        else:
            _seg_touch_on_hit(cache_snapshot, k)
    else:
        _seg_touch_on_hit(cache_snapshot, k)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Doorkeeper: only credit TinyLFU if seen within the current epoch
      - Initialize resident metadata
      - Place into Probation MRU
      - ARC-style ghost hits adapt Protected/Probation split:
          * If key was in Recent-ghost -> favor Probation (shrink Protected)
          * If key was in Frequent-ghost -> favor Protected
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    # Doorkeeper: first sight in epoch -> don't credit LFU; second+ -> credit
    if _doorkeeper_touch(k):
        _lfu_inc(cache_snapshot, k, amount=1)
    else:
        # record presence but give at most a tiny credit (optional)
        pass

    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # ARC-style ghost adaptation
    # If the key reappears after being evicted from Probation, prefer recent (decrease Protected)
    if k in ghost_recent:
        ghost_recent.pop(k, None)
        _adapt_protected_ratio(cache_snapshot, direction=-1, size_hint=obj.size)
    elif k in ghost_frequent:
        ghost_frequent.pop(k, None)
        _adapt_protected_ratio(cache_snapshot, direction=+1, size_hint=obj.size)

    # New resident -> Probation MRU
    _seg_insert_prob(k, obj.size)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove from resident structures and clear resident-only metadata
      - Keep TinyLFU counters for future admission
      - Record key into appropriate ghost list and adapt split bounds dynamically
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Snapshot the segment before removal for ghost classification
    seg = m_segment.get(ek, None)
    _seg_remove(cache_snapshot, ek, evicted_obj.size)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Keep m_lfu_count[ek] for admission heuristics

    # Ghost insertion and limit maintenance
    limit = _ghost_limit(cache_snapshot)
    if seg == 1:
        _ghost_add(ghost_frequent, ek, limit)
    else:
        _ghost_add(ghost_recent, ek, limit)
```
2025-11-27 22:33:48,717 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Sampled TinyLFU-Recency-Size (sTFRS)
# - Same core signal as TFRS (TinyLFU + recency + size), but with O(1) metadata updates
#   and O(k) eviction via small random sampling (k << resident_items).
#   This removes full-cache scans and prevents timeouts on large traces.
# - TinyLFU with lazy-epoch 4-bit counters (counts both resident and non-resident accesses)
# - Recency bonus to protect very recent items
# - Size-aware benefit: small items get proportionally higher retention per byte
# - Multi-hit resident items get a small boost
#
# Key changes vs previous version:
#   1) Eviction scans only a small random sample of residents (default 32), not all keys.
#   2) Maintain an O(1) resident-key index (array + position map) for fast sampling/removal.
#   3) Keep the effective scoring model but improve performance to avoid timeouts.

import math
import random

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU-ish timestamp)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# Fast resident set for sampling (array + index map for O(1) add/remove)
m_resident_keys = []       # list of keys currently resident
m_resident_pos = dict()    # key -> index in m_resident_keys

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Sampling parameters for eviction
SAMPLE_SIZE_BASE = 32      # default random sample size
SAMPLE_SIZE_MIN = 8        # lower bound when cache small
SAMPLE_SIZE_MAX = 64       # upper bound; keep k small for speed

# Precompute log2(1+freq) for 4-bit frequency values (0..15)
_FREQ_GAIN = [math.log2(1 + i) for i in range(16)]


# -----------------------------
# Initialization helper
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)
    # Nothing else capacity-dependent to initialize


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Resident set helpers
# -----------------------------

def _resident_add(key):
    if key in m_resident_pos:
        return
    idx = len(m_resident_keys)
    m_resident_keys.append(key)
    m_resident_pos[key] = idx


def _resident_remove(key):
    idx = m_resident_pos.pop(key, None)
    if idx is None:
        return
    last_idx = len(m_resident_keys) - 1
    if idx != last_idx:
        last_key = m_resident_keys[last_idx]
        m_resident_keys[idx] = last_key
        m_resident_pos[last_key] = idx
    m_resident_keys.pop()


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit stable across caches
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key):
    # score = benefit - recency_gain
    #   benefit      = log2(1 + freq) (+bonus if multi-hit) divided by normalized size
    #   recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        # Should not occur; keep it very evictable
        return float('-inf')
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (_FREQ_GAIN[freq] + extra) / size_norm

    # Recency protection
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    return benefit - recency_gain


def _sample_keys(k):
    # Fast random sample without building an intermediate list
    # Uses our resident array for O(k) sampling.
    n = len(m_resident_keys)
    if n == 0:
        return []
    if k >= n:
        # Small cache: sample all
        return list(m_resident_keys)
    # Reservoir-like: random.sample over a range with indirection to keys
    # We avoid constructing a full list of keys.
    chosen = set()
    out = []
    while len(out) < k:
        idx = random.randrange(0, n)
        if idx not in chosen:
            chosen.add(idx)
            out.append(m_resident_keys[idx])
    return out


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score,
    but choose among a small random sample of residents to avoid full scans.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    n = len(m_resident_keys)
    if n == 0:
        # Fallback: rely on cache_snapshot.cache when our index is desynced (should not happen)
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Adaptive sample size: increase slightly with cache size but keep bounded
    if n <= SAMPLE_SIZE_MIN:
        sample_size = n
    else:
        # Grow very slowly with n to reduce variance a bit
        sample_size = min(SAMPLE_SIZE_MAX, max(SAMPLE_SIZE_MIN, SAMPLE_SIZE_BASE))

    candidates = _sample_keys(sample_size)

    min_key = None
    min_score = None
    min_time = None

    for k in candidates:
        score = _retention_score(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Safety fallback if sampling failed to pick one
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1
    # No change to resident set (already present)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key (so non-resident history matters)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Add key to resident sampling set
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    _resident_add(k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Remove key from resident sampling set
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Keep TinyLFU history to improve future admission/retention
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    _resident_remove(ek)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 8
- Hit Rate: 0.5313

Example 2:
- Trace ID: 11
- Hit Rate: 0.3788

Example 3:
- Trace ID: 30
- Hit Rate: 0.0524

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:33:48 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:33:48,721 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:36:04 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:36:04,434 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:36:04,436 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# sTFRS+ (Sampled TinyLFU + Recency + Size, scan-resistant, O(1) metadata)
# Key improvements vs previous version:
#   1) Fix recency sign: recent items now get a positive credit (were penalized before).
#   2) Recency credit is scan-resistant: strongly reduced for items with zero resident hits.
#   3) Adaptive sampling size grows mildly with cache size; still capped for speed.
#   4) Tuned constants for better balance across LFU/recency/size on mixed traces.

import math
import random

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU-ish timestamp)
m_resident_hits = dict()   # key -> int resident hit count since insertion

# Fast resident set for sampling (array + index map for O(1) add/remove)
m_resident_keys = []       # list of keys currently resident
m_resident_pos = dict()    # key -> index in m_resident_keys

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (retuned)
REC_WIN_MIN = 384          # was 1000: smaller to avoid over-protecting "just touched" items
REC_WIN_MULT = 3           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.50          # stronger recency credit, but scan-resistant via hit-based scaling
MULTI_HIT_BONUS = 0.45     # bonus for items with >=2 resident hits

# Sampling parameters for eviction (retuned/adaptive)
SAMPLE_SIZE_MIN = 12       # slightly larger floor
SAMPLE_SIZE_MAX = 64       # keep bounded for speed

# Precompute log2(1+freq) for 4-bit frequency values (0..15)
_FREQ_GAIN = [math.log2(1 + i) for i in range(16)]


# -----------------------------
# Initialization helper
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Resident set helpers
# -----------------------------

def _resident_add(key):
    if key in m_resident_pos:
        return
    idx = len(m_resident_keys)
    m_resident_keys.append(key)
    m_resident_pos[key] = idx


def _resident_remove(key):
    idx = m_resident_pos.pop(key, None)
    if idx is None:
        return
    last_idx = len(m_resident_keys) - 1
    if idx != last_idx:
        last_key = m_resident_keys[last_idx]
        m_resident_keys[idx] = last_key
        m_resident_pos[last_key] = idx
    m_resident_keys.pop()


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit stable across caches
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _freshness(now, last, window):
    # Freshness in [0,1]: 1.0 for brand new, decays linearly to 0 by window
    if last is None:
        return 0.0  # should not happen for residents; treat as not fresh
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    age_norm = min(1.0, float(age) / float(window))
    return 1.0 - age_norm


def _recency_multiplier(res_hits):
    # Scan-resistance: damp recency credit for items with few/zero resident hits
    #  - 0 hits (brand new, likely cold/scan): 0.25x credit
    #  - 1 hit  (probation): 0.6x credit
    #  - 2+ hits (hot): full credit
    if res_hits <= 0:
        return 0.25
    if res_hits == 1:
        return 0.60
    return 1.0


def _retention_score(cache_snapshot, key):
    # score = benefit + recency_credit   (higher is better to KEEP)
    #   benefit        = log2(1 + freq) (+bonus if multi-hit) / normalized size
    #   recency_credit = REC_WEIGHT * freshness * recency_multiplier
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    res_hits = m_resident_hits.get(key, 0)
    extra = MULTI_HIT_BONUS if res_hits >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (_FREQ_GAIN[freq] + extra) / size_norm

    # Recency protection (credit, not penalty)
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    fresh = _freshness(now, last, window)
    recency_credit = REC_WEIGHT * fresh * _recency_multiplier(res_hits)

    return benefit + recency_credit


def _adaptive_sample_size(n_resident):
    if n_resident <= 0:
        return 0
    # Mild growth with cache size: 16 + 2*sqrt(n), bounded
    k = int(16 + 2.0 * math.sqrt(n_resident))
    if n_resident < SAMPLE_SIZE_MIN:
        k = n_resident
    return min(SAMPLE_SIZE_MAX, max(SAMPLE_SIZE_MIN, k))


def _sample_keys(k):
    n = len(m_resident_keys)
    if n == 0 or k <= 0:
        return []
    if k >= n:
        return list(m_resident_keys)
    # Sample indices and map to keys (avoids set bookkeeping)
    idxs = random.sample(range(n), k)
    return [m_resident_keys[i] for i in idxs]


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score,
    chosen among an adaptive-size random sample of residents. Ties -> oldest.
    '''
    _init_if_needed(cache_snapshot)

    n = len(m_resident_keys)
    if n == 0:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    sample_size = _adaptive_sample_size(n)
    candidates = _sample_keys(sample_size)

    min_key = None
    min_score = None
    min_time = None

    for k in candidates:
        score = _retention_score(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    # resident hit count: starts at 0 on insert, grows with hits
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1
    # resident set unchanged


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key (track non-resident history)
      - Initialize resident metadata: last_access, resident_hits = 0 (probation)
      - Add key to resident sampling set
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    # Start in probation (0 hits) for scan-resistance
    m_resident_hits[k] = 0
    _resident_add(k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Remove key from resident sampling set
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Keep TinyLFU history to improve future retention decisions
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    _resident_remove(ek)
```
2025-11-27 22:36:25,759 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Adaptive SLRU + TinyLFU with ARC-style ghost tuning and size-aware promotion
# - Two resident segments tracked in bytes: Probation (new/once-hit) and Protected (multi-hit)
# - ARC-inspired ghost lists to adapt the Protected/Probation split online
# - TinyLFU with lazy epoch decay; Doorkeeper prevents singletons from inflating LFU
# - Eviction selects lowest retention-score from sampled old items across segments
# - Size-aware promotion threshold: large objects require more hits to enter Protected
# - All operations are O(1) amortized; sampling keeps eviction fast

import math
from collections import OrderedDict

# -----------------------------
# Global metadata
# -----------------------------

# Dynamic Protected ratio (ARC-style tuning via ghost hits)
g_prot_ratio = 0.80
PROT_MIN = 0.05
PROT_MAX = 0.95

# Sampling parameters (eviction)
SAMPLE_K_PROB = 8
SAMPLE_K_PROT = 6
PROB_BIAS_MARGIN = 0.08  # small bias to prefer evicting from Probation if similar score

# Segmented resident LRU (byte-aware)
prob_lru = OrderedDict()      # key -> None (LRU on left, MRU on right)
prot_lru = OrderedDict()      # key -> None
seg_bytes_prob = 0            # total bytes in Probation
seg_bytes_prot = 0            # total bytes in Protected
m_segment = dict()            # key -> 0 (probation) or 1 (protected)

# Per-key resident metadata
m_last_access = dict()        # key -> int time
m_resident_hits = dict()      # key -> int (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Doorkeeper (per-epoch set to dampen one-hit wonders)
door_epoch = -1
door_set = set()

# ARC-style ghosts (LRU lists of recently evicted keys; metadata-only)
ghost_recent = OrderedDict()   # evicted from Probation
ghost_frequent = OrderedDict() # evicted from Protected

# Scoring tunables
REC_WIN_MIN = 1000
REC_WIN_MULT = 4
REC_WEIGHT = 0.35
MULTI_HIT_BONUS = 0.45

# -----------------------------
# Epoch / TinyLFU / Doorkeeper helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch, door_epoch, door_set
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur
    if cur != door_epoch:
        door_epoch = cur
        # Reset doorkeeper each LFU epoch to avoid unbounded growth
        door_set.clear()

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key, amount=1):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + amount)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _doorkeeper_seen(key):
    # Returns True if key has been seen in the current doorkeeper epoch
    return key in door_set

def _doorkeeper_touch(key):
    # Mark key in doorkeeper; return True if it was already present
    if key in door_set:
        return True
    door_set.add(key)
    return False

# -----------------------------
# Segment helpers
# -----------------------------

def _prot_target_bytes(cache_snapshot):
    try:
        cap = int(cache_snapshot.capacity)
        ratio = float(g_prot_ratio)
        return max(0, min(cap, int(cap * ratio)))
    except Exception:
        return 0

def _seg_insert_prob(key, size):
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 0:
        # refresh MRU
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 1:
        # remove from protected first (safety)
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    m_segment[key] = 0
    prob_lru[key] = None
    seg_bytes_prob += size

def _seg_move_to_prot(cache_snapshot, key, size):
    # Move key to Protected MRU; demote overflow back to Probation
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    m_segment[key] = 1
    prot_lru[key] = None
    seg_bytes_prot += size

    # Demote LRU from Protected into Probation until within target
    target = _prot_target_bytes(cache_snapshot)
    while seg_bytes_prot > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        seg_bytes_prot -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            seg_bytes_prob += dsize
            m_segment[dem_key] = 0
        else:
            m_segment.pop(dem_key, None)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _seg_remove(cache_snapshot, key, size):
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 1:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)

# -----------------------------
# Ghost helpers and adaptive split
# -----------------------------

def _ghost_limit(cache_snapshot):
    # Bound ghost metadata: proportional to resident cardinality
    n = max(256, 8 * max(1, len(cache_snapshot.cache)))
    return n

def _ghost_add(ghost_od, key, limit):
    ghost_od[key] = None
    # Maintain MRU at right
    ghost_od.move_to_end(key, last=True)
    # Trim if beyond limit
    while len(ghost_od) > limit:
        ghost_od.popitem(last=False)

def _adapt_protected_ratio(cache_snapshot, direction, size_hint=0):
    # direction: +1 -> increase Protected, -1 -> decrease Protected
    global g_prot_ratio
    cap = max(1, int(cache_snapshot.capacity))
    # Step grows slightly with object size
    step = 0.02 + min(0.10, 0.30 * (float(size_hint) / float(cap)))
    if direction > 0:
        g_prot_ratio = min(PROT_MAX, g_prot_ratio + step)
    else:
        g_prot_ratio = max(PROT_MIN, g_prot_ratio - step)

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _retention_score(cache_snapshot, key):
    # Lower score -> weaker retention -> better eviction candidate
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    freq = _lfu_peek(cache_snapshot, key)
    multi_bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + multi_bonus) / size_norm

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_penalty = REC_WEIGHT * (1.0 - a_norm)  # higher for very recent -> reduces eviction

    return benefit - recency_penalty

def _pick_candidate_with_score(cache_snapshot, order, k_sample):
    if not order:
        return (None, None)
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            key = next(iter(order))
            return (key, _retention_score(cache_snapshot, key))
        except StopIteration:
            return (None, None)
    return (chosen_key, chosen_score)

def _promotion_threshold(size, capacity):
    # Size-aware promotion threshold (resident_hits must reach this value):
    # - Large objects need more confirmations before entering Protected
    frac = float(size) / float(capacity) if capacity > 0 else 0.0
    if frac >= 0.10:
        return 3  # two re-references (insert -> hit -> hit)
    elif frac >= 0.03:
        return 2  # one re-reference
    else:
        return 2  # small objects promote on first hit

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Evict using adaptive SLRU with TinyLFU scoring:
      - Sample candidates from both segments (older side) and compute retention scores
      - Prefer Probation, but allow evicting Protected if clearly lower score
      - Score blends frequency (TinyLFU, with multi-hit bonus), size, and recency
    """
    _init_if_needed(cache_snapshot)

    # Sample from both segments
    p_key, p_score = _pick_candidate_with_score(cache_snapshot, prob_lru, SAMPLE_K_PROB)
    f_key, f_score = _pick_candidate_with_score(cache_snapshot, prot_lru, SAMPLE_K_PROT)

    if p_key is None and f_key is None:
        # Fallback: any key
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    if p_key is None:
        return f_key
    if f_key is None:
        return p_key

    # Prefer evicting from Probation unless it is substantially more valuable to retain
    if (p_score + PROB_BIAS_MARGIN) <= f_score:
        return p_key
    else:
        return f_key

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access time and resident hit count
      - Promote to Protected when resident_hits reaches size-aware threshold
      - Refresh LRU position
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k, amount=1)
    m_last_access[k] = cache_snapshot.access_count
    prev = m_resident_hits.get(k, 1)
    cur_hits = prev + 1
    m_resident_hits[k] = cur_hits

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked (should be rare); treat as fresh insert into Probation
        _seg_insert_prob(k, obj.size)
        return

    # Size-aware promotion
    th = _promotion_threshold(obj.size, cache_snapshot.capacity)
    if seg == 0:
        if cur_hits >= th:
            _seg_move_to_prot(cache_snapshot, k, obj.size)
        else:
            _seg_touch_on_hit(cache_snapshot, k)
    else:
        _seg_touch_on_hit(cache_snapshot, k)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Doorkeeper: only credit TinyLFU if seen within the current epoch
      - Initialize resident metadata
      - Place into Probation MRU
      - ARC-style ghost hits adapt Protected/Probation split:
          * If key was in Recent-ghost -> favor Probation (shrink Protected)
          * If key was in Frequent-ghost -> favor Protected
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    # Doorkeeper: first sight in epoch -> don't credit LFU; second+ -> credit
    if _doorkeeper_touch(k):
        _lfu_inc(cache_snapshot, k, amount=1)
    else:
        # record presence but give at most a tiny credit (optional)
        pass

    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # ARC-style ghost adaptation
    # If the key reappears after being evicted from Probation, prefer recent (decrease Protected)
    if k in ghost_recent:
        ghost_recent.pop(k, None)
        _adapt_protected_ratio(cache_snapshot, direction=-1, size_hint=obj.size)
    elif k in ghost_frequent:
        ghost_frequent.pop(k, None)
        _adapt_protected_ratio(cache_snapshot, direction=+1, size_hint=obj.size)

    # New resident -> Probation MRU
    _seg_insert_prob(k, obj.size)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove from resident structures and clear resident-only metadata
      - Keep TinyLFU counters for future admission
      - Record key into appropriate ghost list and adapt split bounds dynamically
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Snapshot the segment before removal for ghost classification
    seg = m_segment.get(ek, None)
    _seg_remove(cache_snapshot, ek, evicted_obj.size)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Keep m_lfu_count[ek] for admission heuristics

    # Ghost insertion and limit maintenance
    limit = _ghost_limit(cache_snapshot)
    if seg == 1:
        _ghost_add(ghost_frequent, ek, limit)
    else:
        _ghost_add(ghost_recent, ek, limit)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 3
- Hit Rate: 0.3691

Example 2:
- Trace ID: 21
- Hit Rate: 0.0266

Example 3:
- Trace ID: 5
- Hit Rate: 0.3999

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:36:25 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:36:25,760 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:40:07 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:40:07,302 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:40:07,304 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Window-TinyLFU with Eden + SLRU Main (Probation/Protected),
# ARC-style ghost tuning for both Eden size and Protected share,
# size-aware promotions, improved recency/frequency scoring,
# and TinyLFU-based admission bias during eviction.
#
# - Segments (byte-aware):
#   * Eden (window LRU): captures very recent items; new inserts land here.
#   * Main Probation (SLRU once-hit)
#   * Main Protected (SLRU multi-hit)
# - Eviction:
#   * Prefer removing from Eden, unless the incoming object is clearly more
#     frequent than a weak Main candidate (TinyLFU-biased admission).
#   * Otherwise, sample and evict the lowest retention-score candidate from Main,
#     with a bias toward Probation.
# - Updates:
#   * Hits increment TinyLFU and maintain LRU order.
#   * Size-aware promotions out of Eden / Probation into Protected.
#   * Demote Protected overflow into Probation to honor dynamic target.
# - Ghosts:
#   * ghost_eden: items evicted from Eden -> grow Eden on ghost hit.
#   * ghost_recent: items evicted from Probation -> shrink Protected on ghost hit.
#   * ghost_frequent: items evicted from Protected -> grow Protected on ghost hit.
#   * Also shrink Eden a bit on Main ghost hits to avoid window bloat.
#
# All operations are O(1) amortized; sampling keeps eviction decisions fast.

import math
from collections import OrderedDict

# -----------------------------
# Global tunables and metadata
# -----------------------------

# Window (Eden) ratio and Protected ratio (adaptive via ghost hits)
g_eden_ratio = 0.20
EDEN_MIN = 0.03
EDEN_MAX = 0.50

g_prot_ratio = 0.80      # share of Main reserved for Protected
PROT_MIN = 0.10
PROT_MAX = 0.95

# Sampling parameters (eviction from Main)
SAMPLE_K_PROB = 8
SAMPLE_K_PROT = 6
PROB_BIAS_MARGIN = 0.08  # prefer Probation slightly if scores are similar

# Segments (resident) - byte aware
eden_lru = OrderedDict()     # key -> None
prob_lru = OrderedDict()     # key -> None
prot_lru = OrderedDict()     # key -> None

seg_bytes_eden = 0
seg_bytes_prob = 0
seg_bytes_prot = 0

# segment membership: 0=Eden, 1=Probation, 2=Protected
m_segment = dict()

# Per-key resident metadata
m_last_access = dict()        # key -> int time
m_resident_hits = dict()      # key -> int (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Doorkeeper (per-epoch set to dampen one-hit wonders)
door_epoch = -1
door_set = set()

# ARC-style ghosts
ghost_eden = OrderedDict()     # evicted from Eden
ghost_recent = OrderedDict()   # evicted from Probation (Main Recent)
ghost_frequent = OrderedDict() # evicted from Protected (Main Frequent)

# Scoring tunables
REC_WIN_MIN = 1000
REC_WIN_MULT = 4
FREQ_WEIGHT = 1.00
REC_WEIGHT = 0.30
PROT_BASE_BONUS = 0.25
EDEN_BASE_PENALTY = 0.10
MULTI_HIT_BONUS = 0.45

# Admission bias margin (TinyLFU compare of incoming vs main-candidate)
ADMIT_MARGIN = 0  # 0 or 1; conservative admission if incoming <= victim


# -----------------------------
# Epoch / TinyLFU / Doorkeeper
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch, door_epoch, door_set
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur
    if cur != door_epoch:
        door_epoch = cur
        door_set.clear()

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key, amount=1):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + amount)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _doorkeeper_seen(key):
    return key in door_set

def _doorkeeper_touch(key):
    if key in door_set:
        return True
    door_set.add(key)
    return False


# -----------------------------
# Segment helpers and targets
# -----------------------------

def _eden_target_bytes(cache_snapshot):
    try:
        cap = int(cache_snapshot.capacity)
        ratio = float(g_eden_ratio)
        return max(0, min(cap, int(cap * ratio)))
    except Exception:
        return 0

def _main_target_bytes(cache_snapshot):
    cap = int(cache_snapshot.capacity)
    return max(0, cap - _eden_target_bytes(cache_snapshot))

def _prot_target_bytes(cache_snapshot):
    try:
        main = _main_target_bytes(cache_snapshot)
        ratio = float(g_prot_ratio)
        return max(0, min(main, int(main * ratio)))
    except Exception:
        return 0

def _obj_size(cache_snapshot, key):
    robj = cache_snapshot.cache.get(key)
    return robj.size if robj is not None else 0

def _seg_insert_eden(key, size):
    global seg_bytes_eden, seg_bytes_prob, seg_bytes_prot
    prev = m_segment.get(key)
    if prev == 0:
        if key in eden_lru:
            eden_lru.move_to_end(key, last=True)
        else:
            eden_lru[key] = None
        return
    # remove from previous segment if any
    if prev == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif prev == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    m_segment[key] = 0
    eden_lru[key] = None
    seg_bytes_eden += size

def _seg_move_to_prob(cache_snapshot, key, size):
    global seg_bytes_eden, seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    # remove from former segment
    if seg == 0:
        if key in eden_lru:
            eden_lru.pop(key, None)
            seg_bytes_eden -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    m_segment[key] = 1
    prob_lru[key] = None
    seg_bytes_prob += size

def _seg_move_to_prot(cache_snapshot, key, size):
    global seg_bytes_eden, seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    # remove from former segment
    if seg == 0:
        if key in eden_lru:
            eden_lru.pop(key, None)
            seg_bytes_eden -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    m_segment[key] = 2
    prot_lru[key] = None
    seg_bytes_prot += size

    # Demote Protected overflow into Probation to meet target
    target = _prot_target_bytes(cache_snapshot)
    while seg_bytes_prot > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)  # LRU of Protected
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        seg_bytes_prot -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            seg_bytes_prob += dsize
            m_segment[dem_key] = 1
        else:
            m_segment.pop(dem_key, None)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in eden_lru:
            eden_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _seg_remove(cache_snapshot, key, size):
    global seg_bytes_eden, seg_bytes_prob, seg_bytes_prot
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in eden_lru:
            eden_lru.pop(key, None)
            seg_bytes_eden -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        eden_lru.pop(key, None)
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)


# -----------------------------
# Ghost helpers and adaptation
# -----------------------------

def _ghost_limit(cache_snapshot):
    n = max(256, 8 * max(1, len(cache_snapshot.cache)))
    return n

def _ghost_add(ghost_od, key, limit):
    ghost_od[key] = None
    ghost_od.move_to_end(key, last=True)
    while len(ghost_od) > limit:
        ghost_od.popitem(last=False)

def _adapt_eden_ratio(cache_snapshot, direction, size_hint=0):
    global g_eden_ratio
    cap = max(1, int(cache_snapshot.capacity))
    # Step increases slightly with object size
    step = 0.02 + min(0.10, 0.30 * (float(size_hint) / float(cap)))
    if direction > 0:
        g_eden_ratio = min(EDEN_MAX, g_eden_ratio + step)
    else:
        g_eden_ratio = max(EDEN_MIN, g_eden_ratio - step)

def _adapt_protected_ratio(cache_snapshot, direction, size_hint=0):
    global g_prot_ratio
    cap = max(1, int(cache_snapshot.capacity))
    step = 0.02 + min(0.10, 0.30 * (float(size_hint) / float(cap)))
    if direction > 0:
        g_prot_ratio = min(PROT_MAX, g_prot_ratio + step)
    else:
        g_prot_ratio = max(PROT_MIN, g_prot_ratio - step)


# -----------------------------
# Scoring and admission helpers
# -----------------------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_boost(now, last, window):
    if last is None:
        return 0.0
    age = max(0, now - last)
    # recent -> boost close to 1; old -> 0
    x = 1.0 if window <= 0 else max(0.0, 1.0 - min(1.0, float(age) / float(window)))
    return x

def _retention_score(cache_snapshot, key):
    # Higher score -> stronger retention; evict lowest score
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    freq = _lfu_peek(cache_snapshot, key)
    multi_bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    freq_term = (math.log2(1.0 + float(freq)) + multi_bonus) / size_norm

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    rec_term = _recency_boost(now, last, window)

    seg = m_segment.get(key, -1)
    base = 0.0
    if seg == 2:
        base += PROT_BASE_BONUS   # Protected gets extra shielding
    elif seg == 0:
        base -= EDEN_BASE_PENALTY # Eden is easier to evict if needed

    return base + FREQ_WEIGHT * freq_term + REC_WEIGHT * rec_term

def _pick_low_score(cache_snapshot, order, k_sample):
    if not order:
        return (None, None)
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            key = next(iter(order))
            return (key, _retention_score(cache_snapshot, key))
        except StopIteration:
            return (None, None)
    return (chosen_key, chosen_score)

def _promotion_threshold(size, capacity):
    # Size-aware promotion threshold (resident_hits must reach this value)
    frac = float(size) / float(capacity) if capacity > 0 else 0.0
    if frac >= 0.10:
        return 3  # large items need more confirmations
    elif frac >= 0.03:
        return 2  # medium items: one re-reference
    else:
        return 2  # small items: one re-reference to protect

def _incoming_freq_estimate(cache_snapshot, obj):
    # Estimate incoming object's frequency for admission comparison
    f = _lfu_peek(cache_snapshot, obj.key)
    # If seen in doorkeeper this epoch, give it +1 softness
    if _doorkeeper_seen(obj.key):
        f = min(15, f + 1)
    return f


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Evict with Window-TinyLFU bias:
      - Prefer evicting from Eden (window) unless the incoming object is
        clearly less frequent than a weak Main candidate.
      - Otherwise sample from Probation/Protected and evict the weakest score
        with a bias toward Probation.
    """
    _init_if_needed(cache_snapshot)

    # Candidates
    e_key = None
    e_score = None
    if eden_lru:
        # Eden LRU is at the left
        try:
            e_key = next(iter(eden_lru))
            e_score = _retention_score(cache_snapshot, e_key)
        except StopIteration:
            e_key = None
            e_score = None

    p_key, p_score = _pick_low_score(cache_snapshot, prob_lru, SAMPLE_K_PROB)
    f_key, f_score = _pick_low_score(cache_snapshot, prot_lru, SAMPLE_K_PROT)

    # If nothing available, fallback to any key
    if e_key is None and p_key is None and f_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Decide Main candidate
    if p_key is None and f_key is None:
        main_key = None
        main_score = None
    elif p_key is None:
        main_key, main_score = f_key, f_score
    elif f_key is None:
        main_key, main_score = p_key, p_score
    else:
        # Prefer Probation when similar
        if (p_score + PROB_BIAS_MARGIN) <= f_score:
            main_key, main_score = p_key, p_score
        else:
            main_key, main_score = f_key, f_score

    # If Eden exists, try TinyLFU admission bias relative to incoming object
    if e_key is not None:
        if main_key is None:
            # Only Eden available
            return e_key
        # Compare incoming's TinyLFU frequency vs main candidate's
        f_new = _incoming_freq_estimate(cache_snapshot, obj)
        f_victim = _lfu_peek(cache_snapshot, main_key)
        if f_new <= (f_victim + ADMIT_MARGIN):
            # Incoming is not stronger -> evict from Eden
            return e_key
        # Else, incoming is stronger -> prefer evicting the weak Main candidate
        # If scores indicate Eden is far weaker, still evict Eden
        if e_score is not None and main_score is not None and e_score < (main_score - PROB_BIAS_MARGIN):
            return e_key
        return main_key

    # No Eden candidate -> pick from Main
    if main_key is not None:
        return main_key

    # Fallback (shouldn't happen)
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access and resident hit count
      - Promote size-aware:
         * Eden -> Probation on threshold; Eden -> Protected if strongly multi-hit
         * Probation -> Protected on threshold
      - Maintain LRU positions
      - Demote Protected overflow to Probation to honor target
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k, amount=1)
    m_last_access[k] = cache_snapshot.access_count
    prev = m_resident_hits.get(k, 1)
    cur_hits = prev + 1
    m_resident_hits[k] = cur_hits

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked (rare): treat as insert into Eden
        _seg_insert_eden(k, obj.size)
        return

    th = _promotion_threshold(obj.size, cache_snapshot.capacity)

    if seg == 0:
        # Eden: keep recency; early admit on repeated hits
        if cur_hits >= th + 1:
            _seg_move_to_prot(cache_snapshot, k, obj.size)
        elif cur_hits >= th:
            _seg_move_to_prob(cache_snapshot, k, obj.size)
        else:
            _seg_touch_on_hit(cache_snapshot, k)
    elif seg == 1:
        if cur_hits >= th:
            _seg_move_to_prot(cache_snapshot, k, obj.size)
        else:
            _seg_touch_on_hit(cache_snapshot, k)
    else:
        _seg_touch_on_hit(cache_snapshot, k)
        # Keep Protected within target (already handled on promotions)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Doorkeeper: credit TinyLFU only if seen earlier in the epoch
      - Initialize resident metadata
      - Place into Eden MRU
      - Adapt Eden size and Protected/Probation split using ghost hits
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    # Doorkeeper: first sight in epoch -> record only; second+ -> credit LFU
    if _doorkeeper_touch(k):
        _lfu_inc(cache_snapshot, k, amount=1)

    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # Ghost-based adaptive tuning
    # Eden ghost hit -> increase Eden window
    if k in ghost_eden:
        ghost_eden.pop(k, None)
        _adapt_eden_ratio(cache_snapshot, direction=+1, size_hint=obj.size)
    # Main ghost hits -> decrease Eden (favor Main)
    if k in ghost_recent:
        ghost_recent.pop(k, None)
        _adapt_eden_ratio(cache_snapshot, direction=-1, size_hint=obj.size)
        # Also, recent-ghost -> shrink Protected (favor Probation)
        _adapt_protected_ratio(cache_snapshot, direction=-1, size_hint=obj.size)
    if k in ghost_frequent:
        ghost_frequent.pop(k, None)
        _adapt_eden_ratio(cache_snapshot, direction=-1, size_hint=obj.size)
        # Frequent-ghost -> grow Protected
        _adapt_protected_ratio(cache_snapshot, direction=+1, size_hint=obj.size)

    # New resident -> Eden MRU
    _seg_insert_eden(k, obj.size)

    # Soft pressure: if Eden is far above target, gently move oldest into Probation metadata
    # (This doesn't remove objects; it only reclassifies to shape future evictions.)
    eden_target = _eden_target_bytes(cache_snapshot)
    if seg_bytes_eden > eden_target and eden_lru:
        try:
            cand_key = next(iter(eden_lru))  # Eden LRU
            robj = cache_snapshot.cache.get(cand_key)
            if robj is not None:
                f_cand = _lfu_peek(cache_snapshot, cand_key)
                # Compare against weakest Probation sample to decide admission to Main
                p_key, _ = _pick_low_score(cache_snapshot, prob_lru, max(2, SAMPLE_K_PROB // 2))
                f_victim = _lfu_peek(cache_snapshot, p_key) if p_key is not None else -1
                if f_cand > f_victim:
                    _seg_move_to_prob(cache_snapshot, cand_key, robj.size)
                # else keep it in Eden; future evictions will trim Eden first
        except StopIteration:
            pass

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove from resident structures and clear resident-only metadata
      - Keep TinyLFU counters for future admission
      - Record key into appropriate ghost list and adapt list sizes
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    seg = m_segment.get(ek, None)
    _seg_remove(cache_snapshot, ek, evicted_obj.size)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # keep m_lfu_count[ek] to inform admission

    limit = _ghost_limit(cache_snapshot)
    if seg == 0:
        _ghost_add(ghost_eden, ek, limit)
    elif seg == 1:
        _ghost_add(ghost_recent, ek, limit)
    elif seg == 2:
        _ghost_add(ghost_frequent, ek, limit)
```
2025-11-27 22:43:06,382 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# SLRU + TinyLFU + Size-aware sampled eviction (fast and high hit-rate)
# - Two resident segments with byte quotas:
#     Probation (new/once-hit) and Protected (multi-hit)
# - O(1) updates on hit/insert via OrderedDict LRU queues
# - Eviction chooses from Probation first (SLRU), falls back to Protected
# - Within the chosen segment, select victim by sampling a few oldest keys
#   and picking the smallest TinyLFU-Recency-Size score (no full scan)
# - TinyLFU sketch with lazy epoch decay (4-bit counters) tracks popularity
# - Metadata survives evictions where useful (TinyLFU); resident-only info removed

import math
from collections import OrderedDict

# -----------------------------
# Global metadata
# -----------------------------

# Segmented LRU structures (byte-aware)
PROTECTED_RATIO = 0.80        # fraction of capacity reserved for Protected
SAMPLE_K_PROB = 6             # candidates sampled from Probation on eviction
SAMPLE_K_PROT = 4             # candidates sampled from Protected on eviction

prob_lru = OrderedDict()      # key -> None (LRU on left, MRU on right)
prot_lru = OrderedDict()      # key -> None
seg_bytes_prob = 0            # total bytes in Probation
seg_bytes_prot = 0            # total bytes in Protected
m_segment = dict()            # key -> 0 (probation) or 1 (protected)

# Per-key resident metadata
m_last_access = dict()        # key -> int time (for recency scoring)
m_resident_hits = dict()      # key -> int (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Scoring tunables (robust defaults)
REC_WIN_MIN = 1000
REC_WIN_MULT = 4
REC_WEIGHT = 0.25
MULTI_HIT_BONUS = 0.35

# -----------------------------
# Init / TinyLFU helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Segment helpers
# -----------------------------

def _prot_target_bytes(cache_snapshot):
    try:
        return max(0, int(cache_snapshot.capacity * PROTECTED_RATIO))
    except Exception:
        return 0

def _seg_insert_prob(key, size):
    global seg_bytes_prob
    if m_segment.get(key) == 0:
        # refresh MRU
        prob_lru.pop(key, None)
        prob_lru[key] = None
        return
    if m_segment.get(key) == 1:
        # remove from protected first (shouldn't happen on insert)
        prot_lru.pop(key, None)
        global seg_bytes_prot
        seg_bytes_prot -= size
    m_segment[key] = 0
    prob_lru[key] = None
    seg_bytes_prob += size

def _seg_move_to_prot(cache_snapshot, key, size):
    # Move key to Protected MRU
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 1:
        # already in protected: refresh MRU
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    # remove from probation if present
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    # insert into protected
    m_segment[key] = 1
    prot_lru[key] = None
    seg_bytes_prot += size

    # Demote from protected to probation if protected exceeds target
    target = _prot_target_bytes(cache_snapshot)
    while seg_bytes_prot > target and prot_lru:
        # Demote LRU of protected into probation MRU (not evict)
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        seg_bytes_prot -= dsize

        # place into probation MRU if still resident
        if robj is not None:
            prob_lru[dem_key] = None
            seg_bytes_prob += dsize
            m_segment[dem_key] = 0
        else:
            m_segment.pop(dem_key, None)  # no longer resident; clean

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _seg_remove(cache_snapshot, key, size):
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 1:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        # unknown; ensure not lingering
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _retention_score(cache_snapshot, key):
    # Lower score -> weaker retention -> better eviction candidate
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    return benefit - recency_gain

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    # Iterate the oldest k_sample keys in 'order' and return the min-score key
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    # Fallback in case of issues
    if chosen_key is None:
        try:
            return next(iter(order))
        except StopIteration:
            return None
    return chosen_key

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Evict using SLRU: choose from Probation first; if empty, from Protected.
    Within the chosen segment, sample a few LRU-ordered keys and evict the
    one with the smallest TinyLFU-Recency-Size score.
    """
    _init_if_needed(cache_snapshot)

    # Prefer evicting from Probation (new/weak items)
    if prob_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
        return victim

    # Fall back to Protected if Probation empty
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)
        return victim

    # As a last resort, evict any key
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access time and resident hit count
      - Promote from Probation to Protected (SLRU) on first hit
      - Refresh LRU position within its segment
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked (shouldn't happen on a hit); insert into Probation
        _seg_insert_prob(k, obj.size)
        return

    if seg == 0:
        # Promote on first hit (classic SLRU)
        _seg_move_to_prot(cache_snapshot, k, obj.size)
    else:
        # Touch protected
        _seg_touch_on_hit(cache_snapshot, k)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU counter
      - Initialize resident metadata
      - Place into Probation MRU
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # New resident goes to Probation MRU
    _seg_insert_prob(k, obj.size)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata and from segment structures
      - Keep TinyLFU counters to remember popularity of non-residents
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    _seg_remove(cache_snapshot, ek, evicted_obj.size)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Keep m_lfu_count[ek] for future admission/eviction decisions
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 23
- Hit Rate: 0.0593

Example 2:
- Trace ID: 12
- Hit Rate: 0.0423

Example 3:
- Trace ID: 32
- Hit Rate: 0.0878

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:43:06 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:43:06,383 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:46:36 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:46:36,789 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:46:36,790 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Windowed SLRU + TinyLFU + ARC-style adaptation + size-aware sampled eviction
# - Three resident segments (by bytes):
#     Window (very recent), Probation (main new/once-hit), Protected (multi-hit)
# - Eviction order: Window -> Probation -> Protected (minimize main churn)
# - TinyLFU counts (lazy decay) guide which among the oldest to evict (sampled)
# - Size-aware scoring (prefer keeping tiny but hot objects)
# - ARC-like ghost lists dynamically adapt Protected target size (bytes)
# - O(1) updates on hit/insert via OrderedDict LRU queues

import math
from collections import OrderedDict

# ---------------
# Globals
# ---------------

# LRU queues (LRU at left, MRU at right)
win_lru = OrderedDict()   # 0: Window segment (recent)
prob_lru = OrderedDict()  # 1: Probation (main new/once-hit)
prot_lru = OrderedDict()  # 2: Protected (multi-hit)

# Bytes accounting
win_bytes = 0
prob_bytes = 0
prot_bytes = 0

# Resident segment mapping: key -> seg_id {0:win, 1:prob, 2:prot}
m_segment = dict()

# Per-key resident metadata
m_last_access = dict()      # key -> int time
m_resident_hits = dict()    # key -> int

# TinyLFU: 4-bit counters with lazy decay
m_lfu_count = dict()        # key -> (count[0..15], epoch)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Dynamic targets (bytes)
g_prot_target_bytes = 0     # dynamically tuned protected target
g_win_target_bytes = 0      # small window target
g_last_cap = 0

# Ghost lists for ARC-style adaptation (bytes-limited)
ghost_prob = OrderedDict()  # keys evicted from Window/Probation
ghost_prot = OrderedDict()  # keys evicted from Protected
ghost_prob_bytes = 0
ghost_prot_bytes = 0

# Scoring / sampling
SAMPLE_K_WIN = 5
SAMPLE_K_PROB = 6
SAMPLE_K_PROT = 4

# Multi-hit bonus in score
MULTI_HIT_BONUS = 0.5

# ---------------
# Helpers: init / targets / lfu
# ---------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    global g_last_cap, g_prot_target_bytes, g_win_target_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = max(1, int(cache_snapshot.capacity))
    if g_last_cap != cap or g_prot_target_bytes == 0 or g_win_target_bytes == 0:
        g_last_cap = cap
        # Start conservatively: small window, large protected
        g_win_target_bytes = max(1, int(cap * 0.05))
        g_prot_target_bytes = max(1, int(cap * 0.70))

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _cap_bytes(cache_snapshot):
    return max(1, int(cache_snapshot.capacity))

# ---------------
# Ghost lists and adaptation (ARC-like)
# ---------------

def _ghost_cap(cache_snapshot):
    # Total bytes allowed for each ghost list (soft bound)
    return _cap_bytes(cache_snapshot)

def _ghost_add(cache_snapshot, seg_id, key, size):
    # Evicted from which segment? 0/1 -> ghost_prob, 2 -> ghost_prot
    global ghost_prob_bytes, ghost_prot_bytes
    if seg_id == 2:
        if key in ghost_prot:
            old = ghost_prot.pop(key)
            ghost_prot_bytes -= old
        ghost_prot[key] = size
        ghost_prot_bytes += size
        # Trim
        cap = _ghost_cap(cache_snapshot)
        while ghost_prot_bytes > cap and ghost_prot:
            k, s = ghost_prot.popitem(last=False)
            ghost_prot_bytes -= s
    else:
        if key in ghost_prob:
            old = ghost_prob.pop(key)
            ghost_prob_bytes -= old
        ghost_prob[key] = size
        ghost_prob_bytes += size
        cap = _ghost_cap(cache_snapshot)
        while ghost_prob_bytes > cap and ghost_prob:
            k, s = ghost_prob.popitem(last=False)
            ghost_prob_bytes -= s

def _adapt_prot_target(cache_snapshot, delta_bytes):
    global g_prot_target_bytes
    cap = _cap_bytes(cache_snapshot)
    # Bounds: leave at least 5% for window + 5% for probation, at most 90% for protected
    min_prot = int(cap * 0.10)
    max_prot = int(cap * 0.90)
    g_prot_target_bytes = max(min_prot, min(max_prot, g_prot_target_bytes + int(delta_bytes)))

def _adapt_on_ghost_ref(cache_snapshot, key):
    # If the incoming key was recently in a ghost list, adapt protected target
    if key in ghost_prot:
        # We previously kept it hot; increase protected to favor long-term
        s = ghost_prot.get(key, 0)
        _adapt_prot_target(cache_snapshot, max(1, s))
        # Move to MRU in ghost (recency)
        ghost_prot.move_to_end(key, last=True)
    elif key in ghost_prob:
        # Previously evicted from probation/window -> favor recency by shrinking protected
        s = ghost_prob.get(key, 0)
        _adapt_prot_target(cache_snapshot, -max(1, s // 2))
        ghost_prob.move_to_end(key, last=True)

# ---------------
# Segment helpers
# ---------------

def _seg_remove(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    else:
        # clean up any remnants
        win_lru.pop(key, None)
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)
    return seg

def _seg_insert_win(key, size):
    global win_bytes
    # ensure not in others
    if m_segment.get(key) == 0:
        # refresh MRU
        win_lru.pop(key, None)
        win_lru[key] = None
        return
    # Remove from other lists if present
    if m_segment.get(key) == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            global prob_bytes
            prob_bytes -= size
    if m_segment.get(key) == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            global prot_bytes
            prot_bytes -= size
    m_segment[key] = 0
    win_lru[key] = None
    win_bytes += size

def _seg_move_to_prob(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 1:
        # refresh MRU
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    if seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    prob_lru[key] = None
    m_segment[key] = 1
    prob_bytes += size

def _demote_prot_if_needed(cache_snapshot):
    # Demote from protected to probation until within target
    global prot_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(0, min(g_prot_target_bytes, cap))
    while prot_bytes > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        prot_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _trim_window_if_needed(cache_snapshot):
    # Keep window near its target by moving oldest window entries to probation (not evict)
    global win_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(1, min(g_win_target_bytes, cap))
    # Allow a little slack to avoid churn
    slack = max(1, target // 8)
    while win_bytes > (target + slack) and win_lru:
        dem_key, _ = win_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        win_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _seg_move_to_prot(cache_snapshot, key, size):
    # Promote to Protected MRU
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 2:
        # refresh MRU
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    prot_lru[key] = None
    m_segment[key] = 2
    prot_bytes += size
    _demote_prot_if_needed(cache_snapshot)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

# ---------------
# Scoring helpers
# ---------------

def _normalized_size(size, capacity):
    # size as percentage of capacity, keep >= small epsilon
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _retention_score(cache_snapshot, key):
    # Higher score = stronger retention; eviction picks smallest score
    cap = _cap_bytes(cache_snapshot)
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size
    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)
    bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    # Size-aware benefit with gentle diminishing returns on frequency
    benefit = (math.log2(1.0 + float(freq)) + bonus) / size_norm
    return benefit

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    # sample k oldest
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            return next(iter(order))
        except StopIteration:
            return None
    return chosen_key

# ---------------
# Policy entry points
# ---------------

def evict(cache_snapshot, obj):
    """
    Eviction strategy:
      - Prefer evicting from Window first to shield main cache (2Q-style)
      - Then from Probation, finally Protected
      - Within a segment, sample a few oldest and evict the one with the lowest
        TinyLFU size-aware score.
    """
    _init_if_needed(cache_snapshot)

    # Choose from Window first (admission filter / reduces main churn)
    if win_lru:
        victim = _pick_candidate_from_order(cache_snapshot, win_lru, SAMPLE_K_WIN)
        return victim

    # Then from Probation
    if prob_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
        return victim

    # Fallback to Protected if others empty
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)
        return victim

    # Last resort
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access and resident hit count
      - Promote to Protected if in Window/Probation
      - Refresh LRU position within its segment
      - Adapt Protected target: increase on Probation hits, slightly decrease on Protected hits
      - Trim Window toward its target
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked; place into Window
        _seg_insert_win(k, obj.size)
        _trim_window_if_needed(cache_snapshot)
        return

    if seg == 0 or seg == 1:
        # Hit in Window or Probation -> promote to Protected
        _seg_move_to_prot(cache_snapshot, k, obj.size)
        # Adapt: probation/window hit means protected was too small -> grow
        step = max(1, obj.size // 2)
        _adapt_prot_target(cache_snapshot, step)
    else:
        # Protected hit: touch and slightly shrink target to allow more probation
        _seg_touch_on_hit(cache_snapshot, k)
        step = max(1, obj.size // 8)
        _adapt_prot_target(cache_snapshot, -step)

    # Keep window near target
    _trim_window_if_needed(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU for the key (admission learns from requests)
      - Adjust Protected target using ARC-like ghost feedback
      - Initialize resident metadata and place into Window MRU
      - Gently trim Window toward its target (migrate oldest to Probation)
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # ARC-like adaptation using ghost information
    _adapt_on_ghost_ref(cache_snapshot, k)

    # New resident enters Window MRU
    _seg_insert_win(k, obj.size)
    _trim_window_if_needed(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove it from segment structures and resident-only metadata
      - Record into ghost lists for ARC-style adaptation
      - Keep TinyLFU counts to inform future decisions
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = evicted_obj.size

    # Identify segment before removal (for ghost list)
    seg_before = m_segment.get(ek, 1)
    _seg_remove(cache_snapshot, ek, esize)

    # Resident-only metadata cleanup
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # Remember in ghost for adaptation
    _ghost_add(cache_snapshot, seg_before, ek, esize)
```
2025-11-27 22:48:52,366 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Policy: HALO-TFSv2 — Heap-Accelerated LFU with Recency, Freshness, and Gap Prediction
# Key improvements over previous version:
# - Stronger recency sensitivity with adaptive windowing
# - Do not credit LFU on cold insert (reduces one-timer pollution)
# - Per-key EWMA of inter-arrival gaps to predict time-to-next access
# - Fresh-insert "grace" multiplier to avoid immediate churn
# - Multi-hit protection is stronger and starts after the second hit
# - Bounded-rescan victim search for better choices without full scans

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_birth_ts = dict()         # key -> int access_count at insertion
m_resident_hits = dict()    # key -> int resident hit count (starts at 0 on insert)
m_gap_ewma = dict()         # key -> float ≈ EWMA of inter-arrival gap while resident

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 2048   # faster adaptation to workload shifts
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192
HEAP_GROWTH_FACTOR = 4

# Tunables for scoring
SIZE_ALPHA = 0.80               # size normalization exponent; favors small objects
REC_WIN_MIN = 64                # minimum recency window in accesses
REC_WIN_MULT = 6                # recency window ~ REC_WIN_MULT * resident_items
FREQ_WEIGHT = 1.00              # weight of frequency (TinyLFU)
REC_WEIGHT = 1.10               # weight of observed recency
PRED_WEIGHT = 0.90              # weight of predicted return risk (via gap EWMA)
MH_MULT = 1.50                  # multiplicative boost after >=2 resident hits
FRESH_GRACE = 128               # accesses; grace period after insert
FRESH_MULT = 1.30               # multiplicative boost during grace
GAP_BETA = 0.30                 # EWMA smoothing factor for inter-arrival gap

# Victim selection
RESCAN_LIMIT = 12               # bounded extra pops from heap to improve victim choice


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # decay is applied lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)


def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _predicted_risk(now, last, gap_ewma, window):
    # Predict time-to-next using EWMA gap. Convert to risk in (0,1].
    if last is None or last < 0 or gap_ewma is None or gap_ewma <= 0.0:
        return 0.0
    age = max(0, now - last)
    ttn = gap_ewma - age  # time until next (can be <= 0 if due/overdue)
    # Map to (0,1], ≈1 when due/overdue, smaller when far in future
    return 1.0 / (1.0 + (max(0.0, ttn) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency and predicted risk
    window = _recency_window(cache_snapshot)
    r_term = _recency_term(now, m_last_access.get(key), window)
    p_term = _predicted_risk(now, m_last_access.get(key), m_gap_ewma.get(key), window)

    # Freshness and multi-hit multipliers
    birth = m_birth_ts.get(key)
    fresh = (1.0 if birth is None else (FRESH_MULT if (now - birth) <= FRESH_GRACE else 1.0))
    mhits = m_resident_hits.get(key, 0)
    mh_mult = (MH_MULT if mhits >= 2 else 1.0)

    # Final score: combine, then size-normalize, then apply multiplicative boosts
    base = (FREQ_WEIGHT * f_term) + (REC_WEIGHT * r_term) + (PRED_WEIGHT * p_term)
    score = (base / size_norm) * fresh * mh_mult
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    - Seed heap on first use
    - Pop and validate entries lazily (versioning)
    - Recompute scores to reflect latest epochs and metadata
    - Bounded rescan: consider a small set of candidates and pick the weakest
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            # Initialize missing resident metadata best-effort
            m_last_access.setdefault(k, cache_snapshot.access_count)
            m_birth_ts.setdefault(k, cache_snapshot.access_count)
            m_resident_hits.setdefault(k, 0)
            m_gap_ewma.setdefault(k, float(_recency_window(cache_snapshot)))
            _heap_push(cache_snapshot, k)

    # Bounded rescan to find the weakest valid candidate
    best_key = None
    best_tuple = None  # (adjusted_score, score_tuple)
    considered = []

    attempts = 0
    while attempts < RESCAN_LIMIT and m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            attempts += 1
            continue
        # Skip if stale heap entry
        if m_ver.get(k, 0) != v:
            attempts += 1
            continue
        # Recompute current score (reflect decay/window/metadata changes)
        cur_sc = _score_key(cache_snapshot, k)
        # If score drifted upward, reinsert with new score
        if cur_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            attempts += 1
            continue

        # Track the weakest (lowest score) candidate
        adj_sc = cur_sc  # adjustment slots available if needed later
        if (best_tuple is None) or (adj_sc < best_tuple[0]):
            best_key = k
            best_tuple = (adj_sc, (sc, last, k, v))
        considered.append((sc, last, k, v))
        attempts += 1

    # Push back all considered entries except the chosen victim
    for tup in considered:
        if best_tuple is not None and tup[2] == best_key:
            continue
        heapq.heappush(m_heap, tup)

    # Fallbacks
    if best_key is not None:
        return best_key

    # If heap is exhausted or empty, choose the oldest resident
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Update EWMA of inter-arrival gap
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Update frequency only on hits (not on cold insert)
    _lfu_inc(cache_snapshot, k)

    # Update inter-arrival EWMA
    prev = m_last_access.get(k)
    if prev is not None:
        gap = max(1.0, float(now - prev))
        old = m_gap_ewma.get(k)
        if old is None or old <= 0.0:
            m_gap_ewma[k] = gap
        else:
            m_gap_ewma[k] = (1.0 - GAP_BETA) * old + GAP_BETA * gap
    else:
        # Initialize conservatively
        m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    # Hits: increment resident hits
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # Refresh timestamps
    m_last_access[k] = now

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch
      - Do NOT increment LFU on cold insert (reduces one-timer pollution)
      - Initialize resident metadata: last_access, birth_ts, resident_hits = 0
      - Initialize EWMA gap conservatively to recency window
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # No _lfu_inc here: cold items must earn credit by hitting

    m_last_access[k] = now
    m_birth_ts[k] = now
    m_resident_hits[k] = 0
    m_gap_ewma[k] = float(_recency_window(cache_snapshot))

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember popularity)
      - Invalidate its heap version (stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_birth_ts.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_gap_ewma.pop(ek, None)
    m_ver.pop(ek, None)

    _touch_and_maybe_rebuild(cache_snapshot)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 37
- Hit Rate: 0.628

Example 2:
- Trace ID: 40
- Hit Rate: 0.0635

Example 3:
- Trace ID: 20
- Hit Rate: 0.414

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:48:52 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:48:52,367 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:51:03 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:51:03,015 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:51:03,016 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Policy: GD-TinyLFU — GreedyDual with Size-Aware TinyLFU Promotion
# Goals:
# - Strong scan resistance: new items get minimal priority, evicted quickly if they don't hit
# - Robust across mixes: TinyLFU guides promotion; multi-hit objects get strong protection
# - Size-aware: large objects need more evidence; small objects are favored
# - Simple, fast victim selection: pure GreedyDual with a min-heap and lazy invalidation

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp (last touch)
m_resident_hits = dict()    # key -> int resident hit count (starts at 0 on insert)

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 1024   # faster adaptation to workload shifts
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# GreedyDual state
m_heap = []                 # min-heap of (priority, seq, key, version)
m_ver = dict()              # key -> current version to invalidate stale heap entries
m_prio = dict()             # key -> last assigned priority (L + base_value)
m_age_L = 0.0               # GreedyDual "age" (raises on every eviction)
m_seq = 0                   # tie-breaker for heap stability

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192
HEAP_GROWTH_FACTOR = 4

# Tunables
SIZE_ALPHA = 0.85           # size normalization exponent; favors small objects
BIG_PENALTY = 3.0           # extra penalty for large objects relative to capacity
FREQ_WEIGHT = 1.25          # weight of frequency (TinyLFU)
REC_WEIGHT = 0.40           # small short-term recency boost on hit
ONE_HIT_BONUS = 0.70        # small bonus after first resident hit
MH_BONUS = 2.20             # strong bonus after >=2 resident hits
BASE_EPS = 0.02             # base priority on cold insert (per size-normalized unit)

REC_WIN_MIN = 64            # minimum recency window in accesses
REC_WIN_MULT = 6            # recency window ≈ REC_WIN_MULT * resident_items (for REC_WEIGHT)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # decay is applied lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers (GreedyDual)
# -----------------------------

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)


def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _size_norm(cache_snapshot, size):
    # Size normalization with extra penalty for very large items
    size = max(1.0, float(size))
    norm = size ** SIZE_ALPHA
    cap = max(1.0, float(cache_snapshot.capacity))
    frac = size / cap
    norm *= (1.0 + BIG_PENALTY * frac)
    return norm


def _base_value(cache_snapshot, key, is_hit_context):
    """
    Compute the size-normalized "benefit" part (without L) for a key.
    Higher value => more protected.
    """
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return 0.0
    now = cache_snapshot.access_count

    size_factor = _size_norm(cache_snapshot, obj.size)

    # Frequency (decayed) via TinyLFU
    freq = _lfu_peek(cache_snapshot, key)
    f_term = FREQ_WEIGHT * math.log1p(float(freq))

    # Small recency boost only when we are in hit context (avoid helping one-timers)
    r_term = 0.0
    if is_hit_context:
        window = _recency_window(cache_snapshot)
        r_term = REC_WEIGHT * _recency_term(now, m_last_access.get(key), window)

    # Multi-hit bonuses
    mh = m_resident_hits.get(key, 0)
    mh_bonus = 0.0
    if mh >= 2:
        mh_bonus = MH_BONUS
    elif mh == 1:
        mh_bonus = ONE_HIT_BONUS

    base = f_term + r_term + mh_bonus
    # Ensure non-zero minimal utility (protects tiny items slightly)
    base = max(base, BASE_EPS)

    return base / size_factor


def _assign_priority(cache_snapshot, key, is_hit_context):
    """
    Assign a new GreedyDual priority to key and push to heap.
    """
    global m_seq
    base_val = _base_value(cache_snapshot, key, is_hit_context)
    pr = m_age_L + base_val
    m_prio[key] = pr

    v = m_ver.get(key, 0) + 1
    m_ver[key] = v

    m_seq += 1
    heapq.heappush(m_heap, (pr, m_seq, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """
    Rebuild heap when it grows too large due to stale entries.
    """
    global m_heap, m_seq
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    new_heap = []
    m_seq = 0
    for k in cache_snapshot.cache.keys():
        pr = m_prio.get(k)
        if pr is None:
            # Initialize conservatively if missing (cold)
            _assign_priority(cache_snapshot, k, is_hit_context=False)
            pr = m_prio.get(k, m_age_L + BASE_EPS)
        v = m_ver.get(k, 0)
        m_seq += 1
        new_heap.append((pr, m_seq, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    GreedyDual victim selection:
      - Pop the minimum priority resident with a valid version
      - Advance global age L to the popped priority (classic GD invariant)
      - Return the key as victim
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (bootstrap), seed with current residents using cold priorities
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            # Initialize missing resident metadata best-effort
            m_last_access.setdefault(k, cache_snapshot.access_count)
            m_resident_hits.setdefault(k, 0)
            _assign_priority(cache_snapshot, k, is_hit_context=False)

    # Pop until we find a valid resident with a fresh version
    while m_heap:
        pr, _, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            continue
        # Skip if stale heap entry
        if m_ver.get(k, 0) != v:
            continue
        # Found a valid victim; advance GD age and return
        global m_age_L
        m_age_L = max(m_age_L, pr)
        return k

    # Fallback: choose the oldest resident by last access if heap exhausted
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU
      - Increment resident hit count
      - Refresh last-access time
      - Assign a new GD priority (L + base value) and push to heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Hits: increment resident hits
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # Refresh timestamps
    m_last_access[k] = now

    _assign_priority(cache_snapshot, k, is_hit_context=True)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch
      - Do NOT increment LFU on cold insert (one-timers get no credit)
      - Initialize resident metadata: last_access, resident_hits = 0
      - Assign a low GD priority (L + small base value scaled by size)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    m_last_access[k] = now
    m_resident_hits[k] = 0

    _assign_priority(cache_snapshot, k, is_hit_context=False)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember popularity)
      - Invalidate its heap version (stale heap entries will be skipped)
      - Heap cleanup is handled lazily and by periodic rebuilds
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_prio.pop(ek, None)
    m_ver.pop(ek, None)

    _touch_and_maybe_rebuild(cache_snapshot)
```
2025-11-27 22:51:33,824 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 17
- Error: Error - Timeout

Example 2:
- Trace ID: 6
- Hit Rate: 0.2775

Example 3:
- Trace ID: 13
- Error: Error - Timeout

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:51:33 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:51:33,827 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:54:21 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:54:21,099 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:54:21,100 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Fast Size-Aware Segmented LRU with TinyLFU (F-SA-SLRU)
# Goals:
#   - Avoid O(n) scans during evictions (fix timeouts)
#   - Keep good hit rates via two segments (probation/protected)
#   - Be size-aware (penalize large objects), and frequency-aware (TinyLFU)
#   - Promote conservatively (avoid promoting large, single-hit items)
#   - Dynamically adapt protected fraction using a lightweight EWMA of where hits occur

from collections import OrderedDict

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Two LRU segments (keys only); newest at the right (end), oldest at the left (front)
g_probation_lru = OrderedDict()
g_protected_lru = OrderedDict()

# Segment bookkeeping and resident metadata
m_segment = dict()        # key -> 0 probation, 1 protected
m_resident_hits = dict()  # key -> int resident-hit count (starts at 0 on insert)

# Protected size tracking
g_protected_bytes = 0

# TinyLFU sketch (lazy-decayed per-key 4-bit counters)
m_lfu_count = dict()      # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # accesses per epoch; power-of-two recommended

# Scoring / behavior tunables
SIZE_ALPHA = 1.05          # base size penalty exponent; higher penalizes large items more
PROMOTE_MIN_HITS = 1       # minimum resident hits to consider promotion
PROMOTE_LFU_THRESH = 2     # or LFU count threshold to allow early promotion
BIG_ITEM_PROMOTE_HITS = 2  # big items must reach this many hits to promote

SAMPLE_SIZE = 16           # number of LRU-tail candidates to consider when evicting
DEMOTE_BATCH = 2           # max items to demote from protected per eviction call

# Adaptive protected target (fraction of capacity by bytes), driven by where hits occur
g_protected_target_fraction = 0.75
HIT_SHARE_EMA = 0.02       # step for EWMA of "hit was in protected" share
g_hit_share_ema = 0.5      # EWMA state

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # saturating 4-bit counter
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _protected_target_bytes(cache_snapshot):
    cap = cache_snapshot.capacity
    frac = max(0.20, min(0.90, g_protected_target_fraction))
    return int(frac * float(cap))

def _normalized_size(size, capacity):
    return max(1e-12, float(size) / float(capacity))

def _alpha_for_incoming(obj, capacity):
    # Slightly favor evicting larger victims when incoming object is large
    if obj is None:
        return SIZE_ALPHA
    rel = _normalized_size(obj.size, capacity)
    # Increase alpha up to +0.6 when incoming is near whole cache
    return SIZE_ALPHA + 0.6 * min(1.0, rel)

def _seg_of(key):
    return 1 if m_segment.get(key, 0) == 1 else 0

def _ensure_in_segment_structures(key):
    # If our internal LRU sets missed this key (e.g., during warmup), default to probation
    if key in g_probation_lru or key in g_protected_lru:
        return
    g_probation_lru[key] = None
    m_segment[key] = 0
    m_resident_hits.setdefault(key, 0)

def _rebalance_protected(cache_snapshot, max_steps=DEMOTE_BATCH):
    # If protected exceeds its target, demote oldest protected items to probation (LRU)
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    steps = 0
    while g_protected_bytes > target and g_protected_lru and steps < max_steps:
        # Demote LRU from protected to probation
        k_demote, _ = g_protected_lru.popitem(last=False)
        obj = cache_snapshot.cache.get(k_demote)
        if obj is not None:
            g_protected_bytes = max(0, g_protected_bytes - obj.size)
        # Place at MRU of probation (freshly demoted)
        g_probation_lru[k_demote] = None
        m_segment[k_demote] = 0
        steps += 1

def _sample_from_lru(odict, n):
    # Return up to n oldest keys from an OrderedDict without altering it
    out = []
    cnt = 0
    for k in odict.keys():
        out.append(k)
        cnt += 1
        if cnt >= n:
            break
    return out

def _evict_score(cache_snapshot, key, seg, alpha):
    # Larger score = stronger retention; we evict the smallest score
    # Use TinyLFU + resident hit bonus per size penalty
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')
    cap = cache_snapshot.capacity
    size_penalty = (_normalized_size(obj.size, cap)) ** alpha

    freq = float(_lfu_peek(cache_snapshot, key))
    rh = m_resident_hits.get(key, 0)

    # Segment/hit bonuses: protected and multi-hit items get extra credit
    bonus = 0.0
    if seg == 1:
        bonus += 1.0
    if rh >= 1:
        bonus += 0.6
    if rh >= 2:
        bonus += 0.6

    return (freq + bonus) / size_penalty

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose a victim key:
      - Maintain protected near its target by demoting some oldest protected
      - Prefer evicting from probation; if empty, use protected
      - Within a segment, consider a small sample of oldest keys and evict the one with
        the smallest score: (TinyLFU + multi-hit bonus)/size^alpha
      - Alpha increases slightly when incoming object is large to prefer evicting large victims
    """
    _init_if_needed(cache_snapshot)

    # Rebalance protected if oversized
    _rebalance_protected(cache_snapshot, max_steps=DEMOTE_BATCH)

    alpha = _alpha_for_incoming(obj, cache_snapshot.capacity)

    # Select segment to evict from
    segment_to_use = 0 if g_probation_lru else 1
    if segment_to_use == 0:
        candidates = _sample_from_lru(g_probation_lru, SAMPLE_SIZE)
    else:
        candidates = _sample_from_lru(g_protected_lru, SAMPLE_SIZE)
        if not candidates and g_probation_lru:
            # Fallback if protected empty
            candidates = _sample_from_lru(g_probation_lru, SAMPLE_SIZE)
            segment_to_use = 0

    if not candidates:
        # Final fallback: if our structures are out-of-sync, evict arbitrary resident
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Pick weakest candidate
    best_k = None
    best_score = None
    for k in candidates:
        seg = _seg_of(k) if segment_to_use is None else segment_to_use
        score = _evict_score(cache_snapshot, k, seg, alpha)
        if (best_score is None) or (score < best_score):
            best_score = score
            best_k = k

    # As a last guard, if best_k somehow vanished (race), pick arbitrary
    if best_k is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return best_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU count
      - Update resident hit count
      - Move key to MRU of its current segment
      - Promote probation -> protected if it has enough evidence (hits or LFU)
      - Adapt protected target fraction using EWMA of protected-hit share
      - Demote from protected if its bytes exceed target (bounded batch)
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)

    # Ensure key is tracked in segment LRUs (defensive)
    _ensure_in_segment_structures(k)

    # Update hits
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # Adapt protected target fraction based on where hits occur (EWMA of share)
    global g_hit_share_ema, g_protected_target_fraction
    seg = _seg_of(k)
    g_hit_share_ema = (1.0 - HIT_SHARE_EMA) * g_hit_share_ema + HIT_SHARE_EMA * (1.0 if seg == 1 else 0.0)
    # Map share in [0,1] to fraction in [0.3,0.9] with center around 0.6
    g_protected_target_fraction = 0.3 + 0.6 * g_hit_share_ema

    # Segment-specific handling
    if seg == 1:
        # Protected: bump to MRU
        if k in g_protected_lru:
            g_protected_lru.move_to_end(k, last=True)
        else:
            # Defensive: if missing, add to protected
            g_protected_lru[k] = None
            if k in g_probation_lru:
                g_probation_lru.pop(k, None)
            # Account bytes
            global g_protected_bytes
            g_protected_bytes += obj.size
            m_segment[k] = 1
    else:
        # Probation: bump to MRU
        if k in g_probation_lru:
            g_probation_lru.move_to_end(k, last=True)
        else:
            g_probation_lru[k] = None
        # Consider promotion
        cap = cache_snapshot.capacity
        is_big = obj.size >= 0.1 * cap
        hits_needed = BIG_ITEM_PROMOTE_HITS if is_big else PROMOTE_MIN_HITS
        lfu_now = _lfu_peek(cache_snapshot, k)
        if (m_resident_hits.get(k, 0) >= hits_needed) or (lfu_now >= PROMOTE_LFU_THRESH):
            # Promote to protected
            if k in g_probation_lru:
                g_probation_lru.pop(k, None)
            g_protected_lru[k] = None  # MRU
            m_segment[k] = 1
            global g_protected_bytes
            g_protected_bytes += obj.size

    # Enforce protected target
    _rebalance_protected(cache_snapshot, max_steps=DEMOTE_BATCH)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Increment TinyLFU for the key
      - Initialize resident metadata:
          * segment = probation
          * resident_hits = 0
          * place at MRU of probation
      - No change to protected bytes
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)

    # Initialize resident metadata
    m_segment[k] = 0
    m_resident_hits[k] = 0

    # Place in probation MRU
    # If it already exists in our structures (rare), normalize to probation MRU
    if k in g_protected_lru:
        # Shouldn't normally happen on insert; correct it defensively
        g_protected_lru.pop(k, None)
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    g_probation_lru[k] = None  # MRU by insertion order


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove from the appropriate LRU segment and metadata
      - Maintain protected bytes accounting (if it was protected)
      - Keep TinyLFU counters (do not delete)
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Remove from segment structures
    if ek in g_protected_lru:
        g_protected_lru.pop(ek, None)
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)
    else:
        g_probation_lru.pop(ek, None)

    # Remove resident-only metadata
    m_segment.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # TinyLFU count retained across evictions
```
2025-11-27 22:54:38,607 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 29
- Hit Rate: 0.0386

Example 2:
- Trace ID: 14
- Hit Rate: 0.0227

Example 3:
- Trace ID: 9
- Hit Rate: 0.531

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:54:38 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:54:38,608 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m22:57:37 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 22:57:37,516 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 22:57:37,517 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Windowed + Segmented Size-Aware TinyLFU (W-SS-TinyLFU)
# - Three resident segments (by bytes):
#     0: window (pure recency, LRU). New items land here. Evict here first when oversized.
#     1: probation (main): items promoted here from window on first hit.
#     2: protected (main): promoted from probation on subsequent hit; shielded unless oversized.
# - Eviction:
#     * Keep protected <= target by demoting oldest protected to probation (metadata change).
#     * If window > target: evict its LRU.
#     * Else prefer evicting from probation (lowest retention score).
#     * Fallbacks: window LRU (if any) else protected (lowest retention score).
# - Retention score blends:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (probation > protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions and byte accounting.

import math

# -----------------------------
# Global metadata
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (window), 1 (probation), 2 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096  # access-counts between epochs (power of two recommended)

# Byte counters per segment
g_seg_bytes = {0: 0, 1: 0, 2: 0}

# Capacity targeting (by bytes)
WINDOW_FRACTION = 0.18                 # bytes reserved for pure recency window
PROTECTED_MAIN_FRACTION = 0.80         # fraction of main (non-window) bytes for protected

# Scoring tunables
SIZE_ALPHA = 1.05
MULTI_HIT_BONUS = 0.45

# Recency windows and weights
REC_WIN_MIN = 128
REC_WIN_MULT = 2           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.45
W_REC_PROT = 0.10
W_PRED_PROB = 0.20
W_PRED_PROT = 0.08

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.55        # react relatively fast to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to window for unknown keys
    seg = m_segment.get(key, 0)
    if seg not in (0, 1, 2):
        return 0
    return seg

def _targets_bytes(cache_snapshot):
    cap = float(cache_snapshot.capacity)
    window_target = int(WINDOW_FRACTION * cap)
    main_bytes = max(0.0, cap - window_target)
    protected_target = int(PROTECTED_MAIN_FRACTION * main_bytes)
    return window_target, protected_target

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_from_protected_until_within_target(cache_snapshot):
    # Demote oldest protected to probation until protected bytes <= target
    window_target, protected_target = _targets_bytes(cache_snapshot)
    while g_seg_bytes[2] > protected_target:
        k, _ = _find_oldest_in_segment(cache_snapshot, segment_id=2)
        if k is None:
            break
        obj = cache_snapshot.cache.get(k)
        if obj is None:
            break
        # Move from protected (2) to probation (1)
        g_seg_bytes[2] = max(0, g_seg_bytes[2] - obj.size)
        g_seg_bytes[1] += obj.size
        m_segment[k] = 1

def _find_lru_in_window(cache_snapshot):
    # Strict LRU within window (segment 0)
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=0)
    return key

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 2:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        # segment 1 (probation) gets stronger recency; window (0) doesn't use score for eviction
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Segment transitions
# -----------------------------

def _move_segment(cache_snapshot, key, old_seg, new_seg):
    if old_seg == new_seg:
        return
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return
    if old_seg in (0, 1, 2):
        g_seg_bytes[old_seg] = max(0, g_seg_bytes[old_seg] - obj.size)
    g_seg_bytes[new_seg] += obj.size
    m_segment[key] = new_seg

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Demote protected to probation until protected <= target bytes
      - If window exceeds its byte target: evict LRU from window
      - Else prefer: probation (min retention score) -> window LRU -> protected (min score)
    '''
    _init_if_needed(cache_snapshot)

    # Rebalance protected if oversized (metadata only)
    _demote_from_protected_until_within_target(cache_snapshot)

    window_target, _ = _targets_bytes(cache_snapshot)

    # If window oversized, evict strictly from window (LRU)
    if g_seg_bytes[0] > window_target:
        k = _find_lru_in_window(cache_snapshot)
        if k is not None:
            return k

    # Helper to select min-score victim within a given segment (1 or 2)
    def select_min_score(seg_id):
        min_key = None
        min_score = None
        min_time = None
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (min_key is None) or (score < min_score) or (score == min_score and last < min_time):
                min_key = k
                min_score = score
                min_time = last
        return min_key

    # Prefer probation
    victim = select_min_score(1)
    if victim is not None:
        return victim

    # Fallback: window LRU if any
    victim = _find_lru_in_window(cache_snapshot)
    if victim is not None:
        return victim

    # Last resort: protected (rare)
    victim = select_min_score(2)
    if victim is not None:
        return victim

    # Absolute fallback
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - Segment transitions:
          * window (0) -> probation (1) on first hit
          * probation (1) -> protected (2) on subsequent hit
          * protected (2): stay, update recency
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = prev if prev is not None else now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Segment promotions
    seg = _segment_of(k)
    if seg == 0:
        # window -> probation
        _move_segment(cache_snapshot, k, 0, 1)
    elif seg == 1:
        # probation -> protected on 2nd+ hit
        if m_resident_hits.get(k, 1) >= 2:
            _move_segment(cache_snapshot, k, 1, 2)
    # seg == 2: stay in protected

    # Enforce protected target (demote oldest protected if oversized)
    _demote_from_protected_until_within_target(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = window (pure recency)
      - Track segment bytes
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # window

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # Track window bytes
    g_seg_bytes[0] += obj.size


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain per-segment byte accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust bytes by the recorded segment
    seg = _segment_of(ek)
    if seg in (0, 1, 2):
        g_seg_bytes[seg] = max(0, g_seg_bytes[seg] - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```
2025-11-27 22:58:16,835 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 35
- Hit Rate: 0.1562

Example 2:
- Trace ID: 15
- Hit Rate: 0.0228

Example 3:
- Trace ID: 1
- Hit Rate: 0.4779

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m22:58:16 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 22:58:16,836 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m23:00:35 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 23:00:35,472 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 23:00:35,473 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive Segmented SLRU + TinyLFU (AS-TinySLRU)
# - Two resident segments:
#     0) Probation (new or demoted items): recency is strongly weighted
#     1) Protected (reused items): frequency is weighted more than recency
# - TinyLFU with lazy-decayed 8-bit counters (no global sweeping)
# - Eviction: prefer evicting from Probation; if empty, evict from Protected
# - Promotion: on hit in Probation -> move to Protected
# - Adaptive protected share: adjusts based on where hits occur
# - Size-aware benefit but with sublinear size penalty (alpha < 1) for fairness to large reused items
#
# Notes:
# - We cannot perform admission control (misses are always inserted by the engine),
#   so we optimize evictions, promotion, and decay.
# - Metadata kept only for residents: last access time, resident hit count, segment.
#   TinyLFU counters are maintained for both resident and non-resident keys.
#
# Expected behavior:
#   - Recent items get an initial "recency shield" in Probation.
#   - Items with reuse quickly move to Protected and are retained via frequency.
#   - The protected share adapts: more promotions -> increase protection;
#     if most hits already in Protected -> reduce protection to keep fresh items flowing.

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count (starts at 0 upon insert)
m_seg = dict()             # key -> 0 (probation) or 1 (protected)

# TinyLFU sketch (lazy-decayed 8-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096  # accesses between epochs (power of two preferred)
LFU_MAX = 255              # 8-bit saturation

# Adaptive protected-share control
m_prot_frac = 0.50         # desired fraction of resident items in Protected
ADAPT_WINDOW = 2048        # hits per adaptation step
m_hits_window = 0          # hits counted since last adaptation
m_hits_promotions = 0      # hits that caused promotion (Probation -> Protected)
m_hits_protected = 0       # hits within Protected

# Tunables
# Recency windows
REC_WIN_MIN = 64           # minimum window to normalize age
REC_WIN_MULT = 2           # window ~ REC_WIN_MULT * resident_items

# Recency weights by segment
REC_W_PROB = 0.60          # Probation: strong recency protection
REC_W_PROT = 0.15          # Protected: light recency protection

# Size-aware frequency benefit: benefit ~ (log2(1+freq) + bonus) / (size_norm ** ALPHA)
SIZE_ALPHA = 0.70          # sublinear penalty to avoid over-penalizing large hot items

# Multi-hit bonus
BONUS_HITS2 = 0.30         # if resident hits >= 2
BONUS_HITS4 = 0.60         # if resident hits >= 4


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    ent = m_lfu_count.get(key)
    if ent is None:
        return 0
    c, e = ent
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    ent = m_lfu_count.get(key)
    if ent is None:
        c = 0
        e = cur_epoch
    else:
        c, e = ent
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)


def _normalized_size(size, capacity):
    # Represent size as percentage-of-capacity (avoid zeros)
    denom = float(capacity) if capacity > 0 else 1.0
    return max(1e-9, (float(size) * 100.0) / denom)


def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    if window <= 0:
        return 1.0
    return min(1.0, float(age) / float(window))


def _segment_of(key):
    # Default new residents are in probation (0)
    return 1 if m_seg.get(key, 0) == 1 else 0


def _benefit(cache_snapshot, key, obj):
    # Compute base benefit (frequency and size)
    cap = cache_snapshot.capacity
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        sz = obj.size  # fallback to incoming object's size
    else:
        sz = robj.size

    freq = _lfu_peek(cache_snapshot, key)
    hits = m_resident_hits.get(key, 0)
    if hits >= 4:
        extra = BONUS_HITS4
    elif hits >= 2:
        extra = BONUS_HITS2
    else:
        extra = 0.0

    size_norm = _normalized_size(sz, cap)
    return (math.log2(1.0 + float(freq)) + extra) / (size_norm ** SIZE_ALPHA)


def _retention_score(cache_snapshot, key, obj):
    # Lower score -> weaker retention (more likely to evict)
    now = cache_snapshot.access_count
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key, None)

    seg = _segment_of(key)
    rec_w = REC_W_PROB if seg == 0 else REC_W_PROT

    a_norm = _recency_normalized(now, last, window)
    recency_gain = rec_w * (1.0 - a_norm)  # more recent => larger gain

    ben = _benefit(cache_snapshot, key, obj)
    return ben - recency_gain


# -----------------------------
# Protected-segment management
# -----------------------------

def _protected_target_items(cache_snapshot):
    # Target number of protected items by fraction of current residents
    n = max(0, len(cache_snapshot.cache))
    return int(m_prot_frac * n)


def _promote_to_protected(cache_snapshot, key):
    if _segment_of(key) == 1:
        return
    m_seg[key] = 1


def _demote_one_from_protected(cache_snapshot):
    # Demote the oldest protected item (LRU within Protected) back to Probation
    oldest_k = None
    oldest_t = None
    for k in m_seg.keys():
        if m_seg.get(k, 0) != 1:
            continue
        t = m_last_access.get(k, -1)
        if oldest_k is None or t < oldest_t:
            oldest_k = k
            oldest_t = t
    if oldest_k is not None:
        m_seg[oldest_k] = 0


def _enforce_protected_budget(cache_snapshot):
    # Ensure number of protected items stays within target
    target = _protected_target_items(cache_snapshot)
    # Count current protected items
    protected_count = 0
    for k in cache_snapshot.cache.keys():
        if m_seg.get(k, 0) == 1:
            protected_count += 1
    # Demote until within budget
    while protected_count > target and protected_count > 0:
        _demote_one_from_protected(cache_snapshot)
        protected_count -= 1


def _maybe_adapt_protected_share():
    # Adapt m_prot_frac every ADAPT_WINDOW hits
    global m_hits_window, m_hits_promotions, m_hits_protected, m_prot_frac
    if m_hits_window < ADAPT_WINDOW:
        return
    # If we are seeing many promotions, increase protected share to retain reusers.
    # If most hits are already in protected, decrease to allow more probation capacity.
    promote_bias = m_hits_promotions
    protected_bias = m_hits_protected

    if promote_bias > protected_bias * 1.05:
        m_prot_frac = min(0.80, m_prot_frac + 0.05)
    elif protected_bias > promote_bias * 1.05:
        m_prot_frac = max(0.20, m_prot_frac - 0.05)

    # Reset window counters
    m_hits_window = 0
    m_hits_promotions = 0
    m_hits_protected = 0


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the weakest retention:
      - Prefer evicting from Probation; if empty, evict from Protected.
      - Within a segment, choose the minimal retention score with LRU tie-break.
    '''
    _init_if_needed(cache_snapshot)

    # Build candidate set: probation keys first
    prob_candidates = []
    prot_candidates = []
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) == 0:
            prob_candidates.append(k)
        else:
            prot_candidates.append(k)

    candidates = prob_candidates if prob_candidates else prot_candidates

    min_key = None
    min_score = None
    min_time = None

    for k in candidates:
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Increment resident hit count
      - Refresh last-access time
      - If in Probation, promote to Protected and adapt protected share
      - Enforce protected budget by demoting oldest protected items if necessary
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    if _segment_of(k) == 0:
        # Promotion to Protected on reuse
        _promote_to_protected(cache_snapshot, k)
        # Adaptation counters
        global m_hits_window, m_hits_promotions
        m_hits_window += 1
        m_hits_promotions += 1
        _maybe_adapt_protected_share()
        # Keep protected within target
        _enforce_protected_budget(cache_snapshot)
    else:
        # Protected hit
        global m_hits_window, m_hits_protected
        m_hits_window += 1
        m_hits_protected += 1
        _maybe_adapt_protected_share()


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 0
      - Place into Probation segment
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 0
    m_seg[k] = 0
    # No budget enforcement needed here; promotion path handles it.


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU counters across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Retain LFU memory for non-residents
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_seg.pop(ek, None)
```
2025-11-27 23:00:46,366 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Size-aware GreedyDual-Size-Frequency (GDSF) with TinyLFU
# - Byte-capacity aware: eviction prioritizes "value per byte"
# - Recency via GreedyDual's global age (L): on each hit/insert, item's priority H = value/size^alpha + L
#   and on eviction we set L := H(evicted). This causes older/colder items to decay relative to recent touches.
# - Frequency via TinyLFU (Count-Min Sketch) with periodic aging
# - No per-item-count assumptions; decisions use actual obj.size
#
# This policy is simple, fast, and robust across mixed workloads (recency + frequency + size skew).

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Last access time (for LRU tiebreaks only)
m_key_last_access = dict()  # key -> int access_count

# GreedyDual priority per resident key: H(key) = value(key)/size(key)^alpha + L_at_last_touch
m_key_H = dict()  # key -> float

# Global GreedyDual age (inflation)
m_age_L = 0.0

# Remember last chosen victim's H so update_after_evict can advance L precisely
m_last_chosen_evict_H = None

# Track whether we've initialized for the current run
m_inited = False

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)

# -----------------------------
# Tunables
# -----------------------------
# Value normalization: value = (TinyLFU_estimate + bias) / size^alpha
m_value_bias = 1.0      # ensures cold items get some initial value
m_size_alpha = 0.875    # 1.0 favors small items strongly; 0.0 ignores size
m_eps_tiebreak = 1e-12  # to avoid float edge-case instability

# -----------------------------
# Helpers
# -----------------------------

def _maybe_reset_for_new_run(cache_snapshot):
    # If a new trace/run starts in the same process, access_count will return to 0.
    # Reset all state in that case.
    global m_inited, m_key_last_access, m_key_H, m_age_L
    global m_sketch_tables, m_sketch_mask, m_sketch_ops
    global m_last_chosen_evict_H
    if cache_snapshot.access_count == 0 and not m_inited:
        m_key_last_access = dict()
        m_key_H = dict()
        m_age_L = 0.0
        m_last_chosen_evict_H = None
        m_sketch_tables = None
        m_sketch_mask = None
        m_sketch_ops = 0
        m_inited = True


def _init_if_needed(cache_snapshot):
    global m_sketch_tables, m_sketch_mask
    _maybe_reset_for_new_run(cache_snapshot)
    if m_sketch_tables is None:
        # Choose sketch width near capacity/4KB, clamped to [2^12, 2^18]
        # and rounded up to the next power of two.
        cap = max(1, cache_snapshot.capacity)
        target = cap // 4096
        if target < 4096:
            target = 4096
        if target > (1 << 18):
            target = (1 << 18)
        width = 1
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _value_per_size(freq_est, size_bytes):
    s = size_bytes if size_bytes > 0 else 1
    # value normalized by size^alpha
    return (float(freq_est) + m_value_bias) / (s ** m_size_alpha)


def _ensure_H_for_key(cache_snapshot, key):
    # If we haven't yet assigned H to a resident key (e.g., pre-existing before our init),
    # initialize it using current TinyLFU estimate and current age L. This treats it as
    # "recently touched", which is conservative; it will age naturally via L increases.
    if key not in m_key_H:
        obj = cache_snapshot.cache.get(key)
        if obj is None:
            return
        est = _sketch_estimate(key)
        base = _value_per_size(est, obj.size)
        m_key_H[key] = base + m_age_L


def _pick_min_H(cache_snapshot):
    # Returns (key, H, last_access_time) minimizing H; tie-break by older last_access
    min_key, min_H, min_time = None, None, None
    for k, obj in cache_snapshot.cache.items():
        # Ensure H exists
        if k not in m_key_H:
            est = _sketch_estimate(k)
            base = _value_per_size(est, obj.size)
            # initialize H lazily
            H = base + m_age_L
            m_key_H[k] = H
        else:
            H = m_key_H[k]
        t = m_key_last_access.get(k, -1)
        if (min_H is None) or (H < min_H - m_eps_tiebreak) or (abs(H - min_H) <= m_eps_tiebreak and t < min_time):
            min_key, min_H, min_time = k, H, t
    return (min_key, min_H, min_time)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim using size-aware GDSF:
      - H(k) = (TinyLFU_estimate(k) + bias)/size(k)^alpha + L_at_last_touch
      - Evict the key with minimal H
      - On hit/insert we refresh H to base + current L to capture recency
    """
    global m_last_chosen_evict_H

    _init_if_needed(cache_snapshot)

    # Pick key with minimal H (ties: older last_access first)
    victim_key, victim_H, _ = _pick_min_H(cache_snapshot)
    if victim_key is None:
        # Fallback to arbitrary key if something is off
        victim_key = next(iter(cache_snapshot.cache))
        victim_H = m_key_H.get(victim_key, 0.0)

    # Stash selected H so update_after_evict can advance L precisely
    m_last_chosen_evict_H = float(victim_H)
    return victim_key


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Train TinyLFU (+1)
      - Refresh last-access time
      - Refresh H = value/size^alpha + current L
    """
    global m_key_last_access, m_key_H

    _init_if_needed(cache_snapshot)

    k = obj.key
    _sketch_inc(k, 1)
    m_key_last_access[k] = cache_snapshot.access_count

    est = _sketch_estimate(k)
    base = _value_per_size(est, obj.size)
    m_key_H[k] = base + m_age_L


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss resulted in admission by the framework):
      - Train TinyLFU (+1)
      - Record last-access time
      - Initialize H = value/size^alpha + current L
    """
    global m_key_last_access, m_key_H

    _init_if_needed(cache_snapshot)

    k = obj.key
    _sketch_inc(k, 1)
    m_key_last_access[k] = cache_snapshot.access_count

    est = _sketch_estimate(k)
    base = _value_per_size(est, obj.size)
    m_key_H[k] = base + m_age_L


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After eviction:
      - Advance global age L to the H(evicted) (core GreedyDual aging step)
      - Remove resident metadata for that key
    """
    global m_key_last_access, m_key_H, m_age_L, m_last_chosen_evict_H

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Advance GreedyDual age using the exact H of the evicted victim (if available)
    if m_last_chosen_evict_H is not None:
        # Ensure monotonic non-decreasing L
        if m_last_chosen_evict_H > m_age_L:
            m_age_L = m_last_chosen_evict_H
        m_last_chosen_evict_H = None

    # Clean up metadata
    m_key_last_access.pop(ek, None)
    m_key_H.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 34
- Hit Rate: 0.0702

Example 2:
- Trace ID: 0
- Hit Rate: 0.4679

Example 3:
- Trace ID: 31
- Hit Rate: 0.0001

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m23:00:46 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 23:00:46,368 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m23:04:06 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 23:04:06,135 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 23:04:06,136 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# ARC-style (Adaptive Replacement Cache) with TinyLFU guidance
# - Object-count capacity oriented (no dependence on object sizes)
# - Two resident segments:
#     T1 (recent/probation): admits new items
#     T2 (frequent/protected): items promoted on hit (second-chance)
# - Two non-resident ghost lists:
#     B1 tracks keys evicted from T1 (recency history)
#     B2 tracks keys evicted from T2 (frequency history)
# - Adaptive target p for |T1|: grows when misses find key in B1 (favor recency),
#   shrinks when misses find key in B2 (favor frequency).
# - TinyLFU sketch provides lightweight frequency estimates to:
#     - train on every access (hit/insert)
#     - break ties within LRU candidates (evict the lower-frequency among equal-ages)
#
# This policy is robust across diverse workloads and does not rely on byte capacity.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

m_inited = False

# Per-key last access time (for LRU)
m_key_last_access = dict()  # key -> int access_count

# Segment membership: 1 for T1 (probation), 2 for T2 (protected)
m_seg = dict()    # key -> 1|2
m_T1 = set()      # probationary resident keys
m_T2 = set()      # protected resident keys

# Ghost histories (non-resident): key -> last seen time
m_B1 = dict()     # keys evicted from T1
m_B2 = dict()     # keys evicted from T2

# ARC target p (desired size of T1), and estimated capacity in objects
m_p = 0
m_cap_count = None

# Track last seen access_count to reliably reset between runs
m_last_seen_access_count = None

# -----------------------------
# TinyLFU sketch
# -----------------------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_width_mask = None   # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # 8-bit style cap

# -----------------------------
# Helpers
# -----------------------------

def _reset_all_state():
    global m_inited, m_key_last_access, m_seg, m_T1, m_T2, m_B1, m_B2
    global m_p, m_cap_count, m_last_seen_access_count
    global m_sketch_tables, m_sketch_width_mask, m_sketch_ops

    m_key_last_access = dict()
    m_seg = dict()
    m_T1 = set()
    m_T2 = set()
    m_B1 = dict()
    m_B2 = dict()
    m_p = 0
    m_cap_count = None
    m_last_seen_access_count = None

    m_sketch_tables = None
    m_sketch_width_mask = None
    m_sketch_ops = 0

    m_inited = True


def _maybe_reset_for_new_run(cache_snapshot):
    # Reset state if a new run/trace started (access_count restarted or decreased)
    global m_last_seen_access_count
    if not m_inited:
        _reset_all_state()
    if m_last_seen_access_count is None or cache_snapshot.access_count < m_last_seen_access_count:
        _reset_all_state()
    m_last_seen_access_count = cache_snapshot.access_count


def _init_if_needed(cache_snapshot):
    global m_sketch_tables, m_sketch_width_mask
    _maybe_reset_for_new_run(cache_snapshot)
    if m_sketch_tables is None:
        # Use a fixed sketch width (power of two) for stability across unknown capacities.
        # 2^15 counters per row is a good balance of accuracy/memory; cap totals by aging.
        width = 1 << 15  # 32768
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_width_mask = width - 1


def _hash_indices(key):
    # Simple 4-independent hash mixing on Python's hash
    h = hash(key)
    return [(h ^ seed) & m_sketch_width_mask for seed in m_sketch_hash_seeds]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        v = m_sketch_tables[t][i]
        nv = v + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _ensure_member_for_existing(cache_snapshot):
    # Lazily initialize unknown resident keys to probation (T1)
    for k in cache_snapshot.cache.keys():
        if k not in m_seg:
            m_seg[k] = 1
            m_T1.add(k)
            if k not in m_key_last_access:
                m_key_last_access[k] = -1  # very old by default


def _pick_lru_from_set(keyset):
    # Pick the LRU key from the given set; break ties with TinyLFU estimate (evict lower freq)
    if not keyset:
        return None
    min_key = None
    min_time = None
    min_est = None
    for k in keyset:
        t = m_key_last_access.get(k, -1)
        est = _sketch_estimate(k)
        if (min_time is None) or (t < min_time) or (t == min_time and est < min_est):
            min_key = k
            min_time = t
            min_est = est
    return min_key


def _arc_adjust_p(on_B1, on_B2):
    # Adjust ARC target p for |T1| based on which ghost list saw the miss
    # Increase p if miss found in B1 (favor recency), decrease if found in B2 (favor frequency)
    global m_p
    if m_cap_count is None:
        return
    if on_B1:
        # Scale step by relative sizes to speed convergence
        step = max(1, len(m_B2) // max(1, len(m_B1)))
        m_p = min(m_cap_count, m_p + step)
    elif on_B2:
        step = max(1, len(m_B1) // max(1, len(m_B2)))
        m_p = max(0, m_p - step)


def _ensure_cap_count(cache_snapshot):
    # Learn capacity in objects from observed full-cache state (first evict call sets it)
    global m_cap_count
    if m_cap_count is None:
        # When evict() is called, the cache should be full. Use current size as capacity count.
        m_cap_count = max(1, len(cache_snapshot.cache))


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose a victim using ARC's REPLACE rule:
      - Maintain T1 (recent/probation) and T2 (frequent/protected)
      - Target size of T1 is p; REPLACE picks from T1 if |T1|>p or (obj in B2 and |T1|==p), else from T2
      - Within the chosen segment, evict true LRU; tie-break by TinyLFU estimate (lower first)
    """
    _init_if_needed(cache_snapshot)
    _ensure_cap_count(cache_snapshot)
    _ensure_member_for_existing(cache_snapshot)

    k_new = obj.key if obj is not None else None
    from_B2 = k_new in m_B2

    # REPLACE rule
    victim_key = None
    if (len(m_T1) >= 1) and ((from_B2 and len(m_T1) == m_p) or (len(m_T1) > m_p)):
        victim_key = _pick_lru_from_set(m_T1)
        if victim_key is None and m_T2:
            victim_key = _pick_lru_from_set(m_T2)
    else:
        victim_key = _pick_lru_from_set(m_T2)
        if victim_key is None and m_T1:
            victim_key = _pick_lru_from_set(m_T1)

    if victim_key is None:
        # Fallback: evict any resident key
        victim_key = next(iter(cache_snapshot.cache))

    return victim_key


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Train TinyLFU (+1)
      - Update last-access time
      - Promote from T1 -> T2 on hit; refresh recency within segment
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _sketch_inc(k, 1)
    m_key_last_access[k] = cache_snapshot.access_count

    seg = m_seg.get(k)
    if seg == 1:
        # Promote to protected
        if k in m_T1:
            m_T1.discard(k)
        m_T2.add(k)
        m_seg[k] = 2
    elif seg == 2:
        # Refresh recency; nothing else needed as we track only timestamps
        pass
    else:
        # Unknown resident (e.g., pre-existing). Treat as protected after a hit.
        m_seg[k] = 2
        m_T2.add(k)
        m_T1.discard(k)


def update_after_insert(cache_snapshot, obj):
    """
    On insert after a miss:
      - Train TinyLFU (+1)
      - Update last-access time
      - If key was in B1/B2 (ghost), adapt p (ARC) and admit into T2 (it's at least the second reference)
      - Else admit into T1 (probation)
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _sketch_inc(k, 1)
    m_key_last_access[k] = cache_snapshot.access_count

    on_B1 = k in m_B1
    on_B2 = k in m_B2

    # Set capacity estimate if not known
    if m_cap_count is None and len(cache_snapshot.cache) > 0:
        # Not necessarily full, but use current as a reasonable bound until first eviction refines it
        # (will be corrected on first evict call)
        m_cap_count = len(cache_snapshot.cache)

    if on_B1 or on_B2:
        _arc_adjust_p(on_B1, on_B2)
        # Remove from ghost (since it is now resident)
        if on_B1:
            m_B1.pop(k, None)
        if on_B2:
            m_B2.pop(k, None)
        # Admit to protected (frequent)
        prev_seg = m_seg.get(k)
        if prev_seg == 1:
            m_T1.discard(k)
        elif prev_seg == 2:
            m_T2.discard(k)
        m_seg[k] = 2
        m_T2.add(k)
    else:
        # Normal cold admission to probation
        prev_seg = m_seg.get(k)
        if prev_seg == 2:
            m_T2.discard(k)
        elif prev_seg == 1:
            m_T1.discard(k)
        m_seg[k] = 1
        m_T1.add(k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After eviction:
      - Move evicted key to its corresponding ghost list (B1 if from T1, B2 if from T2)
      - Remove resident metadata
      - Keep ghost lists bounded by capacity (ARC)
    """
    _init_if_needed(cache_snapshot)
    _ensure_cap_count(cache_snapshot)

    ek = evicted_obj.key
    seg = m_seg.pop(ek, None)

    # Remove from resident sets
    m_T1.discard(ek)
    m_T2.discard(ek)
    # Do not discard m_key_last_access entirely; keep last seen time for ghost ordering
    last_t = m_key_last_access.get(ek, cache_snapshot.access_count)

    # Insert into the appropriate ghost list
    if seg == 2:
        m_B2[ek] = last_t
    else:
        # Default to B1 if unknown or probation
        m_B1[ek] = last_t

    # Bound ghost sizes (ARC behavior)
    # Ensure |B1| <= c; if overflow, evict LRU from B1
    if len(m_B1) > m_cap_count:
        # Remove LRU from B1
        old_key = min(m_B1.items(), key=lambda kv: kv[1])[0]
        m_B1.pop(old_key, None)

    # Ensure |B1| + |B2| <= c; if overflow, evict LRU from B2
    if (len(m_B1) + len(m_B2)) > m_cap_count and m_B2:
        old_key = min(m_B2.items(), key=lambda kv: kv[1])[0]
        m_B2.pop(old_key, None)
```
2025-11-27 23:04:08,143 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Windowed SLRU + TinyLFU + ARC-style adaptation + size-aware sampled eviction
# - Three resident segments (by bytes):
#     Window (very recent), Probation (main new/once-hit), Protected (multi-hit)
# - Eviction order: Window -> Probation -> Protected (minimize main churn)
# - TinyLFU counts (lazy decay) guide which among the oldest to evict (sampled)
# - Size-aware scoring (prefer keeping tiny but hot objects)
# - ARC-like ghost lists dynamically adapt Protected target size (bytes)
# - O(1) updates on hit/insert via OrderedDict LRU queues

import math
from collections import OrderedDict

# ---------------
# Globals
# ---------------

# LRU queues (LRU at left, MRU at right)
win_lru = OrderedDict()   # 0: Window segment (recent)
prob_lru = OrderedDict()  # 1: Probation (main new/once-hit)
prot_lru = OrderedDict()  # 2: Protected (multi-hit)

# Bytes accounting
win_bytes = 0
prob_bytes = 0
prot_bytes = 0

# Resident segment mapping: key -> seg_id {0:win, 1:prob, 2:prot}
m_segment = dict()

# Per-key resident metadata
m_last_access = dict()      # key -> int time
m_resident_hits = dict()    # key -> int

# TinyLFU: 4-bit counters with lazy decay
m_lfu_count = dict()        # key -> (count[0..15], epoch)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Dynamic targets (bytes)
g_prot_target_bytes = 0     # dynamically tuned protected target
g_win_target_bytes = 0      # small window target
g_last_cap = 0

# Ghost lists for ARC-style adaptation (bytes-limited)
ghost_prob = OrderedDict()  # keys evicted from Window/Probation
ghost_prot = OrderedDict()  # keys evicted from Protected
ghost_prob_bytes = 0
ghost_prot_bytes = 0

# Scoring / sampling
SAMPLE_K_WIN = 5
SAMPLE_K_PROB = 6
SAMPLE_K_PROT = 4

# Multi-hit bonus in score
MULTI_HIT_BONUS = 0.5

# ---------------
# Helpers: init / targets / lfu
# ---------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    global g_last_cap, g_prot_target_bytes, g_win_target_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = max(1, int(cache_snapshot.capacity))
    if g_last_cap != cap or g_prot_target_bytes == 0 or g_win_target_bytes == 0:
        g_last_cap = cap
        # Start conservatively: small window, large protected
        g_win_target_bytes = max(1, int(cap * 0.05))
        g_prot_target_bytes = max(1, int(cap * 0.70))

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _cap_bytes(cache_snapshot):
    return max(1, int(cache_snapshot.capacity))

# ---------------
# Ghost lists and adaptation (ARC-like)
# ---------------

def _ghost_cap(cache_snapshot):
    # Total bytes allowed for each ghost list (soft bound)
    return _cap_bytes(cache_snapshot)

def _ghost_add(cache_snapshot, seg_id, key, size):
    # Evicted from which segment? 0/1 -> ghost_prob, 2 -> ghost_prot
    global ghost_prob_bytes, ghost_prot_bytes
    if seg_id == 2:
        if key in ghost_prot:
            old = ghost_prot.pop(key)
            ghost_prot_bytes -= old
        ghost_prot[key] = size
        ghost_prot_bytes += size
        # Trim
        cap = _ghost_cap(cache_snapshot)
        while ghost_prot_bytes > cap and ghost_prot:
            k, s = ghost_prot.popitem(last=False)
            ghost_prot_bytes -= s
    else:
        if key in ghost_prob:
            old = ghost_prob.pop(key)
            ghost_prob_bytes -= old
        ghost_prob[key] = size
        ghost_prob_bytes += size
        cap = _ghost_cap(cache_snapshot)
        while ghost_prob_bytes > cap and ghost_prob:
            k, s = ghost_prob.popitem(last=False)
            ghost_prob_bytes -= s

def _adapt_prot_target(cache_snapshot, delta_bytes):
    global g_prot_target_bytes
    cap = _cap_bytes(cache_snapshot)
    # Bounds: leave at least 5% for window + 5% for probation, at most 90% for protected
    min_prot = int(cap * 0.10)
    max_prot = int(cap * 0.90)
    g_prot_target_bytes = max(min_prot, min(max_prot, g_prot_target_bytes + int(delta_bytes)))

def _adapt_on_ghost_ref(cache_snapshot, key):
    # If the incoming key was recently in a ghost list, adapt protected target
    if key in ghost_prot:
        # We previously kept it hot; increase protected to favor long-term
        s = ghost_prot.get(key, 0)
        _adapt_prot_target(cache_snapshot, max(1, s))
        # Move to MRU in ghost (recency)
        ghost_prot.move_to_end(key, last=True)
    elif key in ghost_prob:
        # Previously evicted from probation/window -> favor recency by shrinking protected
        s = ghost_prob.get(key, 0)
        _adapt_prot_target(cache_snapshot, -max(1, s // 2))
        ghost_prob.move_to_end(key, last=True)

# ---------------
# Segment helpers
# ---------------

def _seg_remove(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    else:
        # clean up any remnants
        win_lru.pop(key, None)
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)
    return seg

def _seg_insert_win(key, size):
    global win_bytes
    # ensure not in others
    if m_segment.get(key) == 0:
        # refresh MRU
        win_lru.pop(key, None)
        win_lru[key] = None
        return
    # Remove from other lists if present
    if m_segment.get(key) == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            global prob_bytes
            prob_bytes -= size
    if m_segment.get(key) == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            global prot_bytes
            prot_bytes -= size
    m_segment[key] = 0
    win_lru[key] = None
    win_bytes += size

def _seg_move_to_prob(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 1:
        # refresh MRU
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    if seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    prob_lru[key] = None
    m_segment[key] = 1
    prob_bytes += size

def _demote_prot_if_needed(cache_snapshot):
    # Demote from protected to probation until within target
    global prot_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(0, min(g_prot_target_bytes, cap))
    while prot_bytes > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        prot_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _trim_window_if_needed(cache_snapshot):
    # Keep window near its target by moving oldest window entries to probation (not evict)
    global win_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(1, min(g_win_target_bytes, cap))
    # Allow a little slack to avoid churn
    slack = max(1, target // 8)
    while win_bytes > (target + slack) and win_lru:
        dem_key, _ = win_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        win_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _seg_move_to_prot(cache_snapshot, key, size):
    # Promote to Protected MRU
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 2:
        # refresh MRU
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    prot_lru[key] = None
    m_segment[key] = 2
    prot_bytes += size
    _demote_prot_if_needed(cache_snapshot)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

# ---------------
# Scoring helpers
# ---------------

def _normalized_size(size, capacity):
    # size as percentage of capacity, keep >= small epsilon
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _retention_score(cache_snapshot, key):
    # Higher score = stronger retention; eviction picks smallest score
    cap = _cap_bytes(cache_snapshot)
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size
    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)
    bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    # Size-aware benefit with gentle diminishing returns on frequency
    benefit = (math.log2(1.0 + float(freq)) + bonus) / size_norm
    return benefit

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    # sample k oldest
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            return next(iter(order))
        except StopIteration:
            return None
    return chosen_key

# ---------------
# Policy entry points
# ---------------

def evict(cache_snapshot, obj):
    """
    Eviction strategy:
      - Prefer evicting from Window first to shield main cache (2Q-style)
      - Then from Probation, finally Protected
      - Within a segment, sample a few oldest and evict the one with the lowest
        TinyLFU size-aware score.
    """
    _init_if_needed(cache_snapshot)

    # Choose from Window first (admission filter / reduces main churn)
    if win_lru:
        victim = _pick_candidate_from_order(cache_snapshot, win_lru, SAMPLE_K_WIN)
        return victim

    # Then from Probation
    if prob_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
        return victim

    # Fallback to Protected if others empty
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)
        return victim

    # Last resort
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access and resident hit count
      - Promote to Protected if in Window/Probation
      - Refresh LRU position within its segment
      - Adapt Protected target: increase on Probation hits, slightly decrease on Protected hits
      - Trim Window toward its target
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked; place into Window
        _seg_insert_win(k, obj.size)
        _trim_window_if_needed(cache_snapshot)
        return

    if seg == 0 or seg == 1:
        # Hit in Window or Probation -> promote to Protected
        _seg_move_to_prot(cache_snapshot, k, obj.size)
        # Adapt: probation/window hit means protected was too small -> grow
        step = max(1, obj.size // 2)
        _adapt_prot_target(cache_snapshot, step)
    else:
        # Protected hit: touch and slightly shrink target to allow more probation
        _seg_touch_on_hit(cache_snapshot, k)
        step = max(1, obj.size // 8)
        _adapt_prot_target(cache_snapshot, -step)

    # Keep window near target
    _trim_window_if_needed(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU for the key (admission learns from requests)
      - Adjust Protected target using ARC-like ghost feedback
      - Initialize resident metadata and place into Window MRU
      - Gently trim Window toward its target (migrate oldest to Probation)
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # ARC-like adaptation using ghost information
    _adapt_on_ghost_ref(cache_snapshot, k)

    # New resident enters Window MRU
    _seg_insert_win(k, obj.size)
    _trim_window_if_needed(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove it from segment structures and resident-only metadata
      - Record into ghost lists for ARC-style adaptation
      - Keep TinyLFU counts to inform future decisions
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = evicted_obj.size

    # Identify segment before removal (for ghost list)
    seg_before = m_segment.get(ek, 1)
    _seg_remove(cache_snapshot, ek, esize)

    # Resident-only metadata cleanup
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # Remember in ghost for adaptation
    _ghost_add(cache_snapshot, seg_before, ek, esize)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 33
- Hit Rate: 0.6326

Example 2:
- Trace ID: 38
- Hit Rate: 0.1255

Example 3:
- Trace ID: 39
- Hit Rate: 0.1381

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m23:04:08 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 23:04:08,144 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m23:07:58 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 23:07:58,577 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 23:07:58,578 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Improved: W-TinyLFU + SLRU with global sampled eviction and adaptive segment sizing
# - Segments by bytes:
#     Window (very recent admission buffer)
#     Probation (main new/once-hit)
#     Protected (multi-hit)
# - Global eviction sampling across segments (size-aware + LFU + recency + segment bias)
# - TinyLFU with lazy decay (shorter half-life for burst responsiveness)
# - ARC-like ghost feedback adapts targets; plus on-line hit-driven adaptation
# - SLRU promotion: only Probation -> Protected on hit (reduces protected pollution)
# - Window hits stay in Window; Window trims to Probation by LRU
# - Size-aware scoring favors keeping small but hot/recency-weighted items

import math
from collections import OrderedDict

# ---------------
# Globals
# ---------------

# LRU queues (LRU at left, MRU at right)
win_lru = OrderedDict()   # 0: Window segment (recent)
prob_lru = OrderedDict()  # 1: Probation (main new/once-hit)
prot_lru = OrderedDict()  # 2: Protected (multi-hit)

# Bytes accounting
win_bytes = 0
prob_bytes = 0
prot_bytes = 0

# Resident segment mapping: key -> seg_id {0:win, 1:prob, 2:prot}
m_segment = dict()

# Per-key resident metadata
m_last_access = dict()      # key -> int time (access_count)
m_resident_hits = dict()    # key -> int

# TinyLFU: 4-bit counters with lazy decay
m_lfu_count = dict()        # key -> (count[0..15], epoch)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096   # shorter half-life for better burst handling

# Dynamic targets (bytes)
g_prot_target_bytes = 0     # dynamically tuned Protected target (bytes)
g_win_target_bytes = 0      # dynamically tuned Window target (bytes)
g_last_cap = 0

# Ghost lists for ARC-style adaptation (bytes-limited)
ghost_prob = OrderedDict()  # keys evicted from Window/Probation
ghost_prot = OrderedDict()  # keys evicted from Protected
ghost_prob_bytes = 0
ghost_prot_bytes = 0

# Scoring / sampling
SAMPLE_K_WIN = 8
SAMPLE_K_PROB = 8
SAMPLE_K_PROT = 6

# Multi-hit bonus in score
MULTI_HIT_BONUS = 1.0

# Recency half-life (in accesses) controlling how fast old items lose value
RECENCY_HALF_LIFE = 5000.0

# Segment score multipliers (retention bias): higher favors keeping
SEG_WEIGHT = {
    0: 0.85,  # Window slightly penalized
    1: 1.00,  # Probation neutral
    2: 1.15,  # Protected favored
}

# ---------------
# Helpers: init / targets / lfu
# ---------------

def _cap_bytes(cache_snapshot):
    return max(1, int(cache_snapshot.capacity))

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    global g_last_cap, g_prot_target_bytes, g_win_target_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = _cap_bytes(cache_snapshot)
    if g_last_cap != cap or g_prot_target_bytes == 0 or g_win_target_bytes == 0:
        g_last_cap = cap
        # Start with balanced, conservative targets (leave room for Probation)
        g_win_target_bytes = max(1, int(cap * 0.20))
        g_prot_target_bytes = max(1, int(cap * 0.60))
        _ensure_target_bounds(cache_snapshot)

def _ensure_target_bounds(cache_snapshot):
    global g_prot_target_bytes, g_win_target_bytes
    cap = _cap_bytes(cache_snapshot)
    # Keep reasonable bounds
    min_win = int(cap * 0.05)
    max_win = int(cap * 0.40)
    min_prot = int(cap * 0.10)
    max_prot = int(cap * 0.80)

    g_win_target_bytes = max(min_win, min(max_win, int(g_win_target_bytes)))
    g_prot_target_bytes = max(min_prot, min(max_prot, int(g_prot_target_bytes)))

    # Ensure Probation gets at least 10% of cache
    max_sum = int(cap * 0.90)
    total = g_win_target_bytes + g_prot_target_bytes
    if total > max_sum:
        # Scale down proportionally
        if total > 0:
            scale = max_sum / float(total)
            g_win_target_bytes = max(min_win, int(g_win_target_bytes * scale))
            g_prot_target_bytes = max(min_prot, int(g_prot_target_bytes * scale))

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# ---------------
# Ghost lists and adaptation (ARC-like)
# ---------------

def _ghost_cap(cache_snapshot):
    # Total bytes allowed for each ghost list (soft bound)
    return max(1, _cap_bytes(cache_snapshot) // 2)

def _ghost_add(cache_snapshot, seg_id, key, size):
    global ghost_prob_bytes, ghost_prot_bytes
    if seg_id == 2:
        if key in ghost_prot:
            old = ghost_prot.pop(key)
            ghost_prot_bytes -= old
        ghost_prot[key] = size
        ghost_prot_bytes += size
        cap = _ghost_cap(cache_snapshot)
        while ghost_prot_bytes > cap and ghost_prot:
            k, s = ghost_prot.popitem(last=False)
            ghost_prot_bytes -= s
    else:
        if key in ghost_prob:
            old = ghost_prob.pop(key)
            ghost_prob_bytes -= old
        ghost_prob[key] = size
        ghost_prob_bytes += size
        cap = _ghost_cap(cache_snapshot)
        while ghost_prob_bytes > cap and ghost_prob:
            k, s = ghost_prob.popitem(last=False)
            ghost_prob_bytes -= s

def _adapt_on_ghost_ref(cache_snapshot, key):
    # If the incoming key was recently in a ghost list, adapt targets
    if key in ghost_prot:
        s = ghost_prot.get(key, 0)
        _tune_targets(cache_snapshot, delta_win=0, delta_prot=max(1, s))
        ghost_prot.move_to_end(key, last=True)
    elif key in ghost_prob:
        s = ghost_prob.get(key, 0)
        _tune_targets(cache_snapshot, delta_win=max(1, s // 2), delta_prot=-(max(1, s // 4)))
        ghost_prob.move_to_end(key, last=True)

def _tune_targets(cache_snapshot, delta_win=0, delta_prot=0):
    global g_win_target_bytes, g_prot_target_bytes
    if delta_win == 0 and delta_prot == 0:
        return
    g_win_target_bytes += int(delta_win)
    g_prot_target_bytes += int(delta_prot)
    _ensure_target_bounds(cache_snapshot)
    # After changing targets we may need to demote/trim
    _demote_prot_if_needed(cache_snapshot)
    _trim_window_if_needed(cache_snapshot)

# ---------------
# Segment helpers
# ---------------

def _seg_remove(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes = max(0, win_bytes - size)
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes = max(0, prob_bytes - size)
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes = max(0, prot_bytes - size)
    else:
        win_lru.pop(key, None)
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)
    return seg

def _seg_insert_win(key, size):
    global win_bytes, prob_bytes, prot_bytes
    # Remove from wherever it may be
    prev = m_segment.get(key)
    if prev == 0:
        # refresh MRU
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
        else:
            win_lru[key] = None
        return
    if prev == 1 and key in prob_lru:
        prob_lru.pop(key, None)
        prob_bytes = max(0, prob_bytes - size)
    if prev == 2 and key in prot_lru:
        prot_lru.pop(key, None)
        prot_bytes = max(0, prot_bytes - size)
    # Insert to Window MRU
    m_segment[key] = 0
    win_lru[key] = None
    win_bytes += size

def _seg_move_to_prob(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 0 and key in win_lru:
        win_lru.pop(key, None)
        win_bytes = max(0, win_bytes - size)
    if seg == 2 and key in prot_lru:
        prot_lru.pop(key, None)
        prot_bytes = max(0, prot_bytes - size)
    prob_lru[key] = None
    m_segment[key] = 1
    prob_bytes += size

def _seg_move_to_prot(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0 and key in win_lru:
        win_lru.pop(key, None)
        win_bytes = max(0, win_bytes - size)
    if seg == 1 and key in prob_lru:
        prob_lru.pop(key, None)
        prob_bytes = max(0, prob_bytes - size)
    prot_lru[key] = None
    m_segment[key] = 2
    prot_bytes += size
    _demote_prot_if_needed(cache_snapshot)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0 and key in win_lru:
        win_lru.move_to_end(key, last=True)
    elif seg == 1 and key in prob_lru:
        prob_lru.move_to_end(key, last=True)
    elif seg == 2 and key in prot_lru:
        prot_lru.move_to_end(key, last=True)

def _demote_prot_if_needed(cache_snapshot):
    global prot_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(0, min(g_prot_target_bytes, cap))
    while prot_bytes > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        prot_bytes = max(0, prot_bytes - dsize)
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _trim_window_if_needed(cache_snapshot):
    # Keep window near its target by moving oldest window entries to probation
    global win_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(1, min(g_win_target_bytes, cap))
    # small slack to avoid oscillation
    slack = max(1, target // 8)
    while win_bytes > (target + slack) and win_lru:
        dem_key, _ = win_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        win_bytes = max(0, win_bytes - dsize)
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

# ---------------
# Scoring helpers
# ---------------

def _normalized_size(size, capacity):
    # as fraction of capacity; enforce small epsilon
    return max(1e-9, float(size) / float(capacity))

def _recency_weight(cache_snapshot, key):
    # Weight in (0,1]; newer items get weight near 1, older decay toward ~0.5 at half-life
    last = m_last_access.get(key)
    if last is None:
        return 1.0
    age = max(0, cache_snapshot.access_count - last)
    # Smooth decay: w = 1 / (1 + age / H)
    return 1.0 / (1.0 + (float(age) / RECENCY_HALF_LIFE))

def _retention_score(cache_snapshot, key):
    # Higher score = stronger retention; eviction picks smallest score
    cap = _cap_bytes(cache_snapshot)
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size
    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)
    bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 0) >= 2 else 0.0
    rec_w = _recency_weight(cache_snapshot, key)
    seg = m_segment.get(key, 1)
    seg_w = SEG_WEIGHT.get(seg, 1.0)
    # Diminishing returns on frequency; combine with recency; favor small size
    base = (math.log2(1.0 + float(freq)) + bonus) * rec_w
    score = (base / size_norm) * seg_w
    return score

def _pick_global_candidate(cache_snapshot):
    # Sample from tails (oldest) of each segment and pick the globally worst score
    candidates = []

    def add_k(order, k):
        i = 0
        for key in order.keys():
            candidates.append(key)
            i += 1
            if i >= k:
                break

    if win_lru:
        add_k(win_lru, SAMPLE_K_WIN)
    if prob_lru:
        add_k(prob_lru, SAMPLE_K_PROB)
    if prot_lru:
        add_k(prot_lru, SAMPLE_K_PROT)

    if not candidates:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    worst_key = None
    worst_score = None
    for key in candidates:
        s = _retention_score(cache_snapshot, key)
        if worst_score is None or s < worst_score:
            worst_score = s
            worst_key = key
    return worst_key

# ---------------
# Policy entry points
# ---------------

def evict(cache_snapshot, obj):
    """
    Eviction strategy:
      - Global sampling across Window/Probation/Protected tails.
      - Compute TinyLFU + recency + size-aware retention scores, with segment biases.
      - Evict the candidate with the lowest score.
      - If the incoming object's predicted score is worse than all candidates, this still evicts
        the globally worst resident, which implicitly acts as admission control.
    """
    _init_if_needed(cache_snapshot)

    # Optional: compare incoming score to candidate to bias toward keeping strong residents
    victim = _pick_global_candidate(cache_snapshot)
    if victim is None:
        return None

    # Slight admission-like bias: if incoming is clearly weaker than victim, try to evict from Window
    # anyway to reduce main churn. This is a soft nudge and won't degrade global selection much.
    try:
        incoming_size = getattr(obj, "size", 0) or 0
        incoming_key = getattr(obj, "key", None)
        if incoming_key is not None:
            # Predict retention for incoming as if it were in Window
            inc_freq = _lfu_peek(cache_snapshot, incoming_key)
            inc_size_norm = _normalized_size(incoming_size, _cap_bytes(cache_snapshot))
            inc_base = (math.log2(1.0 + float(inc_freq))) * 1.0  # no multi-hit yet
            inc_score = (inc_base / max(1e-9, inc_size_norm)) * SEG_WEIGHT[0]
            victim_score = _retention_score(cache_snapshot, victim)
            # If incoming far worse, and we have Window items, prefer evicting Window oldest
            if inc_score < (victim_score * 0.66) and win_lru:
                # Pick worst among window sample only
                local = None
                worst_s = None
                i = 0
                for k in win_lru.keys():
                    s = _retention_score(cache_snapshot, k)
                    if worst_s is None or s < worst_s:
                        worst_s = s
                        local = k
                    i += 1
                    if i >= SAMPLE_K_WIN:
                        break
                if local is not None:
                    return local
    except Exception:
        pass

    return victim

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access and resident hit count
      - SLRU promotion:
          * Probation hit -> promote to Protected
          * Protected hit -> refresh
          * Window hit -> refresh in Window
      - Adapt targets:
          * Probation hit: increase Protected target (we under-protected)
          * Protected hit: slightly decrease Protected (let Probation breathe)
          * Window hit: slightly increase Window (more recency needed)
      - Maintain Window trim and Protected demotion toward targets
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k)

    if seg == 1:
        # Probation hit -> promote to Protected
        _seg_move_to_prot(cache_snapshot, k, obj.size)
        # Grow protected: stronger long-term locality
        step = max(1, obj.size // 2)
        _tune_targets(cache_snapshot, delta_prot=step)
    elif seg == 2:
        # Protected hit -> refresh; allow a bit more probation by shrinking protected slightly
        _seg_touch_on_hit(cache_snapshot, k)
        step = max(1, obj.size // 16)
        _tune_targets(cache_snapshot, delta_prot=-step)
    else:
        # Window hit -> just refresh in window
        _seg_touch_on_hit(cache_snapshot, k)
        # If we see many window hits, slightly grow window
        step = max(1, obj.size // 8)
        _tune_targets(cache_snapshot, delta_win=step//2)

    # Keep structures near targets
    _trim_window_if_needed(cache_snapshot)
    _demote_prot_if_needed(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU for the key (admission learns from requests)
      - Adjust targets using ghost feedback (ARC-like)
      - Initialize resident metadata and place into Window MRU
      - Trim Window toward its target (migrate oldest to Probation)
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # ARC-like adaptation using ghost information
    _adapt_on_ghost_ref(cache_snapshot, k)

    # New resident enters Window MRU
    _seg_insert_win(k, obj.size)
    _trim_window_if_needed(cache_snapshot)
    _demote_prot_if_needed(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove it from segment structures and resident-only metadata
      - Record into ghost lists for ARC-style adaptation
      - TinyLFU counts are retained to inform future decisions
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = evicted_obj.size

    # Identify segment before removal (for ghost list)
    seg_before = m_segment.get(ek, 1)
    _seg_remove(cache_snapshot, ek, esize)

    # Resident-only metadata cleanup
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # Remember in ghost for adaptation
    _ghost_add(cache_snapshot, seg_before, ek, esize)

    # After removal, ensure targets still feasible (no-op typically)
    _ensure_target_bounds(cache_snapshot)
```
2025-11-27 23:08:15,159 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Windowed SLRU + TinyLFU + ARC-style adaptation + size-aware sampled eviction
# - Three resident segments (by bytes):
#     Window (very recent), Probation (main new/once-hit), Protected (multi-hit)
# - Eviction order: Window -> Probation -> Protected (minimize main churn)
# - TinyLFU counts (lazy decay) guide which among the oldest to evict (sampled)
# - Size-aware scoring (prefer keeping tiny but hot objects)
# - ARC-like ghost lists dynamically adapt Protected target size (bytes)
# - O(1) updates on hit/insert via OrderedDict LRU queues

import math
from collections import OrderedDict

# ---------------
# Globals
# ---------------

# LRU queues (LRU at left, MRU at right)
win_lru = OrderedDict()   # 0: Window segment (recent)
prob_lru = OrderedDict()  # 1: Probation (main new/once-hit)
prot_lru = OrderedDict()  # 2: Protected (multi-hit)

# Bytes accounting
win_bytes = 0
prob_bytes = 0
prot_bytes = 0

# Resident segment mapping: key -> seg_id {0:win, 1:prob, 2:prot}
m_segment = dict()

# Per-key resident metadata
m_last_access = dict()      # key -> int time
m_resident_hits = dict()    # key -> int

# TinyLFU: 4-bit counters with lazy decay
m_lfu_count = dict()        # key -> (count[0..15], epoch)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Dynamic targets (bytes)
g_prot_target_bytes = 0     # dynamically tuned protected target
g_win_target_bytes = 0      # small window target
g_last_cap = 0

# Ghost lists for ARC-style adaptation (bytes-limited)
ghost_prob = OrderedDict()  # keys evicted from Window/Probation
ghost_prot = OrderedDict()  # keys evicted from Protected
ghost_prob_bytes = 0
ghost_prot_bytes = 0

# Scoring / sampling
SAMPLE_K_WIN = 5
SAMPLE_K_PROB = 6
SAMPLE_K_PROT = 4

# Multi-hit bonus in score
MULTI_HIT_BONUS = 0.5

# ---------------
# Helpers: init / targets / lfu
# ---------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    global g_last_cap, g_prot_target_bytes, g_win_target_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = max(1, int(cache_snapshot.capacity))
    if g_last_cap != cap or g_prot_target_bytes == 0 or g_win_target_bytes == 0:
        g_last_cap = cap
        # Start conservatively: small window, large protected
        g_win_target_bytes = max(1, int(cap * 0.05))
        g_prot_target_bytes = max(1, int(cap * 0.70))

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _cap_bytes(cache_snapshot):
    return max(1, int(cache_snapshot.capacity))

# ---------------
# Ghost lists and adaptation (ARC-like)
# ---------------

def _ghost_cap(cache_snapshot):
    # Total bytes allowed for each ghost list (soft bound)
    return _cap_bytes(cache_snapshot)

def _ghost_add(cache_snapshot, seg_id, key, size):
    # Evicted from which segment? 0/1 -> ghost_prob, 2 -> ghost_prot
    global ghost_prob_bytes, ghost_prot_bytes
    if seg_id == 2:
        if key in ghost_prot:
            old = ghost_prot.pop(key)
            ghost_prot_bytes -= old
        ghost_prot[key] = size
        ghost_prot_bytes += size
        # Trim
        cap = _ghost_cap(cache_snapshot)
        while ghost_prot_bytes > cap and ghost_prot:
            k, s = ghost_prot.popitem(last=False)
            ghost_prot_bytes -= s
    else:
        if key in ghost_prob:
            old = ghost_prob.pop(key)
            ghost_prob_bytes -= old
        ghost_prob[key] = size
        ghost_prob_bytes += size
        cap = _ghost_cap(cache_snapshot)
        while ghost_prob_bytes > cap and ghost_prob:
            k, s = ghost_prob.popitem(last=False)
            ghost_prob_bytes -= s

def _adapt_prot_target(cache_snapshot, delta_bytes):
    global g_prot_target_bytes
    cap = _cap_bytes(cache_snapshot)
    # Bounds: leave at least 5% for window + 5% for probation, at most 90% for protected
    min_prot = int(cap * 0.10)
    max_prot = int(cap * 0.90)
    g_prot_target_bytes = max(min_prot, min(max_prot, g_prot_target_bytes + int(delta_bytes)))

def _adapt_on_ghost_ref(cache_snapshot, key):
    # If the incoming key was recently in a ghost list, adapt protected target
    if key in ghost_prot:
        # We previously kept it hot; increase protected to favor long-term
        s = ghost_prot.get(key, 0)
        _adapt_prot_target(cache_snapshot, max(1, s))
        # Move to MRU in ghost (recency)
        ghost_prot.move_to_end(key, last=True)
    elif key in ghost_prob:
        # Previously evicted from probation/window -> favor recency by shrinking protected
        s = ghost_prob.get(key, 0)
        _adapt_prot_target(cache_snapshot, -max(1, s // 2))
        ghost_prob.move_to_end(key, last=True)

# ---------------
# Segment helpers
# ---------------

def _seg_remove(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    else:
        # clean up any remnants
        win_lru.pop(key, None)
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)
    return seg

def _seg_insert_win(key, size):
    global win_bytes
    # ensure not in others
    if m_segment.get(key) == 0:
        # refresh MRU
        win_lru.pop(key, None)
        win_lru[key] = None
        return
    # Remove from other lists if present
    if m_segment.get(key) == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            global prob_bytes
            prob_bytes -= size
    if m_segment.get(key) == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            global prot_bytes
            prot_bytes -= size
    m_segment[key] = 0
    win_lru[key] = None
    win_bytes += size

def _seg_move_to_prob(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 1:
        # refresh MRU
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    if seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    prob_lru[key] = None
    m_segment[key] = 1
    prob_bytes += size

def _demote_prot_if_needed(cache_snapshot):
    # Demote from protected to probation until within target
    global prot_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(0, min(g_prot_target_bytes, cap))
    while prot_bytes > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        prot_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _trim_window_if_needed(cache_snapshot):
    # Keep window near its target by moving oldest window entries to probation (not evict)
    global win_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(1, min(g_win_target_bytes, cap))
    # Allow a little slack to avoid churn
    slack = max(1, target // 8)
    while win_bytes > (target + slack) and win_lru:
        dem_key, _ = win_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        win_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _seg_move_to_prot(cache_snapshot, key, size):
    # Promote to Protected MRU
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 2:
        # refresh MRU
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    prot_lru[key] = None
    m_segment[key] = 2
    prot_bytes += size
    _demote_prot_if_needed(cache_snapshot)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

# ---------------
# Scoring helpers
# ---------------

def _normalized_size(size, capacity):
    # size as percentage of capacity, keep >= small epsilon
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _retention_score(cache_snapshot, key):
    # Higher score = stronger retention; eviction picks smallest score
    cap = _cap_bytes(cache_snapshot)
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size
    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)
    bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    # Size-aware benefit with gentle diminishing returns on frequency
    benefit = (math.log2(1.0 + float(freq)) + bonus) / size_norm
    return benefit

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    # sample k oldest
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            return next(iter(order))
        except StopIteration:
            return None
    return chosen_key

# ---------------
# Policy entry points
# ---------------

def evict(cache_snapshot, obj):
    """
    Eviction strategy:
      - Prefer evicting from Window first to shield main cache (2Q-style)
      - Then from Probation, finally Protected
      - Within a segment, sample a few oldest and evict the one with the lowest
        TinyLFU size-aware score.
    """
    _init_if_needed(cache_snapshot)

    # Choose from Window first (admission filter / reduces main churn)
    if win_lru:
        victim = _pick_candidate_from_order(cache_snapshot, win_lru, SAMPLE_K_WIN)
        return victim

    # Then from Probation
    if prob_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
        return victim

    # Fallback to Protected if others empty
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)
        return victim

    # Last resort
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access and resident hit count
      - Promote to Protected if in Window/Probation
      - Refresh LRU position within its segment
      - Adapt Protected target: increase on Probation hits, slightly decrease on Protected hits
      - Trim Window toward its target
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked; place into Window
        _seg_insert_win(k, obj.size)
        _trim_window_if_needed(cache_snapshot)
        return

    if seg == 0 or seg == 1:
        # Hit in Window or Probation -> promote to Protected
        _seg_move_to_prot(cache_snapshot, k, obj.size)
        # Adapt: probation/window hit means protected was too small -> grow
        step = max(1, obj.size // 2)
        _adapt_prot_target(cache_snapshot, step)
    else:
        # Protected hit: touch and slightly shrink target to allow more probation
        _seg_touch_on_hit(cache_snapshot, k)
        step = max(1, obj.size // 8)
        _adapt_prot_target(cache_snapshot, -step)

    # Keep window near target
    _trim_window_if_needed(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU for the key (admission learns from requests)
      - Adjust Protected target using ARC-like ghost feedback
      - Initialize resident metadata and place into Window MRU
      - Gently trim Window toward its target (migrate oldest to Probation)
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # ARC-like adaptation using ghost information
    _adapt_on_ghost_ref(cache_snapshot, k)

    # New resident enters Window MRU
    _seg_insert_win(k, obj.size)
    _trim_window_if_needed(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove it from segment structures and resident-only metadata
      - Record into ghost lists for ARC-style adaptation
      - Keep TinyLFU counts to inform future decisions
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = evicted_obj.size

    # Identify segment before removal (for ghost list)
    seg_before = m_segment.get(ek, 1)
    _seg_remove(cache_snapshot, ek, esize)

    # Resident-only metadata cleanup
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # Remember in ghost for adaptation
    _ghost_add(cache_snapshot, seg_before, ek, esize)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 16
- Hit Rate: 0.0214

Example 2:
- Trace ID: 4
- Hit Rate: 0.3905

Example 3:
- Trace ID: 28
- Hit Rate: 0.1584

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m23:08:15 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 23:08:15,160 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m23:10:58 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 23:10:58,519 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 23:10:58,521 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Improved: W-TinyLFU + Size-aware SLRU with global sampled eviction and dual ghost-based adaptation
# - Three resident segments (by bytes):
#     Window (very-recent admission buffer), Probation (main once-hit), Protected (multi-hit)
# - Eviction chooses the globally weakest among k oldest from each segment by a size-aware, freq- and age-weighted score
# - Window is NOT the primary eviction sink; we evict chiefly from Probation to preserve recency buffer
# - TinyLFU counters (6-bit, lazy decay) guide both retention and promotion
# - ARC-style ghost lists adapt both Protected target and Window target
# - O(1) updates on hit/insert via OrderedDict LRU queues

import math
from collections import OrderedDict

# ---------------
# Globals
# ---------------

# LRU queues (LRU at left, MRU at right)
win_lru = OrderedDict()   # 0: Window segment (recent)
prob_lru = OrderedDict()  # 1: Probation (main new/once-hit)
prot_lru = OrderedDict()  # 2: Protected (multi-hit)

# Bytes accounting
win_bytes = 0
prob_bytes = 0
prot_bytes = 0

# Resident segment mapping: key -> seg_id {0:win, 1:prob, 2:prot}
m_segment = dict()

# Per-key resident metadata
m_last_access = dict()      # key -> int time
m_resident_hits = dict()    # key -> int (resident hits)

# TinyLFU: 6-bit counters with lazy decay
m_lfu_count = dict()        # key -> (count[0..63], epoch)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096   # more reactive than 8192
LFU_MAX_COUNT = 63

# Dynamic targets (bytes)
g_prot_target_bytes = 0     # protected target
g_win_target_bytes = 0      # window target (adaptive)
g_last_cap = 0

# Ghost lists for ARC-style adaptation (bytes-limited)
ghost_prob = OrderedDict()  # keys evicted from Window/Probation
ghost_prot = OrderedDict()  # keys evicted from Protected
ghost_prob_bytes = 0
ghost_prot_bytes = 0

# Scoring / sampling
SAMPLE_K_WIN = 4
SAMPLE_K_PROB = 8
SAMPLE_K_PROT = 4

# Score tuning
MULTI_HIT_BONUS = 0.8  # bonus for resident multi-hits
AGE_WINDOW_REQS = LFU_DECAY_INTERVAL  # age half-life window (in accesses)

# ---------------
# Helpers: init / targets / lfu
# ---------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _cap_bytes(cache_snapshot):
    return max(1, int(cache_snapshot.capacity))

def _init_if_needed(cache_snapshot):
    global g_last_cap, g_prot_target_bytes, g_win_target_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = _cap_bytes(cache_snapshot)
    if g_last_cap != cap or g_prot_target_bytes == 0 or g_win_target_bytes == 0:
        g_last_cap = cap
        # Start with a balanced split: 20% window, 60% protected (leaves ~20% probation)
        g_win_target_bytes = max(1, int(cap * 0.20))
        g_prot_target_bytes = max(1, int(cap * 0.60))
        _rebalance_targets_bounds(cache_snapshot)

def _rebalance_targets_bounds(cache_snapshot):
    # Ensure targets obey sane bounds and leave some room for probation
    global g_prot_target_bytes, g_win_target_bytes
    cap = _cap_bytes(cache_snapshot)
    min_win = int(cap * 0.02)
    max_win = int(cap * 0.50)
    min_prot = int(cap * 0.10)
    max_prot = int(cap * 0.90)
    # Prefer to leave at least 10% to probation
    max_sum = int(cap * 0.90)
    g_win_target_bytes = max(min_win, min(max_win, g_win_target_bytes))
    g_prot_target_bytes = max(min_prot, min(max_prot, g_prot_target_bytes))
    # Trim sum if needed
    s = g_win_target_bytes + g_prot_target_bytes
    if s > max_sum:
        # Reduce proportionally, but favor not shrinking window too aggressively
        over = s - max_sum
        reduce_prot = min(over, max(0, g_prot_target_bytes - min_prot))
        g_prot_target_bytes -= reduce_prot
        over -= reduce_prot
        if over > 0:
            g_win_target_bytes = max(min_win, g_win_target_bytes - over)

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key, delta=1):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX_COUNT, c + max(1, int(delta)))
    m_lfu_count[key] = (c, cur_epoch)
    return c

# ---------------
# Ghost lists and adaptation (ARC-like)
# ---------------

def _ghost_cap(cache_snapshot):
    # Total bytes allowed for each ghost list (soft bound)
    return _cap_bytes(cache_snapshot)

def _ghost_add(cache_snapshot, seg_id, key, size):
    global ghost_prob_bytes, ghost_prot_bytes
    if seg_id == 2:
        if key in ghost_prot:
            old = ghost_prot.pop(key)
            ghost_prot_bytes -= old
        ghost_prot[key] = size
        ghost_prot_bytes += size
        cap = _ghost_cap(cache_snapshot)
        while ghost_prot_bytes > cap and ghost_prot:
            k, s = ghost_prot.popitem(last=False)
            ghost_prot_bytes -= s
    else:
        if key in ghost_prob:
            old = ghost_prob.pop(key)
            ghost_prob_bytes -= old
        ghost_prob[key] = size
        ghost_prob_bytes += size
        cap = _ghost_cap(cache_snapshot)
        while ghost_prob_bytes > cap and ghost_prob:
            k, s = ghost_prob.popitem(last=False)
            ghost_prob_bytes -= s

def _adapt_targets_on_ghost_ref(cache_snapshot, key):
    # If incoming key hits a ghost list, adapt both protected and window targets.
    # - ghost_prot hit: increase protected (favor long-term)
    # - ghost_prob hit: increase window (favor recency)
    global g_prot_target_bytes, g_win_target_bytes
    cap = _cap_bytes(cache_snapshot)
    if key in ghost_prot:
        s = ghost_prot.get(key, 0)
        g_prot_target_bytes += max(1, s)  # grow protected
        # slight reduction of window to make room, if needed
        g_win_target_bytes -= max(0, s // 4)
        ghost_prot.move_to_end(key, last=True)
        _rebalance_targets_bounds(cache_snapshot)
    elif key in ghost_prob:
        s = ghost_prob.get(key, 0)
        g_win_target_bytes += max(1, s // 2)  # grow window faster
        # slight reduction of protected to make room, if needed
        g_prot_target_bytes -= max(0, s // 4)
        ghost_prob.move_to_end(key, last=True)
        _rebalance_targets_bounds(cache_snapshot)

# ---------------
# Segment helpers
# ---------------

def _seg_remove(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    else:
        win_lru.pop(key, None)
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)
    return seg

def _seg_insert_win(key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 0:
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
        else:
            win_lru[key] = None
        return
    if seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    m_segment[key] = 0
    win_lru[key] = None
    win_bytes += size

def _seg_move_to_prob(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    prob_lru[key] = None
    m_segment[key] = 1
    prob_bytes += size

def _demote_prot_if_needed(cache_snapshot):
    # Demote from protected to probation until within target
    global prot_bytes, prob_bytes
    _rebalance_targets_bounds(cache_snapshot)
    cap = _cap_bytes(cache_snapshot)
    target = max(0, min(g_prot_target_bytes, cap))
    while prot_bytes > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        prot_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _trim_window_if_needed(cache_snapshot):
    # Move oldest window entries to probation until within window target
    global win_bytes, prob_bytes
    _rebalance_targets_bounds(cache_snapshot)
    cap = _cap_bytes(cache_snapshot)
    target = max(1, min(g_win_target_bytes, cap))
    # Allow a little slack to avoid churn
    slack = max(1, target // 8)
    while win_bytes > (target + slack) and win_lru:
        dem_key, _ = win_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        win_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _seg_move_to_prot(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    prot_lru[key] = None
    m_segment[key] = 2
    prot_bytes += size
    _demote_prot_if_needed(cache_snapshot)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

# ---------------
# Scoring helpers
# ---------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _age_factor(cache_snapshot, key):
    # Older => smaller factor (worse retention)
    now = cache_snapshot.access_count
    last = m_last_access.get(key, now)
    age = max(0, now - last)
    w = max(1, AGE_WINDOW_REQS)
    # Smooth decay: 1 / (1 + age / w)
    return 1.0 / (1.0 + (float(age) / float(w)))

def _retention_score(cache_snapshot, key):
    # Higher score = stronger retention; eviction picks the smallest score
    cap = _cap_bytes(cache_snapshot)
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size
    freq = _lfu_peek(cache_snapshot, key)
    rh = m_resident_hits.get(key, 0)
    # Combined benefit: LFU + resident-hit bonus (diminishing returns)
    base = math.log2(1.0 + float(freq)) + MULTI_HIT_BONUS * math.log2(1.0 + float(max(0, rh)))
    # Age devalues stale entries within sampled old set
    age_mult = _age_factor(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)
    # Final retention value per normalized size
    benefit = (base * age_mult) / size_norm
    return benefit

def _pick_global_candidate(cache_snapshot):
    # Sample oldest from each queue and pick globally weakest retention
    candidates = []
    def sample_from(order, k):
        i = 0
        for key in order.keys():
            candidates.append(key)
            i += 1
            if i >= k:
                break
    if win_lru:
        sample_from(win_lru, SAMPLE_K_WIN)
    if prob_lru:
        sample_from(prob_lru, SAMPLE_K_PROB)
    if prot_lru:
        sample_from(prot_lru, SAMPLE_K_PROT)
    if not candidates:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    # Choose min score
    victim = None
    best = None
    for k in candidates:
        sc = _retention_score(cache_snapshot, k)
        if best is None or sc < best:
            best = sc
            victim = k
    return victim

# ---------------
# Policy entry points
# ---------------

def evict(cache_snapshot, obj):
    """
    Eviction strategy:
      - Sample oldest entries from Window, Probation, and Protected
      - Compute size-aware TinyLFU + age retention score
      - Evict the globally weakest candidate
      Rationale: avoids over-evicting recency buffer and can evict oversized, cold Protected members.
    """
    _init_if_needed(cache_snapshot)
    # Before choosing, keep Window near its target (migrates to Probation, not evict)
    _trim_window_if_needed(cache_snapshot)
    # Ensure Protected within target by demoting to Probation if needed
    _demote_prot_if_needed(cache_snapshot)
    # Pick global weakest
    return _pick_global_candidate(cache_snapshot)

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU
      - Update last-access and resident hit count
      - Behavior:
        * Window hit: stay in Window, refresh LRU
        * Probation hit: promote to Protected
        * Protected hit: refresh LRU
      - Adaptation: slightly shrink Protected on Protected hits (more room for probation);
        slightly grow Protected on Probation hits (they were almost cold)
      - Maintain targets and trim/demote if needed
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k)

    if seg is None:
        # Not tracked (shouldn't happen on hit, but be resilient): treat as fresh window entry
        _seg_insert_win(k, obj.size)
        _trim_window_if_needed(cache_snapshot)
        return

    if seg == 0:
        # Window hit: keep in window, refresh
        _seg_touch_on_hit(cache_snapshot, k)
        # Mildly favor window for recency-heavy patterns
        global g_win_target_bytes
        g_win_target_bytes += max(1, obj.size // 16)
        _rebalance_targets_bounds(cache_snapshot)
    elif seg == 1:
        # Probation hit -> promote to Protected
        _seg_move_to_prot(cache_snapshot, k, obj.size)
        # Grow protected slightly: once-cold item just proved useful
        global g_prot_target_bytes
        g_prot_target_bytes += max(1, obj.size // 8)
        _rebalance_targets_bounds(cache_snapshot)
    else:
        # Protected hit: refresh; slightly shrink protected to allow exploration in probation
        _seg_touch_on_hit(cache_snapshot, k)
        global g_prot_target_bytes
        g_prot_target_bytes -= max(1, obj.size // 16)
        _rebalance_targets_bounds(cache_snapshot)

    # Maintain segment limits
    _demote_prot_if_needed(cache_snapshot)
    _trim_window_if_needed(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU for the key (admission learns from requests)
      - Adjust targets using ARC-like ghost feedback (both Protected and Window)
      - Initialize resident metadata and place into Window MRU
      - Trim Window toward its target (migrate oldest to Probation)
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    # Give a slightly stronger initial LFU credit to help near-future recency (admission learning)
    _lfu_inc(cache_snapshot, k, delta=2)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 0

    # ARC-like adaptation using ghost information
    _adapt_targets_on_ghost_ref(cache_snapshot, k)

    # New resident enters Window MRU
    _seg_insert_win(k, obj.size)
    _trim_window_if_needed(cache_snapshot)
    _demote_prot_if_needed(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove it from segment structures and resident-only metadata
      - Record into appropriate ghost list for ARC-style adaptation
      - Keep TinyLFU counts (do not erase) to inform future decisions
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = evicted_obj.size

    # Identify segment before removal (for ghost)
    seg_before = m_segment.get(ek, 1)
    _seg_remove(cache_snapshot, ek, esize)

    # Resident-only metadata cleanup
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # Remember in ghost for adaptation
    _ghost_add(cache_snapshot, seg_before, ek, esize)
    # Optional: small nudge based on evicted segment to stabilize targets
    if seg_before == 2:
        # Evicting Protected means Protected may be too big
        global g_prot_target_bytes
        g_prot_target_bytes -= max(1, esize // 8)
    else:
        # Evicting from Window/Probation -> give Window a tiny nudge
        global g_win_target_bytes
        g_win_target_bytes += max(1, esize // 16)
    _rebalance_targets_bounds(cache_snapshot)
```
2025-11-27 23:11:00,471 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 10
- Hit Rate: 0.1167

Example 2:
- Trace ID: 44
- Hit Rate: 0.1881

Example 3:
- Trace ID: 45
- Hit Rate: 0.1719

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m23:11:00 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 23:11:00,473 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m23:13:34 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 23:13:34,995 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 23:13:34,996 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive Segmented GDS-TinyLFU (AS-GDS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style promoting on hit
# - TinyLFU with faster decay to track recent popularity
# - GDS "clock" priority combines frequency and size; evictions raise the clock
# - Hazard-aware: penalizes items whose age exceeds their expected reuse interval
# - ARC-style adaptive target for protected bytes using two ghost lists (B1/B2)
#   * If a re-reference to a recently evicted probation item occurs, shift capacity
#     toward probation (i.e., reduce protected target); the reverse for protected.
# - Eviction prefers probation; protected is screened unless probation is empty

import math
from collections import OrderedDict

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 2048  # faster decay to stay responsive

# GDS clock and per-key priority
m_clock = 0.0              # global GDS "clock"
m_gds_value = dict()       # key -> float last assigned (clock + base_value)

# Segmented capacity targeting (by bytes), adaptively tuned (ARC-style)
INIT_PROTECTED_FRACTION = 0.66
g_protected_bytes = 0                 # running total of bytes in protected
g_target_protected_bytes = None       # adaptive target in bytes (initialized on first use)

# Ghost lists (recently evicted), LRU and bounded by cache capacity in bytes
ghost_B1 = OrderedDict()   # probation ghost: key -> (time, size)
ghost_B2 = OrderedDict()   # protected ghost: key -> (time, size)
g_ghost_B1_bytes = 0
g_ghost_B2_bytes = 0

# Scoring tunables
SIZE_ALPHA = 1.20          # size penalty exponent (>1 favors small objects)
MULTI_HIT_BONUS = 0.60     # benefit for items with >=2 resident hits
W_FREQ = 1.0               # frequency weight inside base value

# Hazard and recency weights per segment
W_HAZARD_PROB = 0.70
W_REC_PROB = 0.30
W_HAZARD_PROT = 0.45
W_REC_PROT = 0.10

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.45        # react reasonably fast to workload shifts

# Recency window scaling
REC_WIN_MIN = 256
REC_WIN_MULT = 2           # window ~ REC_WIN_MULT * resident_items

# Admission constraints for very large objects
HUGE_FRACTION_NOPROMOTE = 0.50  # if size > 50% capacity, never promote to protected

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    global g_target_protected_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    # Initialize adaptive protected target on first touch
    if g_target_protected_bytes is None:
        cap = cache_snapshot.capacity
        frac = INIT_PROTECTED_FRACTION
        # Clamp to [0, capacity]
        target = int(max(0.0, min(1.0, frac)) * float(cap))
        g_target_protected_bytes = target

def _normalized_size(size, capacity):
    return max(1e-12, float(size) / float(capacity))

def _segment_of(key):
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    # Return adaptive target (already in bytes)
    return g_target_protected_bytes if g_target_protected_bytes is not None else int(INIT_PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _rebalance_segments(cache_snapshot):
    # Demote oldest protected items until protected bytes <= target
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    # Safety check
    if g_protected_bytes <= target:
        return
    while g_protected_bytes > target:
        key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
        if key is None:
            break
        obj = cache_snapshot.cache.get(key)
        if obj is None:
            break
        # Demote to probation
        m_segment[key] = 0
        g_protected_bytes = max(0, g_protected_bytes - obj.size)

# -----------------------------
# Ghost lists (ARC-style adaptivity)
# -----------------------------

def _ghost_add(cache_snapshot, key, size, seg_id):
    global g_ghost_B1_bytes, g_ghost_B2_bytes
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    if seg_id == 0:
        # probation ghost B1
        if key in ghost_B1:
            old_time, old_size = ghost_B1.pop(key)
            g_ghost_B1_bytes -= old_size
        ghost_B1[key] = (now, size)
        g_ghost_B1_bytes += size
        # prune by bytes
        while g_ghost_B1_bytes > cap and len(ghost_B1) > 0:
            k, (t, s) = ghost_B1.popitem(last=False)  # pop oldest
            g_ghost_B1_bytes -= s
    else:
        # protected ghost B2
        if key in ghost_B2:
            old_time, old_size = ghost_B2.pop(key)
            g_ghost_B2_bytes -= old_size
        ghost_B2[key] = (now, size)
        g_ghost_B2_bytes += size
        while g_ghost_B2_bytes > cap and len(ghost_B2) > 0:
            k, (t, s) = ghost_B2.popitem(last=False)
            g_ghost_B2_bytes -= s

def _ghost_check_and_adjust_target_on_insert(cache_snapshot, key, size):
    # ARC-style adaptation:
    # - If key is in B1 (probation ghost), increase probation share => decrease protected target
    # - If key is in B2 (protected ghost), increase protected share => increase protected target
    global g_target_protected_bytes, g_ghost_B1_bytes, g_ghost_B2_bytes
    cap = cache_snapshot.capacity
    adjusted = False
    # amount to shift by: at least size, capped to 1/16 of cache
    step = min(int(0.0625 * cap), max(1, size))

    if key in ghost_B1:
        # Recent miss to probation ghost -> move capacity toward probation
        g_target_protected_bytes = max(0, g_target_protected_bytes - step)
        ghost_B1.pop(key, None)
        adjusted = True
    elif key in ghost_B2:
        # Recent miss to protected ghost -> move capacity toward protected
        g_target_protected_bytes = min(cap, g_target_protected_bytes + step)
        ghost_B2.pop(key, None)
        adjusted = True

    # If we removed from ghosts, adjust their byte counters
    # (pop above already removes, but we need to subtract bytes)
    # Recompute ghost bytes conservatively (cheap since bounded)
    if adjusted:
        total = 0
        for _, s in ghost_B1.values():
            total += s
        g_ghost_B1_bytes = total
        total = 0
        for _, s in ghost_B2.values():
            total += s
        g_ghost_B2_bytes = total

# -----------------------------
# Scoring helpers
# -----------------------------

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)

def _age(now, last):
    if last is None:
        return 1
    return max(1, now - last)

def _hazard(cache_snapshot, key):
    now = cache_snapshot.access_count
    last = m_last_access.get(key)
    age = _age(now, last)
    # expected time to next reuse (lower means soon)
    n_items = max(1, len(cache_snapshot.cache))
    default_window = float(max(REC_WIN_MIN, REC_WIN_MULT * n_items))
    expected = max(1.0, m_irt.get(key, default_window))
    return float(age) / expected  # higher hazard => worse to keep

def _base_value(cache_snapshot, key):
    # Frequency and size-aware base value used by GDS
    cap = cache_snapshot.capacity
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return 0.0
    freq = float(_lfu_peek(cache_snapshot, key))
    size_penalty = (_normalized_size(obj.size, cap)) ** SIZE_ALPHA
    multi_bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    return W_FREQ * math.log2(1.0 + freq) / size_penalty + multi_bonus

def _update_gds_value(cache_snapshot, key):
    # Assign GDS priority on hit/insert
    m_gds_value[key] = m_clock + _base_value(cache_snapshot, key)

def _eviction_score(cache_snapshot, key):
    # Compute eviction priority: smaller -> evict first
    # Start with stored GDS value then subtract penalties
    val = m_gds_value.get(key, 0.0)
    hz = _hazard(cache_snapshot, key)

    now = cache_snapshot.access_count
    last = m_last_access.get(key)
    win = _recency_window(cache_snapshot)
    age_norm = min(1.0, float(_age(now, last)) / float(win))

    seg = _segment_of(key)
    if seg == 1:
        # protected: more tolerant to slower hazard and recency
        val -= (W_HAZARD_PROT * hz + W_REC_PROT * age_norm)
    else:
        val -= (W_HAZARD_PROB * hz + W_REC_PROB * age_norm)
    return val

def _prefer_probation_eviction(cache_snapshot):
    # Return True if there exists any probation item; else False
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) == 0:
            return True
    return False

def _is_huge_object(cache_snapshot, obj):
    return obj.size > int(HUGE_FRACTION_NOPROMOTE * float(cache_snapshot.capacity))

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Rebalance protected bytes toward adaptive target
      - Prefer eviction from probation; if empty, consider protected
      - Select victim with the smallest adjusted eviction score
        Ties broken by oldest last-access time
      - Update GDS clock to the victim's stored priority (pre-adjustment)
    '''
    _init_if_needed(cache_snapshot)

    # Ensure protected does not exceed its target
    _rebalance_segments(cache_snapshot)

    prefer_prob = _prefer_probation_eviction(cache_snapshot)

    min_key = None
    min_score = None
    tie_time = None

    for k in cache_snapshot.cache.keys():
        seg = _segment_of(k)
        if prefer_prob and seg != 0:
            continue
        score = _eviction_score(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if (min_key is None) or (score < min_score) or (score == min_score and last < tie_time):
            min_key = k
            min_score = score
            tie_time = last

    if min_key is None:
        # No probation entries; fall back to scanning protected
        for k in cache_snapshot.cache.keys():
            score = _eviction_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (min_key is None) or (score < min_score) or (score == min_score and last < tie_time):
                min_key = k
                min_score = score
                tie_time = last

    # If still none (empty cache), return None safely
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - Promotion: if in probation and not huge, move to protected
      - Update GDS value to clock + base_value to reinforce retention
      - Enforce adaptive protected target (rebalance if oversized)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize conservatively
        m_irt[k] = float(_recency_window(cache_snapshot))

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion from probation to protected on hit (unless too large)
    seg = _segment_of(k)
    if seg == 0 and not _is_huge_object(cache_snapshot, obj):
        m_segment[k] = 1
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Refresh GDS value
    _update_gds_value(cache_snapshot, k)

    # Enforce adaptive protected target by demoting oldest protected if needed
    _rebalance_segments(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - ARC-like adapt: if key in a ghost list, adjust protected target toward that list
      - Increment TinyLFU for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
      - Initialize GDS value to clock + base_value
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Adapt segment target based on ghost hits
    _ghost_check_and_adjust_target_on_insert(cache_snapshot, k, obj.size)

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    m_irt[k] = float(_recency_window(cache_snapshot))

    # Initialize GDS value (frequency/size-aware) at admission
    _update_gds_value(cache_snapshot, k)

    # Note: protected bytes unchanged (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Raise GDS clock to the victim's stored priority (classic GDS aging)
      - Add victim to appropriate ghost list (ARC-style)
      - Remove resident-only metadata; keep TinyLFU counts
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Raise the clock to the evicted entry's GDS value (if present)
    global m_clock
    ev_val = m_gds_value.pop(ek, None)
    if ev_val is not None:
        # The clock is monotonic non-decreasing
        if ev_val > m_clock:
            m_clock = ev_val

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Add to appropriate ghost list to adapt future segment targets
    _ghost_add(cache_snapshot, ek, evicted_obj.size, seg)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Keep TinyLFU counts across evictions
```
2025-11-27 23:13:53,505 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 46
- Hit Rate: 0.4663

Example 2:
- Trace ID: 25
- Hit Rate: 0.3317

Example 3:
- Trace ID: 2
- Hit Rate: 0.4827

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m23:13:53 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 23:13:53,507 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m23:16:34 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 23:16:34,790 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 23:16:34,792 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Windowed TinyLFU with Segmented main (WTinyLFU-SLRU), size-aware
# - 3 logical segments managed via metadata:
#     0) Window (recency for new entries)
#     1) Probation (main's probationary region)
#     2) Protected (main's protected region)
# - Admission bias: prefer evicting from the window if the incoming object's TinyLFU
#   benefit is lower than the weakest probation resident, preserving strong residents.
# - Size-aware TinyLFU benefit: log2(1+freq) / (size as % of capacity)
# - Probation eviction uses: keep_score = benefit + recency_bonus; evict smallest
# - Promotions/demotions keep segment byte targets roughly balanced
# - TinyLFU counts: lazy-decayed 4-bit counters retained across evictions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_stage = dict()           # key -> 0 (window), 1 (probation), 2 (protected)

# Per-segment byte totals (approx), kept consistent by updates
m_bytes_stage = [0, 0, 0]  # [window_bytes, probation_bytes, protected_bytes]
m_bytes_stamp_items = -1   # to detect when we must rebuild (e.g., after reset)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096  # accesses between epochs (power of two preferred)

# Tunables
WIN_PCT = 0.05             # ~5% of capacity bytes devoted to window
PROT_PCT_MAIN = 0.80       # protected ~80% of main (probation ~20%)
PROB_REC_WEIGHT = 0.20     # weight of recency bonus in probation keep_score
MULTI_HIT_BONUS = 0.25     # bonus to benefit for items with >=2 resident hits
REC_WIN_MIN = 1000         # min recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# -----------------------------
# Initialization and maintenance
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur


def _rebuild_stage_bytes_if_needed(cache_snapshot):
    global m_bytes_stage, m_bytes_stamp_items
    # Build once when we detect mismatch (e.g., after policy swap/reset)
    if m_bytes_stamp_items != len(cache_snapshot.cache):
        b = [0, 0, 0]
        for k, obj in cache_snapshot.cache.items():
            s = m_stage.get(k, 1)  # default unknown to probation
            if s < 0 or s > 2:
                s = 1
                m_stage[k] = 1
            b[s] += obj.size
        m_bytes_stage[0], m_bytes_stage[1], m_bytes_stage[2] = b
        m_bytes_stamp_items = len(cache_snapshot.cache)


def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)
    _rebuild_stage_bytes_if_needed(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Represent size as "percentage of capacity" to stabilize benefit scale
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _benefit(freq, size, capacity, resident_hits=1):
    # Size-aware TinyLFU benefit; small boost for multi-hit residents
    extra = MULTI_HIT_BONUS if resident_hits >= 2 else 0.0
    return (math.log2(1.0 + float(freq)) + extra) / _normalized_size(size, capacity)


def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _probation_keep_score(cache_snapshot, key):
    # Higher score means stronger reason to keep; we evict minimum
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')
    cap = cache_snapshot.capacity
    now = cache_snapshot.access_count
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    freq = _lfu_peek(cache_snapshot, key)
    hits = m_resident_hits.get(key, 1)
    ben = _benefit(freq, obj.size, cap, hits)

    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_bonus = PROB_REC_WEIGHT * (1.0 - a_norm)  # recent -> larger bonus

    return ben + recency_bonus


def _find_lru_in_stage(cache_snapshot, stage):
    # Returns (key, last_time) for the LRU resident in given stage; (None, None) if empty
    lru_key = None
    lru_time = None
    for k in cache_snapshot.cache.keys():
        if m_stage.get(k, 1) != stage:
            continue
        t = m_last_access.get(k, -1)
        if lru_time is None or t < lru_time:
            lru_time = t
            lru_key = k
    return lru_key, lru_time


def _targets(capacity_bytes):
    win_target = int(capacity_bytes * WIN_PCT)
    if win_target < 0:
        win_target = 0
    main_target = max(0, capacity_bytes - win_target)
    prot_target = int(main_target * PROT_PCT_MAIN)
    return win_target, prot_target


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict a victim according to WTinyLFU-SLRU:
      - If window bytes exceed target -> evict LRU in window (recency)
      - Else prefer evicting the weakest probation resident by keep_score
      - Admission bias: if incoming object's benefit is lower than the weakest
        probation resident's benefit, prefer evicting from window instead
      - Fallbacks ensure progress (including protected LRU if needed)
    '''
    _init_if_needed(cache_snapshot)

    cap = cache_snapshot.capacity
    win_target, prot_target = _targets(cap)

    # If window too large, evict LRU from window first
    if m_bytes_stage[0] > win_target:
        key, _ = _find_lru_in_stage(cache_snapshot, 0)
        if key is not None:
            return key

    # Find weakest probation candidate by keep_score (benefit + recency bonus)
    prob_key = None
    prob_score = None
    prob_benefit = None
    prob_last = None

    for k in cache_snapshot.cache.keys():
        if m_stage.get(k, 1) != 1:
            continue
        score = _probation_keep_score(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        if (prob_score is None) or (score < prob_score) or (score == prob_score and last < prob_last):
            prob_score = score
            prob_last = last
            prob_key = k

    # Determine window LRU as an alternative candidate
    win_key, win_last = _find_lru_in_stage(cache_snapshot, 0)

    # Admission bias: compare incoming benefit vs weakest probation benefit
    if prob_key is not None:
        robj = cache_snapshot.cache.get(prob_key)
        # Compute benefit for the probation victim (without recency)
        freq_prob = _lfu_peek(cache_snapshot, prob_key)
        hits_prob = m_resident_hits.get(prob_key, 1)
        prob_benefit = _benefit(freq_prob, robj.size, cap, hits_prob)

        # Incoming object's TinyLFU benefit (no resident bonus)
        freq_new = _lfu_peek(cache_snapshot, obj.key)
        ben_new = _benefit(freq_new, obj.size, cap, resident_hits=1)

        # If incoming is weak relative to probation victim and we have window candidate,
        # prefer evicting from window to protect strong probation residents.
        if (win_key is not None) and (ben_new < prob_benefit):
            return win_key
        # Otherwise evict the weakest probation resident
        return prob_key

    # If no probation exists, evict from window if available
    if win_key is not None:
        return win_key

    # As a last resort, evict LRU from protected (should be rare)
    prot_key, _ = _find_lru_in_stage(cache_snapshot, 2)
    if prot_key is not None:
        return prot_key

    # Fallback: any key
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Increment resident hit count
      - Refresh last-access time
      - Promote across segments:
          window(0) -> probation(1) -> protected(2)
      - If protected exceeds its target bytes, demote its LRU to probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    stage = m_stage.get(k, 1)
    if stage == 0:
        # Promote window -> probation
        m_stage[k] = 1
        m_bytes_stage[0] -= obj.size
        m_bytes_stage[1] += obj.size
    elif stage == 1:
        # Promote probation -> protected
        m_stage[k] = 2
        m_bytes_stage[1] -= obj.size
        m_bytes_stage[2] += obj.size

        # Enforce protected target by demoting its LRU if over target
        _, prot_target = _targets(cache_snapshot.capacity)
        if m_bytes_stage[2] > prot_target:
            demote_key, _ = _find_lru_in_stage(cache_snapshot, 2)
            if demote_key is not None:
                dobj = cache_snapshot.cache.get(demote_key)
                if dobj is not None:
                    m_stage[demote_key] = 1
                    m_bytes_stage[2] -= dobj.size
                    m_bytes_stage[1] += dobj.size
    else:
        # stage == 2: just refreshed recency; nothing else
        pass

    # Keep stamp in sync
    m_bytes_stamp_items = len(cache_snapshot.cache)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place in window (stage 0)
      - If window exceeds its target, spill its LRU to probation (no eviction)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    prev_stage = m_stage.get(k)
    if prev_stage is not None:
        # If reinserted (shouldn't normally happen), adjust bytes bookkeeping
        if 0 <= prev_stage <= 2:
            m_bytes_stage[prev_stage] -= obj.size

    m_stage[k] = 0
    m_bytes_stage[0] += obj.size

    # Spill oldest from window to probation if over target
    win_target, _ = _targets(cache_snapshot.capacity)
    while m_bytes_stage[0] > win_target:
        spill_key, _ = _find_lru_in_stage(cache_snapshot, 0)
        if spill_key is None or spill_key == k:
            # Nothing to spill or new item is only window item; break
            break
        sobj = cache_snapshot.cache.get(spill_key)
        if sobj is None:
            break
        m_stage[spill_key] = 1
        m_bytes_stage[0] -= sobj.size
        m_bytes_stage[1] += sobj.size

    m_bytes_stamp_items = len(cache_snapshot.cache)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (stage, last_access, resident_hits)
      - TinyLFU counters are kept across evictions
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    s = m_stage.pop(ek, None)
    if s is not None and 0 <= s <= 2:
        m_bytes_stage[s] -= evicted_obj.size
        if m_bytes_stage[s] < 0:
            m_bytes_stage[s] = 0  # guard against underflow if out-of-sync
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    m_bytes_stamp_items = len(cache_snapshot.cache)
```
2025-11-27 23:16:50,095 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 26
- Hit Rate: 0.7944

Example 2:
- Trace ID: 36
- Hit Rate: 0.2177

Example 3:
- Trace ID: 43
- Hit Rate: 0.3667

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m23:16:50 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 23:16:50,096 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m23:19:27 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 23:19:27,525 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 23:19:27,526 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive Size-Aware Segmented TinyLFU with ARC-style target tuning (AS-SS-TinyLFU)
# Key ideas:
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; target size is ADAPTIVE in bytes
# - ARC-style adaptive target (in bytes) for protected:
#     * Keep two small "ghost" histories (recently-evicted keys from probation/protected)
#     * On insert, if key was in probation-ghost -> increase protected target
#       else if in protected-ghost -> decrease protected target.
# - Eviction:
#     * Prefer probation, but will evict from protected if its worst candidate
#       is significantly weaker than the worst probation candidate (cross-segment choice).
#     * Value/score combines TinyLFU frequency, size penalty, recency, predicted reuse (IRT),
#       multi-hit bonus, small bias to protect protected, staleness penalty,
#       and packing bias to preserve many small items when a large admission arrives.
# - Frequency: TinyLFU with lazy decay (4-bit counters, epoch >= every 4K accesses).
# - Predicted reuse: EMA of inter-arrival time (IRT).
# - Bytes accounting for protected segment maintained precisely, with on-demand demotions
#   to keep protected near its adaptive target.

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096  # access-counts between epochs (power of two recommended)

# Segmented SLRU target for protected (adaptive, by bytes)
g_protected_bytes = 0
g_protected_target_bytes = None  # set on first _init_if_needed

# Ghost histories (recently-evicted residents) for ARC-style target tuning
ghost_prob = dict()        # key -> (time:int, size:int)
ghost_prot = dict()        # key -> (time:int, size:int)
g_ghost_prob_bytes = 0
g_ghost_prot_bytes = 0

# -----------------------------
# Tunables
# -----------------------------

# Adaptive protected target constraints (fractions of capacity)
PROT_INIT_FRAC = 0.60
PROT_MIN_FRAC = 0.10
PROT_MAX_FRAC = 0.90

# Target adjustment step (bytes) bounds
TARGET_STEP_FRAC = 1.0 / 64.0  # at least 1.6% of capacity
TARGET_STEP_CAP = 0.10         # cap per adjustment to 10% capacity

# Ghost budgets (bytes)
GHOST_BUDGET_FRAC = 1.0  # each ghost list up to 100% of capacity in total bytes

# Scoring tunables
SIZE_ALPHA = 1.25            # >1 penalizes very large objects more (size-aware)
MULTI_HIT_BONUS = 0.35       # extra benefit for items with >=2 resident hits
PROTECTED_STABILITY_BONUS = 0.06  # small bonus to avoid churning protected
STALE_PENALTY = 0.45         # penalty when age >> predicted reuse interval
PACKING_BIAS = 0.25          # prefer keeping many small items when a large item arrives
PROT_CROSS_EVICT_MARGIN = 0.10  # allow protected eviction if clearly worse than probation

# Recency windows and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 4             # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.20
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40          # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    global g_protected_target_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    if g_protected_target_bytes is None:
        cap = max(1, cache_snapshot.capacity)
        g_protected_target_bytes = int(PROT_INIT_FRAC * float(cap))

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(max(PROT_MIN_FRAC * cache_snapshot.capacity,
                   min(PROT_MAX_FRAC * cache_snapshot.capacity,
                       float(g_protected_target_bytes))))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item(s) to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    # Demote until within target or no protected remains
    while g_protected_bytes > target:
        key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
        if key is None:
            break
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            g_protected_bytes = max(0, g_protected_bytes - obj.size)
        m_segment[key] = 0  # probation

def _ghost_budget_bytes(cache_snapshot):
    return int(GHOST_BUDGET_FRAC * float(cache_snapshot.capacity))

def _ghost_add(cache_snapshot, key, size, seg_id):
    # Insert into appropriate ghost with timestamp; prune if exceeds budget
    global g_ghost_prob_bytes, g_ghost_prot_bytes
    now = cache_snapshot.access_count
    budget = _ghost_budget_bytes(cache_snapshot)
    if seg_id == 1:
        prev = ghost_prot.get(key)
        if prev is None:
            ghost_prot[key] = (now, size)
            g_ghost_prot_bytes += size
        else:
            # refresh timestamp, keep size
            ghost_prot[key] = (now, prev[1])
        # prune if over budget
        while g_ghost_prot_bytes > budget and ghost_prot:
            # Remove oldest
            oldest_k = min(ghost_prot, key=lambda x: ghost_prot[x][0])
            _, s = ghost_prot.pop(oldest_k)
            g_ghost_prot_bytes = max(0, g_ghost_prot_bytes - s)
    else:
        prev = ghost_prob.get(key)
        if prev is None:
            ghost_prob[key] = (now, size)
            g_ghost_prob_bytes += size
        else:
            ghost_prob[key] = (now, prev[1])
        while g_ghost_prob_bytes > budget and ghost_prob:
            oldest_k = min(ghost_prob, key=lambda x: ghost_prob[x][0])
            _, s = ghost_prob.pop(oldest_k)
            g_ghost_prob_bytes = max(0, g_ghost_prob_bytes - s)

def _ghost_consume_if_present(cache_snapshot, key):
    # Returns seg_id in which ghost was hit: 0 for probation-ghost, 1 for protected-ghost, or None
    global g_ghost_prob_bytes, g_ghost_prot_bytes
    gp = ghost_prob.pop(key, None)
    if gp is not None:
        _, s = gp
        g_ghost_prob_bytes = max(0, g_ghost_prob_bytes - s)
        return 0
    gpr = ghost_prot.pop(key, None)
    if gpr is not None:
        _, s = gpr
        g_ghost_prot_bytes = max(0, g_ghost_prot_bytes - s)
        return 1
    return None

def _adjust_protected_target_on_ghost_hit(cache_snapshot, seg_id_hit, key_size):
    # ARC-style: ghost hit in probation -> increase protected target
    #            ghost hit in protected -> decrease protected target
    global g_protected_target_bytes
    cap = max(1, cache_snapshot.capacity)
    step_min = int(max(1.0, TARGET_STEP_FRAC * cap))
    step = max(step_min, int(key_size))
    step_cap = int(TARGET_STEP_CAP * float(cap))
    step = min(step, step_cap)
    if seg_id_hit == 0:
        g_protected_target_bytes = min(int(PROT_MAX_FRAC * cap), g_protected_target_bytes + step)
    elif seg_id_hit == 1:
        g_protected_target_bytes = max(int(PROT_MIN_FRAC * cap), g_protected_target_bytes - step)

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key, incoming_obj=None):
    # Larger score -> stronger retention; evict the smallest score.
    now = cache_snapshot.access_count
    cap = max(1, cache_snapshot.capacity)

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    freq_gain = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
        seg_bias = PROTECTED_STABILITY_BONUS
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB
        seg_bias = 0.0

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    # Staleness penalty: if age is well beyond expected reuse, penalize
    stale_penalty = 0.0
    if last is not None:
        age = max(0, now - last)
        # penalize if much older than predicted reuse interval or window
        threshold = max(irt * 1.25, window * 1.0)
        if age > threshold:
            stale_penalty = STALE_PENALTY * (min(2.0, float(age) / float(threshold)) - 1.0)

    # Packing bias: preserve small items when a large admission arrives
    packing_gain = 0.0
    if incoming_obj is not None:
        in_size = max(1, incoming_obj.size)
        # The smaller the resident vs incoming, the larger the gain to retain it
        ratio = min(1.0, float(robj.size) / float(in_size))
        packing_gain = PACKING_BIAS * (1.0 - ratio)

    # Combine
    score = freq_gain - recency_gain - predicted_gain - stale_penalty + seg_bias + packing_gain
    return score

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Adjust protected near its adaptive target by demoting oldest protected if needed
      - Choose victim by comparing both segments:
          * Prefer probation, but if the best protected candidate is clearly worse
            than the best probation candidate (by margin), evict from protected.
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized (demote oldest protected)
    _demote_one_from_protected_if_needed(cache_snapshot)

    # Helper to select best victim in segment
    def select_best(seg_id):
        best_key = None
        best_score = None
        best_time = None
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k, incoming_obj=obj)
            last = m_last_access.get(k, -1)
            if (best_key is None) or (score < best_score) or (score == best_score and last < best_time):
                best_key = k
                best_score = score
                best_time = last
        return best_key, best_score

    prob_key, prob_score = select_best(0)
    prot_key, prot_score = select_best(1)

    # If no items at all
    if prob_key is None and prot_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Prefer probation unless protected is clearly worse by a margin
    if prob_key is not None and prot_key is not None:
        if prot_score + PROT_CROSS_EVICT_MARGIN < prob_score:
            return prot_key
        else:
            return prob_key
    elif prob_key is not None:
        return prob_key
    else:
        return prot_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected and update bytes
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = prev if prev is not None else now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
      - ARC-style ghost check to adapt the protected target:
          * If key in probation-ghost -> increase protected target (recency helped)
          * If key in protected-ghost -> decrease protected target (frequency hurt)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # ARC-style adaptation using ghosts
    seg_ghost = _ghost_consume_if_present(cache_snapshot, k)
    if seg_ghost is not None:
        _adjust_protected_target_on_ghost_hit(cache_snapshot, seg_ghost, obj.size)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
      - Add to appropriate ghost history to enable adaptive target tuning
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed and record ghost
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Record in ghost history for ARC-style target tuning
    _ghost_add(cache_snapshot, ek, evicted_obj.size, seg)

    # Remove resident-only metadata (keep TinyLFU for non-resident frequency)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```
2025-11-27 23:37:28,834 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Adaptive SLRU + TinyLFU with ARC-style ghost tuning and size-aware promotion
# - Two resident segments tracked in bytes: Probation (new/once-hit) and Protected (multi-hit)
# - ARC-inspired ghost lists to adapt the Protected/Probation split online
# - TinyLFU with lazy epoch decay; Doorkeeper prevents singletons from inflating LFU
# - Eviction selects lowest retention-score from sampled old items across segments
# - Size-aware promotion threshold: large objects require more hits to enter Protected
# - All operations are O(1) amortized; sampling keeps eviction fast

import math
from collections import OrderedDict

# -----------------------------
# Global metadata
# -----------------------------

# Dynamic Protected ratio (ARC-style tuning via ghost hits)
g_prot_ratio = 0.80
PROT_MIN = 0.05
PROT_MAX = 0.95

# Sampling parameters (eviction)
SAMPLE_K_PROB = 8
SAMPLE_K_PROT = 6
PROB_BIAS_MARGIN = 0.08  # small bias to prefer evicting from Probation if similar score

# Segmented resident LRU (byte-aware)
prob_lru = OrderedDict()      # key -> None (LRU on left, MRU on right)
prot_lru = OrderedDict()      # key -> None
seg_bytes_prob = 0            # total bytes in Probation
seg_bytes_prot = 0            # total bytes in Protected
m_segment = dict()            # key -> 0 (probation) or 1 (protected)

# Per-key resident metadata
m_last_access = dict()        # key -> int time
m_resident_hits = dict()      # key -> int (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Doorkeeper (per-epoch set to dampen one-hit wonders)
door_epoch = -1
door_set = set()

# ARC-style ghosts (LRU lists of recently evicted keys; metadata-only)
ghost_recent = OrderedDict()   # evicted from Probation
ghost_frequent = OrderedDict() # evicted from Protected

# Scoring tunables
REC_WIN_MIN = 1000
REC_WIN_MULT = 4
REC_WEIGHT = 0.35
MULTI_HIT_BONUS = 0.45

# -----------------------------
# Epoch / TinyLFU / Doorkeeper helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch, door_epoch, door_set
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur
    if cur != door_epoch:
        door_epoch = cur
        # Reset doorkeeper each LFU epoch to avoid unbounded growth
        door_set.clear()

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key, amount=1):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + amount)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _doorkeeper_seen(key):
    # Returns True if key has been seen in the current doorkeeper epoch
    return key in door_set

def _doorkeeper_touch(key):
    # Mark key in doorkeeper; return True if it was already present
    if key in door_set:
        return True
    door_set.add(key)
    return False

# -----------------------------
# Segment helpers
# -----------------------------

def _prot_target_bytes(cache_snapshot):
    try:
        cap = int(cache_snapshot.capacity)
        ratio = float(g_prot_ratio)
        return max(0, min(cap, int(cap * ratio)))
    except Exception:
        return 0

def _seg_insert_prob(key, size):
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 0:
        # refresh MRU
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 1:
        # remove from protected first (safety)
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    m_segment[key] = 0
    prob_lru[key] = None
    seg_bytes_prob += size

def _seg_move_to_prot(cache_snapshot, key, size):
    # Move key to Protected MRU; demote overflow back to Probation
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    m_segment[key] = 1
    prot_lru[key] = None
    seg_bytes_prot += size

    # Demote LRU from Protected into Probation until within target
    target = _prot_target_bytes(cache_snapshot)
    while seg_bytes_prot > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        seg_bytes_prot -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            seg_bytes_prob += dsize
            m_segment[dem_key] = 0
        else:
            m_segment.pop(dem_key, None)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _seg_remove(cache_snapshot, key, size):
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 1:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)

# -----------------------------
# Ghost helpers and adaptive split
# -----------------------------

def _ghost_limit(cache_snapshot):
    # Bound ghost metadata: proportional to resident cardinality
    n = max(256, 8 * max(1, len(cache_snapshot.cache)))
    return n

def _ghost_add(ghost_od, key, limit):
    ghost_od[key] = None
    # Maintain MRU at right
    ghost_od.move_to_end(key, last=True)
    # Trim if beyond limit
    while len(ghost_od) > limit:
        ghost_od.popitem(last=False)

def _adapt_protected_ratio(cache_snapshot, direction, size_hint=0):
    # direction: +1 -> increase Protected, -1 -> decrease Protected
    global g_prot_ratio
    cap = max(1, int(cache_snapshot.capacity))
    # Step grows slightly with object size
    step = 0.02 + min(0.10, 0.30 * (float(size_hint) / float(cap)))
    if direction > 0:
        g_prot_ratio = min(PROT_MAX, g_prot_ratio + step)
    else:
        g_prot_ratio = max(PROT_MIN, g_prot_ratio - step)

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _retention_score(cache_snapshot, key):
    # Lower score -> weaker retention -> better eviction candidate
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    freq = _lfu_peek(cache_snapshot, key)
    multi_bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + multi_bonus) / size_norm

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_penalty = REC_WEIGHT * (1.0 - a_norm)  # higher for very recent -> reduces eviction

    return benefit - recency_penalty

def _pick_candidate_with_score(cache_snapshot, order, k_sample):
    if not order:
        return (None, None)
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            key = next(iter(order))
            return (key, _retention_score(cache_snapshot, key))
        except StopIteration:
            return (None, None)
    return (chosen_key, chosen_score)

def _promotion_threshold(size, capacity):
    # Size-aware promotion threshold (resident_hits must reach this value):
    # - Large objects need more confirmations before entering Protected
    frac = float(size) / float(capacity) if capacity > 0 else 0.0
    if frac >= 0.10:
        return 3  # two re-references (insert -> hit -> hit)
    elif frac >= 0.03:
        return 2  # one re-reference
    else:
        return 2  # small objects promote on first hit

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Evict using adaptive SLRU with TinyLFU scoring:
      - Sample candidates from both segments (older side) and compute retention scores
      - Prefer Probation, but allow evicting Protected if clearly lower score
      - Score blends frequency (TinyLFU, with multi-hit bonus), size, and recency
    """
    _init_if_needed(cache_snapshot)

    # Sample from both segments
    p_key, p_score = _pick_candidate_with_score(cache_snapshot, prob_lru, SAMPLE_K_PROB)
    f_key, f_score = _pick_candidate_with_score(cache_snapshot, prot_lru, SAMPLE_K_PROT)

    if p_key is None and f_key is None:
        # Fallback: any key
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    if p_key is None:
        return f_key
    if f_key is None:
        return p_key

    # Prefer evicting from Probation unless it is substantially more valuable to retain
    if (p_score + PROB_BIAS_MARGIN) <= f_score:
        return p_key
    else:
        return f_key

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access time and resident hit count
      - Promote to Protected when resident_hits reaches size-aware threshold
      - Refresh LRU position
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k, amount=1)
    m_last_access[k] = cache_snapshot.access_count
    prev = m_resident_hits.get(k, 1)
    cur_hits = prev + 1
    m_resident_hits[k] = cur_hits

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked (should be rare); treat as fresh insert into Probation
        _seg_insert_prob(k, obj.size)
        return

    # Size-aware promotion
    th = _promotion_threshold(obj.size, cache_snapshot.capacity)
    if seg == 0:
        if cur_hits >= th:
            _seg_move_to_prot(cache_snapshot, k, obj.size)
        else:
            _seg_touch_on_hit(cache_snapshot, k)
    else:
        _seg_touch_on_hit(cache_snapshot, k)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Doorkeeper: only credit TinyLFU if seen within the current epoch
      - Initialize resident metadata
      - Place into Probation MRU
      - ARC-style ghost hits adapt Protected/Probation split:
          * If key was in Recent-ghost -> favor Probation (shrink Protected)
          * If key was in Frequent-ghost -> favor Protected
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    # Doorkeeper: first sight in epoch -> don't credit LFU; second+ -> credit
    if _doorkeeper_touch(k):
        _lfu_inc(cache_snapshot, k, amount=1)
    else:
        # record presence but give at most a tiny credit (optional)
        pass

    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # ARC-style ghost adaptation
    # If the key reappears after being evicted from Probation, prefer recent (decrease Protected)
    if k in ghost_recent:
        ghost_recent.pop(k, None)
        _adapt_protected_ratio(cache_snapshot, direction=-1, size_hint=obj.size)
    elif k in ghost_frequent:
        ghost_frequent.pop(k, None)
        _adapt_protected_ratio(cache_snapshot, direction=+1, size_hint=obj.size)

    # New resident -> Probation MRU
    _seg_insert_prob(k, obj.size)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove from resident structures and clear resident-only metadata
      - Keep TinyLFU counters for future admission
      - Record key into appropriate ghost list and adapt split bounds dynamically
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Snapshot the segment before removal for ghost classification
    seg = m_segment.get(ek, None)
    _seg_remove(cache_snapshot, ek, evicted_obj.size)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Keep m_lfu_count[ek] for admission heuristics

    # Ghost insertion and limit maintenance
    limit = _ghost_limit(cache_snapshot)
    if seg == 1:
        _ghost_add(ghost_frequent, ek, limit)
    else:
        _ghost_add(ghost_recent, ek, limit)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 43
- Hit Rate: 0.2667

Example 2:
- Trace ID: 3
- Hit Rate: 0.3691

Example 3:
- Trace ID: 27
- Hit Rate: 0.88

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m23:37:28 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 23:37:28,835 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 23:47:43,300 [INFO] openai._base_client: Retrying request to /chat/completions in 0.400252 seconds
[92m23:51:16 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 23:51:16,643 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 23:51:16,646 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive SLRU + TinyLFU with ARC-style ghost tuning, size-aware promotion,
# protected-eviction guard via incoming-score, and corrected recency handling.
# - Two resident segments tracked in bytes: Probation (new/once-hit) and Protected (multi-hit)
# - ARC-inspired ghost lists to adapt the Protected/Probation split online
# - TinyLFU with lazy epoch decay; Doorkeeper prevents singletons from inflating LFU
# - Eviction samples the old end of each segment and uses a retention score
# - Size-aware promotion: larger objects require more confirmations to be promoted
# - Protected eviction is guarded by comparing new object's score to protected candidate
# - Recency weighting corrected to protect very recent items
# - Dynamic sampling sizes adapt to segment population

import math
from collections import OrderedDict

# -----------------------------
# Global metadata
# -----------------------------

# Dynamic Protected ratio (ARC-style tuning via ghost hits)
g_prot_ratio = 0.80
PROT_MIN = 0.05
PROT_MAX = 0.95

# Sampling parameters (eviction)
SAMPLE_BASE_PROB = 6
SAMPLE_BASE_PROT = 4
SAMPLE_MAX_PROB = 32
SAMPLE_MAX_PROT = 24

# Bias/margins
PROB_BIAS_BASE = 0.20          # prefer evicting from Probation if scores close
PROB_BIAS_CAP_BOOST = 0.10     # extra bias if Protected is under target
PROT_EVICT_GUARD = 0.20        # require new object score to exceed protected candidate by this margin

# Segmented resident LRU (byte-aware)
prob_lru = OrderedDict()      # key -> None (LRU on left, MRU on right)
prot_lru = OrderedDict()      # key -> None
seg_bytes_prob = 0            # total bytes in Probation
seg_bytes_prot = 0            # total bytes in Protected
m_segment = dict()            # key -> 0 (probation) or 1 (protected)

# Per-key resident metadata
m_last_access = dict()        # key -> int time
m_resident_hits = dict()      # key -> int (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Doorkeeper (per-epoch set to dampen one-hit wonders)
door_epoch = -1
door_set = set()

# ARC-style ghosts (LRU lists of recently evicted keys; metadata-only)
ghost_recent = OrderedDict()   # evicted from Probation
ghost_frequent = OrderedDict() # evicted from Protected

# Scoring tunables
REC_WIN_MIN = 1000
REC_WIN_MULT = 4
REC_WEIGHT = 0.40
MULTI_HIT_BONUS = 0.50

# -----------------------------
# Epoch / TinyLFU / Doorkeeper helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch, door_epoch, door_set
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur
    if cur != door_epoch:
        door_epoch = cur
        # Reset doorkeeper each LFU epoch to avoid unbounded growth
        door_set.clear()

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key, amount=1):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + amount)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _doorkeeper_touch(key):
    # Mark key in doorkeeper; return True if it was already present
    if key in door_set:
        return True
    door_set.add(key)
    return False

# -----------------------------
# Segment helpers
# -----------------------------

def _prot_target_bytes(cache_snapshot):
    try:
        cap = int(cache_snapshot.capacity)
        ratio = float(g_prot_ratio)
        return max(0, min(cap, int(cap * ratio)))
    except Exception:
        return 0

def _seg_insert_prob(key, size):
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 0:
        # refresh MRU
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 1:
        # remove from protected first (safety)
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    m_segment[key] = 0
    prob_lru[key] = None
    seg_bytes_prob += size

def _seg_move_to_prot(cache_snapshot, key, size):
    # Move key to Protected MRU; demote overflow back to Probation
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    m_segment[key] = 1
    prot_lru[key] = None
    seg_bytes_prot += size

    # Demote LRU from Protected into Probation until within target
    target = _prot_target_bytes(cache_snapshot)
    while seg_bytes_prot > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        seg_bytes_prot -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            seg_bytes_prob += dsize
            m_segment[dem_key] = 0
        else:
            m_segment.pop(dem_key, None)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _seg_remove(cache_snapshot, key, size):
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 1:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)

# -----------------------------
# Ghost helpers and adaptive split
# -----------------------------

def _ghost_limit(cache_snapshot):
    # Bound ghost metadata: proportional to resident cardinality
    n = max(256, 8 * max(1, len(cache_snapshot.cache)))
    return n

def _ghost_add(ghost_od, key, limit):
    ghost_od[key] = None
    # Maintain MRU at right
    ghost_od.move_to_end(key, last=True)
    # Trim if beyond limit
    while len(ghost_od) > limit:
        ghost_od.popitem(last=False)

def _adapt_protected_ratio(cache_snapshot, direction, size_hint=0):
    # direction: +1 -> increase Protected, -1 -> decrease Protected
    global g_prot_ratio
    cap = max(1, int(cache_snapshot.capacity))
    # Step grows slightly with object size
    step = 0.02 + min(0.10, 0.30 * (float(size_hint) / float(cap)))
    if direction > 0:
        g_prot_ratio = min(PROT_MAX, g_prot_ratio + step)
    else:
        g_prot_ratio = max(PROT_MIN, g_prot_ratio - step)

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _benefit_components(cache_snapshot, key, size, last_access, multi_hits):
    freq = _lfu_peek(cache_snapshot, key)
    multi_bonus = MULTI_HIT_BONUS if multi_hits >= 2 else 0.0
    size_norm = _normalized_size(size, cache_snapshot.capacity)
    benefit = (math.log2(1.0 + float(freq)) + multi_bonus) / size_norm

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    now = cache_snapshot.access_count
    a_norm = _recency_normalized(now, last_access, window)
    return benefit, a_norm

def _retention_score(cache_snapshot, key):
    # Lower score -> weaker retention -> better eviction candidate
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size
    last = m_last_access.get(key)
    multi_hits = m_resident_hits.get(key, 1)

    benefit, a_norm = _benefit_components(cache_snapshot, key, size, last, multi_hits)
    # Corrected recency handling: discount older items more, protect very recent ones
    recency_discount = REC_WEIGHT * a_norm  # a_norm ~0 for recent, ~1 for old
    return benefit - recency_discount

def _incoming_score(cache_snapshot, obj):
    # Predict value of the incoming object (not yet resident)
    # Use TinyLFU frequency and size; treat recency as maximally recent (no discount)
    k = obj.key
    size = obj.size
    freq = _lfu_peek(cache_snapshot, k)
    size_norm = _normalized_size(size, cache_snapshot.capacity)
    benefit = math.log2(1.0 + float(freq)) / size_norm
    # No recency discount and no multi-hit bonus yet
    return benefit

def _dynamic_sample_k(order_len, base_k, max_k):
    if order_len <= 0:
        return 0
    # Hybrid of base + sqrt growth
    k = base_k + int(math.sqrt(order_len))
    return max(1, min(max_k, min(order_len, k)))

def _pick_candidate_with_score(cache_snapshot, order, k_sample):
    if not order or k_sample <= 0:
        return (None, None)
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            key = next(iter(order))
            return (key, _retention_score(cache_snapshot, key))
        except StopIteration:
            return (None, None)
    return (chosen_key, chosen_score)

def _promotion_threshold(size, capacity):
    # Size-aware promotion threshold (resident_hits must reach this value):
    # - Very large objects require more confirmations before entering Protected
    frac = float(size) / float(capacity) if capacity > 0 else 0.0
    if frac >= 0.20:
        return 4  # insert(1) -> hit(2) -> hit(3) -> hit(4) to promote
    elif frac >= 0.10:
        return 3
    elif frac >= 0.03:
        return 2
    else:
        return 2

def _prob_bias(cache_snapshot):
    # Prefer Probation eviction more strongly when Protected is under target
    target = _prot_target_bytes(cache_snapshot)
    bias = PROB_BIAS_BASE
    if seg_bytes_prot < target:
        bias += PROB_BIAS_CAP_BOOST
    return bias

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Evict using adaptive SLRU with TinyLFU scoring and protected-eviction guard:
      - Sample candidates from both segments (older side) and compute retention scores
      - Prefer Probation; only evict from Protected if clearly inferior and
        the incoming object's predicted score warrants it
      - Score blends frequency (TinyLFU, with multi-hit bonus), size, and recency (corrected)
    """
    _init_if_needed(cache_snapshot)

    # Dynamic sample sizes based on segment populations
    k_prob = _dynamic_sample_k(len(prob_lru), SAMPLE_BASE_PROB, SAMPLE_MAX_PROB)
    k_prot = _dynamic_sample_k(len(prot_lru), SAMPLE_BASE_PROT, SAMPLE_MAX_PROT)

    # Sample from both segments
    p_key, p_score = _pick_candidate_with_score(cache_snapshot, prob_lru, k_prob)
    f_key, f_score = _pick_candidate_with_score(cache_snapshot, prot_lru, k_prot)

    if p_key is None and f_key is None:
        # Fallback: any key
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    if p_key is None:
        return f_key
    if f_key is None:
        return p_key

    bias = _prob_bias(cache_snapshot)
    n_score = _incoming_score(cache_snapshot, obj)

    # Primary: prefer evicting from Probation unless it is clearly worse to keep
    if (p_score + bias) <= f_score:
        return p_key

    # Secondary guard: only evict from Protected if the incoming object is strong enough
    # i.e., its predicted score exceeds the protected candidate by a margin
    if n_score >= (f_score + PROT_EVICT_GUARD):
        return f_key

    # Otherwise, avoid harming Protected; evict from Probation
    return p_key

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter (weighted: Protected hits count more)
      - Update last-access time and resident hit count
      - Promote to Protected when resident_hits reaches size-aware threshold
      - Refresh LRU position
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    seg = m_segment.get(k)

    # Weight Protected hits a bit more; helps reinforce long-term popularity
    inc = 2 if seg == 1 else 1
    _lfu_inc(cache_snapshot, k, amount=inc)
    m_last_access[k] = cache_snapshot.access_count
    prev = m_resident_hits.get(k, 1)
    cur_hits = prev + 1
    m_resident_hits[k] = cur_hits

    if seg is None:
        # Not tracked (rare); place into Probation
        _seg_insert_prob(k, obj.size)
        return

    # Size-aware promotion
    th = _promotion_threshold(obj.size, cache_snapshot.capacity)
    if seg == 0:
        if cur_hits >= th:
            _seg_move_to_prot(cache_snapshot, k, obj.size)
        else:
            _seg_touch_on_hit(cache_snapshot, k)
    else:
        _seg_touch_on_hit(cache_snapshot, k)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Doorkeeper: only credit TinyLFU if seen within the current epoch
      - Initialize resident metadata
      - Place into Probation MRU
      - ARC-style ghost hits adapt Protected/Probation split:
          * If key was in Recent-ghost -> favor Probation (shrink Protected)
          * If key was in Frequent-ghost -> favor Protected
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    # Doorkeeper: first sight in epoch -> don't credit LFU; second+ -> credit
    if _doorkeeper_touch(k):
        _lfu_inc(cache_snapshot, k, amount=1)

    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # ARC-style ghost adaptation
    if k in ghost_recent:
        ghost_recent.pop(k, None)
        _adapt_protected_ratio(cache_snapshot, direction=-1, size_hint=obj.size)
    elif k in ghost_frequent:
        ghost_frequent.pop(k, None)
        _adapt_protected_ratio(cache_snapshot, direction=+1, size_hint=obj.size)

    # New resident -> Probation MRU
    _seg_insert_prob(k, obj.size)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove from resident structures and clear resident-only metadata
      - Keep TinyLFU counters for future admission
      - Record key into appropriate ghost list and adapt split bounds dynamically
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Snapshot the segment before removal for ghost classification
    seg = m_segment.get(ek, None)
    _seg_remove(cache_snapshot, ek, evicted_obj.size)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Keep m_lfu_count[ek] for admission heuristics

    # Ghost insertion and limit maintenance
    limit = _ghost_limit(cache_snapshot)
    if seg == 1:
        _ghost_add(ghost_frequent, ek, limit)
    else:
        _ghost_add(ghost_recent, ek, limit)
```
2025-11-27 23:54:36,532 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved: Count-based SLRU with TinyLFU, ARC-style adaptive split, and recency-aware scoring
# - Two resident segments by item count, not by bytes:
#     P (probation): admits all new objects; managed by LRU (via last_access timestamps)
#     S (protected): objects that hit at least once; also LRU-managed
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction score blends frequency and recency (recency matters beyond tie-break)
# - ARC-like ghost lists adapt the item split between P and S online (by counts)
#
# This design captures:
#   - Recency (via LRU timestamps and explicit recency in eviction score)
#   - Frequency (via TinyLFU)
#   - Adaptivity between recency-friendly and frequency-friendly behavior
#   - Correctness for caches limited by number of items (not bytes)

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU)
m_key_segment = dict()       # key -> 'P' or 'S'

# Current resident ITEM COUNTS per segment
m_cnt_P = 0
m_cnt_S = 0

# Adaptive target for protected items (S); probation target = capacity_items - target_S
m_target_S_items = None
m_cap_items_est = 0  # our estimate of capacity in number of items (learned at evict time)

# Ghost lists (non-resident metadata) to adapt split; store key -> last_time
m_ghost_P = dict()  # B1
m_ghost_S = dict()  # B2
m_ghost_limit_items = None

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)

# ---------------
# Scoring params
# ---------------
# Recency blend: score = est_freq + rec_weight * min(recency / half_life, rec_cap)
m_rec_half_life = 500.0  # accesses; tune to make recency effect comparable to est_freq
m_rec_cap = 10.0         # cap normalized recency contribution
m_rec_weight_P = 1.0     # probation recency weight
m_rec_weight_S = 0.6     # protected recency weight (S is more persistent)
m_protect_S_bias = 0.25  # additive bias to S candidates to modestly protect them
m_overweight_nudge = 0.2 # when a segment exceeds target, nudge its candidate to be more evictable

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_target_S_items, m_ghost_limit_items
    global m_sketch_tables, m_sketch_mask
    global m_cap_items_est

    # Learn capacity in items opportunistically; on evict() we'll update more accurately.
    if m_cap_items_est < len(cache_snapshot.cache):
        m_cap_items_est = len(cache_snapshot.cache)

    if m_target_S_items is None:
        # Start slightly frequency-friendly; adapt online
        base_items = max(1, len(cache_snapshot.cache))
        m_target_S_items = int(base_items * 0.6)

    if m_ghost_limit_items is None:
        # Each ghost list limited to approximately the cache capacity in items (we adjust later)
        m_ghost_limit_items = max(1, len(cache_snapshot.cache))

    if m_sketch_tables is None:
        # Width scales with estimated items; choose power of two near items*4 (empirical)
        # Minimum width to keep estimates reasonably stable.
        items = max(1, len(cache_snapshot.cache))
        width = 1
        target = max(1024, min(1 << 16, items * 4))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        # Halve all counters (right-shift by 1)
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _normalized_recency(now, last):
    if last is None or last < 0:
        return m_rec_cap
    age = max(0, now - last)
    norm = age / m_rec_half_life
    if norm > m_rec_cap:
        norm = m_rec_cap
    return norm


def _pick_min_score_in_segment(cache_snapshot, seg_tag, now):
    # Returns (key, score, last_time) that minimizes blended score within a segment
    # Score = est_freq + rec_weight * normalized_recency; tie-break by older first
    min_key = None
    min_score = None
    min_time = None

    rec_w = m_rec_weight_S if seg_tag == 'S' else m_rec_weight_P

    for key, obj in cache_snapshot.cache.items():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        est = float(_sketch_estimate(key))
        last = m_key_last_access.get(key, -1)
        rec = _normalized_recency(now, last)
        score = est + rec_w * rec
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = key
            min_score = score
            min_time = last

    return (min_key, min_score, min_time)


def _find_oldest_in_segment(cache_snapshot, seg_tag):
    oldest_key, oldest_time = None, None
    for k in cache_snapshot.cache.keys():
        if m_key_segment.get(k, 'P') != seg_tag:
            continue
        t = m_key_last_access.get(k, -1)
        if oldest_time is None or t < oldest_time:
            oldest_key, oldest_time = k, t
    return oldest_key


def _ghost_add(ghost_dict, key, time_now, which):
    # Add key->time to chosen ghost (which in {'P','S'}), trimming if exceeds limit
    global m_ghost_limit_items

    # Insert/update
    ghost_dict[key] = time_now

    # Trim to limit by evicting oldest
    limit = m_ghost_limit_items or 0
    if limit <= 0:
        return

    while len(ghost_dict) > limit:
        oldest_key, oldest_time = None, None
        for k, t in ghost_dict.items():
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        if oldest_key is None:
            break
        ghost_dict.pop(oldest_key, None)


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    # If key in P-ghost (B1): increase probation share (decrease S target)
    # If key in S-ghost (B2): increase protected share (increase S target)
    global m_target_S_items, m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Update our item-capacity estimate when cache is likely full (best signal: on evict call, but keep here too)
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)

    # Keep ghost size limits around capacity in items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est

    cap_items = max(1, m_cap_items_est)

    # Step size: 1 item per signal (conservative, stable)
    step = 1

    if obj.key in m_ghost_P:
        # Recent ghost hit: favor recency -> increase P share (decrease S)
        m_target_S_items = _clamp((m_target_S_items or 0) - step, 0, cap_items)
        m_ghost_P.pop(obj.key, None)
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: favor frequency -> increase S share
        m_target_S_items = _clamp((m_target_S_items or 0) + step, 0, cap_items)
        m_ghost_S.pop(obj.key, None)


def _maybe_demote_from_S_to_P(cache_snapshot):
    # If S exceeds its target, demote oldest S item to P
    global m_cnt_P, m_cnt_S, m_target_S_items
    if m_target_S_items is None:
        return
    if m_cnt_S > m_target_S_items:
        demote_key = _find_oldest_in_segment(cache_snapshot, 'S')
        if demote_key is not None:
            m_key_segment[demote_key] = 'P'
            m_cnt_S = max(0, m_cnt_S - 1)
            m_cnt_P += 1


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using count-based SLRU + TinyLFU with recency-aware scoring.
    - Compute candidate with minimal blended score in each segment:
        score = est_freq(key) + rec_weight * normalized_recency
    - Bias to evict from the segment exceeding its item-count target.
    - Protect S moderately by adding a small bias compared to P.
    '''
    global m_cnt_P, m_cnt_S, m_target_S_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Learn/refresh capacity in number of items at the moment of eviction (cache is full now)
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    cap_items = max(1, m_cap_items_est)
    if m_target_S_items is None:
        m_target_S_items = int(0.6 * cap_items)
    target_S = _clamp(m_target_S_items, 0, cap_items)
    target_P = cap_items - target_S

    now = cache_snapshot.access_count

    # Find min-score candidate in each segment
    p_key, p_score, p_lru = _pick_min_score_in_segment(cache_snapshot, 'P', now)
    s_key, s_score, s_lru = _pick_min_score_in_segment(cache_snapshot, 'S', now)

    # Prepare adjusted scores
    best_key = None
    best_adj = None

    if p_key is not None:
        adj_p = p_score
        # If P is overweight, make it slightly more likely to evict from P
        if m_cnt_P > target_P:
            adj_p -= m_overweight_nudge
        # No extra protection bias for P
        best_key = p_key
        best_adj = adj_p

    if s_key is not None:
        adj_s = s_score + m_protect_S_bias
        # If S is overweight, encourage eviction from S
        if m_cnt_S > target_S:
            adj_s -= m_overweight_nudge
        if (best_adj is None) or (adj_s < best_adj):
            best_adj = adj_s
            best_key = s_key

    # Fallback: if we somehow didn't find any key (shouldn't happen), pick oldest globally
    if best_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        best_key = oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - If in probation (P), promote to protected (S); if S exceeds target, demote oldest S to P
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    k = obj.key

    # Update TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    # Promote from P to S on hit
    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        m_key_segment[k] = 'S'
        m_cnt_P = max(0, m_cnt_P - 1)
        m_cnt_S += 1
        # If S above target, demote oldest S back to P
        _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S item split using ARC-like ghosts
      - Increment TinyLFU for the key (TinyLFU trains on both hits and misses)
      - Add the new object to probation (P)
      - Record last access time
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_cnt_P += 1

    # Keep S from drifting above target if previous operations changed target
    _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key
      - Update segment item counters
      - Add the key to the corresponding ghost list (count-limited) to guide future adaptation
      - Keep ghost sizes roughly equal to estimated cache capacity in items
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S
    global m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust item counts and add to appropriate ghost
    now = cache_snapshot.access_count
    if seg == 'S':
        m_cnt_S = max(0, m_cnt_S - 1)
        _ghost_add(m_ghost_S, ek, now, which='S')
    else:
        m_cnt_P = max(0, m_cnt_P - 1)
        _ghost_add(m_ghost_P, ek, now, which='P')

    # Update ghost limits to approximate current capacity in items
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 21
- Error: Error - Timeout

Example 2:
- Trace ID: 19
- Hit Rate: 0.2612

Example 3:
- Trace ID: 10
- Hit Rate: 0.1167

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m23:54:36 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 23:54:36,533 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m23:56:34 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-27 23:56:34,340 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-27 23:56:34,342 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Fast, adaptive SLRU with TinyLFU and ARC-style split using O(1) metadata updates
# Key ideas:
#   - Two resident segments managed by O(1) LRU queues (OrderedDict):
#       P (probation): admits all new items; evict from its LRU tail by default
#       S (protected): items promoted on first hit; demote tail back to P if S exceeds target
#   - TinyLFU (Count-Min Sketch) estimates frequency with periodic aging
#   - ARC-style ghost lists (B1 for P evictions, B2 for S evictions) adapt target |S|
#   - Eviction avoids full scans: pick candidate from tails of P and/or S; use TinyLFU
#     to choose lower-frequency victim between the two tails (simple head-to-head)
#   - All operations are O(1), preventing timeouts on long traces

from collections import OrderedDict

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Resident segments (LRU: left=LRU, right=MRU)
m_P = OrderedDict()  # probation: key -> None
m_S = OrderedDict()  # protected: key -> None

# Optional segment map (helps robustness if metadata desync occurs)
m_key_segment = dict()  # key -> 'P' or 'S'

# ARC-like ghost lists to adapt target split, LRU-managed
m_B1 = OrderedDict()  # ghosts of P
m_B2 = OrderedDict()  # ghosts of S
m_ghost_limit_items = 0

# Target size for protected segment S (in items). Probation target = cap_items - target_S.
m_target_S_items = None
m_cap_items_est = 0  # estimated capacity in number of items (learned when cache is full)

# -----------------------------
# TinyLFU (Count-Min Sketch)
# -----------------------------
m_sketch_tables = None      # list of 4 rows (lists of ints)
m_sketch_mask = None        # width-1 if width is power-of-two
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0
m_sketch_age_interval = 50000  # age after this many accesses
m_sketch_counter_cap = 255     # cap for counters to avoid bloating

# -----------------------------
# Helpers
# -----------------------------

def _clamp(v, lo, hi):
    if v < lo:
        return lo
    if v > hi:
        return hi
    return v

def _init_if_needed(cache_snapshot):
    global m_target_S_items, m_cap_items_est, m_ghost_limit_items, m_sketch_tables, m_sketch_mask
    # Learn capacity-in-items estimate when possible
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)
    if m_target_S_items is None:
        base = max(1, len(cache_snapshot.cache))
        m_target_S_items = int(0.6 * base)  # start slightly frequency-friendly
    if m_ghost_limit_items <= 0:
        m_ghost_limit_items = max(1, len(cache_snapshot.cache))
    if m_sketch_tables is None:
        # Fixed smallish width for speed and stability (4K per row)
        width = 4096
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1

def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]

def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        v = m_sketch_tables[t][i]
        nv = v + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()

def _sketch_estimate(key):
    idxs = _hash_indices(key)
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))

def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0

def _ghost_add(ghost_odict, key):
    # Add/move to MRU and trim to limit by evicting LRU
    if key in ghost_odict:
        ghost_odict.move_to_end(key, last=True)
    else:
        ghost_odict[key] = None
    # Trim to limit
    limit = max(0, m_ghost_limit_items)
    while limit > 0 and len(ghost_odict) > limit:
        ghost_odict.popitem(last=False)

def _adapt_targets_on_insert(obj):
    # ARC-style: if key seen in B1, favor recency => decrease |S|
    #            if key seen in B2, favor frequency => increase |S|
    global m_target_S_items
    step = 1
    cap_items = max(1, m_cap_items_est)
    k = obj.key
    if k in m_B1:
        m_B1.pop(k, None)
        m_target_S_items = _clamp((m_target_S_items or 0) - step, 0, cap_items)
    elif k in m_B2:
        m_B2.pop(k, None)
        m_target_S_items = _clamp((m_target_S_items or 0) + step, 0, cap_items)

def _rebalance_S_to_target():
    # If S exceeds target, demote LRU from S to MRU of P
    global m_target_S_items
    target = max(0, m_target_S_items or 0)
    while len(m_S) > target:
        # Demote S LRU -> P MRU
        s_key, _ = m_S.popitem(last=False)
        m_key_segment.pop(s_key, None)
        # Add to P MRU
        if s_key in m_P:
            m_P.move_to_end(s_key, last=True)
        else:
            m_P[s_key] = None
        m_key_segment[s_key] = 'P'

def _ensure_ghost_limits():
    # Keep ghost size limits around estimated capacity
    global m_ghost_limit_items
    cap_items = max(1, m_cap_items_est)
    if m_ghost_limit_items < cap_items:
        m_ghost_limit_items = cap_items
    while len(m_B1) > m_ghost_limit_items:
        m_B1.popitem(last=False)
    while len(m_B2) > m_ghost_limit_items:
        m_B2.popitem(last=False)

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim in O(1):
      - Prefer evicting P's LRU tail; if S is overweight vs target, evict S's tail
      - TinyLFU head-to-head: if the other segment's tail has strictly lower frequency,
        evict that lower-frequency tail instead (protect the more frequent one)
    '''
    _init_if_needed(cache_snapshot)

    # Learn item capacity when full (most reliable signal)
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    cap_items = max(1, m_cap_items_est)
    # Clamp target within [0, cap]
    if m_target_S_items is None:
        m_target_S_items = int(0.6 * cap_items)
    m_target_S_items = _clamp(m_target_S_items, 0, cap_items)
    target_S = m_target_S_items

    # Get LRU candidates from each segment
    p_key = next(iter(m_P)) if m_P else None  # LRU in P
    s_key = next(iter(m_S)) if m_S else None  # LRU in S

    # If metadata desynced (shouldn't), fall back to any key
    if p_key is None and s_key is None:
        # Fallback: pick any key from the cache
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Pick preferred segment
    if not m_P:
        prefer = 'S'
    elif not m_S:
        prefer = 'P'
    elif len(m_S) > target_S:
        prefer = 'S'
    else:
        prefer = 'P'

    # TinyLFU comparison between tails to protect higher-frequency one
    freq_in = _sketch_estimate(obj.key)
    freq_p = _sketch_estimate(p_key) if p_key is not None else float('inf')
    freq_s = _sketch_estimate(s_key) if s_key is not None else float('inf')
    epsilon = 1  # require strictly lower by at least 1

    victim = None
    if prefer == 'P':
        victim = p_key if p_key is not None else s_key
        # If incoming is not "better" than P's tail but S has strictly lower freq, switch
        if s_key is not None and p_key is not None:
            if freq_in < freq_p and (freq_s + epsilon) < freq_p:
                victim = s_key
    else:
        victim = s_key if s_key is not None else p_key
        if s_key is not None and p_key is not None:
            if freq_in < freq_s and (freq_p + epsilon) < freq_s:
                victim = p_key

    if victim is None:
        # As a last resort
        victim = p_key if p_key is not None else s_key
    return victim

def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Train TinyLFU
      - If key in P, promote to S MRU
      - If key in S, refresh to MRU
      - If S exceeds target, demote its LRU to P MRU
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _sketch_inc(k, 1)

    # Remove from ghosts if present (no longer non-resident)
    m_B1.pop(k, None)
    m_B2.pop(k, None)

    if k in m_S:
        # Refresh to MRU
        m_S.move_to_end(k, last=True)
        m_key_segment[k] = 'S'
        return

    if k in m_P:
        # Promote to S MRU
        m_P.pop(k, None)
        m_S[k] = None
        m_key_segment[k] = 'S'
        _rebalance_S_to_target()
        return

    # Robustness: if metadata missing but hit occurred, place in S
    m_S[k] = None
    m_key_segment[k] = 'S'
    _rebalance_S_to_target()

def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the S/P split using ARC-style ghosts
      - Train TinyLFU on the access (miss)
      - Insert into P MRU
      - Keep S within target by demoting its LRU if necessary
    '''
    _init_if_needed(cache_snapshot)

    _adapt_targets_on_insert(obj)
    _ensure_ghost_limits()

    k = obj.key
    _sketch_inc(k, 1)

    # Ensure no stale entries
    if k in m_S:
        m_S.pop(k, None)
    if k in m_P:
        m_P.pop(k, None)

    # Admit into P MRU
    m_P[k] = None
    m_key_segment[k] = 'P'

    # If S above target due to recent adaptations, rebalance
    _rebalance_S_to_target()

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata
      - Record into the corresponding ghost (B1 for P, B2 for S)
      - Maintain ghost size limits ~ capacity
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Determine segment and remove
    seg = None
    if ek in m_P:
        seg = 'P'
        m_P.pop(ek, None)
    elif ek in m_S:
        seg = 'S'
        m_S.pop(ek, None)
    else:
        # fallback to remembered segment, default to P
        seg = m_key_segment.get(ek, 'P')

    m_key_segment.pop(ek, None)

    # Add to appropriate ghost
    if seg == 'S':
        _ghost_add(m_B2, ek)
    else:
        _ghost_add(m_B1, ek)

    # Refresh capacity estimate and ghost limits
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)
    _ensure_ghost_limits()
```
2025-11-27 23:56:39,991 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 32
- Hit Rate: 0.0878

Example 2:
- Trace ID: 8
- Error: Error - Timeout

Example 3:
- Trace ID: 47
- Hit Rate: 0.1732

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m23:56:39 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-27 23:56:39,992 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m00:00:08 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 00:00:08,523 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 00:00:08,524 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Fast Segmented Size-Aware TinyLFU with LRU lists (FS-SSTinyLFU)
# - Two resident segments (probation/protected) managed by O(1) LRU lists
# - Eviction uses small-K sampling from the LRU-head (oldest) of the chosen segment
#   and a size-aware TinyLFU retention score; avoids full-cache scans
# - Protected segment kept near a target fraction (by bytes) via on-the-fly demotions
# - Metadata updates are O(1) and minimal to avoid timeouts on long traces

import math
from collections import OrderedDict

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# LRU lists by segment (key -> size)
g_probation = OrderedDict()
g_protected = OrderedDict()

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)
m_size = dict()            # key -> size (cached for quick access/demotion)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits
RELIEF_WEIGHT = 0.15       # small bias to evict a single large item when new item is large

# Sampling sizes for eviction candidates
SAMPLE_K_PROB = 8
SAMPLE_K_PROT = 6

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _segment_of(key):
    # Determine from LRU lists first (most reliable), fallback to m_segment
    if key in g_protected:
        return 1
    if key in g_probation:
        return 0
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _normalized_size(size, capacity):
    return max(1e-12, float(size) / float(capacity))

def _benefit_score(cache_snapshot, key, size, resident_hits):
    # Higher benefit => stronger retention (harder to evict)
    cap = cache_snapshot.capacity
    size_norm = _normalized_size(size, cap)
    size_penalty = size_norm ** SIZE_ALPHA
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if resident_hits >= 2 else 0.0
    # Use log2(1+freq) for diminishing returns and divide by size_penalty
    return (math.log2(1.0 + freq) + extra) / size_penalty

def _candidate_eviction_score(cache_snapshot, key, incoming_obj):
    # Lower score => better eviction victim
    size = m_size.get(key)
    if size is None:
        robj = cache_snapshot.cache.get(key)
        size = robj.size if robj is not None else 1
        m_size[key] = size
    resident_hits = m_resident_hits.get(key, 1)
    benefit = _benefit_score(cache_snapshot, key, size, resident_hits)
    # Relief bias: prefer evicting larger objects when the incoming is large
    relief = RELIEF_WEIGHT * min(1.0, float(size) / float(max(1, incoming_obj.size)))
    # Final score: retention minus relief
    return benefit - relief

def _iter_oldest(odict, k):
    # Yield up to k oldest keys from an OrderedDict
    i = 0
    for key in odict.keys():
        yield key
        i += 1
        if i >= k:
            break

def _move_to_probation_mru(key, size):
    # Insert/move a key to MRU of probation
    if key in g_probation:
        g_probation.move_to_end(key, last=True)
    else:
        g_probation[key] = size
    m_segment[key] = 0

def _move_to_protected_mru(key, size):
    # Insert/move a key to MRU of protected
    global g_protected_bytes
    if key in g_protected:
        g_protected.move_to_end(key, last=True)
    else:
        g_protected[key] = size
        g_protected_bytes += size
    m_segment[key] = 1

def _demote_one_protected_lru_to_probation():
    # Demote one LRU (oldest/head) from protected to probation MRU
    global g_protected_bytes
    try:
        old_key, size = next(iter(g_protected.items()))
    except StopIteration:
        return
    # Remove from protected
    g_protected.pop(old_key, None)
    g_protected_bytes = max(0, g_protected_bytes - size)
    # Add to probation MRU
    _move_to_probation_mru(old_key, size)

def _rebalance_protected(cache_snapshot):
    target = _protected_target_bytes(cache_snapshot)
    # Demote until protected within target
    while g_protected_bytes > target and g_protected:
        _demote_one_protected_lru_to_probation()

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting LRU protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Use small-K sampling from the chosen segment's LRU-head and select the
        item with the smallest (benefit - relief) score
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized (by demoting to probation)
    _rebalance_protected(cache_snapshot)

    # Choose segment to evict from
    if g_probation:
        segment = g_probation
        sample_k = SAMPLE_K_PROB
    elif g_protected:
        segment = g_protected
        sample_k = SAMPLE_K_PROT
    else:
        # Fallback if LRU lists are empty/out-of-sync: evict any resident key
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Sample up to K oldest candidates and pick the minimum score
    best_key = None
    best_score = None
    for k in _iter_oldest(segment, sample_k):
        score = _candidate_eviction_score(cache_snapshot, k, obj)
        if best_key is None or score < best_score:
            best_key = k
            best_score = score

    # If something went wrong, fallback to oldest key in chosen segment
    if best_key is None:
        try:
            best_key = next(iter(segment.keys()))
        except StopIteration:
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last_access and resident hit count
      - Maintain LRU order within segment
      - Promote to protected (MRU) on hit if in probation
      - Rebalance protected if it exceeds target bytes by demoting its LRU to probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count
    size = obj.size
    m_size[k] = size

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = _segment_of(k)

    if seg == 0:
        # Promote to protected MRU on hit (SLRU-style)
        # Remove from probation if present
        if k in g_probation:
            g_probation.pop(k, None)
        _move_to_protected_mru(k, size)
    else:
        # Already protected: bump to MRU
        _move_to_protected_mru(k, size)

    # Keep protected near target size
    _rebalance_protected(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access = now
          resident_hits = 1
          segment = probation (MRU)
      - Update LRU structure O(1)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count
    size = obj.size
    m_size[k] = size

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_resident_hits[k] = 1

    # Insert into probation MRU
    if k in g_protected:
        # Shouldn't happen, but keep structures consistent
        size_prev = g_protected.pop(k, None)
        if size_prev:
            global g_protected_bytes
            g_protected_bytes = max(0, g_protected_bytes - size_prev)

    _move_to_probation_mru(k, size)
    # No rebalancing needed here; promotions on hits trigger rebalancing


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata and LRU entries for evicted key
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = m_size.get(ek, evicted_obj.size)

    # Remove from LRU lists and fix accounting
    if ek in g_protected:
        g_protected.pop(ek, None)
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - esize)
    else:
        g_probation.pop(ek, None)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_size.pop(ek, None)
```
2025-11-28 00:03:01,245 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 24
- Hit Rate: 0.3318

Example 2:
- Trace ID: 40
- Hit Rate: 0.1429

Example 3:
- Trace ID: 26
- Hit Rate: 0.7925

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m00:03:01 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 00:03:01,246 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m00:06:33 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 00:06:33,898 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 00:06:33,900 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# GreedyDual + TinyLFU + size- and reuse-aware (GDTLR)
# - Core eviction is GreedyDual-Size-Frequency (GDSF):
#     K(key) = L + priority_component
#     Evict the key with smallest K. After eviction, L := evicted K (aging).
# - priority_component blends:
#     * TinyLFU frequency (lazy-decayed 4-bit counters)
#     * size penalty (favor small items using a sub-linear size exponent)
#     * short-term reuse signal from last two access times (recency gap)
#     * small bonus after multiple resident hits
# - Metadata is updated only on hit/insert; no global sweeps required.
#
# Rationale:
#   - GreedyDual's L-aging provides robust recency/aging without overfitting.
#   - TinyLFU preserves long-term utility signals across evictions.
#   - Size exponent avoids overly penalizing moderately large hot objects.
#   - Short-gap boost protects items that are likely to be referenced soon.
#
# Expected behavior:
#   - Stronger size/frequency balance than pure LRU/TinyLFU-recency blends.
#   - Improved stability across heterogeneous traces.

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int last access time (access_count)
m_prev_access = dict()     # key -> int previous access time (or absent if none)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# GreedyDual priorities
m_gd_K = dict()            # key -> float priority K = L + priority_component
gds_L = 0.0                # global aging value

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables
# Size handling
SIZE_EXP = 0.75            # exponent for size normalization (0=ignore size, 1=GDS exact 1/size)
# Frequency and reuse weighting
W_FREQ = 1.0               # weight for frequency component (log-scale)
MULTI_HIT_BONUS = 0.35     # extra bonus for items with >=2 resident hits
GAP_WEIGHT = 0.25          # recency-gap bonus strength (shorter gap -> larger bonus)
COLD_BONUS = 0.08          # small protection for items without a prior gap
# Recency normalization window for gap
REC_WIN_MIN = 1000
REC_WIN_MULT = 3           # window ~ REC_WIN_MULT * resident_items

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Priority helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)


def _size_norm(size, capacity):
    # Normalize size to fraction of capacity; raise to SIZE_EXP for sub-linear penalty
    if capacity <= 0:
        return 1.0
    frac = max(1e-12, float(size) / float(capacity))
    return frac ** SIZE_EXP


def _gap_boost(cache_snapshot, key):
    # Shorter reuse gap -> larger boost (capped by window)
    now = cache_snapshot.access_count
    last = m_last_access.get(key)
    prev = m_prev_access.get(key)
    if last is None:
        return 0.0
    if prev is None:
        # No prior gap known: mild cold-start protection
        return COLD_BONUS
    gap = max(0, last - prev)
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    norm = min(1.0, float(gap) / float(window))
    return GAP_WEIGHT * (1.0 - norm)


def _priority_component(cache_snapshot, key):
    # priority_component = (W_FREQ * log2(1+freq) + multi-hit bonus + gap boost) / size_norm
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return 0.0  # non-resident; should not happen for eviction scoring

    cap = cache_snapshot.capacity
    size = max(1, obj.size)

    freq = _lfu_peek(cache_snapshot, key)
    base = W_FREQ * math.log2(1.0 + float(freq))

    if m_resident_hits.get(key, 0) >= 2:
        base += MULTI_HIT_BONUS

    base += _gap_boost(cache_snapshot, key)

    denom = _size_norm(size, cap)
    return base / denom


def _ensure_K_for_residents(cache_snapshot):
    # Lazily initialize K for any resident key missing it
    global gds_L
    for k in cache_snapshot.cache.keys():
        if k not in m_gd_K:
            # If we lack last access (e.g., warm start), seed it as old to avoid overprotection
            if k not in m_last_access:
                m_last_access[k] = cache_snapshot.access_count - (REC_WIN_MIN * 2)
            # No prior gap: cold-start bonus handled in _gap_boost()
            p = _priority_component(cache_snapshot, k)
            m_gd_K[k] = gds_L + p


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    GreedyDual eviction:
      - Ensure priorities exist for all residents
      - Select the key with the smallest K (tie: oldest last-access)
    '''
    _init_if_needed(cache_snapshot)

    _ensure_K_for_residents(cache_snapshot)

    min_key = None
    min_K = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        K = m_gd_K.get(k)
        if K is None:
            # Should be rare; compute on the fly
            K = gds_L + _priority_component(cache_snapshot, k)
            m_gd_K[k] = K
        last = m_last_access.get(k, -1)
        if (min_K is None) or (K < min_K) or (K == min_K and last < min_time):
            min_K = K
            min_time = last
            min_key = k

    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Update last/prev access times and resident hit count
      - Refresh GreedyDual priority: K = L + priority_component
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # Update access times: prev <- last, last <- now
    last = m_last_access.get(k)
    if last is not None:
        m_prev_access[k] = last
    else:
        m_prev_access.pop(k, None)
    m_last_access[k] = now

    # Frequency and hits
    _lfu_inc(cache_snapshot, k)
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # GreedyDual priority
    p = _priority_component(cache_snapshot, k)
    m_gd_K[k] = gds_L + p


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after miss):
      - Increment TinyLFU for the requested key (admission learning)
      - Initialize resident metadata: last=now, prev=None, resident_hits=1
      - Initialize GreedyDual priority: K = L + priority_component
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = now
    m_prev_access.pop(k, None)
    m_resident_hits[k] = 1

    p = _priority_component(cache_snapshot, k)
    m_gd_K[k] = gds_L + p


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Age the global L to the victim's K (GreedyDual aging)
      - Remove resident-only metadata (TinyLFU counters are retained)
    '''
    _init_if_needed(cache_snapshot)

    global gds_L

    ek = evicted_obj.key
    # Update L to the evicted priority (classic GreedyDual)
    evicted_K = m_gd_K.pop(ek, None)
    if evicted_K is not None:
        gds_L = max(gds_L, evicted_K)

    # Remove resident-only metadata
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Keep TinyLFU counters to preserve learned popularity across evictions
```
2025-11-28 00:07:19,662 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 25
- Hit Rate: 0.3417

Example 2:
- Trace ID: 30
- Hit Rate: 0.0524

Example 3:
- Trace ID: 15
- Hit Rate: 0.0225

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m00:07:19 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 00:07:19,663 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 00:17:38,088 [INFO] openai._base_client: Retrying request to /chat/completions in 0.396322 seconds
[92m00:20:27 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 00:20:27,395 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 00:20:27,397 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# GreedyDual Size-aware TinyLFU with dynamic protection (GD-S-TinyLFU)
# - TinyLFU counts every access with lazy decay
# - GreedyDual priority per resident: pri = L + gain/size^alpha; on hit: pri += gain/size^alpha
# - Eviction selects smallest priority (probation preferred)
# - Two segments (probation/protected), with adaptive protected target via ghost feedback
# - Ghost directory remembers evicted segment-class; on reinsert, adapts protected target
# - Promotion requires at least two resident hits (and stricter for very large objects)
# - Predicted reuse via EMA of inter-arrival time (IRT) augments gain
#
# This improves over the previous version by:
#   * Switching to additive GreedyDual priorities for scan resistance and stability
#   * Tightening promotion rules to avoid polluting protected with 1-hit items
#   * Adapting protected capacity via lightweight ARC-style ghost hits
#   * Using size-aware gain and robust recency/predicted-reuse components

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access   = dict()  # key -> int time of last access
m_prev_access   = dict()  # key -> int prev time (for IRT)
m_resident_hits = dict()  # key -> int resident hits (>=1 after insert)
m_segment       = dict()  # key -> 0 (probation), 1 (protected)

# Predicted reuse (EMA of inter-arrival time)
m_irt = dict()            # key -> float

# TinyLFU sketch (lazy-decayed saturating counters)
m_lfu_count = dict()      # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# GreedyDual priorities
m_gdpri = dict()          # key -> float GD priority
g_L_age = 0.0             # global aging threshold

# Segmented targeting (bytes)
g_target_protected_frac = 0.70  # adaptive
g_protected_bytes = 0           # bytes currently in protected

# ARC-style light ghost directory: key -> (seg_id, time)
g_ghost = dict()
g_avg_size_bytes = 0.0

# -----------------------------
# Tunables
# -----------------------------

# Size-aware exponent (slightly >1 penalizes very large items)
SIZE_ALPHA = 1.05

# Promotion thresholds
LARGE_ITEM_FRAC = 0.20    # if size >= 20% of capacity, require more evidence
PROMOTE_HITS_LARGE = 3
PROMOTE_HITS_DEFAULT = 2

# Recency/reuse settings
REC_TAU_MIN = 256
REC_TAU_MULT = 4          # tau ~ REC_TAU_MULT * resident_items
IRT_EMA_BETA = 0.40

# Gain weights (probation vs protected)
W_F = 1.00                # frequency (log1p TinyLFU)
W_H = 0.75                # bonus for multi-hit residency
W_R_PROB = 0.25           # recency for probation
W_R_PROT = 0.10           # recency for protected
W_P_PROB = 0.30           # predicted reuse (IRT) probation
W_P_PROT = 0.15           # predicted reuse (IRT) protected

# Ghost-adaptive controller
GHOST_STEP = 0.05         # fraction step when a ghost hit occurs
PROTECTED_MIN = 0.10
PROTECTED_MAX = 0.90

# Avg size EMA
AVG_SIZE_BETA = 0.05

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _segment_of(key):
    return 1 if m_segment.get(key, 0) == 1 else 0

def _normalized_size(size, capacity):
    return max(1e-12, float(size) / float(capacity))

def _protected_target_bytes(cache_snapshot):
    frac = max(PROTECTED_MIN, min(PROTECTED_MAX, g_target_protected_frac))
    return int(frac * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _rebalance_protected(cache_snapshot):
    # Demote oldest protected items until within target
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    while g_protected_bytes > target:
        key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
        if key is None:
            break
        obj = cache_snapshot.cache.get(key)
        if obj is None:
            break
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
        m_segment[key] = 0  # demote to probation

def _update_avg_size(obj_size):
    global g_avg_size_bytes
    if g_avg_size_bytes <= 0.0:
        g_avg_size_bytes = float(obj_size)
    else:
        g_avg_size_bytes = (1.0 - AVG_SIZE_BETA) * g_avg_size_bytes + AVG_SIZE_BETA * float(obj_size)

def _ghost_capacity_count(cache_snapshot):
    # Aim for up to 2x resident count based on avg size; fallback to 2x item count
    if g_avg_size_bytes > 0.0:
        approx_items = max(1, int(cache_snapshot.capacity / max(1.0, g_avg_size_bytes)))
    else:
        approx_items = max(1, len(cache_snapshot.cache))
    return max(2 * approx_items, 64)

def _ghost_record(cache_snapshot, key, seg_id):
    # Record evicted key's segment with timestamp and trim
    g_ghost[key] = (seg_id, cache_snapshot.access_count)
    # Trim if too large
    maxc = _ghost_capacity_count(cache_snapshot)
    if len(g_ghost) > maxc:
        # Remove oldest entries
        to_remove = len(g_ghost) - maxc
        # Build list and sort by time
        items = sorted(g_ghost.items(), key=lambda kv: kv[1][1])
        for i in range(to_remove):
            del g_ghost[items[i][0]]

def _ghost_adapt_on_reuse(cache_snapshot, key):
    # If a reinsert occurs for a ghosted key, adapt the protected target
    global g_target_protected_frac
    entry = g_ghost.pop(key, None)
    if entry is None:
        return
    seg_id, _ = entry
    if seg_id == 1:
        # It was protected when evicted -> increase protected fraction
        g_target_protected_frac = min(PROTECTED_MAX, g_target_protected_frac + GHOST_STEP)
    else:
        # It was probation when evicted -> decrease protected fraction
        g_target_protected_frac = max(PROTECTED_MIN, g_target_protected_frac - GHOST_STEP)

def _tau(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_TAU_MIN, REC_TAU_MULT * n_items)

def _recency_factor(now, last, tau):
    if last is None:
        return 0.0
    age = max(0, now - last)
    # Smoothly decays from ~1 for very recent to ~0 for very old
    return 1.0 / (1.0 + float(age) / float(tau))

def _predicted_reuse_factor(irt, tau):
    if irt is None:
        return 0.0
    return 1.0 / (1.0 + float(irt) / float(tau))

def _gain(cache_snapshot, key, seg_id):
    # Compute value gain used by GreedyDual
    now = cache_snapshot.access_count
    tau = _tau(cache_snapshot)

    f = float(_lfu_peek(cache_snapshot, key))
    freq_term = math.log1p(f)  # log1p for diminishing returns
    multi = 1.0 if m_resident_hits.get(key, 1) >= 2 else 0.0
    last = m_last_access.get(key)
    rec_term = _recency_factor(now, last, tau)
    irt = m_irt.get(key)
    pred_term = _predicted_reuse_factor(irt, tau)

    if seg_id == 1:
        w_r = W_R_PROT
        w_p = W_P_PROT
    else:
        w_r = W_R_PROB
        w_p = W_P_PROB

    return W_F * freq_term + W_H * multi + w_r * rec_term + w_p * pred_term

def _priority_increment(cache_snapshot, key, obj, seg_id):
    # Gain scaled by size penalty
    cap = max(1, cache_snapshot.capacity)
    size_norm = _normalized_size(obj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA
    g = _gain(cache_snapshot, key, seg_id)
    return g / size_penalty

def _ensure_priority(cache_snapshot, key, obj):
    # Ensure m_gdpri[key] exists; if missing, initialize based on current metadata
    if key in m_gdpri:
        return
    seg_id = _segment_of(key)
    inc = _priority_increment(cache_snapshot, key, obj, seg_id)
    m_gdpri[key] = g_L_age + inc

def _promotion_allowed(cache_snapshot, obj):
    # Stricter promotion for very large items
    size_frac = _normalized_size(obj.size, cache_snapshot.capacity)
    hits = m_resident_hits.get(obj.key, 1)
    if size_frac >= LARGE_ITEM_FRAC:
        return hits >= PROMOTE_HITS_LARGE or _lfu_peek(cache_snapshot, obj.key) >= 4
    else:
        return hits >= PROMOTE_HITS_DEFAULT or _lfu_peek(cache_snapshot, obj.key) >= 3

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Rebalance protected segment to its adaptive target by demoting oldest protected
      - Prefer evicting from probation; fallback to protected if probation empty
      - Within a segment, evict the smallest GreedyDual priority (tie-break by oldest)
    '''
    _init_if_needed(cache_snapshot)

    # Rebalance protected segment if oversized
    _rebalance_protected(cache_snapshot)

    # Select victim from probation first
    def select_victim(seg_id):
        min_key = None
        min_pri = None
        min_time = None
        for k, robj in cache_snapshot.cache.items():
            if _segment_of(k) != seg_id:
                continue
            # Ensure a priority exists
            _ensure_priority(cache_snapshot, k, robj)
            pri = m_gdpri.get(k, g_L_age)
            last = m_last_access.get(k, -1)
            if (min_key is None) or (pri < min_pri) or (pri == min_pri and last < min_time):
                min_key = k
                min_pri = pri
                min_time = last
        return min_key

    victim = select_victim(0)
    if victim is None:
        victim = select_victim(1)

    if victim is None:
        # Fallback: arbitrary
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return victim


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU
      - Update IRT EMA and access timestamps
      - Increment resident hits
      - Update GreedyDual priority (add size-aware gain)
      - Promote probation -> protected only if evidence threshold met
      - Rebalance protected target via demotions if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count
    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA from delta
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize conservatively
        m_irt[k] = float(_tau(cache_snapshot))

    m_prev_access[k] = prev if prev is not None else now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Ensure GD priority exists and add increment
    seg_id = _segment_of(k)
    _ensure_priority(cache_snapshot, k, obj)
    inc = _priority_increment(cache_snapshot, k, obj, seg_id)
    m_gdpri[k] = max(m_gdpri.get(k, g_L_age), g_L_age) + inc

    # Conditional promotion
    if seg_id == 0 and _promotion_allowed(cache_snapshot, obj):
        m_segment[k] = 1
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Rebalance protected if oversized
    _rebalance_protected(cache_snapshot)

    # Update avg size
    _update_avg_size(obj.size)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after miss):
      - Increment TinyLFU (counts the request)
      - Initialize resident metadata: last_access/prev_access, resident_hits=1, probation
      - Initialize IRT to tau
      - Initialize GreedyDual priority: L + gain/size^alpha
      - Adapt protected target if this key is in ghost (ARC-style)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT conservatively
    m_irt[k] = float(_tau(cache_snapshot))

    # Initialize GD priority
    _ensure_priority(cache_snapshot, k, obj)

    # Ghost feedback to adapt protected fraction
    _ghost_adapt_on_reuse(cache_snapshot, k)

    # Update avg size
    _update_avg_size(obj.size)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Update global L age to victim's priority (GreedyDual)
      - Track ghost segment for adaptive protected target
      - Remove resident-only metadata (keep TinyLFU)
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Update GreedyDual age to evicted priority
    global g_L_age
    ev_pri = m_gdpri.pop(ek, g_L_age)
    if ev_pri > g_L_age:
        g_L_age = ev_pri

    # Adjust protected bytes if needed (based on segment at eviction time)
    seg_id = _segment_of(ek)
    if seg_id == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Record in ghost for adaptive targeting
    _ghost_record(cache_snapshot, ek, seg_id)

    # Remove resident-only metadata; retain TinyLFU memory
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Keep TinyLFU counts across evictions
```
2025-11-28 00:20:51,934 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# W-TinyLFU + Segmented protection + Size-aware retention
# - Two logical segments:
#     1) probation (new/resurrected items)
#     2) protected (promoted on hit; byte-quota limited)
# - TinyLFU frequency counters with lazy epoch decay (8-bit saturating)
# - Size-aware retention: benefit = log1p(freq) / normalized_size
# - Recency bonus added (not subtracted) to protect recent items
# - Protected segment gets an extra bonus; demoted by LRU when over target bytes
# - Eviction uses lazy min-heaps (probation first, then protected) to avoid full scans
#   with lazy invalidation via per-key stamps; periodic score refresh on pop.
#
# This design:
#   - Dramatically reduces per-eviction cost (avoids O(n) scans) -> fewer timeouts
#   - Corrects recency sign (recent items are now protected, not penalized)
#   - Uses size-aware TinyLFU benefit and a protected segment to cut miss rate

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Cache identity (to reset between runs if needed)
m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting
m_prot_bytes = 0
m_prot_target_bytes = 0

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_probation = []           # retention score (lower => more evictable) for probation
h_protected = []           # retention score for protected (used when probation empty)
h_prot_lru = []            # last_access (min-heap) for protected demotions

# TinyLFU counters (lazy decay with epochs; per-key to keep it simple)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Protected segment target (bytes)
PROT_FRAC = 0.80           # target fraction of capacity for protected bytes

# Recency window and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 3           # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.60     # recency weight in probation
REC_WEIGHT_PROT = 0.40     # recency weight in protected
PROT_BONUS = 0.60          # extra benefit for protected segment
MULTI_HIT_BONUS = 0.30     # extra benefit for items with >=2 resident hits

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16  # bound reheap/refresh work per eviction

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC * cache_snapshot.capacity)

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Return size as percentage of capacity to keep scales stable
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _retention_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # treat missing as extremely good (will be filtered by validity)
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)

    seg = m_segment.get(key, 0)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    # Size-aware frequency benefit
    benefit = math.log1p(float(freq)) / size_norm

    # Multi-hit bias
    if m_resident_hits.get(key, 0) >= 2:
        benefit += MULTI_HIT_BONUS

    # Recency bonus
    if seg == 1:
        benefit += PROT_BONUS + REC_WEIGHT_PROT * rec_bonus
    else:
        benefit += REC_WEIGHT_PROB * rec_bonus

    return benefit


# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    # Compute score at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    score = _retention_score(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (score, s, key))
    else:
        heapq.heappush(h_protected, (score, s, key))
        # Also maintain LRU heap for protected demotions
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot, heap_ref, expected_seg):
    # Return a valid key from the given heap, refreshing stale scores when needed.
    # Limit work per call to avoid long stalls.
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        # Skip invalid/stale entries
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Opportunistically refresh score if it drifted
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            # Reinsert with a new stamp
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key
    return None


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        # Push into probation heap with updated score/stamp
        _push_key(cache_snapshot, key)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim:
      1) Pop the weakest from probation heap (lowest retention)
      2) If probation empty, pop the weakest from protected heap
      3) Fallback: any resident key
    '''
    _init_if_needed(cache_snapshot)

    # Prefer evicting from probation
    victim = _pop_best_candidate(cache_snapshot, h_probation, expected_seg=0)
    if victim is None:
        victim = _pop_best_candidate(cache_snapshot, h_protected, expected_seg=1)

    if victim is not None:
        return victim

    # Fallback: arbitrary key (should be rare)
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote probation -> protected on first resident hit
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with new score/recency
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote to protected
        m_segment[k] = 1
        # Account protected bytes
        global m_prot_bytes
        m_prot_bytes += obj.size
        # Push into protected heaps
        _push_key(cache_snapshot, k)
        # Enforce protected target
        _maybe_demote_protected(cache_snapshot)
    else:
        # Already protected: refresh heaps
        _push_key(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place into probation segment and push to heap
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation
    _push_key(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Adjust protected bytes if it was protected
    seg = m_segment.pop(ek, None)
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 36
- Hit Rate: 0.2115

Example 2:
- Trace ID: 4
- Hit Rate: 0.4954

Example 3:
- Trace ID: 0
- Hit Rate: 0.4971

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m00:20:51 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 00:20:51,937 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m00:24:47 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 00:24:47,056 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 00:24:47,060 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive SLRU + TinyLFU + Size-aware retention + ARC-style target tuning
# - Two logical segments:
#     1) probation (new/resurrected items; recency-biased)
#     2) protected (promoted on hit; frequency-biased; byte-quota limited)
# - TinyLFU counters with lazy epoch decay (8-bit saturating)
# - Size-aware retention: benefit ~ log1p(freq) / size_norm^ALPHA
# - Recency bonus added to protect recent items (segment-specific weights)
# - Protected segment gets an extra bonus; demoted by LRU when over target bytes
# - Eviction compares the weakest from both segments and evicts the globally
#   least valuable; but will only evict from protected if the incoming object's
#   value is at least as high as that protected candidate (admission guard)
# - ARC-style adaptation using ghost lists of recently evicted keys to adjust
#   the protected target dynamically (favor recency vs frequency on the fly)
# - Heaps use lazy invalidation via per-key stamps; periodic score refresh on pop

import math
import heapq
from collections import OrderedDict

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Cache identity (to reset between runs if needed)
m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count (while resident)
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting
m_prot_bytes = 0
m_prot_target_bytes = 0

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_probation = []           # retention score (lower => more evictable) for probation
h_protected = []           # retention score for protected
h_prot_lru = []            # last_access (min-heap) for protected demotions

# TinyLFU counters (lazy decay with epochs; per-key)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# ARC-style ghosts (evicted keys remembered by last segment)
g_probation = OrderedDict()  # B1: ghosts of items evicted from probation
g_protected = OrderedDict()  # B2: ghosts of items evicted from protected

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Protected segment target (bytes) - initial, then adapted dynamically
PROT_FRAC_INIT = 0.75

# Recency window and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 3           # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.80     # recency weight in probation
REC_WEIGHT_PROT = 0.25     # recency weight in protected
PROT_BONUS = 0.50          # extra benefit for protected segment
MULTI_HIT_BONUS = 0.20     # bonus for items with >=2 resident hits

# Size sensitivity
SIZE_EXP = 0.80            # exponent on normalized size (0.7..0.9 recommended)

# Protected-eviction admission guard: only evict protected if new_obj_score >= victim_score
PROT_EVICT_GUARD = True

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16  # bound reheap/refresh work per eviction

# Ghost limits and adaptation step
GHOST_MIN = 1024           # minimum ghost capacity per list (items)
ADAPT_UNIT_DIV = 64        # step ~= capacity / ADAPT_UNIT_DIV bytes per adjustment

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch
    global g_probation, g_protected

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC_INIT * cache_snapshot.capacity)

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0

    g_probation.clear()
    g_protected.clear()


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # size fraction of capacity in [~0,1]; clamp away from zero
    return max(1e-9, float(size) / float(max(1, capacity)))


def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _retention_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # missing, will be filtered by validity
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)

    seg = m_segment.get(key, 0)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    # Size-aware frequency benefit with softened size penalty
    benefit = math.log1p(float(freq)) / (size_norm ** SIZE_EXP)

    # Multi-hit bias (resident)
    if m_resident_hits.get(key, 0) >= 2:
        benefit += MULTI_HIT_BONUS

    # Recency bonus and protected bonus
    if seg == 1:
        benefit += PROT_BONUS + REC_WEIGHT_PROT * rec_bonus
    else:
        benefit += REC_WEIGHT_PROB * rec_bonus

    return benefit


def _hypo_retention_for_new(cache_snapshot, obj):
    # Hypothetical retention score for the incoming object (as if it were resident in probation)
    cap = cache_snapshot.capacity
    freq = _lfu_peek(cache_snapshot, obj.key)
    size_norm = _normalized_size(obj.size, cap)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    # Not resident: no last_access -> recency bonus ~ 0
    benefit = math.log1p(float(freq)) / (size_norm ** SIZE_EXP)
    # probation weights (no multi-hit, no prot bonus, no recency)
    return benefit

# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    # Compute score at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    score = _retention_score(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (score, s, key))
    else:
        heapq.heappush(h_protected, (score, s, key))
        # Also maintain LRU heap for protected demotions
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot, heap_ref, expected_seg):
    # Return a valid key from the given heap, refreshing stale scores when needed.
    # Limit work per call to avoid long stalls.
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        # Skip invalid/stale entries
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Opportunistically refresh score if it drifted
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            # Reinsert with a new stamp
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key, score
    return None, None


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        # Push into probation heap with updated score/stamp
        _push_key(cache_snapshot, key)


# -----------------------------
# Ghost helpers (ARC-style)
# -----------------------------

def _ghost_limit(cache_snapshot):
    # Keep ghosts proportional to active set size
    return max(GHOST_MIN, 2 * max(1, len(cache_snapshot.cache)))


def _ghost_touch(od, key):
    if key in od:
        od.move_to_end(key, last=True)
        return True
    return False


def _ghost_add(cache_snapshot, od, key):
    limit = _ghost_limit(cache_snapshot)
    od[key] = None
    od.move_to_end(key, last=True)
    while len(od) > limit:
        od.popitem(last=False)


def _adapt_protected_target(cache_snapshot, b1_hit=False, b2_hit=False):
    # Adjust protected target bytes based on ghost hits (ARC-style)
    # B1 hit => increase recency (decrease protected target)
    # B2 hit => increase frequency (increase protected target)
    global m_prot_target_bytes
    cap = cache_snapshot.capacity
    unit = max(1, cap // ADAPT_UNIT_DIV)
    len_b1 = len(g_probation)
    len_b2 = len(g_protected)
    if b1_hit:
        delta = unit * max(1, len_b2 // max(1, len_b1))
        m_prot_target_bytes = max(0, m_prot_target_bytes - delta)
    elif b2_hit:
        delta = unit * max(1, len_b1 // max(1, len_b2))
        m_prot_target_bytes = min(cap, m_prot_target_bytes + delta)
    # Clamp within [0, cap]
    m_prot_target_bytes = max(0, min(cap, m_prot_target_bytes))

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim:
      - Demote protected by LRU until within target bytes
      - Pop the weakest candidate from both probation and protected
      - Evict the globally worst (lowest retention score)
      - Admission guard: only evict from protected if the incoming object's
        hypothetical score >= protected candidate's score; otherwise prefer
        probation victim when available
    '''
    _init_if_needed(cache_snapshot)

    # Keep protected within target before selecting victims
    _maybe_demote_protected(cache_snapshot)

    # Pull weakest from both segments (reinsert the non-chosen)
    k_prob, s_prob = _pop_best_candidate(cache_snapshot, h_probation, expected_seg=0)
    k_prot, s_prot = _pop_best_candidate(cache_snapshot, h_protected, expected_seg=1)

    if k_prob is None and k_prot is None:
        # Fallback: arbitrary key (should be rare)
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None

    # Compute incoming object's hypothetical score to guard protected evictions
    new_score = _hypo_retention_for_new(cache_snapshot, obj) if PROT_EVICT_GUARD else -float('inf')

    # Decide on victim
    victim = None
    if k_prob is not None and (k_prot is None or s_prob <= s_prot):
        # Probation candidate is globally weakest (or protected absent)
        victim = k_prob
        # Reinsert protected candidate if any
        if k_prot is not None:
            _push_key(cache_snapshot, k_prot)
    elif k_prot is not None:
        # Protected candidate is weakest
        if (not PROT_EVICT_GUARD) or (new_score >= s_prot) or (k_prob is None):
            # Admit only if incoming is at least as valuable as the protected victim,
            # or if no probation candidate is available
            victim = k_prot
            if k_prob is not None:
                _push_key(cache_snapshot, k_prob)
        else:
            # Prefer evicting from probation to avoid protected churn
            if k_prob is not None:
                victim = k_prob
                _push_key(cache_snapshot, k_prot)
            else:
                victim = k_prot  # no choice

    return victim


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote probation -> protected on first resident hit
         (requirement slightly stricter for very large objects)
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with new score/recency
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote to protected on first resident hit, with guard for very large items
        large_guard = (obj.size > 0.25 * cache_snapshot.capacity)
        if (m_resident_hits[k] >= 2 and not large_guard) or (m_resident_hits[k] >= 3) or (_lfu_peek(cache_snapshot, k) >= 3):
            m_segment[k] = 1
            # Account protected bytes
            global m_prot_bytes
            m_prot_bytes += obj.size
            # Push into protected heaps
            _push_key(cache_snapshot, k)
            # Enforce protected target
            _maybe_demote_protected(cache_snapshot)
        else:
            # Still in probation: refresh its score in heap
            _push_key(cache_snapshot, k)
    else:
        # Already protected: refresh heaps (both retention and LRU)
        _push_key(cache_snapshot, k)
        # Enforce protected target if drifted
        _maybe_demote_protected(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Apply ARC-style adaptation based on ghost hits
      - Increment TinyLFU for the requested key (admission sampling)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place into probation segment and push to heap
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key

    # ARC-style target adaptation using ghosts
    b1_hit = _ghost_touch(g_probation, k)
    b2_hit = _ghost_touch(g_protected, k)
    if b1_hit or b2_hit:
        # Remove from ghosts on re-entry
        if b1_hit:
            g_probation.pop(k, None)
        if b2_hit:
            g_protected.pop(k, None)
        _adapt_protected_target(cache_snapshot, b1_hit=b1_hit, b2_hit=b2_hit)
        # Keep protected within target if it shrank
        _maybe_demote_protected(cache_snapshot)

    # Admission sampling into TinyLFU
    _lfu_inc(cache_snapshot, k)

    # Initialize resident metadata
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1  # counts resident hits; 1 so first hit triggers ">=2" logic
    m_segment[k] = 0  # probation

    # Push to probation heap
    _push_key(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Add its key to the corresponding ghost list (for ARC-style adaptation)
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Determine segment and adjust protected bytes
    seg = m_segment.pop(ek, None)
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Add to ghosts (remember origin segment)
    if seg == 1:
        _ghost_add(cache_snapshot, g_protected, ek)
    else:
        _ghost_add(cache_snapshot, g_probation, ek)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```
2025-11-28 00:25:14,873 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Windowed SLRU + TinyLFU + ARC-style adaptation + size-aware sampled eviction
# - Three resident segments (by bytes):
#     Window (very recent), Probation (main new/once-hit), Protected (multi-hit)
# - Eviction order: Window -> Probation -> Protected (minimize main churn)
# - TinyLFU counts (lazy decay) guide which among the oldest to evict (sampled)
# - Size-aware scoring (prefer keeping tiny but hot objects)
# - ARC-like ghost lists dynamically adapt Protected target size (bytes)
# - O(1) updates on hit/insert via OrderedDict LRU queues

import math
from collections import OrderedDict

# ---------------
# Globals
# ---------------

# LRU queues (LRU at left, MRU at right)
win_lru = OrderedDict()   # 0: Window segment (recent)
prob_lru = OrderedDict()  # 1: Probation (main new/once-hit)
prot_lru = OrderedDict()  # 2: Protected (multi-hit)

# Bytes accounting
win_bytes = 0
prob_bytes = 0
prot_bytes = 0

# Resident segment mapping: key -> seg_id {0:win, 1:prob, 2:prot}
m_segment = dict()

# Per-key resident metadata
m_last_access = dict()      # key -> int time
m_resident_hits = dict()    # key -> int

# TinyLFU: 4-bit counters with lazy decay
m_lfu_count = dict()        # key -> (count[0..15], epoch)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Dynamic targets (bytes)
g_prot_target_bytes = 0     # dynamically tuned protected target
g_win_target_bytes = 0      # small window target
g_last_cap = 0

# Ghost lists for ARC-style adaptation (bytes-limited)
ghost_prob = OrderedDict()  # keys evicted from Window/Probation
ghost_prot = OrderedDict()  # keys evicted from Protected
ghost_prob_bytes = 0
ghost_prot_bytes = 0

# Scoring / sampling
SAMPLE_K_WIN = 5
SAMPLE_K_PROB = 6
SAMPLE_K_PROT = 4

# Multi-hit bonus in score
MULTI_HIT_BONUS = 0.5

# ---------------
# Helpers: init / targets / lfu
# ---------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    global g_last_cap, g_prot_target_bytes, g_win_target_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = max(1, int(cache_snapshot.capacity))
    if g_last_cap != cap or g_prot_target_bytes == 0 or g_win_target_bytes == 0:
        g_last_cap = cap
        # Start conservatively: small window, large protected
        g_win_target_bytes = max(1, int(cap * 0.05))
        g_prot_target_bytes = max(1, int(cap * 0.70))

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _cap_bytes(cache_snapshot):
    return max(1, int(cache_snapshot.capacity))

# ---------------
# Ghost lists and adaptation (ARC-like)
# ---------------

def _ghost_cap(cache_snapshot):
    # Total bytes allowed for each ghost list (soft bound)
    return _cap_bytes(cache_snapshot)

def _ghost_add(cache_snapshot, seg_id, key, size):
    # Evicted from which segment? 0/1 -> ghost_prob, 2 -> ghost_prot
    global ghost_prob_bytes, ghost_prot_bytes
    if seg_id == 2:
        if key in ghost_prot:
            old = ghost_prot.pop(key)
            ghost_prot_bytes -= old
        ghost_prot[key] = size
        ghost_prot_bytes += size
        # Trim
        cap = _ghost_cap(cache_snapshot)
        while ghost_prot_bytes > cap and ghost_prot:
            k, s = ghost_prot.popitem(last=False)
            ghost_prot_bytes -= s
    else:
        if key in ghost_prob:
            old = ghost_prob.pop(key)
            ghost_prob_bytes -= old
        ghost_prob[key] = size
        ghost_prob_bytes += size
        cap = _ghost_cap(cache_snapshot)
        while ghost_prob_bytes > cap and ghost_prob:
            k, s = ghost_prob.popitem(last=False)
            ghost_prob_bytes -= s

def _adapt_prot_target(cache_snapshot, delta_bytes):
    global g_prot_target_bytes
    cap = _cap_bytes(cache_snapshot)
    # Bounds: leave at least 5% for window + 5% for probation, at most 90% for protected
    min_prot = int(cap * 0.10)
    max_prot = int(cap * 0.90)
    g_prot_target_bytes = max(min_prot, min(max_prot, g_prot_target_bytes + int(delta_bytes)))

def _adapt_on_ghost_ref(cache_snapshot, key):
    # If the incoming key was recently in a ghost list, adapt protected target
    if key in ghost_prot:
        # We previously kept it hot; increase protected to favor long-term
        s = ghost_prot.get(key, 0)
        _adapt_prot_target(cache_snapshot, max(1, s))
        # Move to MRU in ghost (recency)
        ghost_prot.move_to_end(key, last=True)
    elif key in ghost_prob:
        # Previously evicted from probation/window -> favor recency by shrinking protected
        s = ghost_prob.get(key, 0)
        _adapt_prot_target(cache_snapshot, -max(1, s // 2))
        ghost_prob.move_to_end(key, last=True)

# ---------------
# Segment helpers
# ---------------

def _seg_remove(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    else:
        # clean up any remnants
        win_lru.pop(key, None)
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)
    return seg

def _seg_insert_win(key, size):
    global win_bytes
    # ensure not in others
    if m_segment.get(key) == 0:
        # refresh MRU
        win_lru.pop(key, None)
        win_lru[key] = None
        return
    # Remove from other lists if present
    if m_segment.get(key) == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            global prob_bytes
            prob_bytes -= size
    if m_segment.get(key) == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            global prot_bytes
            prot_bytes -= size
    m_segment[key] = 0
    win_lru[key] = None
    win_bytes += size

def _seg_move_to_prob(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 1:
        # refresh MRU
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    if seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    prob_lru[key] = None
    m_segment[key] = 1
    prob_bytes += size

def _demote_prot_if_needed(cache_snapshot):
    # Demote from protected to probation until within target
    global prot_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(0, min(g_prot_target_bytes, cap))
    while prot_bytes > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        prot_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _trim_window_if_needed(cache_snapshot):
    # Keep window near its target by moving oldest window entries to probation (not evict)
    global win_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(1, min(g_win_target_bytes, cap))
    # Allow a little slack to avoid churn
    slack = max(1, target // 8)
    while win_bytes > (target + slack) and win_lru:
        dem_key, _ = win_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        win_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _seg_move_to_prot(cache_snapshot, key, size):
    # Promote to Protected MRU
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 2:
        # refresh MRU
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    prot_lru[key] = None
    m_segment[key] = 2
    prot_bytes += size
    _demote_prot_if_needed(cache_snapshot)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

# ---------------
# Scoring helpers
# ---------------

def _normalized_size(size, capacity):
    # size as percentage of capacity, keep >= small epsilon
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _retention_score(cache_snapshot, key):
    # Higher score = stronger retention; eviction picks smallest score
    cap = _cap_bytes(cache_snapshot)
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size
    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)
    bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    # Size-aware benefit with gentle diminishing returns on frequency
    benefit = (math.log2(1.0 + float(freq)) + bonus) / size_norm
    return benefit

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    # sample k oldest
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            return next(iter(order))
        except StopIteration:
            return None
    return chosen_key

# ---------------
# Policy entry points
# ---------------

def evict(cache_snapshot, obj):
    """
    Eviction strategy:
      - Prefer evicting from Window first to shield main cache (2Q-style)
      - Then from Probation, finally Protected
      - Within a segment, sample a few oldest and evict the one with the lowest
        TinyLFU size-aware score.
    """
    _init_if_needed(cache_snapshot)

    # Choose from Window first (admission filter / reduces main churn)
    if win_lru:
        victim = _pick_candidate_from_order(cache_snapshot, win_lru, SAMPLE_K_WIN)
        return victim

    # Then from Probation
    if prob_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
        return victim

    # Fallback to Protected if others empty
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)
        return victim

    # Last resort
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access and resident hit count
      - Promote to Protected if in Window/Probation
      - Refresh LRU position within its segment
      - Adapt Protected target: increase on Probation hits, slightly decrease on Protected hits
      - Trim Window toward its target
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked; place into Window
        _seg_insert_win(k, obj.size)
        _trim_window_if_needed(cache_snapshot)
        return

    if seg == 0 or seg == 1:
        # Hit in Window or Probation -> promote to Protected
        _seg_move_to_prot(cache_snapshot, k, obj.size)
        # Adapt: probation/window hit means protected was too small -> grow
        step = max(1, obj.size // 2)
        _adapt_prot_target(cache_snapshot, step)
    else:
        # Protected hit: touch and slightly shrink target to allow more probation
        _seg_touch_on_hit(cache_snapshot, k)
        step = max(1, obj.size // 8)
        _adapt_prot_target(cache_snapshot, -step)

    # Keep window near target
    _trim_window_if_needed(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU for the key (admission learns from requests)
      - Adjust Protected target using ARC-like ghost feedback
      - Initialize resident metadata and place into Window MRU
      - Gently trim Window toward its target (migrate oldest to Probation)
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # ARC-like adaptation using ghost information
    _adapt_on_ghost_ref(cache_snapshot, k)

    # New resident enters Window MRU
    _seg_insert_win(k, obj.size)
    _trim_window_if_needed(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove it from segment structures and resident-only metadata
      - Record into ghost lists for ARC-style adaptation
      - Keep TinyLFU counts to inform future decisions
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = evicted_obj.size

    # Identify segment before removal (for ghost list)
    seg_before = m_segment.get(ek, 1)
    _seg_remove(cache_snapshot, ek, esize)

    # Resident-only metadata cleanup
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # Remember in ghost for adaptation
    _ghost_add(cache_snapshot, seg_before, ek, esize)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 42
- Hit Rate: 0.102

Example 2:
- Trace ID: 18
- Hit Rate: 0.024

Example 3:
- Trace ID: 12
- Hit Rate: 0.0852

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m00:25:14 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 00:25:14,875 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m00:27:28 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 00:27:28,199 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 00:27:28,368 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Improved: Count-based Windowed SLRU + TinyLFU + ARC-style adaptation
# Key changes vs previous version:
# - Treat capacity as number of objects (not bytes). All targets/limits/counting are item-based.
# - Eviction preference: Probation -> Window -> Protected (typical SLRU/W-TinyLFU), not Window first.
# - Admission gating approximation: if incoming object's TinyLFU score is worse than the best probation victim,
#   evict from Window instead when possible (protects long-term items).
# - Simpler, robust metadata updates; O(1) moves within segments; lazy LFU decay.
# - Ghost lists and protected target adapt by item counts (ARC-style).
# - Small sampling on oldest K elements per segment to avoid worst-case thrashing.

import math
from collections import OrderedDict

# ---------------
# Globals (resident state)
# ---------------

# LRU queues (LRU at left, MRU at right)
win_lru = OrderedDict()   # 0: Window (very recent)
prob_lru = OrderedDict()  # 1: Probation (new/once-hit)
prot_lru = OrderedDict()  # 2: Protected (multi-hit)

# Item counts per segment
win_n = 0
prob_n = 0
prot_n = 0

# Resident segment mapping: key -> seg_id {0:win, 1:prob, 2:prot}
m_segment = dict()

# Resident metadata
m_last_access = dict()     # key -> int time (from access_count)
m_resident_hits = dict()   # key -> int number of hits while resident

# TinyLFU: 4-bit counters with lazy decay by epoch
m_lfu_count = dict()       # key -> (count[0..15], epoch)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Dynamic targets (by item count)
g_prot_target_n = 0
g_win_target_n = 0
g_last_cap = 0

# Ghost lists for ARC-style adaptation (item-limited)
ghost_prob = OrderedDict()  # keys evicted from Window/Probation
ghost_prot = OrderedDict()  # keys evicted from Protected
ghost_prob_n = 0
ghost_prot_n = 0

# Sampling sizes
SAMPLE_K_WIN = 6
SAMPLE_K_PROB = 8
SAMPLE_K_PROT = 4

# Score extras
MULTI_HIT_BONUS = 0.6  # bonus per multi-hit resident item
ADMISSION_MARGIN = 0.25  # margin to prefer window eviction over good probation victim

# ---------------
# Helpers: capacity / lfu / init
# ---------------

def _cap_items(cache_snapshot):
    # Capacity is number of objects (per problem statement)
    return max(1, int(cache_snapshot.capacity))

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    global g_last_cap, g_prot_target_n, g_win_target_n
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = _cap_items(cache_snapshot)
    if g_last_cap != cap or g_prot_target_n == 0 or g_win_target_n == 0:
        g_last_cap = cap
        # Reasonable defaults: small window, ample protected
        g_win_target_n = max(1, int(cap * 0.20))
        g_prot_target_n = max(1, int(cap * 0.60))

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    return c if shift <= 0 else (c >> shift)

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# ---------------
# Ghost lists and ARC-style adaptation (item-based)
# ---------------

def _ghost_cap(cache_snapshot):
    # Each ghost list bounded by capacity (soft)
    return _cap_items(cache_snapshot)

def _ghost_add(cache_snapshot, seg_id, key):
    global ghost_prob_n, ghost_prot_n
    if seg_id == 2:
        if key in ghost_prot:
            ghost_prot.pop(key, None)
            ghost_prot_n -= 1
        ghost_prot[key] = 1
        ghost_prot_n += 1
        cap = _ghost_cap(cache_snapshot)
        while ghost_prot_n > cap and ghost_prot:
            k, _ = ghost_prot.popitem(last=False)
            ghost_prot_n -= 1
    else:
        if key in ghost_prob:
            ghost_prob.pop(key, None)
            ghost_prob_n -= 1
        ghost_prob[key] = 1
        ghost_prob_n += 1
        cap = _ghost_cap(cache_snapshot)
        while ghost_prob_n > cap and ghost_prob:
            k, _ = ghost_prob.popitem(last=False)
            ghost_prob_n -= 1

def _adapt_prot_target(cache_snapshot, delta_n):
    global g_prot_target_n
    cap = _cap_items(cache_snapshot)
    # Keep room for window (>=10%), probation (>=10%), and not exceed 80% for protected
    min_prot = max(1, int(cap * 0.10))
    max_prot = max(min_prot, int(cap * 0.80))
    g_prot_target_n = max(min_prot, min(max_prot, g_prot_target_n + int(delta_n)))

def _adapt_on_ghost_ref(cache_snapshot, key):
    if key in ghost_prot:
        # It was hot before; grow protected
        _adapt_prot_target(cache_snapshot, 1)
        ghost_prot.move_to_end(key, last=True)
    elif key in ghost_prob:
        # It was evicted from recent/probation; favor recency
        _adapt_prot_target(cache_snapshot, -1)
        ghost_prob.move_to_end(key, last=True)

# ---------------
# Segment helpers (item-based)
# ---------------

def _seg_remove(cache_snapshot, key):
    global win_n, prob_n, prot_n
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_n -= 1
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_n -= 1
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_n -= 1
    else:
        win_lru.pop(key, None)
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)
    return seg

def _seg_insert_win(key):
    global win_n, prob_n, prot_n
    cur = m_segment.get(key)
    if cur == 0:
        # Refresh MRU
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
        else:
            win_lru[key] = None
        return
    if cur == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_n -= 1
    elif cur == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_n -= 1
    m_segment[key] = 0
    win_lru[key] = None
    win_n += 1

def _seg_move_to_prob(cache_snapshot, key):
    global win_n, prob_n, prot_n
    seg = m_segment.get(key)
    if seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_n -= 1
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_n -= 1
    prob_lru[key] = None
    m_segment[key] = 1
    prob_n += 1

def _demote_prot_if_needed(cache_snapshot):
    global prot_n, prob_n
    target = max(0, min(g_prot_target_n, _cap_items(cache_snapshot)))
    while prot_n > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        prot_n -= 1
        # If still resident (should be), move to probation
        prob_lru[dem_key] = None
        m_segment[dem_key] = 1
        prob_n += 1

def _trim_window_if_needed(cache_snapshot):
    global win_n, prob_n
    target = max(1, min(g_win_target_n, _cap_items(cache_snapshot)))
    slack = min(3, max(1, target // 8))
    while win_n > (target + slack) and win_lru:
        dem_key, _ = win_lru.popitem(last=False)
        win_n -= 1
        prob_lru[dem_key] = None
        m_segment[dem_key] = 1
        prob_n += 1

def _seg_move_to_prot(cache_snapshot, key):
    global win_n, prob_n, prot_n
    seg = m_segment.get(key)
    if seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_n -= 1
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_n -= 1
    prot_lru[key] = None
    m_segment[key] = 2
    prot_n += 1
    _demote_prot_if_needed(cache_snapshot)

def _seg_touch_on_hit(key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

# ---------------
# Scoring helpers (TinyLFU + resident multi-hit bonus)
# ---------------

def _retention_score(cache_snapshot, key):
    # Higher score -> stronger retention (harder to evict)
    freq = _lfu_peek(cache_snapshot, key)
    bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 0) >= 2 else 0.0
    # Gentle diminishing returns on frequency
    return math.log2(1.0 + float(freq)) + bonus

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    if not order:
        return None, None
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            k = next(iter(order))
            return k, _retention_score(cache_snapshot, k)
        except StopIteration:
            return None, None
    return chosen_key, chosen_score

# ---------------
# Policy entry points
# ---------------

def evict(cache_snapshot, obj):
    """
    Eviction strategy (count-based):
      - Prefer evicting from Probation (main) to protect Window recency and Protected frequency.
      - Then from Window, finally Protected.
      - Within a segment, sample the oldest K and evict the one with the lowest TinyLFU score.
      - Admission gating approximation: if the incoming object's LFU score is significantly
        lower than the best Probation victim, prefer evicting from Window when possible.
    """
    _init_if_needed(cache_snapshot)

    # Candidates
    prob_victim, prob_score = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
    win_victim, win_score = _pick_candidate_from_order(cache_snapshot, win_lru, SAMPLE_K_WIN)
    prot_victim, prot_score = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)

    # Incoming object's estimated usefulness
    new_score = _lfu_peek(cache_snapshot, getattr(obj, "key", None))

    # Admission gating: protect a strong probation resident if newcomer is weak
    if prob_victim is not None and win_victim is not None and new_score + ADMISSION_MARGIN < (prob_score or 0.0):
        return win_victim

    # Normal preference order
    if prob_victim is not None:
        return prob_victim
    if win_victim is not None:
        return win_victim
    if prot_victim is not None:
        return prot_victim

    # Fallback
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter and resident hit count.
      - Probation hit -> promote to Protected and increase protected target slightly.
      - Window hit -> if seen more than once (resident) or LFU >= 2, promote to Protected, else refresh in Window.
      - Protected hit -> refresh; slightly decrease protected target (allow more probation space).
      - Keep Window near target; demote Protected if over target.
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k)

    if seg is None:
        # Not tracked (shouldn't normally happen on hit), place into Window
        _seg_insert_win(k)
        _trim_window_if_needed(cache_snapshot)
        return

    if seg == 1:
        # Probation -> Protected
        _seg_move_to_prot(cache_snapshot, k)
        _adapt_prot_target(cache_snapshot, 1)
    elif seg == 0:
        # Window: promote only if likely useful
        if m_resident_hits.get(k, 0) >= 2 or _lfu_peek(cache_snapshot, k) >= 2:
            _seg_move_to_prot(cache_snapshot, k)
            _adapt_prot_target(cache_snapshot, 1)
        else:
            _seg_touch_on_hit(k)
    else:
        # Protected hit
        _seg_touch_on_hit(k)
        _adapt_prot_target(cache_snapshot, -1)

    _trim_window_if_needed(cache_snapshot)
    _demote_prot_if_needed(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU for the key.
      - Use ghost lists for ARC-like adaptation (adjust protected target).
      - Initialize resident metadata and place into Window MRU.
      - Trim Window toward its target by migrating LRU entries to Probation.
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    _adapt_on_ghost_ref(cache_snapshot, k)

    _seg_insert_win(k)
    _trim_window_if_needed(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a resident:
      - Remove it from segment structures and resident metadata.
      - Record into ghost lists for ARC-style adaptation (keep LFU counts).
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Capture segment before removal
    seg_before = m_segment.get(ek, 1)
    _seg_remove(cache_snapshot, ek)

    # Clean resident-only metadata
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # Record in ghost
    _ghost_add(cache_snapshot, seg_before, ek)
```
2025-11-28 00:27:59,136 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 6
- Hit Rate: 0.2775

Example 2:
- Trace ID: 5
- Hit Rate: 0.4888

Example 3:
- Trace ID: 45
- Hit Rate: 0.1719

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m00:27:59 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 00:27:59,137 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m00:30:52 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 00:30:52,675 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 00:30:52,676 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Segmented Size-aware TinyLFU (S-S-TinyLFU)
# - Two segments (probation, protected) to shield multi-hit items from single-hit pollution
# - Size-aware frequency scoring using TinyLFU with lazy-decayed 8-bit counters
# - Recency bonus, stronger in probation, milder in protected
# - Eviction favors evicting from the segment exceeding its byte budget (probation ~20%, protected ~80%)
# - On hit: probation -> protected promotion; on protected hit: refresh
# - On insert: place into probation with 0 resident hits
# - TinyLFU counters persist across evictions (to remember popularity)

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Segment identifiers
SEG_PROB = 0  # probation (new/one-hit items)
SEG_PROT = 1  # protected (multi-hit items)

# Resident metadata
m_last_access = dict()    # key -> int access_count (LRU-ish timestamp)
m_resident_hits = dict()  # key -> int resident hit count
m_seg = dict()            # key -> segment id (SEG_PROB or SEG_PROT)

# Track resident bytes by segment (self-healed on demand)
g_seg_bytes = {SEG_PROB: 0, SEG_PROT: 0}

# TinyLFU sketch (lazy-decayed counters)
m_lfu_count = dict()      # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0

# -----------------------------
# Tunables
# -----------------------------

# TinyLFU parameters
LFU_BITS = 8
LFU_MAX = (1 << LFU_BITS) - 1  # 255
LFU_DECAY_INTERVAL = 16384     # accesses per epoch

# Segment byte budget
PROBATION_BYTE_FRACTION = 0.20  # ~20% of resident bytes in probation

# Recency windows and weights (per segment)
PROB_REC_WEIGHT = 0.60          # strong recency protection in probation
PROT_REC_WEIGHT = 0.20          # mild recency in protected

PROB_REC_WIN_MIN = 256
PROT_REC_WIN_MIN = 1024
PROB_REC_WIN_MULT = 2           # window ~ mult * probation_items
PROT_REC_WIN_MULT = 4           # window ~ mult * protected_items

# Benefit tweaks
PROT_HIT_BONUS = 0.35           # small extra for multi-hit protected items

# -----------------------------
# Initialization helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Segment/accounting helpers
# -----------------------------

def _recompute_seg_bytes(cache_snapshot):
    # Self-heal segment byte counters from the snapshot
    b_prob = 0
    b_prot = 0
    for k, robj in cache_snapshot.cache.items():
        seg = m_seg.get(k, SEG_PROB)
        if seg == SEG_PROT:
            b_prot += robj.size
        else:
            b_prob += robj.size
    g_seg_bytes[SEG_PROB] = b_prob
    g_seg_bytes[SEG_PROT] = b_prot
    return b_prob, b_prot

def _normalized_size(size, capacity):
    # Scale to percentage-of-capacity to keep benefit stable
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _segment_item_counts():
    # Best-effort counts; we only track for normalization, so roughness is OK
    cnt_prob = 0
    cnt_prot = 0
    for seg in m_seg.values():
        if seg == SEG_PROT:
            cnt_prot += 1
        else:
            cnt_prob += 1
    return cnt_prob, cnt_prot

def _choose_segment_for_evict(cache_snapshot):
    # Recompute bytes to be robust
    b_prob, b_prot = _recompute_seg_bytes(cache_snapshot)
    total_bytes = max(1, b_prob + b_prot)
    # Desired byte targets proportional to current resident bytes
    target_prob = PROBATION_BYTE_FRACTION * total_bytes
    overflow_prob = b_prob - target_prob
    overflow_prot = b_prot - (total_bytes - target_prob)

    # Prefer evicting from the segment exceeding its budget the most
    # If neither exceeds, evict from probation if non-empty
    if overflow_prob > 0 and overflow_prob >= max(0.0, overflow_prot):
        return SEG_PROB
    if overflow_prot > 0 and overflow_prot > overflow_prob:
        return SEG_PROT

    # Fallback: evict from probation if it has any items, else protected
    # (non-strict: m_seg might lag slightly, so select by presence)
    cnt_prob, cnt_prot = _segment_item_counts()
    if cnt_prob > 0:
        return SEG_PROB
    return SEG_PROT

# -----------------------------
# Scoring
# -----------------------------

def _retention_score(cache_snapshot, key, seg):
    # score = benefit - recency_gain; lower => better eviction candidate
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')

    size = robj.size
    size_norm = _normalized_size(size, cap)

    freq = _lfu_peek(cache_snapshot, key)
    benefit = math.log2(1.0 + float(freq))

    # Protected items get a slight multi-hit bonus
    if seg == SEG_PROT:
        rh = m_resident_hits.get(key, 0)
        if rh >= 2:
            benefit += PROT_HIT_BONUS

    benefit /= size_norm  # size-aware value-per-byte

    # Recency gain (protects recent items)
    cnt_prob, cnt_prot = _segment_item_counts()
    if seg == SEG_PROB:
        window = max(PROB_REC_WIN_MIN, PROB_REC_WIN_MULT * max(1, cnt_prob))
        rec_w = PROB_REC_WEIGHT
    else:
        window = max(PROT_REC_WIN_MIN, PROT_REC_WIN_MULT * max(1, cnt_prot))
        rec_w = PROT_REC_WEIGHT

    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = rec_w * (1.0 - a_norm)

    return benefit - recency_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict from the segment that exceeds its byte budget.
    Within the chosen segment, evict the item with the smallest size-aware TinyLFU benefit
    after recency adjustment. Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    seg_choice = _choose_segment_for_evict(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    # Iterate only keys belonging to the chosen segment
    for k, robj in cache_snapshot.cache.items():
        if m_seg.get(k, SEG_PROB) != seg_choice:
            continue
        score = _retention_score(cache_snapshot, k, seg_choice)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # If chosen segment empty (metadata may lag), scan the other segment
    if min_key is None:
        alt_seg = SEG_PROT if seg_choice == SEG_PROB else SEG_PROB
        for k, robj in cache_snapshot.cache.items():
            if m_seg.get(k, SEG_PROB) != alt_seg:
                continue
            score = _retention_score(cache_snapshot, k, alt_seg)
            last = m_last_access.get(k, -1)
            if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k

    # Fallback: arbitrary key if none found
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key

def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Refresh last-access time
      - Increment resident hit count
      - Promote from probation to protected on first hit
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    # Promotion logic: probation -> protected on first hit
    prev_seg = m_seg.get(k, SEG_PROB)
    if prev_seg == SEG_PROB:
        m_seg[k] = SEG_PROT
        # Adjust bytes (self-heal will also correct if needed)
        g_seg_bytes[SEG_PROB] = max(0, g_seg_bytes.get(SEG_PROB, 0) - obj.size)
        g_seg_bytes[SEG_PROT] = g_seg_bytes.get(SEG_PROT, 0) + obj.size

def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata:
          segment = probation, resident_hits = 0, last_access = now
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 0
    m_seg[k] = SEG_PROB

    # Track bytes for probation
    g_seg_bytes[SEG_PROB] = g_seg_bytes.get(SEG_PROB, 0) + obj.size

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counts are retained)
      - Adjust segment byte accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    seg = m_seg.pop(ek, SEG_PROB)
    if seg == SEG_PROT:
        g_seg_bytes[SEG_PROT] = max(0, g_seg_bytes.get(SEG_PROT, 0) - evicted_obj.size)
    else:
        g_seg_bytes[SEG_PROB] = max(0, g_seg_bytes.get(SEG_PROB, 0) - evicted_obj.size)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Do not delete m_lfu_count[ek]; preserve history
```
2025-11-28 00:31:17,251 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 11
- Hit Rate: 0.3979

Example 2:
- Trace ID: 37
- Hit Rate: 0.6388

Example 3:
- Trace ID: 29
- Hit Rate: 0.0386

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m00:31:17 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 00:31:17,253 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m00:34:18 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 00:34:18,491 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 00:34:18,495 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive Byte-Aware Segmented TinyLFU (ABSL-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; retains majority of bytes (adaptive)
# - Adaptive segment sizing via ARC-like ghosts:
#     * When a miss hits probation-ghost -> decrease protected target (favor recency)
#     * When a miss hits protected-ghost -> increase protected target (favor frequency)
# - Eviction:
#     * Prefer evicting from probation; if protected is over target, evict from protected
#     * Within a segment, evict the key with the smallest retention score
#       (ties broken by oldest last-access time)
# - Retention score blends:
#     * decayed TinyLFU frequency (4-bit, lazy epoch)
#     * size penalty (size/capacity)^ALPHA
#     * recency (segment-dependent weight)
#     * predicted reuse (EMA of inter-arrival time, segment-dependent weight)
#     * multi-hit bonus and cold-item penalty
#     * protected "shield" bonus when under target
#
# Metadata is updated on hit/insert/evict, with promotions and ghost maintenance.
# TinyLFU counters persist across evictions.

import math
from collections import OrderedDict

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes), adaptive
DEFAULT_PROTECTED_FRACTION = 0.72
g_target_protected_frac = DEFAULT_PROTECTED_FRACTION
g_protected_bytes = 0      # running total of bytes in protected

# Ghost caches (ARC-style) for adaptation (by bytes)
g_ghost_prob = OrderedDict()   # key -> (time:int, size:int)
g_ghost_prot = OrderedDict()   # key -> (time:int, size:int)
g_ghost_prob_bytes = 0
g_ghost_prot_bytes = 0

# Scoring tunables
SIZE_ALPHA = 1.25          # >1 penalizes very large objects more
MULTI_HIT_BONUS = 0.45     # extra benefit for items with >=2 resident hits
COLD_PENALTY = 0.12        # penalty applied to brand-new (single-hit) residents

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.75
W_REC_PROT = 0.14
W_PRED_PROB = 0.20
W_PRED_PROT = 0.10

# Protected shield when under target (harder to evict protected if within budget)
PROT_SHIELD_BONUS = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# Adaptive protected fraction tuning
ADAPT_STEP = 0.03          # step to adjust protected fraction on ghost hits
PROTECTED_FRAC_MIN = 0.20
PROTECTED_FRAC_MAX = 0.90

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    frac = max(PROTECTED_FRAC_MIN, min(PROTECTED_FRAC_MAX, g_target_protected_frac))
    return int(frac * float(cache_snapshot.capacity))

def _find_candidate_in_segment(cache_snapshot, segment_id, target_bytes, shield_protected=True):
    # Returns (key, score, last_access) of the weakest in the given segment, or (None, None, None)
    selected_key = None
    selected_score = None
    selected_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        score = _retention_score(cache_snapshot, k, target_bytes, shield_protected)
        last = m_last_access.get(k, -1)
        if (selected_key is None) or (score < selected_score) or (score == selected_score and last < selected_time):
            selected_key = k
            selected_score = score
            selected_time = last
    return selected_key, selected_score, selected_time

# -----------------------------
# Ghost helpers (ARC-like adapt)
# -----------------------------

def _ghost_budget(cache_snapshot):
    # Per-ghost byte budget (each up to capacity)
    return int(cache_snapshot.capacity)

def _ghost_prob_add(cache_snapshot, key, size):
    global g_ghost_prob_bytes
    now = cache_snapshot.access_count
    if key in g_ghost_prob:
        _, sz = g_ghost_prob.pop(key)
        g_ghost_prob_bytes = max(0, g_ghost_prob_bytes - sz)
    g_ghost_prob[key] = (now, size)
    g_ghost_prob_bytes += size
    _ghost_trim(cache_snapshot)

def _ghost_prot_add(cache_snapshot, key, size):
    global g_ghost_prot_bytes
    now = cache_snapshot.access_count
    if key in g_ghost_prot:
        _, sz = g_ghost_prot.pop(key)
        g_ghost_prot_bytes = max(0, g_ghost_prot_bytes - sz)
    g_ghost_prot[key] = (now, size)
    g_ghost_prot_bytes += size
    _ghost_trim(cache_snapshot)

def _ghost_trim(cache_snapshot):
    global g_ghost_prob_bytes, g_ghost_prot_bytes
    budget = _ghost_budget(cache_snapshot)
    # Trim probation ghost
    while g_ghost_prob_bytes > budget and len(g_ghost_prob) > 0:
        _, (_, sz) = g_ghost_prob.popitem(last=False)
        g_ghost_prob_bytes = max(0, g_ghost_prob_bytes - sz)
    # Trim protected ghost
    while g_ghost_prot_bytes > budget and len(g_ghost_prot) > 0:
        _, (_, sz) = g_ghost_prot.popitem(last=False)
        g_ghost_prot_bytes = max(0, g_ghost_prot_bytes - sz)

def _ghost_hit_and_adapt_on_insert(cache_snapshot, key):
    # If key was recently evicted from probation/protected, adapt target fraction
    global g_target_protected_frac, g_ghost_prob_bytes, g_ghost_prot_bytes
    changed = False
    if key in g_ghost_prob:
        # Favor recency: decrease protected target
        _, sz = g_ghost_prob.pop(key)
        g_ghost_prob_bytes = max(0, g_ghost_prob_bytes - sz)
        g_target_protected_frac = max(PROTECTED_FRAC_MIN, g_target_protected_frac - ADAPT_STEP)
        changed = True
    if key in g_ghost_prot:
        # Favor frequency: increase protected target
        _, sz = g_ghost_prot.pop(key)
        g_ghost_prot_bytes = max(0, g_ghost_prot_bytes - sz)
        g_target_protected_frac = min(PROTECTED_FRAC_MAX, g_target_protected_frac + ADAPT_STEP)
        changed = True
    if changed:
        # Ensure ghosts stay within budget after removal (defensive)
        _ghost_trim(cache_snapshot)

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key, target_bytes=None, shield_protected=True):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    # Protected shield only if under target and requested
    prot_bonus = 0.0
    if shield_protected and seg == 1:
        if target_bytes is None:
            target_bytes = _protected_target_bytes(cache_snapshot)
        if g_protected_bytes <= target_bytes:
            prot_bonus = PROT_SHIELD_BONUS

    # Cold-item penalty (brand-new residents are easier to evict)
    cold_pen = COLD_PENALTY if m_resident_hits.get(key, 1) <= 1 else 0.0

    return benefit - recency_gain - predicted_gain + prot_bonus - cold_pen

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Adapt protected size target via ghosts out of band (on insert)
      - Prefer evicting from probation; if protected exceeds its target bytes,
        evict from protected instead
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    target = _protected_target_bytes(cache_snapshot)

    # Decide which segment to draw the victim from
    # - If protected is oversized, select from protected
    # - Else prefer probation; if empty, fall back to protected
    choose_protected = (g_protected_bytes > target)

    # Find candidates
    victim_key = None

    if not choose_protected:
        # Try probation first
        k_prob, s_prob, t_prob = _find_candidate_in_segment(cache_snapshot, 0, target, shield_protected=True)
        if k_prob is not None:
            victim_key = k_prob
        else:
            # No probation items -> take from protected
            k_prot, s_prot, t_prot = _find_candidate_in_segment(cache_snapshot, 1, target, shield_protected=True)
            if k_prot is not None:
                victim_key = k_prot
    else:
        # Protected oversized -> take from protected
        k_prot, s_prot, t_prot = _find_candidate_in_segment(cache_snapshot, 1, target, shield_protected=False)
        if k_prot is not None:
            victim_key = k_prot
        else:
            # Fallback to probation
            k_prob, s_prob, t_prob = _find_candidate_in_segment(cache_snapshot, 0, target, shield_protected=True)
            if k_prob is not None:
                victim_key = k_prob

    if victim_key is not None:
        return victim_key

    # Final fallback: arbitrary
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected (bytes accounted)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize conservatively
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = prev if prev is not None else now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt protected/recency balance if this key was seen in ghosts
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    # ARC-like ghost adaptation (before we initialize metadata)
    _ghost_hit_and_adapt_on_insert(cache_snapshot, k)

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)
    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Add evicted key to appropriate ghost (probation/protected) for adaptive sizing
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed and capture segment for ghosting
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)
        _ghost_prot_add(cache_snapshot, ek, evicted_obj.size)
    else:
        _ghost_prob_add(cache_snapshot, ek, evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```
2025-11-28 00:39:40,556 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 14
- Hit Rate: 0.0228

Example 2:
- Trace ID: 28
- Hit Rate: 0.1767

Example 3:
- Trace ID: 34
- Hit Rate: 0.0789

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m00:39:40 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 00:39:40,558 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m00:42:13 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 00:42:13,240 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 00:42:13,242 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# GreedyDual-Size with TinyLFU (GDS-TinyLFU)
# - Unifies frequency, size, and recency via GreedyDual "inflation" L
# - Frequency is estimated using a lightweight, lazily-decayed TinyLFU (4-bit counters)
# - Priority (H) for each resident item:
#       H(key) = L + benefit(key)
#       benefit(key) = (log2(1 + freq_tlfu) + multi_hit_bonus) / (size_percent_of_capacity)
#   where size_percent_of_capacity = (size_bytes * 100 / capacity_bytes)
# - Eviction always removes the resident with the smallest H. After eviction, L = H(victim)
# - On hit/insert, the item’s H is recomputed (refresh), increasing with rising L and frequency
# - This design yields:
#     * Recency: via L increasing on every eviction (older items with stale H fall behind L)
#     * Size-awareness: larger items require higher frequency to survive (benefit divides by size%)
#     * Frequency: TinyLFU counters capture popularity with decay; multi-hit bonus favors sustained reuse
#
# Notes:
# - We retain TinyLFU counts after eviction (for admission guidance on reinsert).
# - No global sweeps are required (lazy-decay by epochs).
# - Lightweight metadata with O(1) updates; eviction scans current residents to find minimum H.

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU-ish timestamp)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_priority = dict()        # key -> float GDS priority H = L + benefit

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0

# GreedyDual inflation (recency via rising floor)
m_gds_L = 0.0              # Global inflation factor updated on eviction

# Tunables (robust defaults)
LFU_DECAY_INTERVAL = 4096  # access-counts between epochs (power of two recommended)
MULTI_HIT_BONUS = 0.8      # extra benefit for items with >=2 resident hits
ADMIT_KICK = 0.05          # small admission boost to avoid instant churn for cold inserts


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping/updates to entries required


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit count without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size_percent(size_bytes, capacity_bytes):
    # Scale to "percentage of capacity" to keep benefit in a stable range
    return max(1e-9, (float(size_bytes) * 100.0) / float(capacity_bytes))


def _benefit(cache_snapshot, key):
    # Size-aware TinyLFU benefit used by GDS:
    # benefit = (log2(1 + freq) + multi_hit_bonus) / size_percent
    cap = cache_snapshot.capacity
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return 0.0
    size_norm = _normalized_size_percent(obj.size, cap)

    freq = float(_lfu_peek(cache_snapshot, key))
    bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0

    return (math.log2(1.0 + freq) + bonus) / size_norm


def _priority_refresh(cache_snapshot, key):
    # H = L + benefit
    global m_gds_L
    b = _benefit(cache_snapshot, key)
    h = m_gds_L + b
    m_priority[key] = h
    return h


def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest GDS-TinyLFU priority H.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_h = None
    min_time = None

    for k, robj in cache_snapshot.cache.items():
        # Ensure a priority exists; lazily refresh if missing
        h = m_priority.get(k)
        if h is None:
            h = _priority_refresh(cache_snapshot, k)
        last = m_last_access.get(k, -1)

        if (min_h is None) or (h < min_h) or (h == min_h and last < min_time):
            min_h = h
            min_time = last
            min_key = k

    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Refresh GDS priority (H = L + benefit)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    _priority_refresh(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - Initialize GDS priority with a small admission kick
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # Base priority from GDS
    h = _priority_refresh(cache_snapshot, k)

    # Small admission boost to reduce immediate churn for cold inserts
    size_norm = _normalized_size_percent(obj.size, cache_snapshot.capacity)
    m_priority[k] = h + (ADMIT_KICK / size_norm)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Update GreedyDual inflation L to victim's priority H
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    global m_gds_L

    ek = evicted_obj.key

    # Determine victim's priority (should exist); if missing, compute
    h_victim = m_priority.pop(ek, None)
    if h_victim is None:
        # Reconstruct as best-effort; use current L + benefit
        h_victim = _priority_refresh(cache_snapshot, ek)

    # GreedyDual inflation increases to the evicted item's H
    if h_victim > m_gds_L:
        m_gds_L = h_victim

    # Clean up resident-only metadata; keep TinyLFU for non-resident memory
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```
2025-11-28 00:42:21,937 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved policy: Heap-Accelerated TinyLFU with Size and Recency (HALO-TFS)
# - Fast eviction via a lazy min-heap of retention scores (no full scans)
# - TinyLFU with lazy epoch decay (per-key small counters remembered across evictions)
# - Size-aware, recency-aware scoring with multi-hit boost
# - Robust to workload shifts; avoids timeouts via O(log n) victim selection and periodic heap rebuilds

import math
import heapq

# --------------------------------
# Global metadata (module scope)
# --------------------------------

# Per-key resident metadata
m_last_access = dict()      # key -> int access_count timestamp
m_resident_hits = dict()    # key -> int resident hit count (>=1 once inserted)

# TinyLFU counts with lazy epoch decay (saturating small counters)
m_lfu_count = dict()        # key -> (count:int[0..LFU_MAX], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 4096   # accesses per epoch (power of two recommended)
LFU_MAX = 31                # 5-bit saturating counter (0..31)

# Min-heap for eviction: (score, last_access, key, version)
m_heap = []
m_ver = dict()              # key -> current version to invalidate stale heap entries

# Maintenance
m_touch_count = 0
REBUILD_CHECK_PERIOD = 8192  # how often to check if heap needs rebuilding
HEAP_GROWTH_FACTOR = 4       # if heap > factor * resident_count, rebuild

# Tunables for scoring
SIZE_ALPHA = 0.75           # size normalization exponent; smaller favors small objects
REC_WIN_MIN = 64            # minimum recency window
REC_WIN_MULT = 8            # recency window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.75           # strength of recency term added to frequency
MULTI_HIT_BONUS = 0.50      # multiplicative boost for items with >=2 hits while resident


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # no sweeping; decay handled lazily per key


def _lfu_peek(cache_snapshot, key):
    """Return decayed TinyLFU count without modifying stored epoch if key missing."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    """Increment TinyLFU count (with lazy decay) and write back current epoch."""
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring
# -----------------------------

def _recency_term(now, last, window):
    # Returns a value in (0,1]; close to 1 for very recent, decays smoothly with age
    if last is None or last < 0:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return 1.0 / (1.0 + (float(age) / float(window)))


def _score_key(cache_snapshot, key):
    """Compute retention score for a resident key. Higher score => more protected."""
    now = cache_snapshot.access_count
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf')  # non-resident; never select
    size = max(1.0, float(obj.size))
    size_norm = size ** SIZE_ALPHA

    # Frequency estimate (TinyLFU)
    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log1p(float(freq))  # softer than linear, stabilizes at high freq

    # Recency component
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    r_term = _recency_term(now, m_last_access.get(key), window)

    # Multi-hit boost (stronger protection after the second hit)
    mh = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    mult = 1.0 + mh

    # Final score: combine frequency and recency, then size-normalize
    score = ((f_term + REC_WEIGHT * r_term) * mult) / size_norm
    return score


def _heap_push(cache_snapshot, key):
    """Compute score and push a fresh entry for key into the heap."""
    v = m_ver.get(key, 0) + 1
    m_ver[key] = v
    sc = _score_key(cache_snapshot, key)
    last = m_last_access.get(key, -1)
    heapq.heappush(m_heap, (sc, last, key, v))


def _maybe_rebuild_heap(cache_snapshot):
    """Rebuild heap when it grows too large due to stale entries."""
    global m_heap
    n = max(1, len(cache_snapshot.cache))
    if len(m_heap) <= HEAP_GROWTH_FACTOR * n:
        return
    # Rebuild heap from current residents with fresh scores/versions
    new_heap = []
    for k in cache_snapshot.cache.keys():
        v = m_ver.get(k, 0) + 1
        m_ver[k] = v
        sc = _score_key(cache_snapshot, k)
        last = m_last_access.get(k, -1)
        new_heap.append((sc, last, k, v))
    heapq.heapify(new_heap)
    m_heap = new_heap


def _touch_and_maybe_rebuild(cache_snapshot):
    global m_touch_count
    m_touch_count += 1
    if (m_touch_count % REBUILD_CHECK_PERIOD) == 0:
        _maybe_rebuild_heap(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose an eviction victim quickly using a min-heap of retention scores.
    Lazy invalidation ensures correctness despite changing scores/epochs.
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    # If heap is empty (e.g., unusual bootstrap), seed with current residents
    if not m_heap and cache_snapshot.cache:
        for k in cache_snapshot.cache.keys():
            if k not in m_ver:
                # Initialize resident metadata if missing (best effort)
                m_last_access.setdefault(k, cache_snapshot.access_count)
                m_resident_hits.setdefault(k, 1)
            _heap_push(cache_snapshot, k)

    # Candidate's "would-be" score (informal comparison; does not affect required eviction)
    # This is used only to help prefer weaker residents when ties occur.
    cand_freq = _lfu_peek(cache_snapshot, obj.key) + 1  # will be incremented on insert
    cand_f_term = math.log1p(float(cand_freq))
    cand_size_norm = max(1.0, float(obj.size)) ** SIZE_ALPHA
    cand_score = (cand_f_term + REC_WEIGHT * 1.0) / cand_size_norm  # recency ~1 on insert

    # Pop until we find a valid, up-to-date victim
    while m_heap:
        sc, last, k, v = heapq.heappop(m_heap)
        # Skip if not resident anymore
        if k not in cache_snapshot.cache:
            continue
        # Skip if stale entry
        if m_ver.get(k, 0) != v:
            continue
        # Recompute current score to account for epoch/window changes
        new_sc = _score_key(cache_snapshot, k)
        # If the score drifted upward (got better), reinsert with new score
        if new_sc > sc + 1e-12:
            _heap_push(cache_snapshot, k)
            continue
        # Optional tie-breaker with candidate: if resident clearly stronger than candidate,
        # try to find a weaker one by peeking more; but if none, return this one.
        if new_sc >= cand_score:
            # Keep searching a bit for something weaker; cap extra attempts to avoid overhead
            attempts = 0
            tmp = [(sc, last, k, v)]
            victim = None
            while attempts < 8 and m_heap:
                sc2, last2, k2, v2 = heapq.heappop(m_heap)
                if k2 not in cache_snapshot.cache or m_ver.get(k2, 0) != v2:
                    attempts += 1
                    continue
                cur_sc2 = _score_key(cache_snapshot, k2)
                if cur_sc2 > sc2 + 1e-12:
                    _heap_push(cache_snapshot, k2)
                    attempts += 1
                    continue
                if cur_sc2 < cand_score or cur_sc2 < new_sc:
                    victim = (cur_sc2, last2, k2, v2)
                    break
                tmp.append((sc2, last2, k2, v2))
                attempts += 1
            # Push back any entries we popped but didn't choose
            for ent in tmp:
                heapq.heappush(m_heap, ent)
            if victim is not None:
                return victim[2]
            # Fall back to the original k
        return k

    # Fallback: choose the oldest resident if heap is somehow empty
    min_k = None
    min_last = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if min_last is None or last < min_last:
            min_last = last
            min_k = k
    return min_k


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Advance TinyLFU epoch if needed and increment frequency
      - Increment resident hit count
      - Refresh last-access time
      - Push updated score to heap (lazy invalidation of older entries)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Advance TinyLFU epoch and increment counter for requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - Push entry into heap
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    _heap_push(cache_snapshot, k)
    _touch_and_maybe_rebuild(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU to remember its popularity)
      - Invalidate its heap version (lazy: stale heap entries will be skipped)
    """
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_ver.pop(ek, None)
    _touch_and_maybe_rebuild(cache_snapshot)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 44
- Hit Rate: 0.0917

Example 2:
- Trace ID: 31
- Hit Rate: 0.0836

Example 3:
- Trace ID: 38
- Hit Rate: 0.1255

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m00:42:21 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 00:42:21,938 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m00:45:19 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 00:45:19,898 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 00:45:19,900 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# BARC-Lite: Byte-aware Adaptive Recency with two LRU segments (ARC-inspired)
# - Two resident segments: T1 (recent/probation) and T2 (frequent/protected)
# - Choose eviction from T1 or T2 to track target T1 size p adaptively (in bytes)
# - Adapt p using ghost lists B1/B2 (recently evicted keys from T1/T2)
# - LRU maintained via per-segment min-heaps of (last_access, key, version)
# - No full scans; O(log n) victim selection; robust lazy invalidation
#
# Rationale:
# - Pure LRU (recency) can thrash on looping scans; pure LFU can hold stale items.
# - ARC adapts between recency and frequency using ghosts; here we translate to bytes.
# - Works well across diverse patterns without admission control hooks.

import heapq
from collections import deque

# -----------------------------
# Global metadata
# -----------------------------

# Segments: 1 = T1 (recent/probation), 2 = T2 (frequent/protected)
g_seg = dict()          # key -> 1 or 2
g_last = dict()         # key -> last access_count (LRU time)
g_ver = dict()          # key -> version for heap invalidation

# Per-segment min-heaps by LRU time
# Each entry: (last_access, key, version)
g_heap1 = []
g_heap2 = []

# Segment byte totals
g_bytes1 = 0
g_bytes2 = 0

# Adaptive target for T1 in bytes
g_cap_bytes = 0
g_p_bytes = 0

# Ghost lists for adaptation (recently evicted keys by segment)
# Map for membership + size tracking, and deque for insertion order (with time)
g_B1_map = dict()       # key -> size
g_B2_map = dict()       # key -> size
g_B1_q = deque()        # deque of (time, key) for B1
g_B2_q = deque()        # deque of (time, key) for B2
g_ghost_bytes = 0
GHOST_MAX_BYTES_FACTOR = 1.0  # combined ghosts limited to ~1.0 * capacity in bytes

# Initialization guard
g_inited = False


# -----------------------------
# Helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    global g_inited, g_cap_bytes, g_p_bytes
    if not g_inited:
        g_cap_bytes = max(1, int(cache_snapshot.capacity))
        # Start with 20% of bytes budget for T1 (recent)
        g_p_bytes = max(0, min(g_cap_bytes, g_cap_bytes // 5))
        g_inited = True
    else:
        # Update capacity if it changed
        cap = max(1, int(cache_snapshot.capacity))
        if cap != g_cap_bytes:
            g_cap_bytes = cap
            # Clamp p within [0, capacity]
            g_p_bytes = max(0, min(g_p_bytes, g_cap_bytes))


def _heap_push(seg, key):
    """Push updated LRU entry for key into segment heap with fresh version."""
    v = g_ver.get(key, 0) + 1
    g_ver[key] = v
    last = g_last.get(key, 0)
    ent = (last, key, v)
    if seg == 1:
        heapq.heappush(g_heap1, ent)
    else:
        heapq.heappush(g_heap2, ent)


def _pop_oldest_from_seg(seg):
    """Pop oldest valid entry from the specified segment heap."""
    heap = g_heap1 if seg == 1 else g_heap2
    while heap:
        last, k, v = heapq.heappop(heap)
        if g_seg.get(k, 0) != seg:
            continue  # moved segments or evicted
        if g_ver.get(k, 0) != v:
            continue  # stale entry
        return k
    return None


def _ensure_seed_from_residents(cache_snapshot):
    """
    If our metadata is empty but the cache already contains residents (e.g., warm-start),
    seed all current residents into T1 with last=0 (unknown recency).
    """
    global g_bytes1, g_bytes2
    if not g_seg and cache_snapshot.cache:
        g_bytes1 = 0
        g_bytes2 = 0
        for k, obj in cache_snapshot.cache.items():
            # Seed as T1 (probation) with unknown last (0)
            if k in g_seg:
                continue
            g_seg[k] = 1
            g_last[k] = 0
            _heap_push(1, k)
            g_bytes1 += int(getattr(obj, "size", 1))


def _arc_adjust_p_on_insert(cache_snapshot, obj):
    """
    After a miss insertion, adjust target p based on ghost hits:
      - If key was in B1 (recent list), increase p (favor recency)
      - If key was in B2 (frequent list), decrease p (favor frequency)
    """
    global g_p_bytes, g_ghost_bytes
    cap = g_cap_bytes
    k = obj.key
    step = max(int(cap // 64), int(getattr(obj, "size", 1)))
    if k in g_B1_map:
        g_p_bytes = min(cap, g_p_bytes + step)
        # Remove from ghost B1 (lazy removal from deque)
        sz = g_B1_map.pop(k, 0)
        g_ghost_bytes = max(0, g_ghost_bytes - sz)
    elif k in g_B2_map:
        g_p_bytes = max(0, g_p_bytes - step)
        sz = g_B2_map.pop(k, 0)
        g_ghost_bytes = max(0, g_ghost_bytes - sz)
    # Clamp
    g_p_bytes = max(0, min(g_p_bytes, cap))


def _ghost_trim_if_needed(cache_snapshot):
    """Keep combined ghost bytes <= GHOST_MAX_BYTES_FACTOR * capacity."""
    global g_ghost_bytes
    limit = int(GHOST_MAX_BYTES_FACTOR * g_cap_bytes)
    if limit <= 0:
        # Drop all ghosts if capacity is weird
        g_B1_map.clear()
        g_B2_map.clear()
        g_B1_q.clear()
        g_B2_q.clear()
        g_ghost_bytes = 0
        return

    # Pop the oldest across B1/B2 until within limit
    while g_ghost_bytes > limit and (g_B1_q or g_B2_q):
        # Find oldest head between B1 and B2
        head1 = g_B1_q[0] if g_B1_q else None
        head2 = g_B2_q[0] if g_B2_q else None
        use_b1 = False
        if head1 and head2:
            use_b1 = head1[0] <= head2[0]
        elif head1:
            use_b1 = True
        elif head2:
            use_b1 = False
        # Pop from chosen deque until we find a key that's still in its map
        if use_b1:
            _, k = g_B1_q.popleft()
            sz = g_B1_map.pop(k, None)
            if sz is not None:
                g_ghost_bytes = max(0, g_ghost_bytes - sz)
        else:
            _, k = g_B2_q.popleft()
            sz = g_B2_map.pop(k, None)
            if sz is not None:
                g_ghost_bytes = max(0, g_ghost_bytes - sz)


def _add_to_ghost(cache_snapshot, key, size, seg_was):
    """Record an eviction in the corresponding ghost list (B1 for T1, B2 for T2)."""
    global g_ghost_bytes
    now = cache_snapshot.access_count
    sz = int(size)
    if seg_was == 1:
        g_B1_map[key] = sz
        g_B1_q.append((now, key))
        g_ghost_bytes += sz
    else:
        g_B2_map[key] = sz
        g_B2_q.append((now, key))
        g_ghost_bytes += sz
    _ghost_trim_if_needed(cache_snapshot)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Choose a victim according to adaptive two-segment LRU:
      - Keep T1 (recent/probation) close to target g_p_bytes
      - If T1 exceeds p, evict from T1 LRU; otherwise evict from T2 LRU
      - Fall back between segments as needed
    """
    _init_if_needed(cache_snapshot)
    _ensure_seed_from_residents(cache_snapshot)

    # Decide which segment to evict from
    # Prefer evicting from T1 if it exceeds target p; else from T2
    from_seg = None
    if g_bytes1 > g_p_bytes and g_heap1:
        from_seg = 1
    elif g_heap2:
        from_seg = 2
    elif g_heap1:
        from_seg = 1
    else:
        # Heaps somehow empty; fallback to any resident (oldest by our last if available)
        # Simple linear fallback (should be rare)
        oldest_k = None
        oldest_t = None
        for k in cache_snapshot.cache.keys():
            t = g_last.get(k, 0)
            if oldest_t is None or t < oldest_t:
                oldest_t = t
                oldest_k = k
        return oldest_k

    # Pop oldest valid entry from chosen segment; if empty, try the other
    victim = _pop_oldest_from_seg(from_seg)
    if victim is None:
        other = 2 if from_seg == 1 else 1
        victim = _pop_oldest_from_seg(other)
        if victim is None:
            # As last resort, pick any key
            for k in cache_snapshot.cache.keys():
                return k
            return None
    return victim


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - If in T1 (probation), promote to T2 (protected)
      - If in T2, refresh LRU time
      - If not tracked (rare), seed into T1 then immediately promote to T2
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count
    size = int(getattr(obj, "size", 1))

    seg = g_seg.get(k, 0)
    if seg == 1:
        # Promote to T2
        g_seg[k] = 2
        g_last[k] = now
        # Move bytes from T1 -> T2
        global g_bytes1, g_bytes2
        g_bytes1 = max(0, g_bytes1 - size)
        g_bytes2 += size
        _heap_push(2, k)
    elif seg == 2:
        # Refresh T2 LRU position
        g_last[k] = now
        _heap_push(2, k)
    else:
        # Untracked resident (seed as T1 then promote)
        g_seg[k] = 1
        g_last[k] = now
        _heap_push(1, k)
        g_bytes1 += size
        # Now promote to T2 due to this hit
        g_seg[k] = 2
        g_last[k] = now
        _heap_push(2, k)
        g_bytes1 = max(0, g_bytes1 - size)
        g_bytes2 += size


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Adjust adaptive target p if key was in a ghost list
      - Insert as MRU of T1 (probation)
    """
    _init_if_needed(cache_snapshot)

    _arc_adjust_p_on_insert(cache_snapshot, obj)

    k = obj.key
    now = cache_snapshot.access_count
    size = int(getattr(obj, "size", 1))

    # Insert into T1
    g_seg[k] = 1
    g_last[k] = now
    _heap_push(1, k)

    global g_bytes1
    g_bytes1 += size


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident metadata
      - Add key to corresponding ghost list (B1 if from T1, B2 if from T2) with its size
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = int(getattr(evicted_obj, "size", 1))
    seg_was = g_seg.pop(ek, 1)  # default to T1 if unknown

    global g_bytes1, g_bytes2
    if seg_was == 1:
        g_bytes1 = max(0, g_bytes1 - esize)
    else:
        g_bytes2 = max(0, g_bytes2 - esize)

    # Clean per-key metadata
    g_last.pop(ek, None)
    g_ver.pop(ek, None)

    # Record into ghosts for adaptation
    _add_to_ghost(cache_snapshot, ek, esize, seg_was)
```
2025-11-28 00:45:24,256 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# W-TinyLFU + Segmented protection + Size-aware retention
# - Two logical segments:
#     1) probation (new/resurrected items)
#     2) protected (promoted on hit; byte-quota limited)
# - TinyLFU frequency counters with lazy epoch decay (8-bit saturating)
# - Size-aware retention: benefit = log1p(freq) / normalized_size
# - Recency bonus added (not subtracted) to protect recent items
# - Protected segment gets an extra bonus; demoted by LRU when over target bytes
# - Eviction uses lazy min-heaps (probation first, then protected) to avoid full scans
#   with lazy invalidation via per-key stamps; periodic score refresh on pop.
#
# This design:
#   - Dramatically reduces per-eviction cost (avoids O(n) scans) -> fewer timeouts
#   - Corrects recency sign (recent items are now protected, not penalized)
#   - Uses size-aware TinyLFU benefit and a protected segment to cut miss rate

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Cache identity (to reset between runs if needed)
m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting
m_prot_bytes = 0
m_prot_target_bytes = 0

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_probation = []           # retention score (lower => more evictable) for probation
h_protected = []           # retention score for protected (used when probation empty)
h_prot_lru = []            # last_access (min-heap) for protected demotions

# TinyLFU counters (lazy decay with epochs; per-key to keep it simple)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# -----------------------------
# Tunables
# -----------------------------

# Frequency decay
LFU_DECAY_INTERVAL = 4096  # accesses per epoch step (power of two recommended)
LFU_COUNTER_MAX = 255

# Protected segment target (bytes)
PROT_FRAC = 0.80           # target fraction of capacity for protected bytes

# Recency window and weights
REC_WIN_MIN = 512
REC_WIN_MULT = 3           # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.60     # recency weight in probation
REC_WEIGHT_PROT = 0.40     # recency weight in protected
PROT_BONUS = 0.60          # extra benefit for protected segment
MULTI_HIT_BONUS = 0.30     # extra benefit for items with >=2 resident hits

# Heap maintenance
SCORE_REFRESH_EPS = 1e-6
MAX_HEAP_FIX_PER_EVICT = 16  # bound reheap/refresh work per eviction

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC * cache_snapshot.capacity)

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Return size as percentage of capacity to keep scales stable
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _retention_score(cache_snapshot, key):
    # Higher score = more worth keeping. Evict the minimum score.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # treat missing as extremely good (will be filtered by validity)
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)

    seg = m_segment.get(key, 0)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec_bonus = _recency_bonus(now, m_last_access.get(key), rec_window)

    # Size-aware frequency benefit
    benefit = math.log1p(float(freq)) / size_norm

    # Multi-hit bias
    if m_resident_hits.get(key, 0) >= 2:
        benefit += MULTI_HIT_BONUS

    # Recency bonus
    if seg == 1:
        benefit += PROT_BONUS + REC_WEIGHT_PROT * rec_bonus
    else:
        benefit += REC_WEIGHT_PROB * rec_bonus

    return benefit


# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    # Compute score at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    score = _retention_score(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (score, s, key))
    else:
        heapq.heappush(h_protected, (score, s, key))
        # Also maintain LRU heap for protected demotions
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot, heap_ref, expected_seg):
    # Return a valid key from the given heap, refreshing stale scores when needed.
    # Limit work per call to avoid long stalls.
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        score, stamp, key = heapq.heappop(heap)
        # Skip invalid/stale entries
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Opportunistically refresh score if it drifted
        new_score = _retention_score(cache_snapshot, key)
        if abs(new_score - score) > SCORE_REFRESH_EPS:
            # Reinsert with a new stamp
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key
    return None


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        # Push into probation heap with updated score/stamp
        _push_key(cache_snapshot, key)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim:
      1) Pop the weakest from probation heap (lowest retention)
      2) If probation empty, pop the weakest from protected heap
      3) Fallback: any resident key
    '''
    _init_if_needed(cache_snapshot)

    # Prefer evicting from probation
    victim = _pop_best_candidate(cache_snapshot, h_probation, expected_seg=0)
    if victim is None:
        victim = _pop_best_candidate(cache_snapshot, h_protected, expected_seg=1)

    if victim is not None:
        return victim

    # Fallback: arbitrary key (should be rare)
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote probation -> protected on first resident hit
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with new score/recency
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        # Promote to protected
        m_segment[k] = 1
        # Account protected bytes
        global m_prot_bytes
        m_prot_bytes += obj.size
        # Push into protected heaps
        _push_key(cache_snapshot, k)
        # Enforce protected target
        _maybe_demote_protected(cache_snapshot)
    else:
        # Already protected: refresh heaps
        _push_key(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place into probation segment and push to heap
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation
    _push_key(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Adjust protected bytes if it was protected
    seg = m_segment.pop(ek, None)
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 23
- Hit Rate: 0.0606

Example 2:
- Trace ID: 20
- Hit Rate: 0.4051

Example 3:
- Trace ID: 35
- Hit Rate: 0.0671

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m00:45:24 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 00:45:24,258 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 00:55:45,398 [INFO] openai._base_client: Retrying request to /chat/completions in 0.425371 seconds
[92m00:59:08 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 00:59:08,597 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 00:59:08,602 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# SLRU + TinyLFU (faster decay) + GDS-LFU priority + size-tamed retention
# - Two segments (probation/protected) with byte quota for protected.
# - TinyLFU counters with lazy epoch decay (shorter interval to adapt faster).
# - GreedyDual-LFU priority: H = L + value / size_factor, evict min(H).
#     * L is a global "clock" raised to the last evicted H. This imparts aging.
#     * value blends decayed frequency, small recency, and segment/multi-hit bonuses.
# - Promotion requires 2 resident hits (first hit stays in probation) to reduce pollution.
# - Size-tamed: size_factor = (size/capacity)^alpha with small alpha to not punish big items too much.
# - Heaps (lazy, stamped) for eviction candidates (probation first, then protected).
# - Protected segment demotion by LRU when over its byte target.
#
# Goals versus previous version:
#   - Better adaptivity: faster LFU decay + GD clock aging => reduced stale frequency bias.
#   - Less pollution: promotion on 2nd resident hit; protected is truly for re-referenced items.
#   - Higher hit-rate focus: only mild size normalization (alpha<1) instead of strict size-aware division.
#   - Still O(log n) per update via heaps with lazy invalidation.

import math
import heapq

# -----------------------------
# Global metadata (module scope)
# -----------------------------

m_cache_identity = None

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count while resident
m_segment = dict()         # key -> 0: probation, 1: protected
m_stamp = dict()           # key -> monotonic int used to invalidate stale heap entries

# Protected bytes accounting
m_prot_bytes = 0
m_prot_target_bytes = 0

# Heaps (lazy invalidation; tuples hold (priority, stamp, key))
h_probation = []           # priority for probation (min-heap)
h_protected = []           # priority for protected (min-heap)
h_prot_lru = []            # last_access (min-heap) for protected demotions

# TinyLFU counters (lazy decay with epochs; per-key)
m_lfu_count = dict()       # key -> (count:int[0..255], epoch:int)
m_lfu_epoch = 0

# GreedyDual clock
m_gd_clock = 0.0

# -----------------------------
# Tunables
# -----------------------------

# TinyLFU decay (shorter -> adapts quicker to shifts)
LFU_DECAY_INTERVAL = 1024
LFU_COUNTER_MAX = 255

# Protected segment target (bytes)
PROT_FRAC = 0.70

# Promotion threshold (resident hits required to enter protected)
PROMOTE_HITS = 2

# Recency window and weights
REC_WIN_MIN = 256
REC_WIN_MULT = 2           # window ~= REC_WIN_MULT * resident_items
REC_WEIGHT_PROB = 0.25     # recency weight in probation
REC_WEIGHT_PROT = 0.15     # recency weight in protected
PROT_BONUS = 0.35          # extra value for protected segment
MULTI_HIT_BONUS = 0.25     # extra value for items with >=2 resident hits

# Size normalization (tamed influence on hit-rate)
SIZE_ALPHA = 0.25          # value is divided by (size/cap)^alpha

# Heap maintenance
SCORE_REFRESH_EPS = 1e-9
MAX_HEAP_FIX_PER_EVICT = 24

# -----------------------------
# Init/reset helpers
# -----------------------------

def _reset_all(cache_snapshot):
    global m_cache_identity
    global m_last_access, m_resident_hits, m_segment, m_stamp
    global m_prot_bytes, m_prot_target_bytes
    global h_probation, h_protected, h_prot_lru
    global m_lfu_count, m_lfu_epoch
    global m_gd_clock

    m_cache_identity = id(cache_snapshot.cache)

    m_last_access.clear()
    m_resident_hits.clear()
    m_segment.clear()
    m_stamp.clear()

    m_prot_bytes = 0
    m_prot_target_bytes = int(PROT_FRAC * cache_snapshot.capacity)

    h_probation.clear()
    h_protected.clear()
    h_prot_lru.clear()

    m_lfu_count.clear()
    m_lfu_epoch = 0

    m_gd_clock = 0.0


def _init_if_needed(cache_snapshot):
    global m_cache_identity
    if m_cache_identity is None or m_cache_identity != id(cache_snapshot.cache):
        _reset_all(cache_snapshot)
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy; no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(LFU_COUNTER_MAX, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size_ratio(size, capacity):
    # Return size as fraction of capacity (0,1]; guard tiny values to avoid div-by-zero
    return max(1e-9, float(size) / float(capacity))


def _recency_bonus(now, last, window):
    # Returns [0,1]; 1 for very recent, ~0 for very old/unknown
    if last is None:
        return 0.0
    age = max(0, now - last)
    if window <= 0:
        return 0.0
    return max(0.0, 1.0 - min(1.0, float(age) / float(window)))


def _priority_value(cache_snapshot, key):
    # GreedyDual-LFU style priority:
    #   H = L + value / (size_ratio ** SIZE_ALPHA)
    # Evict the minimum H.
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('inf')  # invalid; filtered by stamp/segment checks elsewhere
    size = obj.size

    freq = _lfu_peek(cache_snapshot, key)
    seg = m_segment.get(key, 0)
    rec_window = max(REC_WIN_MIN, REC_WIN_MULT * max(1, len(cache_snapshot.cache)))
    rec = _recency_bonus(now, m_last_access.get(key), rec_window)

    # Value components
    value = math.log1p(float(freq))
    if m_resident_hits.get(key, 0) >= 2:
        value += MULTI_HIT_BONUS
    if seg == 1:
        value += PROT_BONUS + REC_WEIGHT_PROT * rec
    else:
        value += REC_WEIGHT_PROB * rec

    size_ratio = _normalized_size_ratio(size, cap)
    size_factor = size_ratio ** SIZE_ALPHA

    return m_gd_clock + (value / size_factor)


# -----------------------------
# Heap helpers (lazy, stamped)
# -----------------------------

def _next_stamp(key):
    s = m_stamp.get(key, 0) + 1
    m_stamp[key] = s
    return s


def _push_key(cache_snapshot, key):
    # Compute priority at push time and place into the appropriate heap(s)
    seg = m_segment.get(key, 0)
    s = _next_stamp(key)
    prio = _priority_value(cache_snapshot, key)
    if seg == 0:
        heapq.heappush(h_probation, (prio, s, key))
    else:
        heapq.heappush(h_protected, (prio, s, key))
        # Maintain LRU heap for protected demotions
        last = m_last_access.get(key, -1)
        heapq.heappush(h_prot_lru, (last, s, key))


def _is_valid(cache_snapshot, key, expected_seg, stamp):
    if key not in cache_snapshot.cache:
        return False
    if m_segment.get(key) != expected_seg:
        return False
    if m_stamp.get(key, 0) != stamp:
        return False
    return True


def _pop_best_candidate(cache_snapshot, heap_ref, expected_seg):
    # Return a valid (key, priority) from the given heap, refreshing stale entries when needed.
    attempts = 0
    heap = heap_ref
    while heap and attempts < MAX_HEAP_FIX_PER_EVICT:
        prio, stamp, key = heapq.heappop(heap)
        # Skip invalid/stale entries
        if not _is_valid(cache_snapshot, key, expected_seg, stamp):
            attempts += 1
            continue
        # Opportunistically refresh priority if it drifted (e.g., due to GD clock / recency / freq change)
        new_prio = _priority_value(cache_snapshot, key)
        if abs(new_prio - prio) > SCORE_REFRESH_EPS:
            _push_key(cache_snapshot, key)
            attempts += 1
            continue
        return key, prio
    return None, None


def _maybe_demote_protected(cache_snapshot):
    # Demote oldest protected items (by LRU) until protected bytes within target
    global m_prot_bytes
    while m_prot_bytes > m_prot_target_bytes and h_prot_lru:
        last, stamp, key = heapq.heappop(h_prot_lru)
        if not _is_valid(cache_snapshot, key, expected_seg=1, stamp=stamp):
            continue
        # Demote to probation
        m_segment[key] = 0
        obj = cache_snapshot.cache.get(key)
        if obj is not None:
            m_prot_bytes = max(0, m_prot_bytes - obj.size)
        _push_key(cache_snapshot, key)


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose a victim with minimum GreedyDual-LFU priority:
      1) Pop the weakest from probation heap
      2) If probation empty, pop the weakest from protected heap
      3) Fallback: any resident key
    Also raise the global GD clock L to the evicted entry's priority.
    '''
    _init_if_needed(cache_snapshot)
    global m_gd_clock

    victim, vprio = _pop_best_candidate(cache_snapshot, h_probation, expected_seg=0)
    if victim is None:
        victim, vprio = _pop_best_candidate(cache_snapshot, h_protected, expected_seg=1)

    if victim is None:
        # Fallback: arbitrary key (rare). Update clock based on computed priority.
        try:
            victim = next(iter(cache_snapshot.cache))
            vprio = _priority_value(cache_snapshot, victim)
        except StopIteration:
            return None

    # Advance GD clock to the evicted priority to age the rest
    if vprio is not None and math.isfinite(vprio):
        m_gd_clock = max(m_gd_clock, vprio)

    return victim


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote probation -> protected when resident hits >= PROMOTE_HITS
      - Maintain protected-byte quota via LRU demotion
      - Refresh heaps with updated priority
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k, 0)
    if seg == 0:
        if m_resident_hits[k] >= PROMOTE_HITS:
            # Promote to protected
            m_segment[k] = 1
            global m_prot_bytes
            m_prot_bytes += obj.size
            _push_key(cache_snapshot, k)
            _maybe_demote_protected(cache_snapshot)
        else:
            # Stay probation, refresh priority
            _push_key(cache_snapshot, k)
    else:
        # Protected: refresh priority and LRU
        _push_key(cache_snapshot, k)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU for the requested key (admission sampling)
      - Initialize resident metadata: last_access, resident_hits = 0 (no resident hits yet)
      - Place into probation segment and push to heap
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 0
    m_segment[k] = 0  # probation
    _push_key(cache_snapshot, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
      - Adjust protected bytes if needed
      - Note: GD clock L is already advanced during evict()
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Adjust protected bytes if it was protected
    seg = m_segment.pop(ek, None)
    if seg == 1:
        global m_prot_bytes
        m_prot_bytes = max(0, m_prot_bytes - evicted_obj.size)

    # Clean resident-only metadata; do NOT delete LFU counters
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_stamp.pop(ek, None)
```
2025-11-28 00:59:20,958 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Windowed SLRU + TinyLFU + ARC-style adaptation + size-aware sampled eviction
# - Three resident segments (by bytes):
#     Window (very recent), Probation (main new/once-hit), Protected (multi-hit)
# - Eviction order: Window -> Probation -> Protected (minimize main churn)
# - TinyLFU counts (lazy decay) guide which among the oldest to evict (sampled)
# - Size-aware scoring (prefer keeping tiny but hot objects)
# - ARC-like ghost lists dynamically adapt Protected target size (bytes)
# - O(1) updates on hit/insert via OrderedDict LRU queues

import math
from collections import OrderedDict

# ---------------
# Globals
# ---------------

# LRU queues (LRU at left, MRU at right)
win_lru = OrderedDict()   # 0: Window segment (recent)
prob_lru = OrderedDict()  # 1: Probation (main new/once-hit)
prot_lru = OrderedDict()  # 2: Protected (multi-hit)

# Bytes accounting
win_bytes = 0
prob_bytes = 0
prot_bytes = 0

# Resident segment mapping: key -> seg_id {0:win, 1:prob, 2:prot}
m_segment = dict()

# Per-key resident metadata
m_last_access = dict()      # key -> int time
m_resident_hits = dict()    # key -> int

# TinyLFU: 4-bit counters with lazy decay
m_lfu_count = dict()        # key -> (count[0..15], epoch)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Dynamic targets (bytes)
g_prot_target_bytes = 0     # dynamically tuned protected target
g_win_target_bytes = 0      # small window target
g_last_cap = 0

# Ghost lists for ARC-style adaptation (bytes-limited)
ghost_prob = OrderedDict()  # keys evicted from Window/Probation
ghost_prot = OrderedDict()  # keys evicted from Protected
ghost_prob_bytes = 0
ghost_prot_bytes = 0

# Scoring / sampling
SAMPLE_K_WIN = 5
SAMPLE_K_PROB = 6
SAMPLE_K_PROT = 4

# Multi-hit bonus in score
MULTI_HIT_BONUS = 0.5

# ---------------
# Helpers: init / targets / lfu
# ---------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    global g_last_cap, g_prot_target_bytes, g_win_target_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = max(1, int(cache_snapshot.capacity))
    if g_last_cap != cap or g_prot_target_bytes == 0 or g_win_target_bytes == 0:
        g_last_cap = cap
        # Start conservatively: small window, large protected
        g_win_target_bytes = max(1, int(cap * 0.05))
        g_prot_target_bytes = max(1, int(cap * 0.70))

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _cap_bytes(cache_snapshot):
    return max(1, int(cache_snapshot.capacity))

# ---------------
# Ghost lists and adaptation (ARC-like)
# ---------------

def _ghost_cap(cache_snapshot):
    # Total bytes allowed for each ghost list (soft bound)
    return _cap_bytes(cache_snapshot)

def _ghost_add(cache_snapshot, seg_id, key, size):
    # Evicted from which segment? 0/1 -> ghost_prob, 2 -> ghost_prot
    global ghost_prob_bytes, ghost_prot_bytes
    if seg_id == 2:
        if key in ghost_prot:
            old = ghost_prot.pop(key)
            ghost_prot_bytes -= old
        ghost_prot[key] = size
        ghost_prot_bytes += size
        # Trim
        cap = _ghost_cap(cache_snapshot)
        while ghost_prot_bytes > cap and ghost_prot:
            k, s = ghost_prot.popitem(last=False)
            ghost_prot_bytes -= s
    else:
        if key in ghost_prob:
            old = ghost_prob.pop(key)
            ghost_prob_bytes -= old
        ghost_prob[key] = size
        ghost_prob_bytes += size
        cap = _ghost_cap(cache_snapshot)
        while ghost_prob_bytes > cap and ghost_prob:
            k, s = ghost_prob.popitem(last=False)
            ghost_prob_bytes -= s

def _adapt_prot_target(cache_snapshot, delta_bytes):
    global g_prot_target_bytes
    cap = _cap_bytes(cache_snapshot)
    # Bounds: leave at least 5% for window + 5% for probation, at most 90% for protected
    min_prot = int(cap * 0.10)
    max_prot = int(cap * 0.90)
    g_prot_target_bytes = max(min_prot, min(max_prot, g_prot_target_bytes + int(delta_bytes)))

def _adapt_on_ghost_ref(cache_snapshot, key):
    # If the incoming key was recently in a ghost list, adapt protected target
    if key in ghost_prot:
        # We previously kept it hot; increase protected to favor long-term
        s = ghost_prot.get(key, 0)
        _adapt_prot_target(cache_snapshot, max(1, s))
        # Move to MRU in ghost (recency)
        ghost_prot.move_to_end(key, last=True)
    elif key in ghost_prob:
        # Previously evicted from probation/window -> favor recency by shrinking protected
        s = ghost_prob.get(key, 0)
        _adapt_prot_target(cache_snapshot, -max(1, s // 2))
        ghost_prob.move_to_end(key, last=True)

# ---------------
# Segment helpers
# ---------------

def _seg_remove(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    else:
        # clean up any remnants
        win_lru.pop(key, None)
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)
    return seg

def _seg_insert_win(key, size):
    global win_bytes
    # ensure not in others
    if m_segment.get(key) == 0:
        # refresh MRU
        win_lru.pop(key, None)
        win_lru[key] = None
        return
    # Remove from other lists if present
    if m_segment.get(key) == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            global prob_bytes
            prob_bytes -= size
    if m_segment.get(key) == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            global prot_bytes
            prot_bytes -= size
    m_segment[key] = 0
    win_lru[key] = None
    win_bytes += size

def _seg_move_to_prob(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 1:
        # refresh MRU
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    if seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    prob_lru[key] = None
    m_segment[key] = 1
    prob_bytes += size

def _demote_prot_if_needed(cache_snapshot):
    # Demote from protected to probation until within target
    global prot_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(0, min(g_prot_target_bytes, cap))
    while prot_bytes > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        prot_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _trim_window_if_needed(cache_snapshot):
    # Keep window near its target by moving oldest window entries to probation (not evict)
    global win_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(1, min(g_win_target_bytes, cap))
    # Allow a little slack to avoid churn
    slack = max(1, target // 8)
    while win_bytes > (target + slack) and win_lru:
        dem_key, _ = win_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        win_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _seg_move_to_prot(cache_snapshot, key, size):
    # Promote to Protected MRU
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 2:
        # refresh MRU
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    prot_lru[key] = None
    m_segment[key] = 2
    prot_bytes += size
    _demote_prot_if_needed(cache_snapshot)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

# ---------------
# Scoring helpers
# ---------------

def _normalized_size(size, capacity):
    # size as percentage of capacity, keep >= small epsilon
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _retention_score(cache_snapshot, key):
    # Higher score = stronger retention; eviction picks smallest score
    cap = _cap_bytes(cache_snapshot)
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size
    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)
    bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    # Size-aware benefit with gentle diminishing returns on frequency
    benefit = (math.log2(1.0 + float(freq)) + bonus) / size_norm
    return benefit

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    # sample k oldest
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            return next(iter(order))
        except StopIteration:
            return None
    return chosen_key

# ---------------
# Policy entry points
# ---------------

def evict(cache_snapshot, obj):
    """
    Eviction strategy:
      - Prefer evicting from Window first to shield main cache (2Q-style)
      - Then from Probation, finally Protected
      - Within a segment, sample a few oldest and evict the one with the lowest
        TinyLFU size-aware score.
    """
    _init_if_needed(cache_snapshot)

    # Choose from Window first (admission filter / reduces main churn)
    if win_lru:
        victim = _pick_candidate_from_order(cache_snapshot, win_lru, SAMPLE_K_WIN)
        return victim

    # Then from Probation
    if prob_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
        return victim

    # Fallback to Protected if others empty
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)
        return victim

    # Last resort
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access and resident hit count
      - Promote to Protected if in Window/Probation
      - Refresh LRU position within its segment
      - Adapt Protected target: increase on Probation hits, slightly decrease on Protected hits
      - Trim Window toward its target
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked; place into Window
        _seg_insert_win(k, obj.size)
        _trim_window_if_needed(cache_snapshot)
        return

    if seg == 0 or seg == 1:
        # Hit in Window or Probation -> promote to Protected
        _seg_move_to_prot(cache_snapshot, k, obj.size)
        # Adapt: probation/window hit means protected was too small -> grow
        step = max(1, obj.size // 2)
        _adapt_prot_target(cache_snapshot, step)
    else:
        # Protected hit: touch and slightly shrink target to allow more probation
        _seg_touch_on_hit(cache_snapshot, k)
        step = max(1, obj.size // 8)
        _adapt_prot_target(cache_snapshot, -step)

    # Keep window near target
    _trim_window_if_needed(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU for the key (admission learns from requests)
      - Adjust Protected target using ARC-like ghost feedback
      - Initialize resident metadata and place into Window MRU
      - Gently trim Window toward its target (migrate oldest to Probation)
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # ARC-like adaptation using ghost information
    _adapt_on_ghost_ref(cache_snapshot, k)

    # New resident enters Window MRU
    _seg_insert_win(k, obj.size)
    _trim_window_if_needed(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove it from segment structures and resident-only metadata
      - Record into ghost lists for ARC-style adaptation
      - Keep TinyLFU counts to inform future decisions
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = evicted_obj.size

    # Identify segment before removal (for ghost list)
    seg_before = m_segment.get(ek, 1)
    _seg_remove(cache_snapshot, ek, esize)

    # Resident-only metadata cleanup
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # Remember in ghost for adaptation
    _ghost_add(cache_snapshot, seg_before, ek, esize)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 16
- Hit Rate: 0.0214

Example 2:
- Trace ID: 13
- Hit Rate: 0.0

Example 3:
- Trace ID: 39
- Hit Rate: 0.1381

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m00:59:20 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 00:59:20,963 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m01:01:39 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 01:01:39,523 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 01:01:39,525 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Windowed SLRU (by object count) + TinyLFU + ARC-style adaptation + sampled eviction
# - Three resident segments (by object count):
#     Window (very recent), Probation (main new/once-hit), Protected (multi-hit)
# - Eviction preference: choose from Window vs Probation using TinyLFU score; fall back to Protected
# - TinyLFU with lazy decay guides which among the oldest to evict (sampled oldest K)
# - ARC-like ghost lists dynamically adapt Protected target size (counts)
# - O(1) updates on hit/insert via OrderedDict LRU queues
#
# Important: This policy treats capacity as a count of objects (not bytes).

import math
from collections import OrderedDict

# ---------------
# Globals
# ---------------

# LRU queues (LRU at left, MRU at right)
win_lru = OrderedDict()   # 0: Window segment (recent)
prob_lru = OrderedDict()  # 1: Probation (main new/once-hit)
prot_lru = OrderedDict()  # 2: Protected (multi-hit)

# Counts accounting (by number of objects)
win_cnt = 0
prob_cnt = 0
prot_cnt = 0

# Resident segment mapping: key -> seg_id {0:win, 1:prob, 2:prot}
m_segment = dict()

# Per-key resident metadata
m_last_access = dict()      # key -> int time
m_resident_hits = dict()    # key -> int (resident-only hit count)

# TinyLFU: 4-bit counters with lazy decay
m_lfu_count = dict()        # key -> (count[0..15], epoch)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Dynamic targets (counts)
g_prot_target = 0     # dynamically tuned protected target (count)
g_win_target = 0      # window target (count)
g_last_cap = 0

# Ghost lists for ARC-style adaptation (count-limited)
ghost_prob = OrderedDict()  # keys evicted from Window/Probation
ghost_prot = OrderedDict()  # keys evicted from Protected

# Scoring / sampling
SAMPLE_K_WIN = 6
SAMPLE_K_PROB = 8
SAMPLE_K_PROT = 3

# Score shaping
MULTI_HIT_BONUS = 0.75
PROTECTED_SEGMENT_BONUS = 0.75
AGE_PENALTY_WEIGHT = 0.20  # small penalty for very old items

# ---------------
# Helpers: init / targets / lfu
# ---------------

def _cap_count(cache_snapshot):
    # Treat capacity as number of objects
    return max(1, int(cache_snapshot.capacity))

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    global g_last_cap, g_prot_target, g_win_target
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = _cap_count(cache_snapshot)
    if g_last_cap != cap or g_prot_target == 0 or g_win_target == 0:
        g_last_cap = cap
        # Start with a modest window and a solid protected region
        g_win_target = max(1, int(cap * 0.10))
        g_prot_target = max(1, int(cap * 0.50))

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# ---------------
# Ghost lists and adaptation (ARC-like)
# ---------------

def _ghost_cap(cache_snapshot):
    # Total entries allowed for each ghost list (soft bound, per list)
    return _cap_count(cache_snapshot)

def _ghost_add(cache_snapshot, seg_id, key):
    # Evicted from which resident segment? 0/1 -> ghost_prob, 2 -> ghost_prot
    if seg_id == 2:
        if key in ghost_prot:
            ghost_prot.pop(key, None)
        ghost_prot[key] = None
        # Trim oldest if over cap
        cap = _ghost_cap(cache_snapshot)
        while len(ghost_prot) > cap and ghost_prot:
            ghost_prot.popitem(last=False)
    else:
        if key in ghost_prob:
            ghost_prob.pop(key, None)
        ghost_prob[key] = None
        cap = _ghost_cap(cache_snapshot)
        while len(ghost_prob) > cap and ghost_prob:
            ghost_prob.popitem(last=False)

def _adapt_prot_target(cache_snapshot, delta_count):
    global g_prot_target
    cap = _cap_count(cache_snapshot)
    # Bounds: leave at least 10% for window + 10% for probation, at most 80% for protected
    min_prot = int(cap * 0.10)
    max_prot = int(cap * 0.80)
    g_prot_target = max(min_prot, min(max_prot, g_prot_target + int(delta_count)))

def _adapt_on_ghost_ref(cache_snapshot, key):
    # If the incoming key was recently in a ghost list, adapt protected target
    if key in ghost_prot:
        # We previously kept it hot; increase protected to favor long-term
        _adapt_prot_target(cache_snapshot, +1)
        ghost_prot.move_to_end(key, last=True)
    elif key in ghost_prob:
        # Previously evicted from probation/window -> favor recency by shrinking protected
        _adapt_prot_target(cache_snapshot, -1)
        ghost_prob.move_to_end(key, last=True)

# ---------------
# Segment helpers (count-based)
# ---------------

def _seg_remove(cache_snapshot, key):
    global win_cnt, prob_cnt, prot_cnt
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_cnt -= 1
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_cnt -= 1
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_cnt -= 1
    else:
        win_lru.pop(key, None)
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)
    return seg

def _seg_insert_win(key):
    global win_cnt, prob_cnt, prot_cnt
    # Remove from any other segment first
    seg = m_segment.get(key)
    if seg == 0:
        # Refresh MRU
        if key in win_lru:
            win_lru.pop(key, None)
            win_lru[key] = None
        else:
            win_lru[key] = None
        return
    if seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_cnt -= 1
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_cnt -= 1
    m_segment[key] = 0
    win_lru[key] = None
    win_cnt += 1

def _seg_move_to_prob(cache_snapshot, key):
    global win_cnt, prob_cnt, prot_cnt
    seg = m_segment.get(key)
    if seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_cnt -= 1
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_cnt -= 1
    m_segment[key] = 1
    prob_lru[key] = None
    prob_cnt += 1

def _seg_move_to_prot(cache_snapshot, key):
    global win_cnt, prob_cnt, prot_cnt
    seg = m_segment.get(key)
    if seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_cnt -= 1
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_cnt -= 1
    m_segment[key] = 2
    prot_lru[key] = None
    prot_cnt += 1
    _demote_prot_if_needed(cache_snapshot)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _demote_prot_if_needed(cache_snapshot):
    # Demote from protected to probation until within target
    global prot_cnt, prob_cnt
    target = max(0, min(g_prot_target, _cap_count(cache_snapshot)))
    while prot_cnt > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        # Confirm still resident
        if dem_key in cache_snapshot.cache:
            prot_cnt -= 1
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_cnt += 1
        else:
            prot_cnt -= 1
            m_segment.pop(dem_key, None)

def _trim_window_if_needed(cache_snapshot):
    # Keep window near its target by moving oldest window entries to probation (not evict)
    global win_cnt, prob_cnt
    target = max(1, min(g_win_target, _cap_count(cache_snapshot)))
    # Allow small slack to reduce churn
    slack = max(1, target // 4)
    while win_cnt > (target + slack) and win_lru:
        dem_key, _ = win_lru.popitem(last=False)
        if dem_key in cache_snapshot.cache:
            win_cnt -= 1
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_cnt += 1
        else:
            win_cnt -= 1
            m_segment.pop(dem_key, None)

# ---------------
# Scoring helpers
# ---------------

def _retention_score(cache_snapshot, key):
    # Higher score = stronger retention; eviction picks smallest score
    freq = _lfu_peek(cache_snapshot, key)
    bonus = 0.0
    if m_resident_hits.get(key, 1) >= 2:
        bonus += MULTI_HIT_BONUS
    if m_segment.get(key) == 2:
        bonus += PROTECTED_SEGMENT_BONUS
    # Small age penalty so very old entries are easier to evict
    last = m_last_access.get(key, cache_snapshot.access_count)
    age = max(0, cache_snapshot.access_count - last)
    age_penalty = math.log2(1.0 + float(age)) * AGE_PENALTY_WEIGHT
    # Diminishing returns for very high freq
    return math.log2(1.0 + float(freq)) + bonus - age_penalty

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    # sample k oldest
    for key in order.keys():
        # defensive: skip if not in cache (should not happen often)
        if key not in cache_snapshot.cache:
            continue
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            # return oldest present key
            for key in order.keys():
                if key in cache_snapshot.cache:
                    return key
            return None
        except StopIteration:
            return None
    return chosen_key

# ---------------
# Policy entry points
# ---------------

def evict(cache_snapshot, obj):
    """
    Eviction strategy (count-based):
      - Prefer evicting from Window when it's over target to shield main cache
      - Otherwise, compare candidates from Window and Probation and evict the lower scored one
      - Fall back to Protected (rare) if others empty
      - Within a segment, sample a few oldest and evict the one with the lowest TinyLFU score
    """
    _init_if_needed(cache_snapshot)

    # Pre-trim structures toward targets (moves only, no evictions)
    _demote_prot_if_needed(cache_snapshot)
    _trim_window_if_needed(cache_snapshot)

    cand_win = cand_prob = None

    if win_lru:
        cand_win = _pick_candidate_from_order(cache_snapshot, win_lru, SAMPLE_K_WIN)
    if prob_lru:
        cand_prob = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)

    # If window is bloated vs target or probation empty, evict from window
    if win_lru and (win_cnt > g_win_target or not prob_lru):
        return cand_win if cand_win is not None else next(iter(win_lru))

    # Otherwise choose the weaker between window and probation (if both exist)
    if cand_win is not None and cand_prob is not None:
        sw = _retention_score(cache_snapshot, cand_win)
        sp = _retention_score(cache_snapshot, cand_prob)
        return cand_win if sw < sp else cand_prob

    # Only probation has entries
    if cand_prob is not None:
        return cand_prob

    # Only window has entries
    if cand_win is not None:
        return cand_win

    # Fallback to Protected if others empty
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)
        if victim is not None:
            return victim
        try:
            return next(iter(prot_lru))
        except StopIteration:
            pass

    # Last resort
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access and resident hit count
      - Promote to Protected if in Window/Probation
      - Refresh LRU position within its segment
      - Adapt Protected target: increase on Probation/Window hits, slightly decrease on Protected hits
      - Trim Window toward its target
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Shouldn't happen, but defensively place into Window
        _seg_insert_win(k)
        _trim_window_if_needed(cache_snapshot)
        return

    if seg == 0 or seg == 1:
        # Hit in Window or Probation -> promote to Protected
        _seg_move_to_prot(cache_snapshot, k)
        # Adapt: probation/window hit means protected was too small -> grow
        _adapt_prot_target(cache_snapshot, +1)
    else:
        # Protected hit: touch and slightly shrink target to allow more probation
        _seg_touch_on_hit(cache_snapshot, k)
        _adapt_prot_target(cache_snapshot, -1)

    # Keep window near target
    _trim_window_if_needed(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU for the key (admission learns from requests)
      - Adjust Protected target using ARC-like ghost feedback
      - Initialize resident metadata and place into Window MRU
      - Gently trim Window toward its target (migrate oldest to Probation)
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # ARC-like adaptation using ghost information
    _adapt_on_ghost_ref(cache_snapshot, k)

    # New resident enters Window MRU
    _seg_insert_win(k)
    _trim_window_if_needed(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove it from segment structures and resident-only metadata
      - Record into ghost lists for ARC-style adaptation
      - Keep TinyLFU counts to inform future decisions
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Identify segment before removal (for ghost list)
    seg_before = m_segment.get(ek, 1)
    _seg_remove(cache_snapshot, ek)

    # Resident-only metadata cleanup
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # Remember in ghost for adaptation
    _ghost_add(cache_snapshot, seg_before, ek)
```
2025-11-28 01:02:27,845 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Segmented Size-Aware TinyLFU (SS-TinyLFU)
# - Two resident segments (probation/protected), SLRU-style:
#     * probation: newly admitted and single-hit items
#     * protected: promoted upon hit; gets most of the capacity
# - Eviction prefers probation; protected is shielded unless it exceeds target bytes
# - Within a segment, victims are chosen by a unified score combining:
#     * TinyLFU frequency (decayed, 4-bit counters)
#     * size penalty (size/capacity)^ALPHA
#     * recency bonus (stronger in probation, weaker in protected)
#     * predicted reuse (EMA of inter-arrival time)
#     * slight bonus for multi-hit residents
# - TinyLFU uses lazy epochs (no global sweeps)
# - Metadata is updated on hit/insert/evict, including segment promotions/demotions

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.80  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 1000
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.65
W_REC_PROT = 0.18
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _find_oldest_in_segment(cache_snapshot, segment_id):
    # Returns (key, last_access) of the oldest in the given segment, or (None, None)
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if _segment_of(k) != segment_id:
            continue
        last = m_last_access.get(k, -1)
        if oldest_time is None or last < oldest_time:
            oldest_time = last
            oldest_key = k
    return oldest_key, oldest_time

def _demote_one_from_protected_if_needed(cache_snapshot):
    # If protected exceeds its target, demote the oldest protected item to probation
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    if g_protected_bytes <= target:
        return
    key, _ = _find_oldest_in_segment(cache_snapshot, segment_id=1)
    if key is None:
        return
    # Demote
    obj = cache_snapshot.cache.get(key)
    if obj is not None:
        g_protected_bytes = max(0, g_protected_bytes - obj.size)
    m_segment[key] = 0  # probation

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, evict the key with the smallest retention score
        (ties broken by oldest last-access time)
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized
    _demote_one_from_protected_if_needed(cache_snapshot)

    # First pass: try probation
    min_key = None
    min_score = None
    min_time = None

    # Helper to select within a given segment
    def select_from_segment(seg_id):
        nonlocal min_key, min_score, min_time
        found = False
        for k in cache_snapshot.cache.keys():
            if _segment_of(k) != seg_id:
                continue
            score = _retention_score(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            if (not found) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k
                found = True
        return found

    has_probation = select_from_segment(0)
    if not has_probation:
        # No probation items -> select from protected (rare, e.g., tiny caches)
        selected = select_from_segment(1)
        if not selected:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - If in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promotion to protected on hit (if not already)
    seg = _segment_of(k)
    if seg == 0:
        m_segment[k] = 1
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_one_from_protected_if_needed(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # No change to protected bytes on insert (probation by default)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 2
- Hit Rate: 0.4826

Example 2:
- Trace ID: 1
- Hit Rate: 0.4792

Example 3:
- Trace ID: 17
- Error: Error - Timeout

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m01:02:27 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 01:02:27,846 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m01:06:09 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 01:06:09,527 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 01:06:09,528 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Improved: SS-TinyLFU with O(1) LRU maintenance and O(K) victim sampling
# Key changes vs previous:
# - Avoid full scans on eviction -> fixes timeouts on long traces
# - Maintain explicit per-segment LRUs (OrderedDict) for O(1) touch/promote/demote
# - Evict by sampling K oldest from target segment (probation, else protected)
#   and selecting the lowest retention score (freq/size-aware + predicted reuse)
# - Constant-time enforcement of protected target via LRU demotion
# - Keep TinyLFU lazy decay and reuse-distance EMA
#
# Behavior summary:
# - Two segments (probation/protected) using SLRU discipline
# - Hits in probation promote to protected
# - Protected gets most bytes; if oversized, oldest protected demoted to probation
# - Eviction prefers probation; falls back to protected if empty
# - Candidate victim chosen among K oldest of the segment by a size-aware
#   TinyLFU-based score with recency/reuse predictors

import math
from collections import OrderedDict

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int time of last access (LRU)
m_prev_access = dict()     # key -> int time of previous access (for IRT estimation)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_segment = dict()         # key -> 0 (probation), 1 (protected)

# Exponential moving average of inter-arrival time (in access_count units)
m_irt = dict()             # key -> float EMA of reuse distance

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Per-segment LRU (left=LRU, right=MRU)
probation_lru = OrderedDict()   # key -> None
protected_lru = OrderedDict()   # key -> None

# Segmented SLRU capacity targeting (by bytes)
PROTECTED_FRACTION = 0.82  # target fraction of cache bytes for protected segment
g_protected_bytes = 0      # running total of bytes in protected

# Scoring tunables
SIZE_ALPHA = 1.10          # >1 penalizes very large objects slightly more
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Recency windows and weights
REC_WIN_MIN = 2000
REC_WIN_MULT = 3           # window ~ REC_WIN_MULT * resident_items

# Recency and predicted-reuse weights (probation vs protected)
W_REC_PROB = 0.55
W_REC_PROT = 0.15
W_PRED_PROB = 0.25
W_PRED_PROT = 0.12

# EMA weight for inter-arrival time (IRT)
IRT_EMA_BETA = 0.40        # higher -> react faster to changing reuse intervals

# Victim sampling
VICTIM_SAMPLE_MIN = 6
VICTIM_SAMPLE_MAX = 32

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating counter (0..15)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# General helpers
# -----------------------------

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _normalized_size(size, capacity):
    # Size as fraction of capacity (avoid zero)
    return max(1e-12, float(size) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _irt_normalized(irt, window):
    # irt: expected time to next reuse; smaller is better
    return 1.0 if window <= 0 else min(1.0, float(irt) / float(window))

def _segment_of(key):
    # Default to probation for unknown keys
    return 1 if m_segment.get(key, 0) == 1 else 0

def _protected_target_bytes(cache_snapshot):
    return int(PROTECTED_FRACTION * float(cache_snapshot.capacity))

def _lru_touch(seg_id, key):
    if seg_id == 1:
        if key in protected_lru:
            protected_lru.move_to_end(key, last=True)
    else:
        if key in probation_lru:
            probation_lru.move_to_end(key, last=True)

def _lru_add(seg_id, key):
    # Ensure uniqueness, then add as MRU
    if seg_id == 1:
        probation_lru.pop(key, None)
        protected_lru.pop(key, None)
        protected_lru[key] = None
    else:
        probation_lru.pop(key, None)
        protected_lru.pop(key, None)
        probation_lru[key] = None

def _lru_remove(key):
    probation_lru.pop(key, None)
    protected_lru.pop(key, None)

def _demote_from_protected_until_target(cache_snapshot):
    global g_protected_bytes
    target = _protected_target_bytes(cache_snapshot)
    while g_protected_bytes > target and protected_lru:
        # Demote LRU from protected to probation (insert as MRU in probation)
        k, _ = protected_lru.popitem(last=False)
        obj = cache_snapshot.cache.get(k)
        if obj is not None:
            g_protected_bytes = max(0, g_protected_bytes - obj.size)
        m_segment[k] = 0
        probation_lru[k] = None  # as MRU

# -----------------------------
# Scoring (eviction priority)
# -----------------------------

def _retention_score(cache_snapshot, key):
    # Smaller score -> weaker retention -> more likely to evict
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # shouldn't happen

    size_norm = _normalized_size(robj.size, cap)
    size_penalty = size_norm ** SIZE_ALPHA

    # Frequency component (decayed)
    freq = float(_lfu_peek(cache_snapshot, key))
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    benefit = (math.log2(1.0 + freq) + extra) / size_penalty

    # Recency and predicted reuse components
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)

    last = m_last_access.get(key)
    age_norm = _recency_normalized(now, last, window)

    irt = m_irt.get(key, float(window))
    irt_norm = _irt_normalized(irt, window)

    seg = _segment_of(key)
    if seg == 1:
        w_rec = W_REC_PROT
        w_pred = W_PRED_PROT
    else:
        w_rec = W_REC_PROB
        w_pred = W_PRED_PROB

    recency_gain = w_rec * (1.0 - age_norm)      # recent -> larger gain
    predicted_gain = w_pred * (1.0 - irt_norm)   # smaller predicted reuse -> larger gain

    return benefit - recency_gain - predicted_gain

def _sample_size(lru_len):
    if lru_len <= 0:
        return 0
    # Scale with sqrt to balance cost and quality
    k = int(max(VICTIM_SAMPLE_MIN, min(VICTIM_SAMPLE_MAX, math.sqrt(lru_len))))
    return max(1, k)

def _select_victim_from_lru(cache_snapshot, seg_id):
    # Iterate K oldest items from the segment's LRU (left->right) and pick the minimum score
    if seg_id == 1:
        lru = protected_lru
    else:
        lru = probation_lru

    n = len(lru)
    if n == 0:
        return None

    k = _sample_size(n)

    min_key = None
    min_score = None
    min_time = None
    count = 0
    for kkey in lru:  # iteration order: LRU to MRU
        score = _retention_score(cache_snapshot, kkey)
        last = m_last_access.get(kkey, -1)
        if (min_key is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = kkey
            min_score = score
            min_time = last
        count += 1
        if count >= k:
            break
    return min_key

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict one resident key:
      - Keep protected near its target by demoting oldest protected if needed (O(1) per demotion)
      - Prefer evicting from probation; fall back to protected if probation empty
      - Within a segment, examine K oldest items and evict the one with the smallest retention score
    '''
    _init_if_needed(cache_snapshot)

    # Adjust protected segment if oversized (constant-time demotions)
    _demote_from_protected_until_target(cache_snapshot)

    # Prefer probation
    victim = _select_victim_from_lru(cache_snapshot, seg_id=0)
    if victim is None:
        # No probation items -> select from protected (rare)
        victim = _select_victim_from_lru(cache_snapshot, seg_id=1)
        if victim is None:
            # Fallback: arbitrary
            try:
                return next(iter(cache_snapshot.cache))
            except StopIteration:
                return None

    return victim


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU (counts every request)
      - Update last/prev access and IRT EMA
      - Increment resident hit count
      - Touch LRU position; if in probation, promote to protected
      - Enforce protected target by demoting oldest protected if oversized
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    # Update IRT EMA using delta between consecutive hits
    prev = m_last_access.get(k)
    if prev is not None:
        delta = max(1, now - prev)
        old_irt = m_irt.get(k, float(delta))
        m_irt[k] = IRT_EMA_BETA * float(delta) + (1.0 - IRT_EMA_BETA) * float(old_irt)
    else:
        # Initialize with a conservative default
        n_items = max(1, len(cache_snapshot.cache))
        window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
        m_irt[k] = float(window)

    m_prev_access[k] = now
    m_last_access[k] = now
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Touch/promotion
    seg = _segment_of(k)
    if seg == 1:
        _lru_touch(1, k)
    else:
        # Promote to protected
        _lru_remove(k)
        m_segment[k] = 1
        _lru_add(1, k)
        # Track protected bytes
        global g_protected_bytes
        g_protected_bytes += obj.size

    # Enforce protected target (demote oldest protected if oversized)
    _demote_from_protected_until_target(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the key (counts the request)
      - Initialize resident metadata:
          last_access, prev_access = now
          resident_hits = 1
          irt = default window
          segment = probation, added as MRU in probation LRU
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count

    _lfu_inc(cache_snapshot, k)

    m_last_access[k] = now
    m_prev_access[k] = now
    m_resident_hits[k] = 1
    m_segment[k] = 0  # probation

    # Initialize IRT to a conservative default
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    m_irt[k] = float(window)

    # Add to probation LRU as MRU
    _lru_remove(k)      # ensure uniqueness
    _lru_add(0, k)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata
      - Retain TinyLFU counters across evictions
      - Maintain protected-bytes accounting
      - Remove from the appropriate LRU
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    # Adjust protected bytes if needed
    seg = _segment_of(ek)
    if seg == 1:
        global g_protected_bytes
        g_protected_bytes = max(0, g_protected_bytes - evicted_obj.size)

    # Remove from LRUs
    _lru_remove(ek)

    # Remove resident-only metadata (keep TinyLFU)
    m_last_access.pop(ek, None)
    m_prev_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_segment.pop(ek, None)
    m_irt.pop(ek, None)
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
```
2025-11-28 01:06:30,031 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 9
- Hit Rate: 0.531

Example 2:
- Trace ID: 7
- Hit Rate: 0.4145

Example 3:
- Trace ID: 22
- Hit Rate: 0.06

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m01:06:30 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 01:06:30,032 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m01:09:47 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 01:09:47,619 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 01:09:47,621 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Adaptive Windowed TinyLFU with Size and Recency (AW-TinyLFR)
# - Two implicit regions:
#     window (recency-protected, good for bursts)
#     main   (frequency/size-aware, good for steady reuse)
# - TinyLFU frequency via lazy-epoch 4-bit counters
# - Adaptive target for window size using ARC-like ghost feedback
# - Size-aware benefit with stronger penalty in window (discourage one-hit large objects)
# - Recency plays strong role in window, light role in main
# - Staleness penalty in main to evict long-idle items despite past frequency
# - Region pressure steers evictions to keep window near adaptive target
# - O(n) victim scan with robust tie-breaking

import math
from collections import OrderedDict

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()    # key -> int access_count (LRU timestamp)
m_resident_hits = dict()  # key -> int resident hit count (>=1 once inserted)
m_region = dict()         # key -> 0(window) or 1(main)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()      # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0

# Adaptive window ghosts (ARC-like)
m_ghost_recent = OrderedDict()  # keys recently evicted from window
m_ghost_freq = OrderedDict()    # keys recently evicted from main
m_ghost_cap_keys = 2048         # max entries across each ghost list (keys, not bytes)

# Target window ratio (bytes) adapted using ghost hits
WIN_MIN_RATIO = 0.05
WIN_MAX_RATIO = 0.80
m_win_ratio = 0.20  # start with 20% of capacity for window (by bytes)

# -----------------------------
# Tunables
# -----------------------------

# TinyLFU decay (smaller -> adapts faster)
LFU_DECAY_INTERVAL = 4096  # access-counts per epoch (power of two recommended)

# Recency windows (in access-counts), per region
REC_WIN_MIN_WIN = 128
REC_WIN_MULT_WIN = 2       # ~2 * window_items

REC_WIN_MIN_MAIN = 1000
REC_WIN_MULT_MAIN = 8      # ~8 * total_items

# Recency weights
REC_WEIGHT_WIN = 0.60
REC_WEIGHT_MAIN = 0.15

# Size penalty exponents (benefit /= size_norm ** exp)
WIN_SIZE_EXP = 1.35
MAIN_SIZE_EXP = 1.05

# Extra boost for multi-hit residents
MULTI_HIT_BONUS = 0.50

# Staleness penalty in main (penalize very old items despite freq)
STALE_PENALTY_WEIGHT = 0.30
STALE_AGE_START = 0.85  # normalized age beyond which staleness applies

# Region pressure to steer evictions toward/away from window to meet target
PRESSURE_WEIGHT = 0.20   # magnitude of pressure adjustment

# Normalization guards
SIZE_NORM_MIN = 0.05     # minimum percent-of-capacity used for normalization


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch advance, no sweeping


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift > 0:
        c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)  # 4-bit saturating
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Ghost helpers (ARC-style adapt)
# -----------------------------

def _ghost_touch(ghost, key):
    # Return True if key was present and moved to MRU; else False
    if key in ghost:
        ghost.move_to_end(key, last=True)
        return True
    return False


def _ghost_add(ghost, key, now, cap):
    # Insert/move to MRU, enforce capacity
    ghost[key] = now
    ghost.move_to_end(key, last=True)
    while len(ghost) > cap:
        ghost.popitem(last=False)  # evict LRU from ghost


def _adapt_window_ratio(on_recent_ghost_reuse, on_freq_ghost_reuse):
    global m_win_ratio
    # ARC-like step: larger adjustment when opposite ghost is larger
    b1 = len(m_ghost_recent)
    b2 = len(m_ghost_freq)
    # Base step
    base = 0.02
    # Proportional scaling within [base, 5*base]
    scale_up = min(5.0, 1.0 + (b2 / float(max(1, b1))))
    scale_dn = min(5.0, 1.0 + (b1 / float(max(1, b2))))

    if on_recent_ghost_reuse:
        m_win_ratio = min(WIN_MAX_RATIO, m_win_ratio + base * scale_up)
    elif on_freq_ghost_reuse:
        m_win_ratio = max(WIN_MIN_RATIO, m_win_ratio - base * scale_dn)


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size_percent(size, capacity):
    # Percent of capacity (0..100]. Guard to avoid extreme blow-ups
    pn = (float(size) * 100.0) / float(max(1, capacity))
    return max(SIZE_NORM_MIN, pn)


def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    if window <= 0:
        return 1.0
    return min(1.0, float(age) / float(window))


def _compute_region_pressure(cache_snapshot, window_bytes):
    cap = max(1, cache_snapshot.capacity)
    tgt_bytes = max(1.0, m_win_ratio * cap)
    # Positive deviation means window over target
    deviation = (float(window_bytes) - tgt_bytes) / tgt_bytes
    # Clamp to [-1, 1] to avoid runaway
    deviation = max(-1.0, min(1.0, deviation))
    # Window items get negative adjust when over target (easier to evict),
    # protection when under target (positive).
    press_win = -PRESSURE_WEIGHT * deviation
    # Main gets opposite effect
    press_main = +PRESSURE_WEIGHT * deviation
    return press_win, press_main


def _region_of(k):
    # Default region for unknown metadata: window if only 1 hit so far, else main
    rh = m_resident_hits.get(k, 1)
    return m_region.get(k, 0 if rh <= 1 else 1)


def _retention_score_for_key(cache_snapshot, key, now, n_items, win_items,
                             window_bytes, press_win, press_main):
    obj = cache_snapshot.cache.get(key)
    if obj is None:
        return float('-inf'), -1  # should not happen

    cap = cache_snapshot.capacity
    size = obj.size
    size_norm = _normalized_size_percent(size, cap)

    reg = _region_of(key)
    freq = _lfu_peek(cache_snapshot, key)
    base = math.log2(1.0 + float(freq))
    if m_resident_hits.get(key, 1) >= 2:
        base += MULTI_HIT_BONUS

    if reg == 0:
        # Window: strong recency, stronger size penalty
        benefit = base / pow(size_norm, WIN_SIZE_EXP)
        win_len = max(REC_WIN_MIN_WIN, REC_WIN_MULT_WIN * max(1, win_items))
        a_norm = _recency_normalized(now, m_last_access.get(key), win_len)
        rec_gain = REC_WEIGHT_WIN * (1.0 - a_norm)
        stale_pen = 0.0
        pressure = press_win
    else:
        # Main: frequency and size dominate, light recency, staleness penalty if very old
        benefit = base / pow(size_norm, MAIN_SIZE_EXP)
        main_len = max(REC_WIN_MIN_MAIN, REC_WIN_MULT_MAIN * max(1, n_items))
        a_norm = _recency_normalized(now, m_last_access.get(key), main_len)
        rec_gain = REC_WEIGHT_MAIN * (1.0 - a_norm)
        stale_pen = STALE_PENALTY_WEIGHT * max(0.0, a_norm - STALE_AGE_START)
        pressure = press_main

    # Lower score = weaker retention = more likely eviction
    score = (benefit - rec_gain - stale_pen) + pressure
    last = m_last_access.get(key, -1)
    return score, last


# -----------------------------
# Initialization
# -----------------------------

def _init_if_needed(cache_snapshot):
    # Maintain LFU epoch
    _lfu_maybe_advance_epoch(cache_snapshot)
    # Adapt ghosts capacity to current resident size
    global m_ghost_cap_keys
    n = max(1, len(cache_snapshot.cache))
    # Ghosts up to ~4x residents, but no less than 1024
    m_ghost_cap_keys = max(1024, 4 * n)
    # Trim if needed
    while len(m_ghost_recent) > m_ghost_cap_keys:
        m_ghost_recent.popitem(last=False)
    while len(m_ghost_freq) > m_ghost_cap_keys:
        m_ghost_freq.popitem(last=False)
    # Clamp window ratio
    global m_win_ratio
    m_win_ratio = min(WIN_MAX_RATIO, max(WIN_MIN_RATIO, m_win_ratio))


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Evict the resident key with the smallest AW-TinyLFR retention score.
    Ties are broken by oldest last-access time.
    """
    _init_if_needed(cache_snapshot)

    now = cache_snapshot.access_count
    n_items = max(1, len(cache_snapshot.cache))

    # Compute window stats in a single pass
    win_items = 0
    window_bytes = 0
    for k in cache_snapshot.cache.keys():
        if _region_of(k) == 0:
            win_items += 1
            ok = cache_snapshot.cache.get(k)
            if ok is not None:
                window_bytes += ok.size

    press_win, press_main = _compute_region_pressure(cache_snapshot, window_bytes)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score, last = _retention_score_for_key(
            cache_snapshot, k, now, n_items, win_items, window_bytes, press_win, press_main
        )
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
      - Promote from window -> main on second resident hit
    """
    _init_if_needed(cache_snapshot)
    k = obj.key

    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count

    rh = m_resident_hits.get(k, 1) + 1
    m_resident_hits[k] = rh

    # Promote to main upon second hit
    if m_region.get(k, 0) == 0 and rh >= 2:
        m_region[k] = 1


def update_after_insert(cache_snapshot, obj):
    """
    On insert (after a miss):
      - Count the access in TinyLFU
      - Initialize resident metadata: last_access, resident_hits = 1, region=window
      - If the key matches a ghost, adapt window target ratio (ARC-like)
    """
    _init_if_needed(cache_snapshot)
    k = obj.key

    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1
    m_region[k] = 0  # start in window

    # Ghost feedback: adapt window target if this was a re-reference
    recent_hit = _ghost_touch(m_ghost_recent, k)
    freq_hit = False
    if not recent_hit:
        freq_hit = _ghost_touch(m_ghost_freq, k)
    # Remove from ghosts once (re)admitted
    if recent_hit:
        try:
            del m_ghost_recent[k]
        except KeyError:
            pass
    if freq_hit:
        try:
            del m_ghost_freq[k]
        except KeyError:
            pass
    _adapt_window_ratio(on_recent_ghost_reuse=recent_hit, on_freq_ghost_reuse=freq_hit)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata (keep TinyLFU counts)
      - Insert the evicted key into the appropriate ghost list to inform adaptation
    """
    _init_if_needed(cache_snapshot)
    ek = evicted_obj.key
    now = cache_snapshot.access_count

    # Determine which region it belonged to (default window if unknown)
    reg = m_region.pop(ek, 0)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Retain TinyLFU counts across evictions

    # Add to ghosts
    if reg == 0:
        _ghost_add(m_ghost_recent, ek, now, m_ghost_cap_keys)
    else:
        _ghost_add(m_ghost_freq, ek, now, m_ghost_cap_keys)
```
2025-11-28 01:09:53,296 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# SLRU + TinyLFU + Size-aware sampled eviction (fast and high hit-rate)
# - Two resident segments with byte quotas:
#     Probation (new/once-hit) and Protected (multi-hit)
# - O(1) updates on hit/insert via OrderedDict LRU queues
# - Eviction chooses from Probation first (SLRU), falls back to Protected
# - Within the chosen segment, select victim by sampling a few oldest keys
#   and picking the smallest TinyLFU-Recency-Size score (no full scan)
# - TinyLFU sketch with lazy epoch decay (4-bit counters) tracks popularity
# - Metadata survives evictions where useful (TinyLFU); resident-only info removed

import math
from collections import OrderedDict

# -----------------------------
# Global metadata
# -----------------------------

# Segmented LRU structures (byte-aware)
PROTECTED_RATIO = 0.80        # fraction of capacity reserved for Protected
SAMPLE_K_PROB = 6             # candidates sampled from Probation on eviction
SAMPLE_K_PROT = 4             # candidates sampled from Protected on eviction

prob_lru = OrderedDict()      # key -> None (LRU on left, MRU on right)
prot_lru = OrderedDict()      # key -> None
seg_bytes_prob = 0            # total bytes in Probation
seg_bytes_prot = 0            # total bytes in Protected
m_segment = dict()            # key -> 0 (probation) or 1 (protected)

# Per-key resident metadata
m_last_access = dict()        # key -> int time (for recency scoring)
m_resident_hits = dict()      # key -> int (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()          # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Scoring tunables (robust defaults)
REC_WIN_MIN = 1000
REC_WIN_MULT = 4
REC_WEIGHT = 0.25
MULTI_HIT_BONUS = 0.35

# -----------------------------
# Init / TinyLFU helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    _lfu_maybe_advance_epoch(cache_snapshot)

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Segment helpers
# -----------------------------

def _prot_target_bytes(cache_snapshot):
    try:
        return max(0, int(cache_snapshot.capacity * PROTECTED_RATIO))
    except Exception:
        return 0

def _seg_insert_prob(key, size):
    global seg_bytes_prob
    if m_segment.get(key) == 0:
        # refresh MRU
        prob_lru.pop(key, None)
        prob_lru[key] = None
        return
    if m_segment.get(key) == 1:
        # remove from protected first (shouldn't happen on insert)
        prot_lru.pop(key, None)
        global seg_bytes_prot
        seg_bytes_prot -= size
    m_segment[key] = 0
    prob_lru[key] = None
    seg_bytes_prob += size

def _seg_move_to_prot(cache_snapshot, key, size):
    # Move key to Protected MRU
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 1:
        # already in protected: refresh MRU
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    # remove from probation if present
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    # insert into protected
    m_segment[key] = 1
    prot_lru[key] = None
    seg_bytes_prot += size

    # Demote from protected to probation if protected exceeds target
    target = _prot_target_bytes(cache_snapshot)
    while seg_bytes_prot > target and prot_lru:
        # Demote LRU of protected into probation MRU (not evict)
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        seg_bytes_prot -= dsize

        # place into probation MRU if still resident
        if robj is not None:
            prob_lru[dem_key] = None
            seg_bytes_prob += dsize
            m_segment[dem_key] = 0
        else:
            m_segment.pop(dem_key, None)  # no longer resident; clean

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _seg_remove(cache_snapshot, key, size):
    global seg_bytes_prob, seg_bytes_prot
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 1:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        # unknown; ensure not lingering
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _retention_score(cache_snapshot, key):
    # Lower score -> weaker retention -> better eviction candidate
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    return benefit - recency_gain

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    # Iterate the oldest k_sample keys in 'order' and return the min-score key
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    # Fallback in case of issues
    if chosen_key is None:
        try:
            return next(iter(order))
        except StopIteration:
            return None
    return chosen_key

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Evict using SLRU: choose from Probation first; if empty, from Protected.
    Within the chosen segment, sample a few LRU-ordered keys and evict the
    one with the smallest TinyLFU-Recency-Size score.
    """
    _init_if_needed(cache_snapshot)

    # Prefer evicting from Probation (new/weak items)
    if prob_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
        return victim

    # Fall back to Protected if Probation empty
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)
        return victim

    # As a last resort, evict any key
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access time and resident hit count
      - Promote from Probation to Protected (SLRU) on first hit
      - Refresh LRU position within its segment
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked (shouldn't happen on a hit); insert into Probation
        _seg_insert_prob(k, obj.size)
        return

    if seg == 0:
        # Promote on first hit (classic SLRU)
        _seg_move_to_prot(cache_snapshot, k, obj.size)
    else:
        # Touch protected
        _seg_touch_on_hit(cache_snapshot, k)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU counter
      - Initialize resident metadata
      - Place into Probation MRU
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # New resident goes to Probation MRU
    _seg_insert_prob(k, obj.size)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove resident-only metadata and from segment structures
      - Keep TinyLFU counters to remember popularity of non-residents
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    _seg_remove(cache_snapshot, ek, evicted_obj.size)

    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Keep m_lfu_count[ek] for future admission/eviction decisions
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 46
- Hit Rate: 0.4663

Example 2:
- Trace ID: 41
- Hit Rate: 0.1777

Example 3:
- Trace ID: 33
- Hit Rate: 0.7606

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m01:09:53 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 01:09:53,297 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m01:13:39 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 01:13:39,238 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 01:13:39,239 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Windowed SLRU + TinyLFU + ARC-style adaptive protected target + size-aware sampled eviction
# - Three resident segments with byte quotas: Window (recency), Probation (main-new), Protected (main-hot)
# - Adaptive target for Protected vs Probation (ARC ghosts) for balancing recency vs frequency
# - O(1) LRU queues via OrderedDict for each segment
# - Eviction priority: trim Window if above target; else Probation (sampled scoring); fallback to Protected
# - Within sampled segment, pick min TinyLFU-Recency-Size score (small, fast sample; adaptive for large inserts)
# - TinyLFU with lazy epoch decay (4-bit counters) tracks popularity; metadata persists across evictions
# - Resident-only metadata removed on eviction; ghosts maintained and bounded to guide adaptation

import math
from collections import OrderedDict

# -----------------------------
# Global metadata
# -----------------------------

# Ratios and sampling tunables
WINDOW_RATIO = 0.10              # fraction of capacity reserved for Window (recency)
PROTECTED_RATIO_INIT = 0.75      # fraction of main (capacity - window) initially for Protected
SAMPLE_K_PROB_BASE = 6
SAMPLE_K_PROT_BASE = 4
SAMPLE_K_LARGE_BOOST = 8         # extra samples if incoming obj is large
LARGE_OBJ_THRESH_FRAC = 0.05     # >=5% of capacity considered large

# ARC-style adaptation step (~2% of capacity, min-safe)
ADAPT_STEP_FRAC = 0.02

# Segment LRU structures (byte-aware)
#   segment codes: 2 = Window, 0 = Probation, 1 = Protected
win_lru = OrderedDict()          # key -> None (LRU on left, MRU on right)
prob_lru = OrderedDict()
prot_lru = OrderedDict()
seg_bytes_win = 0
seg_bytes_prob = 0
seg_bytes_prot = 0
m_segment = dict()               # key -> 2 (window) / 0 (probation) / 1 (protected)

# Per-key resident metadata
m_last_access = dict()           # key -> int time
m_resident_hits = dict()         # key -> int (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()             # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Ghost lists for ARC-style adaptation (remember non-resident keys)
ghost_prob = OrderedDict()       # keys evicted from Probation/Window (recency-biased)
ghost_prot = OrderedDict()       # keys evicted from Protected (frequency-biased)

# Adaptive protected target (bytes)
g_prot_target_bytes = None

# Scoring tunables (robust defaults)
REC_WIN_MIN = 1000
REC_WIN_MULT = 4
REC_WEIGHT = 0.25
MULTI_HIT_BONUS = 0.35

# -----------------------------
# TinyLFU helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    global g_prot_target_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    # Initialize adaptive protected target lazily
    if g_prot_target_bytes is None:
        cap = int(getattr(cache_snapshot, 'capacity', 0) or 0)
        w = _win_target_bytes(cache_snapshot)
        main = max(0, cap - w)
        g_prot_target_bytes = int(main * PROTECTED_RATIO_INIT)

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Targets and adaptation
# -----------------------------

def _win_target_bytes(cache_snapshot):
    try:
        return max(0, int(cache_snapshot.capacity * WINDOW_RATIO))
    except Exception:
        return 0

def _prot_target_bytes(cache_snapshot):
    # Clamp protected target within [0, main_bytes]
    cap = int(getattr(cache_snapshot, 'capacity', 0) or 0)
    win = _win_target_bytes(cache_snapshot)
    main = max(0, cap - win)
    pt = int(g_prot_target_bytes or 0)
    if pt < 0:
        pt = 0
    if pt > main:
        pt = main
    return pt

def _adapt_step_bytes(cache_snapshot):
    cap = int(getattr(cache_snapshot, 'capacity', 0) or 0)
    step = max(1, int(cap * ADAPT_STEP_FRAC))
    return step

def _adjust_prot_target(cache_snapshot, delta_bytes):
    global g_prot_target_bytes
    if g_prot_target_bytes is None:
        _init_if_needed(cache_snapshot)
    g_prot_target_bytes = max(0, int(g_prot_target_bytes + delta_bytes))
    # clamp later via _prot_target_bytes when used

def _ghost_max_items(cache_snapshot):
    # Bound each ghost to at most 2x current resident item count (cheap)
    n = max(1, len(getattr(cache_snapshot, 'cache', {}) or {}))
    return 2 * n

# -----------------------------
# Segment helpers
# -----------------------------

def _seg_insert_window(key, size):
    global seg_bytes_win, seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 2:
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
        else:
            win_lru[key] = None
        return
    # Remove from other segments if present
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 1:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        # ensure not lingering
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)
    # Insert into Window MRU
    m_segment[key] = 2
    win_lru[key] = None
    seg_bytes_win += size

def _seg_insert_prob(key, size):
    global seg_bytes_prob, seg_bytes_win, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 0:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    # Remove from other segments
    if seg == 2:
        if key in win_lru:
            win_lru.pop(key, None)
            seg_bytes_win -= size
    elif seg == 1:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        win_lru.pop(key, None)
        prot_lru.pop(key, None)
    # Insert into Probation MRU
    m_segment[key] = 0
    prob_lru[key] = None
    seg_bytes_prob += size

def _seg_move_to_prot(cache_snapshot, key, size):
    # Move key to Protected MRU; source may be Window or Probation
    global seg_bytes_win, seg_bytes_prob, seg_bytes_prot
    seg = m_segment.get(key)
    if seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 2:
        if key in win_lru:
            win_lru.pop(key, None)
            seg_bytes_win -= size
    else:
        win_lru.pop(key, None)
        prob_lru.pop(key, None)
    # Insert into Protected MRU
    m_segment[key] = 1
    prot_lru[key] = None
    seg_bytes_prot += size
    # Ensure Protected does not exceed its target; demote LRU to Probation
    _ensure_prot_within_target(cache_snapshot)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 2:
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
    elif seg == 0:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _seg_remove(cache_snapshot, key, size):
    global seg_bytes_win, seg_bytes_prob, seg_bytes_prot
    seg = m_segment.pop(key, None)
    if seg == 2:
        if key in win_lru:
            win_lru.pop(key, None)
            seg_bytes_win -= size
    elif seg == 0:
        if key in prob_lru:
            prob_lru.pop(key, None)
            seg_bytes_prob -= size
    elif seg == 1:
        if key in prot_lru:
            prot_lru.pop(key, None)
            seg_bytes_prot -= size
    else:
        win_lru.pop(key, None)
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)

def _ensure_prot_within_target(cache_snapshot):
    # Demote Protected LRU into Probation until within target
    global seg_bytes_prot, seg_bytes_prob
    target = _prot_target_bytes(cache_snapshot)
    while seg_bytes_prot > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        seg_bytes_prot -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            seg_bytes_prob += dsize
            m_segment[dem_key] = 0
        else:
            m_segment.pop(dem_key, None)

# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale to [0, inf), avoid zero
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _retention_score(cache_snapshot, key):
    # Lower score -> weaker retention -> better eviction candidate
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size

    freq = _lfu_peek(cache_snapshot, key)
    extra = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_penalty = REC_WEIGHT * a_norm  # higher age -> higher penalty

    return benefit - recency_penalty

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    # Iterate the oldest k_sample keys in 'order' and return the min-score key
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            return next(iter(order))
        except StopIteration:
            return None
    return chosen_key

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    """
    Evict with Windowed SLRU priority:
      1) If Window exceeds its byte target, evict Window LRU (pure recency).
      2) Else evict from Probation using TinyLFU-Recency-Size sampled scoring.
      3) If Probation empty, fall back to Window LRU; else Protected with sampling.
    Adaptive sampling: boost sample size for large incoming objects.
    """
    _init_if_needed(cache_snapshot)

    # Keep protected within target by demoting to probation (does not free space)
    _ensure_prot_within_target(cache_snapshot)

    cap = cache_snapshot.capacity
    win_target = _win_target_bytes(cache_snapshot)

    # Adaptive sampling boost for large inserts
    large_boost = 0
    try:
        if obj is not None and cap > 0 and (float(obj.size) / float(cap)) >= LARGE_OBJ_THRESH_FRAC:
            large_boost = SAMPLE_K_LARGE_BOOST
    except Exception:
        large_boost = 0

    # 1) If Window is above target, evict from Window LRU
    if win_lru and seg_bytes_win > win_target:
        try:
            return next(iter(win_lru))  # oldest in Window
        except StopIteration:
            pass

    # 2) Prefer evicting from Probation (new/weak items)
    if prob_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB_BASE + large_boost)
        return victim

    # 3) If Probation empty, try Window before Protected (maintain hot set)
    if win_lru:
        try:
            return next(iter(win_lru))  # oldest in Window
        except StopIteration:
            pass

    # 4) Fall back to Protected if necessary
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT_BASE + (large_boost // 2))
        return victim

    # Last resort: any key
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access time and resident hit count
      - If in Window, promote to Protected on second hit
      - If in Probation, promote to Protected (SLRU)
      - Refresh LRU position within its segment
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = min(255, m_resident_hits.get(k, 1) + 1)  # saturate a bit

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked (rare): insert into Window to recover
        _seg_insert_window(k, obj.size)
        return

    if seg == 2:
        # Promote from Window to Protected on second hit
        if m_resident_hits.get(k, 1) >= 2:
            _seg_move_to_prot(cache_snapshot, k, obj.size)
        else:
            _seg_touch_on_hit(cache_snapshot, k)
    elif seg == 0:
        # Classic SLRU: first hit -> Protected
        _seg_move_to_prot(cache_snapshot, k, obj.size)
    else:
        # Protected touch
        _seg_touch_on_hit(cache_snapshot, k)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU counter
      - Initialize resident metadata
      - ARC-style adaptation using ghost lists:
          * If key in ghost_prob (recency-ghost), decrease Protected target (favor recency)
          * If key in ghost_prot (frequency-ghost), increase Protected target (favor frequency)
      - Place into Window MRU (recency segment)
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # ARC-style adaptation
    step = _adapt_step_bytes(cache_snapshot)
    if k in ghost_prob:
        _adjust_prot_target(cache_snapshot, -step)  # favor recency (more Probation)
        try:
            ghost_prob.pop(k, None)
        except Exception:
            pass
    if k in ghost_prot:
        _adjust_prot_target(cache_snapshot, +step)  # favor frequency (more Protected)
        try:
            ghost_prot.pop(k, None)
        except Exception:
            pass

    # New resident goes to Window MRU
    _seg_insert_window(k, obj.size)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Add key to appropriate ghost list (bounded) to guide adaptation
      - Remove resident-only metadata and from segment structures
      - Keep TinyLFU counters to remember popularity of non-residents
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Capture segment before removal
    seg = m_segment.get(ek)

    # Remove from resident structures
    _seg_remove(cache_snapshot, ek, evicted_obj.size)

    # Update ghosts (Window and Probation -> recency-ghost; Protected -> frequency-ghost)
    try:
        if seg == 1:
            ghost_prot[ek] = None
            ghost_prot.move_to_end(ek, last=True)
            # Bound ghost_prot
            while len(ghost_prot) > _ghost_max_items(cache_snapshot):
                ghost_prot.popitem(last=False)
        else:
            # Treat seg==2 (Window) and seg==0 (Probation) as recency-ghost
            ghost_prob[ek] = None
            ghost_prob.move_to_end(ek, last=True)
            # Bound ghost_prob
            while len(ghost_prob) > _ghost_max_items(cache_snapshot):
                ghost_prob.popitem(last=False)
    except Exception:
        pass

    # Drop resident-only metadata
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Keep TinyLFU m_lfu_count[ek] for future decisions
```
2025-11-28 01:14:00,718 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 32
- Hit Rate: 0.0878

Example 2:
- Trace ID: 46
- Hit Rate: 0.4663

Example 3:
- Trace ID: 14
- Hit Rate: 0.0228

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m01:14:00 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 01:14:00,719 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m01:17:05 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 01:17:05,238 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 01:17:05,240 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# ARC-bytes with TinyLFU doorkeeper (ATLRU)
# - Two resident segments (ARC-style):
#     T1: Recently inserted (probationary)
#     T2: Frequently/reused (protected)
#   Eviction prefers T1 unless T1 is at/beyond target p (in bytes),
#   or the incoming key is in B2 (frequent ghost), then evict from T1; else from T2.
# - Two ghost lists store metadata of recently evicted items:
#     B1: Ghosts from T1 (recently used)
#     B2: Ghosts from T2 (frequently used)
#   Ghost hits adapt p (target bytes for T1): B1 hit -> increase p; B2 hit -> decrease p.
# - Size aware (all limits and adaptation are in bytes).
# - TinyLFU 4-bit, lazy-decayed counters act as a doorkeeper to immediately place hot items into T2 on insert.
# - LRU within each segment: eviction picks the oldest by last-access time in the chosen segment.
# - Metadata retained across evictions:
#     - TinyLFU counters for all keys
#     - Ghost entries (bounded by capacity) to adapt across phases

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key segment membership for resident keys: 'T1' or 'T2'
m_seg = dict()             # key -> 'T1' | 'T2'

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count timestamp
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# Resident byte sizes by segment
m_T1_bytes = 0
m_T2_bytes = 0

# ARC target for T1 in bytes (adapted online via ghost hits)
m_p_bytes = 0

# Ghost lists (non-resident metadata) with simple LRU via timestamp
# key -> (last_access_time:int, size:int)
m_B1 = dict()  # evicted from T1 (recency ghosts)
m_B2 = dict()  # evicted from T2 (frequency ghosts)
m_B1_bytes = 0
m_B2_bytes = 0

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # accesses per epoch (power of two recommended)

# Doorkeeper threshold: if decayed TinyLFU >= this on insert, place into T2
DOORKEEPER_FREQ = 2

# Ghost capacity factor (each ghost list is capped to this many bytes)
GHOST_CAP_MULT = 1.0  # each of B1 and B2 is limited to capacity bytes

# Reset detection across runs (if simulator reuses module)
_last_seen_access = -1
_last_seen_capacity = -1


# -----------------------------
# Helpers: reset/init
# -----------------------------

def _reset_all():
    global m_seg, m_last_access, m_resident_hits
    global m_T1_bytes, m_T2_bytes, m_p_bytes
    global m_B1, m_B2, m_B1_bytes, m_B2_bytes
    global m_lfu_count, m_lfu_epoch
    global _last_seen_access, _last_seen_capacity

    m_seg = dict()
    m_last_access = dict()
    m_resident_hits = dict()

    m_T1_bytes = 0
    m_T2_bytes = 0
    m_p_bytes = 0

    m_B1 = dict()
    m_B2 = dict()
    m_B1_bytes = 0
    m_B2_bytes = 0

    m_lfu_count = dict()
    m_lfu_epoch = 0

    _last_seen_access = -1
    _last_seen_capacity = -1


def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur


def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift


def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


def _init_if_needed(cache_snapshot):
    global _last_seen_access, _last_seen_capacity, m_p_bytes
    # Detect a new run or capacity change and reset if needed
    if _last_seen_access != -1 and cache_snapshot.access_count < _last_seen_access:
        _reset_all()
    if _last_seen_capacity != -1 and cache_snapshot.capacity != _last_seen_capacity:
        _reset_all()

    _last_seen_access = cache_snapshot.access_count
    _last_seen_capacity = cache_snapshot.capacity

    # Ensure TinyLFU epoch is current
    _lfu_maybe_advance_epoch(cache_snapshot)

    # Initialize p to a reasonable default if zero (warmup)
    if m_p_bytes <= 0:
        m_p_bytes = max(0, min(cache_snapshot.capacity // 2, cache_snapshot.capacity))


# -----------------------------
# Ghost list maintenance
# -----------------------------

def _ghost_limit(cache_snapshot):
    # Each ghost list up to capacity * GHOST_CAP_MULT bytes
    return int(cache_snapshot.capacity * GHOST_CAP_MULT)


def _ghost_add_B1(cache_snapshot, key, time, size):
    global m_B1_bytes
    prev = m_B1.get(key)
    if prev is not None:
        # Replace time/size (size likely same as when evicted)
        old_t, old_s = prev
        m_B1_bytes -= old_s
    m_B1[key] = (time, size)
    m_B1_bytes += size
    _ghost_trim_B1(cache_snapshot)


def _ghost_add_B2(cache_snapshot, key, time, size):
    global m_B2_bytes
    prev = m_B2.get(key)
    if prev is not None:
        old_t, old_s = prev
        m_B2_bytes -= old_s
    m_B2[key] = (time, size)
    m_B2_bytes += size
    _ghost_trim_B2(cache_snapshot)


def _ghost_trim_B1(cache_snapshot):
    global m_B1_bytes
    limit = _ghost_limit(cache_snapshot)
    while m_B1_bytes > limit and m_B1:
        # Remove oldest by time
        old_key, (old_t, old_s) = min(m_B1.items(), key=lambda kv: kv[1][0])
        m_B1.pop(old_key, None)
        m_B1_bytes -= old_s


def _ghost_trim_B2(cache_snapshot):
    global m_B2_bytes
    limit = _ghost_limit(cache_snapshot)
    while m_B2_bytes > limit and m_B2:
        old_key, (old_t, old_s) = min(m_B2.items(), key=lambda kv: kv[1][0])
        m_B2.pop(old_key, None)
        m_B2_bytes -= old_s


# -----------------------------
# Segment helpers
# -----------------------------

def _ensure_resident_entry(cache_snapshot, key):
    # If a resident key is missing segment metadata, default it to T1
    # and fix sizes based on current object size.
    global m_T1_bytes, m_T2_bytes
    if key in m_seg:
        return
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return
    m_seg[key] = 'T1'
    m_T1_bytes += robj.size
    # Initialize a plausible access time if missing (treat as old)
    if key not in m_last_access:
        m_last_access[key] = cache_snapshot.access_count


def _replace_target_segment(cache_snapshot, incoming_key):
    # ARC Replace() rule, size-aware (bytes):
    # Evict from T1 if:
    #   - T1_bytes > p, or
    #   - T1_bytes == p and incoming_key in B2
    # Otherwise evict from T2.
    bT1 = m_T1_bytes
    bT2 = m_T2_bytes
    cap = cache_snapshot.capacity

    # If no residents, nothing to do
    if bT1 + bT2 == 0:
        return None

    if bT1 > m_p_bytes or (bT1 == m_p_bytes and incoming_key in m_B2):
        # If T1 empty due to metadata drift, fallback to T2
        if bT1 > 0:
            return 'T1'
        elif bT2 > 0:
            return 'T2'
        else:
            return None
    else:
        if bT2 > 0:
            return 'T2'
        elif bT1 > 0:
            return 'T1'
        else:
            return None


def _pick_lru_from_segment(cache_snapshot, segment):
    # Iterate resident keys and return the one with the oldest last_access in given segment
    min_key = None
    min_time = None
    # As a secondary tiebreaker, use smaller TinyLFU benefit (lower freq/byte)
    min_benefit = None
    cap = max(1, cache_snapshot.capacity)

    for k in cache_snapshot.cache.keys():
        _ensure_resident_entry(cache_snapshot, k)
        if m_seg.get(k) != segment:
            continue
        last = m_last_access.get(k, -1)
        # Benefit proxy: log2(1 + freq) / (size/capacity)
        robj = cache_snapshot.cache.get(k)
        if robj is None:
            continue
        size_norm = max(1e-9, float(robj.size) / float(cap))
        freq = _lfu_peek(cache_snapshot, k)
        benefit = math.log2(1.0 + float(freq)) / (size_norm + 1e-12)

        if (min_time is None) or (last < min_time) or (last == min_time and benefit < min_benefit):
            min_key = k
            min_time = last
            min_benefit = benefit

    return min_key


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    ARC-bytes eviction:
      - Choose segment to evict via Replace() rule (bytes-aware).
      - Evict the LRU within that segment.
      - Fallback to global LRU with TinyLFU benefit tiebreaker if needed.
    '''
    _init_if_needed(cache_snapshot)

    # Choose target segment based on ARC rule
    seg = _replace_target_segment(cache_snapshot, obj.key)
    victim = None
    if seg is not None:
        victim = _pick_lru_from_segment(cache_snapshot, seg)

    if victim is None:
        # Fallback: global oldest with TinyLFU benefit tiebreaker
        min_key = None
        min_time = None
        min_benefit = None
        cap = max(1, cache_snapshot.capacity)
        for k in cache_snapshot.cache.keys():
            _ensure_resident_entry(cache_snapshot, k)
            last = m_last_access.get(k, -1)
            robj = cache_snapshot.cache.get(k)
            if robj is None:
                continue
            size_norm = max(1e-9, float(robj.size) / float(cap))
            freq = _lfu_peek(cache_snapshot, k)
            benefit = math.log2(1.0 + float(freq)) / (size_norm + 1e-12)
            if (min_time is None) or (last < min_time) or (last == min_time and benefit < min_benefit):
                min_key = k
                min_time = last
                min_benefit = benefit
        victim = min_key

    if victim is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return victim


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Refresh last-access time
      - Promote to T2 if currently in T1 (ARC)
      - Track resident hit count
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    now = cache_snapshot.access_count
    m_last_access[k] = now

    seg = m_seg.get(k)
    if seg is None:
        # Fix-up if missing: assume T1
        _ensure_resident_entry(cache_snapshot, k)
        seg = m_seg.get(k)

    if seg == 'T1':
        # Move to T2
        global m_T1_bytes, m_T2_bytes
        m_seg[k] = 'T2'
        m_T1_bytes = max(0, m_T1_bytes - obj.size)
        m_T2_bytes += obj.size

    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter and update last-access time
      - ARC admission:
          * If key is in B1: increase p by size and admit to T2
          * If key is in B2: decrease p by size and admit to T2
          * Else: if TinyLFU >= DOORKEEPER_FREQ, admit to T2; otherwise to T1
      - Initialize resident metadata: resident_hits
      - Remove from ghost lists if present
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    now = cache_snapshot.access_count
    freq = _lfu_inc(cache_snapshot, k)
    m_last_access[k] = now

    global m_T1_bytes, m_T2_bytes, m_p_bytes, m_B1_bytes, m_B2_bytes

    in_B1 = k in m_B1
    in_B2 = k in m_B2

    if in_B1:
        m_p_bytes = min(cache_snapshot.capacity, m_p_bytes + obj.size)
        # Admit to T2
        m_seg[k] = 'T2'
        m_T2_bytes += obj.size
        # Remove from B1
        t, s = m_B1.pop(k)
        m_B1_bytes -= s
    elif in_B2:
        m_p_bytes = max(0, m_p_bytes - obj.size)
        # Admit to T2
        m_seg[k] = 'T2'
        m_T2_bytes += obj.size
        # Remove from B2
        t, s = m_B2.pop(k)
        m_B2_bytes -= s
    else:
        # Not in ghosts; use TinyLFU doorkeeper to optionally go straight to T2
        if freq >= DOORKEEPER_FREQ:
            m_seg[k] = 'T2'
            m_T2_bytes += obj.size
        else:
            m_seg[k] = 'T1'
            m_T1_bytes += obj.size

    # Initialize resident hit count (first resident access just happened)
    # If admitted to T2 directly, treat as multi-hit
    m_resident_hits[k] = 2 if m_seg[k] == 'T2' else 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Add evicted key to appropriate ghost list (B1 if from T1, else B2), with timestamp and size
      - Remove resident-only metadata and update segment sizes
      - Retain TinyLFU counters across evictions (for admission)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = evicted_obj.size
    etime = m_last_access.get(ek, cache_snapshot.access_count)

    seg = m_seg.pop(ek, None)

    # Update resident bytes
    global m_T1_bytes, m_T2_bytes
    if seg == 'T1':
        m_T1_bytes = max(0, m_T1_bytes - esize)
        _ghost_add_B1(cache_snapshot, ek, etime, esize)
    else:
        # Default evictions or 'T2' go to B2
        m_T2_bytes = max(0, m_T2_bytes - esize)
        _ghost_add_B2(cache_snapshot, ek, etime, esize)

    # Remove resident-only metadata
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    # Do NOT delete LFU counters; keep learning across evictions
```
2025-11-28 01:17:39,784 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 3
- Hit Rate: 0.4404

Example 2:
- Trace ID: 13
- Hit Rate: 0.0

Example 3:
- Trace ID: 9
- Hit Rate: 0.531

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m01:17:39 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 01:17:39,786 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m01:20:09 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 01:20:09,532 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 01:20:09,534 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Segmented GDSF with TinyLFU admission (SG-TinyLFU)
# - Two resident segments:
#     Probation (Q): recency-biased admission window (LRU by timestamp)
#     Protected (P): frequency- and size-aware using GreedyDual-Size-Frequency (GDSF)
# - TinyLFU sketch with lazy-decayed 4-bit counters (retained across evictions)
# - Eviction prefers the oldest in Probation; if Q is empty, evict the min-GDSF in Protected
# - On hit: Q -> promote to P; P -> refresh GDSF priority
# - On insert: admit to Q
# - On evict: remove resident-only metadata; keep TinyLFU counts
#
# Rationale:
#   - The small Q window captures bursty recency and avoids immediate self-thrashing
#   - P uses size-aware frequency density and GreedyDual aging to keep compact hot items
#   - TinyLFU filters noise and adapts quickly via lazy decay
#
# Expected benefits over the unified single-score approach:
#   - Far fewer "newbie" self-evictions (via Q-LRU)
#   - Better handling of skew with size-awareness and GD aging in P
#   - Robustness across traces due to separation of recency (Q) and frequency (P)

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Segment membership: 'Q' = probation, 'P' = protected
m_seg = dict()             # key -> 'Q' or 'P'
m_last_access = dict()     # key -> int access_count (for Q-LRU and general recency)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# Track bytes per segment (for accounting; eviction selection prefers Q first)
m_bytes_Q = 0
m_bytes_P = 0

# GreedyDual state for protected segment
m_gd_L = 0.0               # global aging floor
m_gd_H = dict()            # key -> current H priority used for eviction in P

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # accesses per epoch; power-of-two recommended

# Tunables
PROBATION_FRAC = 0.20      # fraction of capacity conceptually reserved as an admission window
ALPHA_SIZE = 1.0           # exponent for size normalization in GDSF (1.0 = divide by size)
MULTI_HIT_BONUS = 0.75     # extra TinyLFU "value" once item proves itself (>=2 resident hits)

# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

# -----------------------------
# Value / priority helpers
# -----------------------------

def _value_from_freq(freq, resident_hits):
    # Base value from frequency; extra value once item proves itself in-cache
    # Use log to tame heavy skew and improve generalization
    extra = MULTI_HIT_BONUS if resident_hits >= 2 else 0.0
    return math.log2(1.0 + float(freq)) + extra

def _gd_base_value(cache_snapshot, key, size_bytes):
    # Compute value density used by GDSF: v / size^alpha
    freq = _lfu_peek(cache_snapshot, key)
    rh = m_resident_hits.get(key, 1)
    v = _value_from_freq(freq, rh)
    denom = float(max(1, size_bytes)) ** ALPHA_SIZE
    return v / denom

def _gd_refresh_priority(cache_snapshot, key, size_bytes):
    # On accesses/promotions in P, set H = base_value + L
    base = _gd_base_value(cache_snapshot, key, size_bytes)
    H = base + m_gd_L
    m_gd_H[key] = H
    return H

# -----------------------------
# Internal selection helpers
# -----------------------------

def _oldest_in_Q(cache_snapshot):
    # Return (key, last_access) of the oldest resident in Q; None if empty
    oldest_key = None
    oldest_time = None
    for k in cache_snapshot.cache.keys():
        if m_seg.get(k) != 'Q':
            continue
        last = m_last_access.get(k, -1)
        if oldest_key is None or last < oldest_time:
            oldest_key = k
            oldest_time = last
    if oldest_key is None:
        return None
    return oldest_key, oldest_time

def _min_gdsf_in_P(cache_snapshot):
    # Return (key, H) with minimal GDSF priority in P; None if empty
    min_key = None
    min_H = None
    for k, obj in cache_snapshot.cache.items():
        if m_seg.get(k) != 'P':
            continue
        size = obj.size
        H = m_gd_H.get(k)
        if H is None:
            # Lazily initialize if missing
            H = _gd_refresh_priority(cache_snapshot, k, size)
        if (min_H is None) or (H < min_H):
            min_H = H
            min_key = k
    if min_key is None:
        return None
    return min_key, min_H

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict policy:
      1) Prefer evicting from the probation (Q) segment: oldest by last-access
      2) If Q is empty, evict from protected (P) by minimal GDSF priority (H)
         and advance the global aging floor L to the evicted H (classic GreedyDual)
    '''
    _lfu_maybe_advance_epoch(cache_snapshot)

    # 1) Oldest in Q
    q_choice = _oldest_in_Q(cache_snapshot)
    if q_choice is not None:
        victim_key, _ = q_choice
        return victim_key

    # 2) Min GDSF in P
    p_choice = _min_gdsf_in_P(cache_snapshot)
    if p_choice is not None:
        victim_key, victim_H = p_choice
        # Advance the global aging floor to the evicted H
        # This increases recency pressure as in GreedyDual
        global m_gd_L
        m_gd_L = float(victim_H)
        return victim_key

    # Fallback: no segmentation info; evict oldest across the cache
    # (should rarely happen)
    min_key = None
    min_time = None
    for k in cache_snapshot.cache.keys():
        last = m_last_access.get(k, -1)
        if (min_key is None) or (last < min_time):
            min_key = k
            min_time = last
    return min_key

def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Increment resident hit count
      - Refresh last-access time
      - If in Q: promote to P
      - If in P: refresh its GDSF priority (H = base + L)
    '''
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    size = obj.size

    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_seg.get(k)
    if seg == 'Q':
        # Promote to protected segment
        global m_bytes_Q, m_bytes_P
        m_seg[k] = 'P'
        # Adjust bytes accounting
        m_bytes_Q = max(0, m_bytes_Q - size)
        m_bytes_P += size
        # Initialize its GDSF priority on promotion
        _gd_refresh_priority(cache_snapshot, k, size)
    elif seg == 'P':
        # Refresh priority in protected segment
        _gd_refresh_priority(cache_snapshot, k, size)
    else:
        # Shouldn't happen: resident hit but no segment; default to P
        m_seg[k] = 'P'
        _gd_refresh_priority(cache_snapshot, k, size)

def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after miss is resolved by evictions):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
      - Admit into probation (Q)
    '''
    _lfu_maybe_advance_epoch(cache_snapshot)

    k = obj.key
    size = obj.size

    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # Admit new item into probation
    global m_bytes_Q
    m_seg[k] = 'Q'
    m_bytes_Q += size
    # Do not assign GDSF priority yet; only needed in P

def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After a resident is evicted:
      - Remove resident-only metadata (keep TinyLFU across evictions)
      - Adjust segment bytes accounting
      - Clear GDSF priority if any
    '''
    _lfu_maybe_advance_epoch(cache_snapshot)

    ek = evicted_obj.key
    esize = evicted_obj.size

    # Adjust bytes by segment membership
    seg = m_seg.pop(ek, None)
    global m_bytes_Q, m_bytes_P
    if seg == 'Q':
        m_bytes_Q = max(0, m_bytes_Q - esize)
    elif seg == 'P':
        m_bytes_P = max(0, m_bytes_P - esize)

    # Clear resident-only metadata
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
    m_gd_H.pop(ek, None)

    # Note: do NOT delete TinyLFU counters; they are admission memory
```
2025-11-28 01:20:48,580 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# TinyLFU-Recency-Size (TFRS) eviction
# - A single, unified priority that balances:
#     1) size-aware TinyLFU frequency (log2(1+freq) / normalized_size)
#     2) recency bonus (recently-accessed items are protected)
# - Decayed frequency via lazy-epoch 4-bit counters (no global sweep)
# - Eviction: scan resident keys and evict the one with the smallest retention score
#   score = benefit - recency_gain, where
#     benefit      = log2(1 + lfu_count) / (size * 100 / capacity)
#     recency_gain = REC_WEIGHT * (1 - min(1, age / window)), window ~= 4 * cache_items
# - On hit/insert: increment TinyLFU counter and refresh metadata
# - Items with multiple hits are slightly favored via a small boost to benefit

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()       # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192  # access-counts between epochs (power of two recommended)

# Tunables (empirically robust)
REC_WIN_MIN = 1000         # minimum recency window for normalization
REC_WIN_MULT = 4           # window ~ REC_WIN_MULT * resident_items
REC_WEIGHT = 0.25          # strength of recency bonus in retention score
MULTI_HIT_BONUS = 0.35     # extra benefit for items with >=2 resident hits

# Lazily initialize capacity-dependent values if needed
def _init_if_needed(cache_snapshot):
    # Nothing capacity-dependent cached globally; ensure epoch is consistent
    _lfu_maybe_advance_epoch(cache_snapshot)


# -----------------------------
# TinyLFU helpers (lazy decay)
# -----------------------------

def _current_epoch(cache_snapshot):
    # Simple epoch mapping from access_count to epoch
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL


def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed


def _lfu_peek(cache_snapshot, key):
    # Return decayed 4-bit counter without modifying stored epoch unless present
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    # Decay by right shifts; clamp to 0..15
    c >>= shift
    return c


def _lfu_inc(cache_snapshot, key):
    # Increment decayed count lazily and write back with current epoch
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c


# -----------------------------
# Scoring helpers
# -----------------------------

def _normalized_size(size, capacity):
    # Scale size to "percentage of capacity" to keep benefit in a stable range
    # Avoid division by zero; capacity > 0 by problem statement
    return max(1e-9, (float(size) * 100.0) / float(capacity))


def _recency_normalized(now, last, window):
    # age normalized to [0,1]; last may be missing -> treat as far in the past
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))


def _retention_score(cache_snapshot, key, obj):
    # Compute eviction score for a resident key: smaller -> more likely to evict
    # score = benefit - recency_gain
    # benefit      = log2(1 + freq) / normalized_size
    # recency_gain = REC_WEIGHT * (1 - normalized_age)
    now = cache_snapshot.access_count
    cap = cache_snapshot.capacity

    # Lookup resident object to get its size
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')  # should not happen; makes it never chosen
    size = robj.size

    # TinyLFU frequency
    freq = _lfu_peek(cache_snapshot, key)
    # Benefit favors multi-hit residents a bit more
    if m_resident_hits.get(key, 1) >= 2:
        extra = MULTI_HIT_BONUS
    else:
        extra = 0.0
    size_norm = _normalized_size(size, cap)
    benefit = (math.log2(1.0 + float(freq)) + extra) / size_norm

    # Recency gain protects recent items
    n_items = max(1, len(cache_snapshot.cache))
    window = max(REC_WIN_MIN, REC_WIN_MULT * n_items)
    last = m_last_access.get(key)
    a_norm = _recency_normalized(now, last, window)
    recency_gain = REC_WEIGHT * (1.0 - a_norm)

    # Lower score = weaker retention = better eviction candidate
    return benefit - recency_gain


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict the resident key with the smallest TinyLFU-Recency-Size retention score.
    Ties are broken by oldest last-access time.
    '''
    _init_if_needed(cache_snapshot)

    min_key = None
    min_score = None
    min_time = None

    for k in cache_snapshot.cache.keys():
        score = _retention_score(cache_snapshot, k, obj)
        last = m_last_access.get(k, -1)
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_score = score
            min_time = last
            min_key = k

    # Fallback: arbitrary key if none found (should not occur)
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter (counts every request)
      - Increment resident hit count
      - Refresh last-access time
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key
      - Initialize resident metadata: last_access, resident_hits = 1
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident-only metadata (TinyLFU counters are retained across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    # Do NOT delete m_lfu_count[ek]; TinyLFU must remember non-resident frequency
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 15
- Hit Rate: 0.0228

Example 2:
- Trace ID: 10
- Hit Rate: 0.1167

Example 3:
- Trace ID: 17
- Hit Rate: 0.0247

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m01:20:48 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 01:20:48,582 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m01:23:21 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 01:23:21,101 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 01:23:21,140 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# SLRU + TinyLFU + Size-aware + Ghost-adaptive (SLRUTinyLFUSz+)
# - Two resident segments: probation (new/once-hit) and protected (multi-hit)
# - TinyLFU sketch with lazy decay remembers non-resident popularity
# - Size-aware benefit: log2(1+freq) / normalized_size
# - Recency awareness with segment-dependent weights
# - Eviction prefers probation; if empty, falls back to protected
# - Admission-aware eviction: compares resident vs. candidate benefit
# - Ghost history: if a missed key was recently evicted, grow protected target
# - Adaptive protected target: up on ghost hits; down when protected items get evicted

import math

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_last_access = dict()     # key -> int access_count (LRU timestamp)
m_resident_hits = dict()   # key -> int resident hit count (>=1 once inserted)
m_seg = dict()             # key -> 0 probation, 1 protected

# Segment accounting (bytes)
m_prob_bytes = 0
m_prot_bytes = 0
m_protected_target_bytes = 0  # desired bytes in protected
m_last_capacity = None

# Ghost history (recently evicted keys)
m_ghost_ts = dict()         # key -> int last seen eviction time
m_ghost_order = []          # simple FIFO for trimming
GHOST_MAX = 50000           # cap ghost directory size

# TinyLFU sketch (lazy-decayed 4-bit counters)
m_lfu_count = dict()        # key -> (count:int[0..15], epoch:int)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192   # access-counts between epochs (power of two recomm.)

# Tunables (robust defaults)
REC_WIN_MIN = 256           # shorter base window improves short-term recency
REC_WIN_MULT = 4            # window ~ REC_WIN_MULT * resident_items
# Segment weights
PROB_SEG_BOOST = 0.65       # scales frequency benefit in probation
PROT_SEG_BOOST = 1.0        # scales frequency benefit in protected
PROB_REC_WEIGHT = 0.25      # recency contribution in probation
PROT_REC_WEIGHT = 0.55      # recency contribution in protected
# Candidate-aware delta weighting (resident benefit - candidate benefit)
DELTA_WEIGHT = 0.65

# Multi-hit bonus to frequency benefit
MULTI_HIT_BONUS = 0.35

# Protected target bounds and step
PROT_INIT_FRAC = 0.70       # initial protected target (% of capacity)
PROT_MIN_FRAC = 0.20
PROT_MAX_FRAC = 0.95
PROT_ADAPT_STEP_FRAC = 0.05 # fraction of capacity per adaptation step
PROT_ADAPT_STEP_MIN = 4096  # minimum bytes per adaptation step

# -----------------------------
# Helpers
# -----------------------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur  # lazy epoch; no sweeping needed

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    c >>= shift
    return c

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _normalized_size(size, capacity):
    # size as percent of capacity; keep in stable numeric range
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _recency_normalized(now, last, window):
    if last is None:
        return 1.0
    age = max(0, now - last)
    return 1.0 if window <= 0 else min(1.0, float(age) / float(window))

def _seg_of(key):
    # default unseen residents to probation
    return 0 if m_seg.get(key, 0) == 0 else 1

def _prot_bounds(capacity):
    lo = int(PROT_MIN_FRAC * capacity)
    hi = int(PROT_MAX_FRAC * capacity)
    return (lo, hi)

def _adapt_step(capacity):
    return max(PROT_ADAPT_STEP_MIN, int(PROT_ADAPT_STEP_FRAC * capacity))

def _clamp_prot_target(capacity):
    global m_protected_target_bytes
    lo, hi = _prot_bounds(capacity)
    if m_protected_target_bytes < lo:
        m_protected_target_bytes = lo
    elif m_protected_target_bytes > hi:
        m_protected_target_bytes = hi

def _recompute_segment_bytes(cache_snapshot):
    global m_prob_bytes, m_prot_bytes
    prob = 0
    prot = 0
    for k, robj in cache_snapshot.cache.items():
        if _seg_of(k) == 1:
            prot += robj.size
        else:
            prob += robj.size
    m_prob_bytes = prob
    m_prot_bytes = prot

def _init_if_needed(cache_snapshot):
    global m_last_capacity, m_protected_target_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = cache_snapshot.capacity
    if m_last_capacity != cap:
        m_last_capacity = cap
        # initialize protected target and recompute bytes
        m_protected_target_bytes = int(PROT_INIT_FRAC * cap)
        _clamp_prot_target(cap)
        _recompute_segment_bytes(cache_snapshot)

def _recency_window(cache_snapshot):
    n_items = max(1, len(cache_snapshot.cache))
    return max(REC_WIN_MIN, REC_WIN_MULT * n_items)

def _benefit(cache_snapshot, key, size, freq, resident_hits):
    size_norm = _normalized_size(size, cache_snapshot.capacity)
    bonus = MULTI_HIT_BONUS if resident_hits >= 2 else 0.0
    return (math.log2(1.0 + float(freq)) + bonus) / size_norm

def _keep_score(cache_snapshot, key, cand_benefit):
    now = cache_snapshot.access_count
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('inf'), -1  # shouldn't happen; make it very strong
    size = robj.size
    seg = _seg_of(key)
    last = m_last_access.get(key)
    freq = _lfu_peek(cache_snapshot, key)
    hits = m_resident_hits.get(key, 1)

    # base benefit
    res_ben = _benefit(cache_snapshot, key, size, freq, hits)

    # recency gain in [0,1], higher means more recent
    window = _recency_window(cache_snapshot)
    a_norm = _recency_normalized(now, last, window)
    rec_gain = 1.0 - a_norm

    # segment weighting
    seg_boost = PROT_SEG_BOOST if seg == 1 else PROB_SEG_BOOST
    rec_w = PROT_REC_WEIGHT if seg == 1 else PROB_REC_WEIGHT

    keep = seg_boost * res_ben + rec_w * rec_gain

    # admission-aware delta: if resident better than candidate -> raise keep
    # otherwise lower keep so it's easier to evict
    keep += DELTA_WEIGHT * (res_ben - cand_benefit)

    return keep, (last if last is not None else -1)

def _promote_to_protected(cache_snapshot, key):
    global m_prob_bytes, m_prot_bytes
    if _seg_of(key) == 1:
        return
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return
    size = robj.size
    m_seg[key] = 1
    m_prob_bytes = max(0, m_prob_bytes - size)
    m_prot_bytes += size
    _enforce_protected_budget(cache_snapshot)

def _demote_one_protected(cache_snapshot):
    # Demote the oldest protected item to probation. Returns True if demoted.
    global m_prob_bytes, m_prot_bytes
    oldest_key = None
    oldest_ts = None
    for k in cache_snapshot.cache.keys():
        if _seg_of(k) != 1:
            continue
        ts = m_last_access.get(k, -1)
        if oldest_ts is None or ts < oldest_ts:
            oldest_ts = ts
            oldest_key = k
    if oldest_key is None:
        return False
    robj = cache_snapshot.cache.get(oldest_key)
    if robj is None:
        return False
    size = robj.size
    m_seg[oldest_key] = 0
    m_prot_bytes = max(0, m_prot_bytes - size)
    m_prob_bytes += size
    return True

def _enforce_protected_budget(cache_snapshot):
    # Demote oldest protected until target satisfied
    while m_prot_bytes > m_protected_target_bytes:
        if not _demote_one_protected(cache_snapshot):
            break

def _ghost_add(cache_snapshot, key):
    # Add to ghost directory; trim if too large
    if key in m_ghost_ts:
        # refresh position by removing then re-add at tail
        try:
            m_ghost_order.remove(key)
        except ValueError:
            pass
    m_ghost_ts[key] = cache_snapshot.access_count
    m_ghost_order.append(key)
    if len(m_ghost_order) > GHOST_MAX:
        old = m_ghost_order.pop(0)
        m_ghost_ts.pop(old, None)

def _ghost_hit_and_adapt(cache_snapshot, key):
    global m_protected_target_bytes
    if key in m_ghost_ts:
        # Recently evicted key re-referenced: grow protected target
        step = _adapt_step(cache_snapshot.capacity)
        m_protected_target_bytes += step
        _clamp_prot_target(cache_snapshot.capacity)
        # Remove ghost entry (consumed)
        try:
            m_ghost_order.remove(key)
        except ValueError:
            pass
        m_ghost_ts.pop(key, None)

# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Evict a resident key guided by:
      - Prefer probation victims; fallback to protected if needed
      - Size-aware TinyLFU benefit and recency (segment-weighted)
      - Candidate-aware comparison: prefer evicting residents weaker than candidate
      - Tie-break by oldest last-access
    '''
    _init_if_needed(cache_snapshot)

    # Estimate candidate benefit (include this request by adding +1)
    cand_freq = _lfu_peek(cache_snapshot, obj.key) + 1
    cand_benefit = _benefit(cache_snapshot, obj.key, obj.size, cand_freq, 1)

    # First pass: consider probation only if any exist
    have_prob = any(_seg_of(k) == 0 for k in cache_snapshot.cache.keys())
    search_seg = 0 if have_prob else 1

    min_key = None
    min_score = None
    min_time = None

    # Helper to attempt selecting victim from a given segment
    def scan_segment(seg):
        nonlocal min_key, min_score, min_time
        for k in cache_snapshot.cache.keys():
            if _seg_of(k) != seg:
                continue
            score, last = _keep_score(cache_snapshot, k, cand_benefit)
            if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
                min_score = score
                min_time = last
                min_key = k

    scan_segment(search_seg)
    if min_key is None:
        # fallback: scan the other segment
        scan_segment(1 - search_seg)

    # Absolute fallback: any key
    if min_key is None:
        try:
            return next(iter(cache_snapshot.cache))
        except StopIteration:
            return None
    return min_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU counter
      - Increment resident hit count
      - Refresh last-access time
      - If in probation, promote to protected (SLRU)
      - Enforce protected budget via demotions
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    # Promote on first re-reference if probation
    if _seg_of(k) == 0:
        _promote_to_protected(cache_snapshot, k)
    else:
        # Already protected; ensure budget is respected
        _enforce_protected_budget(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Increment TinyLFU counter for the requested key (counts the access)
      - Initialize resident metadata: last_access, resident_hits = 1
      - Place into probation segment
      - If the key is in ghost history, adapt by growing protected target
      - Enforce protected budget (no effect unless promotions occurred)
    '''
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # Ghost-adaptive: grow protected target if this was recently evicted
    _ghost_hit_and_adapt(cache_snapshot, k)

    # Place in probation; update segment bytes
    global m_prob_bytes
    m_seg[k] = 0
    m_prob_bytes += obj.size

    # No promotion on insert; just ensure protected budget is sane
    _clamp_prot_target(cache_snapshot.capacity)
    _enforce_protected_budget(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Update segment bytes and remove resident-only metadata
      - Add victim to ghost history for adaptive protected sizing
      - If a protected item was evicted, shrink protected target
      - TinyLFU counters are retained (learn across evictions)
    '''
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = evicted_obj.size
    seg = _seg_of(ek)

    # Update segment bytes and membership
    global m_prob_bytes, m_prot_bytes, m_protected_target_bytes
    if seg == 1:
        m_prot_bytes = max(0, m_prot_bytes - esize)
        # Protected eviction indicates over-protection; shrink target
        m_protected_target_bytes -= _adapt_step(cache_snapshot.capacity)
        _clamp_prot_target(cache_snapshot.capacity)
    else:
        m_prob_bytes = max(0, m_prob_bytes - esize)

    m_seg.pop(ek, None)
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # Keep TinyLFU knowledge across evictions
    _ghost_add(cache_snapshot, ek)
```
2025-11-28 01:23:55,399 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Improved: Count-based SLRU with TinyLFU, ARC-style adaptive split, and recency-aware scoring
# - Two resident segments by item count, not by bytes:
#     P (probation): admits all new objects; managed by LRU (via last_access timestamps)
#     S (protected): objects that hit at least once; also LRU-managed
# - Global TinyLFU (Count-Min Sketch) for frequency estimation with periodic aging
# - Eviction score blends frequency and recency (recency matters beyond tie-break)
# - ARC-like ghost lists adapt the item split between P and S online (by counts)
#
# This design captures:
#   - Recency (via LRU timestamps and explicit recency in eviction score)
#   - Frequency (via TinyLFU)
#   - Adaptivity between recency-friendly and frequency-friendly behavior
#   - Correctness for caches limited by number of items (not bytes)

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()   # key -> int access_count (for LRU)
m_key_segment = dict()       # key -> 'P' or 'S'

# Current resident ITEM COUNTS per segment
m_cnt_P = 0
m_cnt_S = 0

# Adaptive target for protected items (S); probation target = capacity_items - target_S
m_target_S_items = None
m_cap_items_est = 0  # our estimate of capacity in number of items (learned at evict time)

# Ghost lists (non-resident metadata) to adapt split; store key -> last_time
m_ghost_P = dict()  # B1
m_ghost_S = dict()  # B2
m_ghost_limit_items = None

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None       # list of lists (counters)
m_sketch_mask = None         # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0             # operations since last aging
m_sketch_age_interval = 50000  # age after this many ops
m_sketch_counter_cap = 255     # cap per counter (8-bit style)

# ---------------
# Scoring params
# ---------------
# Recency blend: score = est_freq + rec_weight * min(recency / half_life, rec_cap)
m_rec_half_life = 500.0  # accesses; tune to make recency effect comparable to est_freq
m_rec_cap = 10.0         # cap normalized recency contribution
m_rec_weight_P = 1.0     # probation recency weight
m_rec_weight_S = 0.6     # protected recency weight (S is more persistent)
m_protect_S_bias = 0.25  # additive bias to S candidates to modestly protect them
m_overweight_nudge = 0.2 # when a segment exceeds target, nudge its candidate to be more evictable

# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_target_S_items, m_ghost_limit_items
    global m_sketch_tables, m_sketch_mask
    global m_cap_items_est

    # Learn capacity in items opportunistically; on evict() we'll update more accurately.
    if m_cap_items_est < len(cache_snapshot.cache):
        m_cap_items_est = len(cache_snapshot.cache)

    if m_target_S_items is None:
        # Start slightly frequency-friendly; adapt online
        base_items = max(1, len(cache_snapshot.cache))
        m_target_S_items = int(base_items * 0.6)

    if m_ghost_limit_items is None:
        # Each ghost list limited to approximately the cache capacity in items (we adjust later)
        m_ghost_limit_items = max(1, len(cache_snapshot.cache))

    if m_sketch_tables is None:
        # Width scales with estimated items; choose power of two near items*4 (empirical)
        # Minimum width to keep estimates reasonably stable.
        items = max(1, len(cache_snapshot.cache))
        width = 1
        target = max(1024, min(1 << 16, items * 4))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    # Count-Min Sketch estimate
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        # Halve all counters (right-shift by 1)
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _normalized_recency(now, last):
    if last is None or last < 0:
        return m_rec_cap
    age = max(0, now - last)
    norm = age / m_rec_half_life
    if norm > m_rec_cap:
        norm = m_rec_cap
    return norm


def _pick_min_score_in_segment(cache_snapshot, seg_tag, now):
    # Returns (key, score, last_time) that minimizes blended score within a segment
    # Score = est_freq + rec_weight * normalized_recency; tie-break by older first
    min_key = None
    min_score = None
    min_time = None

    rec_w = m_rec_weight_S if seg_tag == 'S' else m_rec_weight_P

    for key, obj in cache_snapshot.cache.items():
        if m_key_segment.get(key, 'P') != seg_tag:
            continue
        est = float(_sketch_estimate(key))
        last = m_key_last_access.get(key, -1)
        rec = _normalized_recency(now, last)
        score = est + rec_w * rec
        if (min_score is None) or (score < min_score) or (score == min_score and last < min_time):
            min_key = key
            min_score = score
            min_time = last

    return (min_key, min_score, min_time)


def _find_oldest_in_segment(cache_snapshot, seg_tag):
    oldest_key, oldest_time = None, None
    for k in cache_snapshot.cache.keys():
        if m_key_segment.get(k, 'P') != seg_tag:
            continue
        t = m_key_last_access.get(k, -1)
        if oldest_time is None or t < oldest_time:
            oldest_key, oldest_time = k, t
    return oldest_key


def _ghost_add(ghost_dict, key, time_now, which):
    # Add key->time to chosen ghost (which in {'P','S'}), trimming if exceeds limit
    global m_ghost_limit_items

    # Insert/update
    ghost_dict[key] = time_now

    # Trim to limit by evicting oldest
    limit = m_ghost_limit_items or 0
    if limit <= 0:
        return

    while len(ghost_dict) > limit:
        oldest_key, oldest_time = None, None
        for k, t in ghost_dict.items():
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        if oldest_key is None:
            break
        ghost_dict.pop(oldest_key, None)


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    # If key in P-ghost (B1): increase probation share (decrease S target)
    # If key in S-ghost (B2): increase protected share (increase S target)
    global m_target_S_items, m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Update our item-capacity estimate when cache is likely full (best signal: on evict call, but keep here too)
    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)

    # Keep ghost size limits around capacity in items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est

    cap_items = max(1, m_cap_items_est)

    # Step size: 1 item per signal (conservative, stable)
    step = 1

    if obj.key in m_ghost_P:
        # Recent ghost hit: favor recency -> increase P share (decrease S)
        m_target_S_items = _clamp((m_target_S_items or 0) - step, 0, cap_items)
        m_ghost_P.pop(obj.key, None)
    elif obj.key in m_ghost_S:
        # Frequent ghost hit: favor frequency -> increase S share
        m_target_S_items = _clamp((m_target_S_items or 0) + step, 0, cap_items)
        m_ghost_S.pop(obj.key, None)


def _maybe_demote_from_S_to_P(cache_snapshot):
    # If S exceeds its target, demote oldest S item to P
    global m_cnt_P, m_cnt_S, m_target_S_items
    if m_target_S_items is None:
        return
    if m_cnt_S > m_target_S_items:
        demote_key = _find_oldest_in_segment(cache_snapshot, 'S')
        if demote_key is not None:
            m_key_segment[demote_key] = 'P'
            m_cnt_S = max(0, m_cnt_S - 1)
            m_cnt_P += 1


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Choose an eviction victim using count-based SLRU + TinyLFU with recency-aware scoring.
    - Compute candidate with minimal blended score in each segment:
        score = est_freq(key) + rec_weight * normalized_recency
    - Bias to evict from the segment exceeding its item-count target.
    - Protect S moderately by adding a small bias compared to P.
    '''
    global m_cnt_P, m_cnt_S, m_target_S_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    # Learn/refresh capacity in number of items at the moment of eviction (cache is full now)
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    cap_items = max(1, m_cap_items_est)
    if m_target_S_items is None:
        m_target_S_items = int(0.6 * cap_items)
    target_S = _clamp(m_target_S_items, 0, cap_items)
    target_P = cap_items - target_S

    now = cache_snapshot.access_count

    # Find min-score candidate in each segment
    p_key, p_score, p_lru = _pick_min_score_in_segment(cache_snapshot, 'P', now)
    s_key, s_score, s_lru = _pick_min_score_in_segment(cache_snapshot, 'S', now)

    # Prepare adjusted scores
    best_key = None
    best_adj = None

    if p_key is not None:
        adj_p = p_score
        # If P is overweight, make it slightly more likely to evict from P
        if m_cnt_P > target_P:
            adj_p -= m_overweight_nudge
        # No extra protection bias for P
        best_key = p_key
        best_adj = adj_p

    if s_key is not None:
        adj_s = s_score + m_protect_S_bias
        # If S is overweight, encourage eviction from S
        if m_cnt_S > target_S:
            adj_s -= m_overweight_nudge
        if (best_adj is None) or (adj_s < best_adj):
            best_adj = adj_s
            best_key = s_key

    # Fallback: if we somehow didn't find any key (shouldn't happen), pick oldest globally
    if best_key is None:
        oldest_key, oldest_time = None, None
        for k in cache_snapshot.cache.keys():
            t = m_key_last_access.get(k, -1)
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        best_key = oldest_key if oldest_key is not None else next(iter(cache_snapshot.cache))

    return best_key


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency
      - Refresh last-access time
      - If in probation (P), promote to protected (S); if S exceeds target, demote oldest S to P
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    k = obj.key

    # Update TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    # Promote from P to S on hit
    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        m_key_segment[k] = 'S'
        m_cnt_P = max(0, m_cnt_P - 1)
        m_cnt_S += 1
        # If S above target, demote oldest S back to P
        _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt the P/S item split using ARC-like ghosts
      - Increment TinyLFU for the key (TinyLFU trains on both hits and misses)
      - Add the new object to probation (P)
      - Record last access time
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghost lists
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key

    # Train TinyLFU on the access (miss)
    _sketch_inc(k, 1)

    # Admit into probation
    m_key_segment[k] = 'P'
    m_key_last_access[k] = cache_snapshot.access_count
    m_cnt_P += 1

    # Keep S from drifting above target if previous operations changed target
    _maybe_demote_from_S_to_P(cache_snapshot)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key
      - Update segment item counters
      - Add the key to the corresponding ghost list (count-limited) to guide future adaptation
      - Keep ghost sizes roughly equal to estimated cache capacity in items
    '''
    global m_key_last_access, m_key_segment
    global m_cnt_P, m_cnt_S
    global m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key

    seg = m_key_segment.get(ek, 'P')  # default to probation if unknown

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust item counts and add to appropriate ghost
    now = cache_snapshot.access_count
    if seg == 'S':
        m_cnt_S = max(0, m_cnt_S - 1)
        _ghost_add(m_ghost_S, ek, now, which='S')
    else:
        m_cnt_P = max(0, m_cnt_P - 1)
        _ghost_add(m_ghost_P, ek, now, which='P')

    # Update ghost limits to approximate current capacity in items
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 34
- Hit Rate: 0.0965

Example 2:
- Trace ID: 11
- Hit Rate: 0.3361

Example 3:
- Trace ID: 8
- Hit Rate: 0.5152

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m01:23:55 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 01:23:55,400 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m01:27:05 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 01:27:05,884 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 01:27:05,885 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# Improved policy: Strict SLRU with ARC-style adaptive split, TinyLFU-guided P eviction,
# and demotion-marked B2 ghosts to better adapt for frequency.
#
# Key ideas:
# - Two resident segments by item count (not bytes):
#     P (probation): all new objects start here; LRU managed via last_access timestamps
#     S (protected): objects that hit at least once; also LRU
# - Eviction always selects from P (probation). If P is empty, we demote the oldest S item to P,
#   then evict from P. This strongly protects frequently used items.
# - When choosing a P victim, we use TinyLFU-estimated frequency blended with recency to avoid
#   evicting high-frequency objects that may be momentarily cold.
# - ARC-style ghost lists (B1: P-evictions; B2: S-evictions) adapt the S target size online.
#   Because we only evict directly from P, we "mark" S->P demotions and credit their eventual
#   eviction to B2 if they are evicted soon after demotion. This recovers the key ARC signal.
# - TinyLFU is aged periodically, and we fast-track insertions with sufficiently high frequency
#   estimates to S to reduce warmup misses for hot keys.

# -----------------------------
# Global metadata (module scope)
# -----------------------------

# Per-key resident metadata
m_key_last_access = dict()    # key -> int access_count (for LRU)
m_key_segment = dict()        # key -> 'P' or 'S'

# Current resident ITEM COUNTS per segment (kept in sync, but may be corrected by recount)
m_cnt_P = 0
m_cnt_S = 0

# Adaptive target for protected items (S); P target = cap_items - target_S
m_target_S_items = None
m_cap_items_est = 0  # estimated capacity (in number of items), learned at evict time

# Ghost lists (non-resident metadata) to adapt split; store key -> last_time
m_ghost_P = dict()   # B1: keys evicted from P
m_ghost_S = dict()   # B2: keys evicted from S (via demotion mark)
m_ghost_limit_items = None

# Demotion marks: if a key was demoted S->P recently, remember timestamp to credit to B2 on eviction
m_demote_mark = dict()  # key -> demote_time

# ---------------
# TinyLFU sketch
# ---------------
m_sketch_tables = None      # list of 4 tables (Count-Min Sketch)
m_sketch_mask = None        # bitmask for power-of-two width
m_sketch_hash_seeds = (0x9e3779b1, 0x7f4a7c15, 0x94d049bb, 0x2545f491)
m_sketch_ops = 0            # operations since last aging
m_sketch_age_interval = 20000  # age after this many ops (faster adaptation)
m_sketch_counter_cap = 255     # cap per counter (8-bit style)

# ---------------
# Scoring params
# ---------------
# Score in P: score = est_freq + rec_weight * min(recency / half_life, rec_cap)
# Lower score = better eviction candidate
m_rec_half_life = 200.0   # accesses; smaller gives stronger recency effect
m_rec_cap = 20.0          # cap normalized recency contribution
m_rec_weight_P = 1.4      # probation recency weight
m_fasttrack_S_threshold = 6  # on insert, if est_freq >= threshold, admit directly to S

# Demotion -> B2 attribution window (accesses)
m_demote_b2_window = 4 * int(m_rec_half_life)  # credit to B2 if evicted soon after demotion


# -----------------------------
# Helpers
# -----------------------------

def _clamp(val, lo, hi):
    return lo if val < lo else (hi if val > hi else val)


def _init_if_needed(cache_snapshot):
    global m_target_S_items, m_ghost_limit_items
    global m_sketch_tables, m_sketch_mask
    global m_cap_items_est

    # Learn capacity in items opportunistically
    if m_cap_items_est < len(cache_snapshot.cache):
        m_cap_items_est = len(cache_snapshot.cache)

    if m_target_S_items is None:
        base_items = max(1, len(cache_snapshot.cache))
        m_target_S_items = int(base_items * 0.5)  # start balanced

    if m_ghost_limit_items is None:
        m_ghost_limit_items = max(1, len(cache_snapshot.cache))

    if m_sketch_tables is None:
        # Width scales with estimated items; choose power of two near items*4
        items = max(1, len(cache_snapshot.cache))
        width = 1
        target = max(1024, min(1 << 16, items * 4))
        while width < target:
            width <<= 1
        m_sketch_tables = [[0] * width for _ in range(4)]
        m_sketch_mask = width - 1


def _hash_indices(key):
    h = hash(key)
    return [ (h ^ seed) & m_sketch_mask for seed in m_sketch_hash_seeds ]


def _sketch_inc(key, delta=1):
    global m_sketch_ops
    idxs = _hash_indices(key)
    for t, i in enumerate(idxs):
        val = m_sketch_tables[t][i]
        nv = val + delta
        if nv > m_sketch_counter_cap:
            nv = m_sketch_counter_cap
        m_sketch_tables[t][i] = nv
    m_sketch_ops += 1
    _sketch_maybe_age()


def _sketch_estimate(key):
    idxs = _hash_indices(key)
    return min(m_sketch_tables[t][i] for t, i in enumerate(idxs))


def _sketch_maybe_age():
    global m_sketch_ops
    if m_sketch_ops >= m_sketch_age_interval:
        for t in range(4):
            row = m_sketch_tables[t]
            for i, v in enumerate(row):
                row[i] = v >> 1
        m_sketch_ops = 0


def _normalized_recency(now, last):
    if last is None or last < 0:
        return m_rec_cap
    age = max(0, now - last)
    norm = age / m_rec_half_life
    if norm > m_rec_cap:
        norm = m_rec_cap
    return norm


def _ghost_add(ghost_dict, key, time_now):
    # Add key->time to chosen ghost, trimming if exceeds limit
    global m_ghost_limit_items

    ghost_dict[key] = time_now

    limit = m_ghost_limit_items or 0
    if limit <= 0:
        return

    while len(ghost_dict) > limit:
        oldest_key, oldest_time = None, None
        for k, t in ghost_dict.items():
            if oldest_time is None or t < oldest_time:
                oldest_key, oldest_time = k, t
        if oldest_key is None:
            break
        ghost_dict.pop(oldest_key, None)


def _adapt_targets_on_insert(cache_snapshot, obj):
    # ARC-style adaptation based on which ghost the newly inserted key appears in
    global m_target_S_items, m_ghost_P, m_ghost_S, m_ghost_limit_items, m_cap_items_est

    _init_if_needed(cache_snapshot)

    if len(cache_snapshot.cache) > m_cap_items_est:
        m_cap_items_est = len(cache_snapshot.cache)

    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est

    cap_items = max(1, m_cap_items_est)
    step = 1

    if obj.key in m_ghost_P:
        # Favor recency -> expand P (decrease S)
        m_target_S_items = _clamp((m_target_S_items or 0) - step, 0, cap_items)
        m_ghost_P.pop(obj.key, None)
    elif obj.key in m_ghost_S:
        # Favor frequency -> expand S
        m_target_S_items = _clamp((m_target_S_items or 0) + step, 0, cap_items)
        m_ghost_S.pop(obj.key, None)


def _recount_segments(cache_snapshot):
    # Recompute P/S counts from m_key_segment for resident keys; default unknown -> 'P'
    global m_cnt_P, m_cnt_S

    cntP = 0
    cntS = 0
    # Ensure unknown residents are treated as 'P' lazily
    for k in cache_snapshot.cache.keys():
        seg = m_key_segment.get(k)
        if seg == 'S':
            cntS += 1
        else:
            # Default to P
            if seg != 'P':
                m_key_segment[k] = 'P'
            cntP += 1
        # Ensure last_access at least exists
        if k not in m_key_last_access:
            m_key_last_access[k] = -1

    m_cnt_P = cntP
    m_cnt_S = cntS


def _find_oldest_in_segment(cache_snapshot, seg_tag):
    oldest_key, oldest_time = None, None
    for k in cache_snapshot.cache.keys():
        if m_key_segment.get(k, 'P') != seg_tag:
            continue
        t = m_key_last_access.get(k, -1)
        if oldest_time is None or t < oldest_time:
            oldest_key, oldest_time = k, t
    return oldest_key


def _pick_min_score_in_P(cache_snapshot, now):
    # Pick the P member minimizing: est_freq + rec_weight * normalized_recency
    min_key = None
    min_score = None
    min_time = None

    for key in cache_snapshot.cache.keys():
        if m_key_segment.get(key, 'P') != 'P':
            continue
        est = float(_sketch_estimate(key))
        last = m_key_last_access.get(key, -1)
        rec = _normalized_recency(now, last)
        score = est + m_rec_weight_P * rec
        if (min_score is None) or (score < min_score) or (score == min_score and last < (min_time if min_time is not None else last)):
            min_key = key
            min_score = score
            min_time = last

    return (min_key, min_score, min_time)


def _demote_one_from_S_to_P(cache_snapshot, now):
    # Demote oldest S item to P, mark for potential B2 attribution
    global m_cnt_P, m_cnt_S, m_demote_mark
    demote_key = _find_oldest_in_segment(cache_snapshot, 'S')
    if demote_key is not None:
        m_key_segment[demote_key] = 'P'
        m_cnt_S = max(0, m_cnt_S - 1)
        m_cnt_P += 1
        m_demote_mark[demote_key] = now
    return demote_key


# -----------------------------
# Policy entry points
# -----------------------------

def evict(cache_snapshot, obj):
    '''
    Strict SLRU eviction:
      - Prefer evicting from probation (P) using a TinyLFU+recency blended score.
      - If P is empty, demote oldest S -> P (mark demotion), then evict from P.
      - Never directly evict from S unless demotion fails (edge fallback).
    '''
    global m_target_S_items, m_cap_items_est

    _init_if_needed(cache_snapshot)
    _recount_segments(cache_snapshot)

    # Update capacity estimate (items) at eviction time (cache is full now)
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items

    now = cache_snapshot.access_count

    # Ensure P is non-empty; if empty, demote one from S
    if m_cnt_P == 0 and m_cnt_S > 0:
        _demote_one_from_S_to_P(cache_snapshot, now)

    # Choose victim from P
    p_key, p_score, _ = _pick_min_score_in_P(cache_snapshot, now)

    if p_key is not None:
        return p_key

    # Fallbacks: If P still empty (e.g., no metadata), try oldest globally, or S oldest
    fallback = _find_oldest_in_segment(cache_snapshot, 'P')
    if fallback is not None:
        return fallback
    s_oldest = _find_oldest_in_segment(cache_snapshot, 'S')
    if s_oldest is not None:
        return s_oldest

    # Last resort: arbitrary resident key
    return next(iter(cache_snapshot.cache))


def update_after_hit(cache_snapshot, obj):
    '''
    On hit:
      - Increment TinyLFU frequency.
      - Refresh last-access time.
      - If in probation (P), promote to protected (S).
    '''
    global m_cnt_P, m_cnt_S

    _init_if_needed(cache_snapshot)

    k = obj.key

    # Train TinyLFU
    _sketch_inc(k, 1)

    # Refresh LRU timestamp
    m_key_last_access[k] = cache_snapshot.access_count

    # Promote from P to S on first hit
    seg = m_key_segment.get(k, 'P')
    if seg == 'P':
        m_key_segment[k] = 'S'
        m_cnt_P = max(0, m_cnt_P - 1)
        m_cnt_S += 1
        # Clear any stale demotion mark
        m_demote_mark.pop(k, None)


def update_after_insert(cache_snapshot, obj):
    '''
    On insert (after a miss):
      - Adapt S target using ARC-like ghosts.
      - Train TinyLFU on the key.
      - Admit into P, but fast-track to S if very frequent (estimate >= threshold).
      - Record last access time.
      - If S exceeds target due to fast-track, demote oldest S to P (marked).
    '''
    global m_cnt_P, m_cnt_S, m_target_S_items

    _init_if_needed(cache_snapshot)

    # Adapt targets based on ghosts (ARC-style)
    _adapt_targets_on_insert(cache_snapshot, obj)

    k = obj.key
    now = cache_snapshot.access_count

    # Train TinyLFU on miss
    _sketch_inc(k, 1)

    # Default admission into P
    seg = 'P'
    m_key_segment[k] = seg
    m_key_last_access[k] = now
    m_cnt_P += 1

    # Fast-track very hot keys into S to reduce warmup misses
    est = _sketch_estimate(k)
    cap_items = max(1, m_cap_items_est or len(cache_snapshot.cache) or 1)
    target_S = _clamp(m_target_S_items or 0, 0, cap_items)

    if est >= m_fasttrack_S_threshold:
        # Move to S immediately
        m_key_segment[k] = 'S'
        m_cnt_P = max(0, m_cnt_P - 1)
        m_cnt_S += 1
        # If S exceeds target, demote oldest S to P
        if m_cnt_S > target_S:
            _demote_one_from_S_to_P(cache_snapshot, now)


def update_after_evict(cache_snapshot, obj, evicted_obj):
    '''
    After evicting a victim:
      - Remove resident metadata for that key.
      - Update segment item counters.
      - Add the key to the corresponding ghost list:
          * If the key was recently demoted from S->P, credit to B2 (S ghost).
          * Otherwise, credit to B1 (P ghost).
      - Keep ghost sizes roughly equal to estimated cache capacity in items.
    '''
    global m_cnt_P, m_cnt_S, m_cap_items_est, m_ghost_limit_items

    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    now = cache_snapshot.access_count

    # Determine current recorded segment for the evicted key (default P)
    seg = m_key_segment.get(ek, 'P')

    # Cleanup resident metadata
    m_key_last_access.pop(ek, None)
    m_key_segment.pop(ek, None)

    # Adjust item counts
    if seg == 'S':
        m_cnt_S = max(0, m_cnt_S - 1)
    else:
        m_cnt_P = max(0, m_cnt_P - 1)

    # Attribute ghost entry:
    # If recently demoted from S->P, credit to B2; else B1.
    demote_time = m_demote_mark.pop(ek, None)
    if demote_time is not None and now - demote_time <= m_demote_b2_window:
        _ghost_add(m_ghost_S, ek, now)
    else:
        _ghost_add(m_ghost_P, ek, now)

    # Update ghost limits to approximate current capacity in items
    full_items = len(cache_snapshot.cache)
    if full_items > m_cap_items_est:
        m_cap_items_est = full_items
    if m_ghost_limit_items is None or m_ghost_limit_items < m_cap_items_est:
        m_ghost_limit_items = m_cap_items_est
```
2025-11-28 01:27:49,546 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Prompt: You are optimizing a cache eviction algorithm to minimize cache miss rates.
    
## Context:
The cache receives a sequence of access requests for objects, and when the cache is full, it must evict an object to make space for a new one. The cache is full when the total number of cached objects reaches its capacity. Focus on improving the `evict` function, the `update_after_hit` function, the `update_after_insert` function, and the `update_after_evict` function to find a cache eviction algorithm with as low miss rate as possible.

## Current Cache Eviction Algorithm Implementation:
```python
# Windowed SLRU + TinyLFU + ARC-style adaptation + size-aware sampled eviction
# - Three resident segments (by bytes):
#     Window (very recent), Probation (main new/once-hit), Protected (multi-hit)
# - Eviction order: Window -> Probation -> Protected (minimize main churn)
# - TinyLFU counts (lazy decay) guide which among the oldest to evict (sampled)
# - Size-aware scoring (prefer keeping tiny but hot objects)
# - ARC-like ghost lists dynamically adapt Protected target size (bytes)
# - O(1) updates on hit/insert via OrderedDict LRU queues

import math
from collections import OrderedDict

# ---------------
# Globals
# ---------------

# LRU queues (LRU at left, MRU at right)
win_lru = OrderedDict()   # 0: Window segment (recent)
prob_lru = OrderedDict()  # 1: Probation (main new/once-hit)
prot_lru = OrderedDict()  # 2: Protected (multi-hit)

# Bytes accounting
win_bytes = 0
prob_bytes = 0
prot_bytes = 0

# Resident segment mapping: key -> seg_id {0:win, 1:prob, 2:prot}
m_segment = dict()

# Per-key resident metadata
m_last_access = dict()      # key -> int time
m_resident_hits = dict()    # key -> int

# TinyLFU: 4-bit counters with lazy decay
m_lfu_count = dict()        # key -> (count[0..15], epoch)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Dynamic targets (bytes)
g_prot_target_bytes = 0     # dynamically tuned protected target
g_win_target_bytes = 0      # small window target
g_last_cap = 0

# Ghost lists for ARC-style adaptation (bytes-limited)
ghost_prob = OrderedDict()  # keys evicted from Window/Probation
ghost_prot = OrderedDict()  # keys evicted from Protected
ghost_prob_bytes = 0
ghost_prot_bytes = 0

# Scoring / sampling
SAMPLE_K_WIN = 5
SAMPLE_K_PROB = 6
SAMPLE_K_PROT = 4

# Multi-hit bonus in score
MULTI_HIT_BONUS = 0.5

# ---------------
# Helpers: init / targets / lfu
# ---------------

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur

def _init_if_needed(cache_snapshot):
    global g_last_cap, g_prot_target_bytes, g_win_target_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = max(1, int(cache_snapshot.capacity))
    if g_last_cap != cap or g_prot_target_bytes == 0 or g_win_target_bytes == 0:
        g_last_cap = cap
        # Start conservatively: small window, large protected
        g_win_target_bytes = max(1, int(cap * 0.05))
        g_prot_target_bytes = max(1, int(cap * 0.70))

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _cap_bytes(cache_snapshot):
    return max(1, int(cache_snapshot.capacity))

# ---------------
# Ghost lists and adaptation (ARC-like)
# ---------------

def _ghost_cap(cache_snapshot):
    # Total bytes allowed for each ghost list (soft bound)
    return _cap_bytes(cache_snapshot)

def _ghost_add(cache_snapshot, seg_id, key, size):
    # Evicted from which segment? 0/1 -> ghost_prob, 2 -> ghost_prot
    global ghost_prob_bytes, ghost_prot_bytes
    if seg_id == 2:
        if key in ghost_prot:
            old = ghost_prot.pop(key)
            ghost_prot_bytes -= old
        ghost_prot[key] = size
        ghost_prot_bytes += size
        # Trim
        cap = _ghost_cap(cache_snapshot)
        while ghost_prot_bytes > cap and ghost_prot:
            k, s = ghost_prot.popitem(last=False)
            ghost_prot_bytes -= s
    else:
        if key in ghost_prob:
            old = ghost_prob.pop(key)
            ghost_prob_bytes -= old
        ghost_prob[key] = size
        ghost_prob_bytes += size
        cap = _ghost_cap(cache_snapshot)
        while ghost_prob_bytes > cap and ghost_prob:
            k, s = ghost_prob.popitem(last=False)
            ghost_prob_bytes -= s

def _adapt_prot_target(cache_snapshot, delta_bytes):
    global g_prot_target_bytes
    cap = _cap_bytes(cache_snapshot)
    # Bounds: leave at least 5% for window + 5% for probation, at most 90% for protected
    min_prot = int(cap * 0.10)
    max_prot = int(cap * 0.90)
    g_prot_target_bytes = max(min_prot, min(max_prot, g_prot_target_bytes + int(delta_bytes)))

def _adapt_on_ghost_ref(cache_snapshot, key):
    # If the incoming key was recently in a ghost list, adapt protected target
    if key in ghost_prot:
        # We previously kept it hot; increase protected to favor long-term
        s = ghost_prot.get(key, 0)
        _adapt_prot_target(cache_snapshot, max(1, s))
        # Move to MRU in ghost (recency)
        ghost_prot.move_to_end(key, last=True)
    elif key in ghost_prob:
        # Previously evicted from probation/window -> favor recency by shrinking protected
        s = ghost_prob.get(key, 0)
        _adapt_prot_target(cache_snapshot, -max(1, s // 2))
        ghost_prob.move_to_end(key, last=True)

# ---------------
# Segment helpers
# ---------------

def _seg_remove(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    else:
        # clean up any remnants
        win_lru.pop(key, None)
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)
    return seg

def _seg_insert_win(key, size):
    global win_bytes
    # ensure not in others
    if m_segment.get(key) == 0:
        # refresh MRU
        win_lru.pop(key, None)
        win_lru[key] = None
        return
    # Remove from other lists if present
    if m_segment.get(key) == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            global prob_bytes
            prob_bytes -= size
    if m_segment.get(key) == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            global prot_bytes
            prot_bytes -= size
    m_segment[key] = 0
    win_lru[key] = None
    win_bytes += size

def _seg_move_to_prob(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 1:
        # refresh MRU
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    if seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    prob_lru[key] = None
    m_segment[key] = 1
    prob_bytes += size

def _demote_prot_if_needed(cache_snapshot):
    # Demote from protected to probation until within target
    global prot_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(0, min(g_prot_target_bytes, cap))
    while prot_bytes > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        prot_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _trim_window_if_needed(cache_snapshot):
    # Keep window near its target by moving oldest window entries to probation (not evict)
    global win_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(1, min(g_win_target_bytes, cap))
    # Allow a little slack to avoid churn
    slack = max(1, target // 8)
    while win_bytes > (target + slack) and win_lru:
        dem_key, _ = win_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        win_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _seg_move_to_prot(cache_snapshot, key, size):
    # Promote to Protected MRU
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 2:
        # refresh MRU
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    prot_lru[key] = None
    m_segment[key] = 2
    prot_bytes += size
    _demote_prot_if_needed(cache_snapshot)

def _seg_touch_on_hit(cache_snapshot, key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

# ---------------
# Scoring helpers
# ---------------

def _normalized_size(size, capacity):
    # size as percentage of capacity, keep >= small epsilon
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _retention_score(cache_snapshot, key):
    # Higher score = stronger retention; eviction picks smallest score
    cap = _cap_bytes(cache_snapshot)
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size
    freq = _lfu_peek(cache_snapshot, key)
    size_norm = _normalized_size(size, cap)
    bonus = MULTI_HIT_BONUS if m_resident_hits.get(key, 1) >= 2 else 0.0
    # Size-aware benefit with gentle diminishing returns on frequency
    benefit = (math.log2(1.0 + float(freq)) + bonus) / size_norm
    return benefit

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    # sample k oldest
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            return next(iter(order))
        except StopIteration:
            return None
    return chosen_key

# ---------------
# Policy entry points
# ---------------

def evict(cache_snapshot, obj):
    """
    Eviction strategy:
      - Prefer evicting from Window first to shield main cache (2Q-style)
      - Then from Probation, finally Protected
      - Within a segment, sample a few oldest and evict the one with the lowest
        TinyLFU size-aware score.
    """
    _init_if_needed(cache_snapshot)

    # Choose from Window first (admission filter / reduces main churn)
    if win_lru:
        victim = _pick_candidate_from_order(cache_snapshot, win_lru, SAMPLE_K_WIN)
        return victim

    # Then from Probation
    if prob_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
        return victim

    # Fallback to Protected if others empty
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)
        return victim

    # Last resort
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU counter
      - Update last-access and resident hit count
      - Promote to Protected if in Window/Probation
      - Refresh LRU position within its segment
      - Adapt Protected target: increase on Probation hits, slightly decrease on Protected hits
      - Trim Window toward its target
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 1) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked; place into Window
        _seg_insert_win(k, obj.size)
        _trim_window_if_needed(cache_snapshot)
        return

    if seg == 0 or seg == 1:
        # Hit in Window or Probation -> promote to Protected
        _seg_move_to_prot(cache_snapshot, k, obj.size)
        # Adapt: probation/window hit means protected was too small -> grow
        step = max(1, obj.size // 2)
        _adapt_prot_target(cache_snapshot, step)
    else:
        # Protected hit: touch and slightly shrink target to allow more probation
        _seg_touch_on_hit(cache_snapshot, k)
        step = max(1, obj.size // 8)
        _adapt_prot_target(cache_snapshot, -step)

    # Keep window near target
    _trim_window_if_needed(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU for the key (admission learns from requests)
      - Adjust Protected target using ARC-like ghost feedback
      - Initialize resident metadata and place into Window MRU
      - Gently trim Window toward its target (migrate oldest to Probation)
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 1

    # ARC-like adaptation using ghost information
    _adapt_on_ghost_ref(cache_snapshot, k)

    # New resident enters Window MRU
    _seg_insert_win(k, obj.size)
    _trim_window_if_needed(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After evicting a victim:
      - Remove it from segment structures and resident-only metadata
      - Record into ghost lists for ARC-style adaptation
      - Keep TinyLFU counts to inform future decisions
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = evicted_obj.size

    # Identify segment before removal (for ghost list)
    seg_before = m_segment.get(ek, 1)
    _seg_remove(cache_snapshot, ek, esize)

    # Resident-only metadata cleanup
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # Remember in ghost for adaptation
    _ghost_add(cache_snapshot, seg_before, ek, esize)
```

## Performance Results and Feedback:
The current cache eviction algorithm was evaluated on multiple real-world traces with different access patterns. Here are the results:

Example 1:
- Trace ID: 24
- Hit Rate: 0.2699

Example 2:
- Trace ID: 16
- Hit Rate: 0.0214

Example 3:
- Trace ID: 0
- Hit Rate: 0.3906

## Key Information:
- Higher hit rates (lower miss rates) are better.
- `evict` defines how the algorithm chooses the eviction victim.
- `update_after_hit` defines how the algorithm update the metadata it maintains immediately after a cache hit.
- `update_after_insert` defines how the algorithm updates the metadata it maintains immediately after inserting a new object into the cache.
- `update_after_evict` defines how the algorithm updates the metadata it maintains immediately after evicting the victim.
You have read-only access to these data and no access to any functions:
- An "object" represents the unit of a request, such as inserting an object into the cache or retrieving an object from the cache. Each object `obj` provides the following **read-only** attributes that you can reference:
    - `obj.key` (str): A string that uniquely identifies the object.
    - `obj.size` (int): A positive integer representing the size of the object in bytes.
- You can also reference the following **read-only** attributes provided by a cache snapshots `cache_snapshot`:
    - `cache_snapshot.cache` (dict): A dictionary containing the cached objects, where the keys are the objects' keys, and the values are the corresponding objects themselves.
    - `cache_snapshot.size` (int): A non-negative integer representing the current total size of the cache in bytes.
    - `cache_snapshot.capacity` (int): A positive integer representing the maximum allowed size of the cache in bytes.
    - `cache_snapshot.access_count` (int): The current total number of cache accesses. You can also use this to represent current time.
    - `cache_snapshot.hit_count` (int): The current total number of cache hits.
    - `cache_snapshot.miss_count` (int): The current total number of cache misses.

## Your Task:
Analyze the performance feedback and rewrite the cache eviction algorithm to:
1. Reduce overall cache miss rates
2. Make better decisions about which object to evict when the cache is full
3. Make better designs about which metadata to maintain
4. Improve metadata updates after cache hits, inserts, and evictions

Provide the complete improved cache eviction algorithm implementation in Python.

```python
# Your improved cache eviction algorithm here
```

[92m01:27:49 - LiteLLM:INFO[0m: utils.py:3427 - 
LiteLLM completion() model= gpt-5; provider = openai
2025-11-28 01:27:49,547 [INFO] LiteLLM: 
LiteLLM completion() model= gpt-5; provider = openai
[92m01:30:46 - LiteLLM:INFO[0m: utils.py:1307 - Wrapper: Completed Call, calling success_handler
2025-11-28 01:30:46,233 [INFO] LiteLLM: Wrapper: Completed Call, calling success_handler
2025-11-28 01:30:46,253 [INFO] gepa.adapters.caching_adapter_gpt5_1.caching_program_adapter: LM Response: ```python
# W-TinyLFU inspired cache with:
# - Three resident segments (bytes): Window (recent), Probation (main), Protected (multi-hit)
# - Evict from Probation first, then Window, then Protected (Caffeine-style)
# - TinyLFU with lazy decay guides victim selection (size-aware + recency-aware score)
# - Size-aware sampled eviction from the oldest K in a segment
# - Dynamic segment sizing via light hill-climbing using per-segment hit ratios + ARC-like ghosts
# - Gentle promotions: Window hits stay in Window; Probation hits promote to Protected

import math
from collections import OrderedDict

# ---------------
# Globals/state
# ---------------

# LRU queues (LRU at left, MRU at right)
win_lru = OrderedDict()   # segment 0: Window (recent admission buffer)
prob_lru = OrderedDict()  # segment 1: Probation (main, once-hit)
prot_lru = OrderedDict()  # segment 2: Protected (multi-hit)

# Bytes accounting
win_bytes = 0
prob_bytes = 0
prot_bytes = 0

# Resident segment mapping: key -> seg_id {0:win, 1:prob, 2:prot}
m_segment = dict()

# Resident metadata
m_last_access = dict()     # key -> int time
m_resident_hits = dict()   # key -> int number of resident hits since insert

# TinyLFU: 4-bit counters with lazy decay
m_lfu_count = dict()       # key -> (count[0..15], epoch)
m_lfu_epoch = 0
LFU_DECAY_INTERVAL = 8192

# Dynamic targets (bytes)
g_prot_target_bytes = 0
g_win_target_bytes = 0
g_last_cap = 0

# Ghost lists for ARC-style adaptation (bytes-limited)
ghost_prob = OrderedDict()  # evicted from Window/Probation
ghost_prot = OrderedDict()  # evicted from Protected
ghost_prob_bytes = 0
ghost_prot_bytes = 0

# Sampling sizes
SAMPLE_K_WIN = 6
SAMPLE_K_PROB = 8
SAMPLE_K_PROT = 4

# Retention scoring weights
MULTI_HIT_BONUS_SCALE = 0.25
RECENCY_WEIGHT = 0.35  # weight for recency factor in benefit

# Segment-hit tracking for hill-climbing adaptation
g_hits_window = 0
g_hits_prob = 0
g_hits_prot = 0
g_last_rebalance_epoch = -1

# ---------------
# Helpers: capacity/epoch/lfu
# ---------------

def _cap_bytes(cache_snapshot):
    return max(1, int(cache_snapshot.capacity))

def _current_epoch(cache_snapshot):
    return cache_snapshot.access_count // LFU_DECAY_INTERVAL

def _lfu_peek(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        return 0
    c, e = entry
    shift = cur_epoch - e
    if shift <= 0:
        return c
    return c >> shift

def _lfu_inc(cache_snapshot, key):
    cur_epoch = _current_epoch(cache_snapshot)
    entry = m_lfu_count.get(key)
    if entry is None:
        c = 0
        e = cur_epoch
    else:
        c, e = entry
        shift = cur_epoch - e
        if shift > 0:
            c >>= shift
    c = min(15, c + 1)
    m_lfu_count[key] = (c, cur_epoch)
    return c

def _maybe_rebalance_targets(cache_snapshot):
    # Light hill-climbing: adjust window/protected targets based on where hits happen
    global g_hits_window, g_hits_prob, g_hits_prot, g_win_target_bytes, g_prot_target_bytes
    cap = _cap_bytes(cache_snapshot)
    total = g_hits_window + g_hits_prob + g_hits_prot
    if total < 128:  # need enough signal
        return

    min_win = int(max(1, cap * 0.02))
    max_win = int(max(1, cap * 0.30))
    min_prot = int(max(1, cap * 0.10))
    max_prot = int(max(1, cap * 0.90))
    min_prob = int(max(1, cap * 0.05))  # always leave at least 5% for probation

    step = max(1, cap // 50)  # ~2% step

    rw = g_hits_window / float(total)
    rp = g_hits_prob / float(total)
    rpr = g_hits_prot / float(total)

    # If many hits are in window, expand window a bit
    if rw > 0.45 and g_win_target_bytes < max_win:
        g_win_target_bytes = min(max_win, g_win_target_bytes + step)
    elif rw < 0.20 and g_win_target_bytes > min_win:
        g_win_target_bytes = max(min_win, g_win_target_bytes - step)

    # If probation receives more hits than protected, increase protected to capture them
    if rp > rpr * 1.10 and g_prot_target_bytes < max_prot:
        g_prot_target_bytes = min(max_prot, g_prot_target_bytes + step)
    elif rpr > rp * 1.20 and g_prot_target_bytes > min_prot:
        g_prot_target_bytes = max(min_prot, g_prot_target_bytes - step)

    # Ensure enough room for probation
    if (g_win_target_bytes + g_prot_target_bytes) > (cap - min_prob):
        # Prefer reducing protected first
        over = (g_win_target_bytes + g_prot_target_bytes) - (cap - min_prob)
        reduce_prot = min(over, max(0, g_prot_target_bytes - min_prot))
        g_prot_target_bytes -= reduce_prot
        over -= reduce_prot
        if over > 0:
            g_win_target_bytes = max(min_win, g_win_target_bytes - over)

    # Reset counters
    g_hits_window = 0
    g_hits_prob = 0
    g_hits_prot = 0

def _lfu_maybe_advance_epoch(cache_snapshot):
    global m_lfu_epoch, g_last_rebalance_epoch
    cur = _current_epoch(cache_snapshot)
    if cur != m_lfu_epoch:
        m_lfu_epoch = cur
    # Periodically rebalance once per epoch
    if g_last_rebalance_epoch != cur:
        _maybe_rebalance_targets(cache_snapshot)
        g_last_rebalance_epoch = cur

def _init_if_needed(cache_snapshot):
    global g_last_cap, g_prot_target_bytes, g_win_target_bytes
    _lfu_maybe_advance_epoch(cache_snapshot)
    cap = _cap_bytes(cache_snapshot)
    if g_last_cap != cap or g_prot_target_bytes == 0 or g_win_target_bytes == 0:
        g_last_cap = cap
        # Start with a moderate window and protected; probation is the remainder
        g_win_target_bytes = max(1, int(cap * 0.12))
        g_prot_target_bytes = max(1, int(cap * 0.60))

# ---------------
# Ghost lists and ARC-like adaptation
# ---------------

def _ghost_cap(cache_snapshot):
    # Limit each ghost list to capacity bytes (soft bound)
    return _cap_bytes(cache_snapshot)

def _ghost_add(cache_snapshot, seg_id, key, size):
    global ghost_prob_bytes, ghost_prot_bytes
    if seg_id == 2:
        if key in ghost_prot:
            old = ghost_prot.pop(key)
            ghost_prot_bytes -= old
        ghost_prot[key] = size
        ghost_prot_bytes += size
        cap = _ghost_cap(cache_snapshot)
        while ghost_prot_bytes > cap and ghost_prot:
            k, s = ghost_prot.popitem(last=False)
            ghost_prot_bytes -= s
    else:
        if key in ghost_prob:
            old = ghost_prob.pop(key)
            ghost_prob_bytes -= old
        ghost_prob[key] = size
        ghost_prob_bytes += size
        cap = _ghost_cap(cache_snapshot)
        while ghost_prob_bytes > cap and ghost_prob:
            k, s = ghost_prob.popitem(last=False)
            ghost_prob_bytes -= s

def _adapt_prot_target(cache_snapshot, delta_bytes):
    # Adjust protected target while keeping feasibility with window/probation
    global g_prot_target_bytes, g_win_target_bytes
    cap = _cap_bytes(cache_snapshot)
    min_win = int(max(1, cap * 0.02))
    min_prot = int(max(1, cap * 0.10))
    max_prot = int(max(1, cap * 0.90))
    min_prob = int(max(1, cap * 0.05))

    g_prot_target_bytes = max(min_prot, min(max_prot, g_prot_target_bytes + int(delta_bytes)))

    # Ensure enough space left for window and probation
    if g_prot_target_bytes + g_win_target_bytes > cap - min_prob:
        # Prefer to trim protected slightly
        overflow = g_prot_target_bytes + g_win_target_bytes - (cap - min_prob)
        g_prot_target_bytes = max(min_prot, g_prot_target_bytes - overflow)

    # Clamp window minimal if necessary
    g_win_target_bytes = max(min_win, g_win_target_bytes)

def _adapt_on_ghost_ref(cache_snapshot, key):
    # ARC-style: adjust based on which ghost had the key
    if key in ghost_prot:
        s = ghost_prot.get(key, 0)
        _adapt_prot_target(cache_snapshot, max(1, s // 2))
        ghost_prot.move_to_end(key, last=True)
    elif key in ghost_prob:
        s = ghost_prob.get(key, 0)
        _adapt_prot_target(cache_snapshot, -max(1, s // 3))
        ghost_prob.move_to_end(key, last=True)

# ---------------
# Segment operations
# ---------------

def _seg_remove(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.pop(key, None)
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    else:
        win_lru.pop(key, None)
        prob_lru.pop(key, None)
        prot_lru.pop(key, None)
    return seg

def _seg_insert_win(key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 0:
        # Refresh MRU
        if key in win_lru:
            win_lru.pop(key, None)
        win_lru[key] = None
        return
    # Remove from other segments if present
    if seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    m_segment[key] = 0
    win_lru[key] = None
    win_bytes += size

def _seg_move_to_prob(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
        else:
            prob_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 2:
        if key in prot_lru:
            prot_lru.pop(key, None)
            prot_bytes -= size
    prob_lru[key] = None
    m_segment[key] = 1
    prob_bytes += size

def _seg_move_to_prot(cache_snapshot, key, size):
    global win_bytes, prob_bytes, prot_bytes
    seg = m_segment.get(key)
    if seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)
        else:
            prot_lru[key] = None
        return
    if seg == 0:
        if key in win_lru:
            win_lru.pop(key, None)
            win_bytes -= size
    elif seg == 1:
        if key in prob_lru:
            prob_lru.pop(key, None)
            prob_bytes -= size
    prot_lru[key] = None
    m_segment[key] = 2
    prot_bytes += size
    _demote_prot_if_needed(cache_snapshot)

def _seg_touch_on_hit(key):
    seg = m_segment.get(key)
    if seg == 0:
        if key in win_lru:
            win_lru.move_to_end(key, last=True)
    elif seg == 1:
        if key in prob_lru:
            prob_lru.move_to_end(key, last=True)
    elif seg == 2:
        if key in prot_lru:
            prot_lru.move_to_end(key, last=True)

def _demote_prot_if_needed(cache_snapshot):
    global prot_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(0, min(g_prot_target_bytes, cap))
    while prot_bytes > target and prot_lru:
        dem_key, _ = prot_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        prot_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

def _trim_window_if_needed(cache_snapshot):
    global win_bytes, prob_bytes
    cap = _cap_bytes(cache_snapshot)
    target = max(1, min(g_win_target_bytes, cap))
    slack = max(1, target // 8)
    while win_bytes > (target + slack) and win_lru:
        dem_key, _ = win_lru.popitem(last=False)
        robj = cache_snapshot.cache.get(dem_key)
        dsize = robj.size if robj is not None else 0
        win_bytes -= dsize
        if robj is not None:
            prob_lru[dem_key] = None
            m_segment[dem_key] = 1
            prob_bytes += dsize
        else:
            m_segment.pop(dem_key, None)

# ---------------
# Scoring helpers
# ---------------

def _normalized_size(size, capacity):
    return max(1e-9, (float(size) * 100.0) / float(capacity))

def _retention_score(cache_snapshot, key):
    # Higher score -> stronger retention (harder to evict)
    cap = _cap_bytes(cache_snapshot)
    robj = cache_snapshot.cache.get(key)
    if robj is None:
        return float('-inf')
    size = robj.size
    size_norm = _normalized_size(size, cap)

    freq = _lfu_peek(cache_snapshot, key)
    f_term = math.log2(1.0 + float(freq))

    hits = m_resident_hits.get(key, 0)
    multi_bonus = MULTI_HIT_BONUS_SCALE * math.log2(1.0 + float(hits))

    last = m_last_access.get(key, cache_snapshot.access_count)
    age = max(0, cache_snapshot.access_count - last)
    # half-life around LFU_DECAY_INTERVAL/2 -> recent touches get a positive factor up to ~1
    half = max(1.0, float(LFU_DECAY_INTERVAL) / 2.0)
    recency_factor = 1.0 / (1.0 + (age / half))

    seg = m_segment.get(key, 1)
    seg_bias = 0.15 if seg == 2 else 0.0  # slightly favor protected items

    benefit = (f_term + multi_bonus + (RECENCY_WEIGHT * recency_factor) + seg_bias) / size_norm
    return benefit

def _pick_candidate_from_order(cache_snapshot, order, k_sample):
    if not order:
        return None
    chosen_key = None
    chosen_score = None
    i = 0
    for key in order.keys():
        score = _retention_score(cache_snapshot, key)
        if chosen_score is None or score < chosen_score:
            chosen_score = score
            chosen_key = key
        i += 1
        if i >= k_sample:
            break
    if chosen_key is None:
        try:
            return next(iter(order))
        except StopIteration:
            return None
    return chosen_key

# ---------------
# Policy entry points
# ---------------

def evict(cache_snapshot, obj):
    """
    Victim selection:
      - Prefer evicting from Probation first (protect recency window)
      - Then from Window, finally from Protected
      - Within a segment, sample a few oldest keys and evict the lowest score
    """
    _init_if_needed(cache_snapshot)

    # 1) Probation first
    if prob_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prob_lru, SAMPLE_K_PROB)
        return victim

    # 2) Then Window
    if win_lru:
        victim = _pick_candidate_from_order(cache_snapshot, win_lru, SAMPLE_K_WIN)
        return victim

    # 3) Finally Protected
    if prot_lru:
        victim = _pick_candidate_from_order(cache_snapshot, prot_lru, SAMPLE_K_PROT)
        return victim

    # Fallback
    try:
        return next(iter(cache_snapshot.cache))
    except StopIteration:
        return None

def update_after_hit(cache_snapshot, obj):
    """
    On hit:
      - Increment TinyLFU and update last-access and resident hit count
      - Record per-segment hit for adaptation
      - If in Probation -> promote to Protected
      - If in Window -> keep in Window (touch only); promote later on second hit if trimmed to Probation
      - If in Protected -> touch; slight shrink of protected target to allow churn
      - Trim Window toward its target
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = m_resident_hits.get(k, 0) + 1

    seg = m_segment.get(k)
    if seg is None:
        # Not tracked due to external reasons; reinsert into window
        _seg_insert_win(k, obj.size)
        m_resident_hits[k] = 1
        m_last_access[k] = cache_snapshot.access_count
        _trim_window_if_needed(cache_snapshot)
        return

    # Record hit for adaptation
    global g_hits_window, g_hits_prob, g_hits_prot
    if seg == 0:
        g_hits_window += 1
        _seg_touch_on_hit(k)
        # Optionally, if clearly popular and tiny, fast-track to probation
        if m_resident_hits.get(k, 0) >= 2 and obj.size <= max(1, _cap_bytes(cache_snapshot) // 200):  # <=0.5% cap
            _seg_move_to_prob(cache_snapshot, k, obj.size)
    elif seg == 1:
        g_hits_prob += 1
        _seg_move_to_prot(cache_snapshot, k, obj.size)
        # Grow protected slightly on probation hits
        _adapt_prot_target(cache_snapshot, max(1, obj.size // 8))
    else:
        g_hits_prot += 1
        _seg_touch_on_hit(k)
        # Slightly shrink protected to allow exploration when protected dominates
        _adapt_prot_target(cache_snapshot, -max(1, obj.size // 16))

    _trim_window_if_needed(cache_snapshot)

def update_after_insert(cache_snapshot, obj):
    """
    On insert (after miss):
      - Increment TinyLFU and set resident metadata (hits=0)
      - ARC-like adaptation via ghost lists
      - Admission placement:
           * Default: Window MRU
           * If object is very large and low LFU, place directly into Probation
      - Trim the Window toward its target
    """
    _init_if_needed(cache_snapshot)

    k = obj.key
    _lfu_inc(cache_snapshot, k)
    m_last_access[k] = cache_snapshot.access_count
    m_resident_hits[k] = 0

    # ARC-style adaptation based on ghost reference
    _adapt_on_ghost_ref(cache_snapshot, k)

    cap = _cap_bytes(cache_snapshot)
    freq = _lfu_peek(cache_snapshot, k)
    # Large low-frequency objects skip window to avoid displacing many recent items
    if obj.size >= max(1, cap // 4) and freq <= 1:
        _seg_move_to_prob(cache_snapshot, k, obj.size)
    else:
        _seg_insert_win(k, obj.size)

    _trim_window_if_needed(cache_snapshot)

def update_after_evict(cache_snapshot, obj, evicted_obj):
    """
    After eviction:
      - Remove from segment queues and resident metadata
      - Record into ghost lists for ARC-style adaptation
      - Keep TinyLFU counters (not cleared) to inform future admissions
    """
    _init_if_needed(cache_snapshot)

    ek = evicted_obj.key
    esize = evicted_obj.size

    seg_before = m_segment.get(ek, 1)
    _seg_remove(cache_snapshot, ek, esize)

    # Resident-only metadata cleanup
    m_last_access.pop(ek, None)
    m_resident_hits.pop(ek, None)

    # Ghost tracking for adaptation
    _ghost_add(cache_snapshot, seg_before, ek, esize)
```
